# Experimental Design
## Analysis of Variance (ANOVA)
ANOVA is using the same underlying mechanism as linear regression. However, the angle that ANOVA chooses to look at is slight different from the traditional linear regression. It can be more useful in the case with **qualitative variables** and **designed experiments**.  

<br>
Experimental Design  

 * **Factor**: explanatory or predictor variable to be studied in an investigation  
 * **Treatment** (or Factor Level): "value" of a factor applied to the experimental unit  
 * **Experimental Unit**: person, animal, piece of material, etc. that is subjected to treatment(s) and provides a response  
 * **Single Factor Experiment**: one explanatory variable considered  
 * **Multifactor Experiment**: more than one explanatory variable  
 * **Classification Factor**: A factor that is not under the control of the experimenter (observational data)  
 * **Experimental Factor**: assigned by the experimenter  
 
<br>
Basics of experimental design:  

 * Choices that a statistician has to make:  
    + set of treatments  
    + set of experimental units  
    + treatment assignment (selection bias)  
    + measurement (measurement bias, blind experiments)  
    
 * Advancements in experimental design:  
 
    1. **Factorial Experiments**:  
    consider multiple factors at the same time (interaction)  

    2. **Replication**: repetition of experiment  
        * assess mean squared error  
        * control over precision of experiment (power)  
 
    3. **Randomization**  
        * Before R.A. Fisher (1900s), treatments were assigned systematically or subjectively  
        * randomization: assign treatments to experimental units at random, which averages out systematic effects that cannot be control by the investigator  

    4. **Local control**: Blocking or Stratification  
        * Reduce experimental errors and increase power by placing restrictions on the randomization of treatments to experimental units.  
        
Randomization may also eliminate correlations due to time and space.

### Completely Randomized Design (CRD)

Treatment factor A with $a\ge2$ treatments levels.
Experimental units are randomly assinged to each treatment. The number of experiemntal units in each group can be  

 * equal (balanced): n
 * unequal (unbalanced):  $n_i$ for the i-th group (i = 1,...,a).
 
 The total sample size is $N=\sum_{i=1}^{a}n_i$
 
 Possible assignments of units to treatments are $k=\frac{N!}{n_1!n_2!...n_a!}$
 
 Each has probability 1/k of being selected. 
 Each experimental unit is measured with a response $Y_{ij}$, in which j denotes unit and i denotes treatment.  
 
 Treatment
 
| | 1 | 2 | ... | a |
|:--|:-:|:-:|:-:|:-:|
|   |$Y_{11}$|$Y_{21}$|...|$Y_{a1}$|
|   |$Y_{12}$|...|...|...|
|   |...|...|...|...|
|Sample Mean | $\bar{Y_{1.}}$|$\bar{Y_{2.}}$| ... | $\bar{Y_{a.}}$
| Sample SD | $s_1$| $s_2$| ...| $s_a$|

where $\bar{Y_{i.}}=\frac{1}{n_i}\sum_{j=1}^{n_i}Y_{ij}$ 

$s_i^2=\frac{1}{n_i-1}\sum_{j=1}^{n_i}(Y_{ij}-\bar{Y_i})^2$

And the grand mean is $\bar{Y_{..}}=\frac{1}{N}\sum_{i}\sum_{j}Y_{ij}$

#### Single Factor (One-Way) ANOVA

Partitioning the Variance  

The total variability of the $Y_{ij}$ observation can be measured as the deviation of $Y_{ij}$ around the overall mean $\bar{Y_{..}}$:  $Y_{ij} - \bar{Y_{..}}$  

This can be rewritten as: 

\begin{align*}
Y_{ij} - \bar{Y_{..}}&=Y_{ij} - \bar{Y_{..}} + \bar{Y_{i.}} - \bar{Y_{i.}} \\
&= (\bar{Y_{i.}}-\bar{Y_{..}})+(Y_{ij}-\bar{Y_{i.}})
\end{align*}

where 

 * the first term is the *between* treatment differences (i.e., the deviation of the treatment mean from the overall mean)  
 * the second term is *within* treatment differences (i.e., the deviation of the observation around its treatment mean)

\begin{align*}
\sum_{i}\sum_{j}(Y_{ij} - \bar{Y_{..}})^2 &=  \sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2+\sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2 \\
SSTO &= SSTR + SSE \\
total~SS &= treatment~SS + error~SS \\
(N-1)~d.f. &= (a-1)~d.f. + (N - a) ~ d.f.
\end{align*}

we lose a d.f. for the total corrected SSTO because of the estimation of the mean ($\sum_{i}\sum_{j}(Y_{ij} - \bar{Y_{..}})=0$)  
And, for the SSTR $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})=0$

Accordingly, $MSTR= \frac{SST}{a-1}$ and $MSR=\frac{SSE}{N-a}$

ANOVA table

Source of Variation | SS | df | MS
---|:-:|:-:|:-:
Between Treatments | $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2$ | a-1 | SSTR/(a-1)
Error (within treatments) | $\sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2$| N-a | SSE/(N-a)
Total (corrected) | $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2$ | N-1 | 

Linear Model Explanation of ANOVA

##### Cell means model

$Y_{ij}=\mu_i+\epsilon_{ij}$

where  
 * $Y_{ij}$ response variable in j-th subject for the i-th treatment  
 * $\mu_i$: parameters (fixed) representing the unknown population mean for the i-th treatment  
 * $\epsilon_{ij}$ independent $N(0,\sigma^2)$ errors  
 
 * $E(Y_{ij})=\mu_i$ $var(Y_{ij})=var(\epsilon_{ij})=\sigma^2$  
 * All observations have the same variance
 
 
Example:

a = 3 (3 treatments) $n_1=n_2=n_3=2$


$$
\begin{align*}
\left(\begin{array}{c} 
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &= 
\left(\begin{array}{ccc} 
1 & 0 & 0 \\ 
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1 \\ 
0 & 0 & 1 \\ 
\end{array}\right)
\left(\begin{array}{c}
\mu_1 \\
\mu_2 \\
\mu_3 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &= \mathbf{X\beta} +\mathbf{\epsilon}
\end{align*}
$$
$X_{k,ij}=1$ if the k-th treatment is used  

$X_{k,ij}=0$ Otherwise

Note: no intercept term. 

$$
\begin{align}
\mathbf{b}= \left[\begin{array}{c}
\mu_1 \\
\mu_2 \\
\mu_3 \\
\end{array}\right] &= 
(\mathbf{x}'\mathbf{x})^{-1}\mathbf{x}'\mathbf{y} \\

& = 
\left[\begin{array}{ccc}
n_1 & 0 & 0\\
0 & n_2 & 0\\
0 & 0 & n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_1\\
Y_2\\
Y_3\\
\end{array}\right] \\

& = 
\left[\begin{array}{c}
\bar{Y_1}\\
\bar{Y_2}\\
\bar{Y_3}\\
\end{array}\right]
\end{align} (\#eq:beta_origin)
$$

is the BLUE (best linear unbiased estimator) for $\beta=[\mu_1 \mu_2\mu_3]'$ 

$$E(\mathbf{b})=\beta$$

$$
var(\mathbf{b})=\sigma^2(\mathbf{X'X})^{-1}=\sigma^2
\left[\begin{array}{ccc}
1/n_1 & 0 & 0\\
0 & 1/n_2 & 0\\
0 & 0 & 1/n_3\\
\end{array}\right]
$$

$var(b_i)=var(\hat{\mu_i})=\sigma^2/n_i$  where $\mathbf{b} \sim N(\beta,\sigma^2(\mathbf{X'X})^{-1})$

$$
\begin{align*}
MSE &= \frac{1}{N-a} \sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2 \\
    &= \frac{1}{N-a} \sum_{i}[(n_i-1)\frac{\sum_{i}(Y_{ij}-\bar{Y_{i.}})^2}{n_i-1}] \\
    &= \frac{1}{N-a} \sum_{i}(n_i-1)s_1^2
\end{align*}
$$

We have $E(s_i^2)=\sigma^2$
$E(MSE)=\frac{1}{N-a}\sum_{i}(n_i-1)\sigma^2=\sigma^2$  

Hence, MSE is an unbiased estimator of $\sigma^2$, regardless of whether the treatment means are equal or not.

$E(MSTR)=\sigma^2+\frac{\sum_{i}n_i(\mu_i-\mu_.)^2}{a-1}$
where 
$\mu_.=\frac{\sum_{i=1}^{a}n_i\mu_i}{\sum_{i=1}^{a}n_i}$
If all treatment means are equals (=$\mu_.$), $E(MSTR)=\sigma^2$.

Then we can use an F-test for teh equality of all treatment means: 
$$H_0:\mu_1=\mu_2=..=\mu_a$$


$$H_a: not~al l~ \mu_i ~ are ~ equal $$

$F=\frac{MSTR}{MSE}$
where large values of F support $H_a$ (since MSTR will tend to exceed MSE when $H_a$ holds)
and F near 1 support $H_0$ (upper tail test)

**Equivalently**, when $H_0$ is true, $F \sim f_{(a-1,N-a)}$  

 * If $F \leq f_{(a-1,N-a;1-\alpha)}$, we cannot reject $H_0$  
 * If $F \geq f_{(a-1,N-a;1-\alpha)}$, we reject $H_0$  

 Note: If a = 2 (2 treatments), F-test = two sample t-test
 
<br>

##### Treatment Effects (Factor Effects)
Besides Cell means model, we have another way to formalize  one-way ANOVA: 
$$Y_{ij} = \mu + \tau_i + \epsilon_{ij}$$
where  

 * $Y_{ij}$ is the j-th response for the i-th treatment  
 * $\tau_i$ i-th treatment effect  
 * $\mu$ constant component, common to all observations  
 * $\epsilon_{ij}$ independent random errors ~ $N(0,\sigma^2)$  



For example, a = 3, $n_1=n_2=n_3=2$
$$
\begin{align}
\left(\begin{array}{c} 
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &= 
\left(\begin{array}{cccc} 
1 & 1 & 0 & 0 \\ 
1 & 1 & 0 & 0 \\ 
1 & 0 & 1 & 0 \\ 
1 & 0 & 1 & 0 \\ 
1 & 0 & 0 & 1 \\ 
1 & 0 & 0 & 1 \\ 
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_1 \\
\tau_2 \\
\tau_3\\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &= \mathbf{X\beta} +\mathbf{\epsilon} (\#eq:unsolvable)
\end{align}
$$

However, 


$$
\mathbf{X'X} = \left(\begin{array}{cccc}
\sum_{i}n_i & n_1 & n_2 & n_3 \\
n_1 & n_1 & 0 & 0 \\
n_2 & 0 & n_2 & 0 \\
n_3 & 0 & 0 & n_3 \\
\end{array}\right)
$$

is **singular** thus does not exist, $\mathbf{b}$ is insolvable (infinite solutions)
Hence, we have to impose restrictions on the parameters to a model matrix $\mathbf{X}$ of full rank.

Whatever restriction we use, we still have: 
$E(Y_{ij})=\mu + \tau_i = \mu_i = mean ~ response ~ for ~ i-th ~ treatment$

###### Restriction on sum of tau

$\sum_{i=1}^{a}\tau_i=0$ 

implies 

$$
\mu= \mu +\frac{1}{a}\sum_{i=1}^{a}(\mu+\tau_i)
$$
is the average of the treatment mean (grand mean) (overall mean) 

$$
\begin{align*}
\tau_i  &=(\mu+\tau_i) -\mu = \mu_i-\mu \\
        &= (treatment ~ mean) -(grand~mean) \\
        &= treatment ~ effect
\end{align*}
$$
$$
\tau_a=-\tau_1-\tau_2-...-\tau_{a-1}
$$
Hence, the mean for the a-th treatment is 
$$
\mu_a=\mu+\tau_a=\mu-\tau_1-\tau_2-...-\tau_{a-1}
$$

Hence, the model need only "a" parameters:
$$
\mu,\tau_1,\tau_2,..,\tau_{a-1}
$$


Equation \@ref(eq:unsolvable) becomes


$$
\begin{align*}
\left(\begin{array}{c} 
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &= 
\left(\begin{array}{cccc} 
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1 \\ 
1 & -1 & -1 \\ 
1 & -1 & -1 \\ 
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_1 \\
\tau_2 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &= \mathbf{X\beta} +\mathbf{\epsilon}

\end{align*}
$$

where $\beta\equiv[\mu,\tau_1,\tau_2]'$


Equation \@ref(eq:beta_origin) with $\sum_{i}\tau_i=0$ becomes

$$
\begin{align}
\mathbf{b}= \left[\begin{array}{c}
\hat{\mu} \\
\hat{\tau_1} \\
\hat{\tau_2} \\
\end{array}\right] &= 
(\mathbf{x}'\mathbf{x})^{-1}\mathbf{x}'\mathbf{y} \\

& = 
\left[\begin{array}{ccc}
\sum_{i}n_i & n_1-n_3 & n_2-n_3\\
n_1-n_3 & n_1+n_3 & n_3\\
n_2-n_3 & n_3 & n_2-n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_{..}\\
Y_{1.}-Y_{3.}\\
Y_{2.}-Y_{3.}\\
\end{array}\right] \\

& =
\left[\begin{array}{c}
\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\bar{Y_{1.}}-\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\bar{Y_{2.}}-\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\end{array}\right]\\

& = 
\left[\begin{array}{c}
\hat{\mu}\\
\hat{\tau_1}\\
\hat{\tau_2}\\
\end{array}\right]
\end{align}
$$

and $\hat{\tau_3}=-\hat{\tau_1}-\hat{\tau_2}=\bar{Y_3}-\frac{1}{3} \sum_{i}\bar{Y_{i.}}$


In R, `lm()` uses the restriction $\tau_1=0$





#### Two Factor Fixed Effect ANOVA
##### Balanced

