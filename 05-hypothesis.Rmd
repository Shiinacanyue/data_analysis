# Confidence Intervals & Hypothesis Testing

 * Make **inferences** (an interpretation) about the true parameter value $\beta$ based on our estimator/estimate
 * Test whether our underlying assumptions (about the true population parameters, random variables, or model specification) hold true.


Testing does not  

 * Confirm with 100% a hypothesis is true
 * Confirm with 100% a hypothesis is false
 * Tell you how to interpret the estimate value (Economic vs. Practical vs. Statistical Significance)


Hypothesis: Translate an objective in better understanding the results in terms of specifying a value (or sets of values) in which our population parameters should/should not lie. 

 * **Null hypothesis** ($H_0$): A statement about the population parameter that we take to be true in which we would need the data to provide substantial evidence that against it. 
    + Can be either a single value (ex: $H_0: \beta=0$) or a set of values (ex: $H_0: \beta_1 \ge 0$)
    + Will generally be the value you would not like the population parameter to be (subjective)
        - $H_0: \beta_1=0$ means you would like to see a non-zero coefficient
        - $H_0: \beta_1 \ge 0$ means you would like to see a negative effect
    + "Test of Significance" refers to the two-sided test: $H_0: \beta_j=0$
 * **Alternative hypothesis** ($H_a$ or $H_1$) (Research Hypothesis): All other possible values that the population parameter may be if the null hypothesis does not hold. 


**Type I Error**  

Error made when $H_0$ is rejected when, in fact, $H_0$ is true.  
The probability of committing a Type I error is $\alpha$ (known as **level of significance** of the test)  

Type I error ($\alpha$): probability of rejecting $H_0$ when it is true.  

Legal analogy: In U.S. law, a defendant is presumed to be "innocent until proven guilty".  
If the null hypothesis is that a person is innocent, the Type I error is the probability that you conclude the person is guilty when he is innocent. 


<br>

**Type II Error**  

Type II error level ($\beta$): probability that you fail to reject the null hypothesis when it is false.  

In the legal analogy, this is the probability that you fail to find the person guilty when he or she is guilty. 

Error made when $H_0$ is not rejected when, in fact, $H_1$ is true  
The probability of committing a Type II error is $\beta$ (known as the **power** of the test) 




## For the Mean ($\mu$)

| | Confidence Interval $100(1-\alpha)%$ | Sample Sizes <br> Confidence $\alpha$, Error d | Hypothesis Testing <br> Test Statistic |
|---|---|---|---|
When $\sigma^2$ is known, X is normal (or $n \ge 25$) | $\bar{X} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$ | $n \approx \frac{z_{\alpha/2}^2 \sigma^2}{d^2}$| $z = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}$ |
When $\sigma^2$ is unknown, X is normal (or $n \ge 25$) | $\bar{X} \pm t_{\alpha/2}\frac{s}{\sqrt{n}}$ | $n \approx \frac{z_{\alpha/2}^2 s^2}{d^2}$| $t = \frac{\bar{X}-\mu_0}{s/\sqrt{n}}$ |

## For Single Proportions (p)

| Confidence Interval $100(1-\alpha)%$ | Sample Sizes <br> Confidence $\alpha$, Error d (prior estimate for $\hat{p}$) | (No prior estimate for $\hat{p}$)|Hypothesis Testing <br> Test Statistic |
|---|---|---|---|
|$\hat{p} \pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ | $n \approx \frac{z_{\alpha/2}^2 \hat{p}(1-\hat{p})}{d^2}$| $n \approx \frac{z_{\alpha/2}^2}{4d^2}$ |$z = \frac{\hat{p}-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}$ |

## For Difference of Two Proportions ($p_1 - p_2$)

**Mean** 

$$
\hat{p_1}-\hat{p_2}
$$

**Variance**
$$
\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}
$$

**$100(1-\alpha)%$ Confidence Interval**  

$$
\hat{p_1}-\hat{p_2} + z_{\alpha/2}\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
$$

**Sample Sizes, Confidence $\alpha$, Error d**  
(Prior Estimate fo $\hat{p_1},\hat{p_2}$)

$$
n \approx \frac{z_{\alpha/2}^2[p_1(1-p_1)+p_2(1-p_2)]}{d^2}
$$

(No Prior Estimates for $\hat{p}$)

$$
n \approx \frac{z_{\alpha/2}^2}{2d^2}
$$

**Hypothesis Testing - Test Statistics**  

Null Value $(p_1 - p_2) \neq 0$

$$
z = \frac{(\hat{p_1} - \hat{p_2})-(p_1 - p_2)_0}{\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}}
$$


Null Value $(p_1 - p_2)_0 = 0$

$$
z = \frac{\hat{p_1} - \hat{p_2}}{\sqrt{\hat{p}(1-\hat{p})(\frac{1}{n_1}+\frac{1}{n_2})}}
$$

where   

$$
\hat{p}= \frac{x_1 + x_2}{n_1 + n_2} = \frac{n_1 \hat{p_1} + n_2 \hat{p_2}}{n_1 + n_2}
$$


## For a signle variance ($\sigma^2$)
**$100(1-\alpha)%$ Confidence Interval**  

$$
L_1 = \frac{(n-1)s^2}{\chi^2_{\alpha/2}} \\
L_1 = \frac{(n-1)s^2}{\chi^2_{1-\alpha/2}}
$$
**Hypothesis Testing Test Statistic**

$$
\chi^2 = \frac{(n-1)s^2}{\sigma^2_0}
$$

## For Two Variances ($\sigma^2_1,\sigma^2_2$)

$$
F_{ndf,ddf}= \frac{s^2_1}{s^2_2}
$$
where $s^2_1>s^2_2, ndf = n_1-1,ddf = n_2-1$


## For Difference of Means ($\mu_1-\mu_2$), Independent Samples

| | $100(1-\alpha)%$ Confidence Interval | Hypothesis Testing <br> Test Statistic | |
|---|---|---|---|
|When $\sigma^2$ is known | $\bar{X}_1 - \bar{X}_2 \pm z_{\alpha/2}\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}$ | $z= \frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)_0}{\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}}$| |
|When $\sigma^2$ is unknown, Variances Assumed EQUAL |  $\bar{X}_1 - \bar{X}_2 \pm t_{\alpha/2}\sqrt{s^2_p(\frac{1}{n_1}+\frac{1}{n_2})}$ | $t = \frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)_0}{\sqrt{s^2_p(\frac{1}{n_1}+\frac{1}{n_2})}}$| Pooled Variance: $s_p^2 = \frac{(n_1 -1)s^2_1 - (n_2-1)s^2_2}{n_1 + n_2 -2}$ <br> Degrees of Freedom: $\gamma = n_1 + n_2 -2$|
|When $\sigma^2$ is unknown, Variances Assumed UNEQUAL |  $\bar{X}_1 - \bar{X}_2 \pm t_{\alpha/2}\sqrt{(\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2})}$ | $t = \frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)_0}{\sqrt{(\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2})}}$| Degrees of Freedom: $\gamma = \frac{(\frac{s_1^2}{n_1}+\frac{s^2_2}{n_2})^2}{\frac{(\frac{s_1^2}{n_1})^2}{n_1-1}+\frac{(\frac{s_2^2}{n_2})^2}{n_2-1}}$|


## For Difference of Means ($\mu_1 - \mu_2$), Paired Samples (D = X-Y)  

**$100(1-\alpha)%$ Confidence Interval**  
$$
\bar{D} \pm t_{\alpha/2}\frac{s_d}{\sqrt{n}}
$$

**Hypothesis Testing Test Statistic**  

$$
t = \frac{\bar{D}-D_0}{s_d / \sqrt{n}}
$$


