# Analysis of Variance (ANOVA)
ANOVA is using the same underlying mechanism as linear regression. However, the angle that ANOVA chooses to look at is slightly different from the traditional linear regression. It can be more useful in the case with **qualitative variables** and **designed experiments**.  

<br>
Experimental Design  

 * **Factor**: explanatory or predictor variable to be studied in an investigation  
 * **Treatment** (or Factor Level): "value" of a factor applied to the experimental unit  
 * **Experimental Unit**: person, animal, piece of material, etc. that is subjected to treatment(s) and provides a response  
 * **Single Factor Experiment**: one explanatory variable considered  
 * **Multifactor Experiment**: more than one explanatory variable  
 * **Classification Factor**: A factor that is not under the control of the experimenter (observational data)  
 * **Experimental Factor**: assigned by the experimenter  
 
<br>
Basics of experimental design:  

 * Choices that a statistician has to make:  
    + set of treatments  
    + set of experimental units  
    + treatment assignment (selection bias)  
    + measurement (measurement bias, blind experiments)  
    
 * Advancements in experimental design:  
 
    1. **Factorial Experiments**:  
    consider multiple factors at the same time (interaction)  

    2. **Replication**: repetition of experiment  
        * assess mean squared error  
        * control over precision of experiment (power)  
 
    3. **Randomization**  
        * Before R.A. Fisher (1900s), treatments were assigned systematically or subjectively  
        * randomization: assign treatments to experimental units at random, which averages out systematic effects that cannot be control by the investigator  

    4. **Local control**: Blocking or Stratification  
        * Reduce experimental errors and increase power by placing restrictions on the randomization of treatments to experimental units.  
        
Randomization may also eliminate correlations due to time and space.

## Completely Randomized Design (CRD)

Treatment factor A with $a\ge2$  treatments levels.
Experimental units are randomly assinged to each treatment. The number of experiemntal units in each group can be  

 * equal (balanced): n
 * unequal (unbalanced):  $n_i$ for the i-th group (i = 1,...,a).
 
 The total sample size is $N=\sum_{i=1}^{a}n_i$
 
 Possible assignments of units to treatments are $k=\frac{N!}{n_1!n_2!...n_a!}$
 
 Each has probability 1/k of being selected. 
 Each experimental unit is measured with a response $Y_{ij}$, in which j denotes unit and i denotes treatment.  
 
 Treatment
 
| | 1 | 2 | ... | a |
|:--|:-:|:-:|:-:|:-:|
|   |$Y_{11}$|$Y_{21}$|...|$Y_{a1}$|
|   |$Y_{12}$|...|...|...|
|   |...|...|...|...|
|Sample Mean | $\bar{Y_{1.}}$|$\bar{Y_{2.}}$| ... | $\bar{Y_{a.}}$
| Sample SD | $s_1$| $s_2$| ...| $s_a$|

where $\bar{Y_{i.}}=\frac{1}{n_i}\sum_{j=1}^{n_i}Y_{ij}$  

$s_i^2=\frac{1}{n_i-1}\sum_{j=1}^{n_i}(Y_{ij}-\bar{Y_i})^2$  

And the grand mean is $\bar{Y_{..}}=\frac{1}{N}\sum_{i}\sum_{j}Y_{ij}$  

### Single Factor (One-Way) ANOVA

Partitioning the Variance  

The total variability of the $Y_{ij}$ observation can be measured as the deviation of $Y_{ij}$ around the overall mean $\bar{Y_{..}}$:  $Y_{ij} - \bar{Y_{..}}$  

This can be rewritten as: 
$$
\begin{split}
Y_{ij} - \bar{Y_{..}}&=Y_{ij} - \bar{Y_{..}} + \bar{Y_{i.}} - \bar{Y_{i.}} \\
&= (\bar{Y_{i.}}-\bar{Y_{..}})+(Y_{ij}-\bar{Y_{i.}})
\end{split}
$$
where 

 * the first term is the *between* treatment differences (i.e., the deviation of the treatment mean from the overall mean)  
 * the second term is *within* treatment differences (i.e., the deviation of the observation around its treatment mean)

<br>


$$
\begin{split}
\sum_{i}\sum_{j}(Y_{ij} - \bar{Y_{..}})^2 &=  \sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2+\sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2 \\
SSTO &= SSTR + SSE \\
total~SS &= treatment~SS + error~SS \\
(N-1)~d.f. &= (a-1)~d.f. + (N - a) ~ d.f.
\end{split}
$$

we lose a d.f. for the total corrected SSTO because of the estimation of the mean ($\sum_{i}\sum_{j}(Y_{ij} - \bar{Y_{..}})=0$)  
And, for the SSTR $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})=0$  

Accordingly, $MSTR= \frac{SST}{a-1}$ and $MSR=\frac{SSE}{N-a}$  

**ANOVA Table**

Source of Variation | SS | df | MS
---|:-:|:-:|:-:
Between Treatments | $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2$ | a-1 | SSTR/(a-1)
Error (within treatments) | $\sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2$| N-a | SSE/(N-a)
Total (corrected) | $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2$ | N-1 | 

Linear Model Explanation of ANOVA

#### Cell means model

$Y_{ij}=\mu_i+\epsilon_{ij}$  

where  
 * $Y_{ij}$ response variable in j-th subject for the i-th treatment  
 * $\mu_i$: parameters (fixed) representing the unknown population mean for the i-th treatment  
 * $\epsilon_{ij}$  independent  $N(0,\sigma^2)$  errors  
 
 * $E(Y_{ij})=\mu_i$ $var(Y_{ij})=var(\epsilon_{ij})=\sigma^2$  
 * All observations have the same variance
 
 
Example:

a = 3 (3 treatments) $n_1=n_2=n_3=2$  


<br>



$$
\begin{split}
\left(\begin{array}{c} 
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &= 
\left(\begin{array}{ccc} 
1 & 0 & 0 \\ 
1 & 0 & 0 \\ 
0 & 1 & 0 \\ 
0 & 1 & 0 \\ 
0 & 0 & 1 \\ 
0 & 0 & 1 \\ 
\end{array}\right)
\left(\begin{array}{c}
\mu_1 \\
\mu_2 \\
\mu_3 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &= \mathbf{X\beta} +\mathbf{\epsilon}
\end{split}
$$


$X_{k,ij}=1$ if the k-th treatment is used  

$X_{k,ij}=0$ Otherwise  

<br>


Note: no intercept term.  

\begin{equation}
\begin{split}
\mathbf{b}= \left[\begin{array}{c}
\mu_1 \\
\mu_2 \\
\mu_3 \\
\end{array}\right] &= 
(\mathbf{x}'\mathbf{x})^{-1}\mathbf{x}'\mathbf{y} \\
& = 
\left[\begin{array}{ccc}
n_1 & 0 & 0\\
0 & n_2 & 0\\
0 & 0 & n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_1\\
Y_2\\
Y_3\\
\end{array}\right] \\
& = 
\left[\begin{array}{c}
\bar{Y_1}\\
\bar{Y_2}\\
\bar{Y_3}\\
\end{array}\right] 
\end{split} 
(\#eq:betaorigin)
\end{equation}

is the BLUE (best linear unbiased estimator) for $\beta=[\mu_1 \mu_2\mu_3]'$  

<br>


$$E(\mathbf{b})=\beta$$  


$$
var(\mathbf{b})=\sigma^2(\mathbf{X'X})^{-1}=\sigma^2
\left[\begin{array}{ccc}
1/n_1 & 0 & 0\\
0 & 1/n_2 & 0\\
0 & 0 & 1/n_3\\
\end{array}\right]
$$


$var(b_i)=var(\hat{\mu_i})=\sigma^2/n_i$  where $\mathbf{b} \sim N(\beta,\sigma^2(\mathbf{X'X})^{-1})$  


$$
\begin{split}
MSE &= \frac{1}{N-a} \sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2 \\
    &= \frac{1}{N-a} \sum_{i}[(n_i-1)\frac{\sum_{i}(Y_{ij}-\bar{Y_{i.}})^2}{n_i-1}] \\
    &= \frac{1}{N-a} \sum_{i}(n_i-1)s_1^2
\end{split}
$$

We have $E(s_i^2)=\sigma^2$  


$E(MSE)=\frac{1}{N-a}\sum_{i}(n_i-1)\sigma^2=\sigma^2$  

Hence, MSE is an unbiased estimator of $\sigma^2$, regardless of whether the treatment means are equal or not.

$E(MSTR)=\sigma^2+\frac{\sum_{i}n_i(\mu_i-\mu_.)^2}{a-1}$  
where 
$\mu_.=\frac{\sum_{i=1}^{a}n_i\mu_i}{\sum_{i=1}^{a}n_i}$  
If all treatment means are equals (=$\mu_.$), $E(MSTR)=\sigma^2$.  

Then we can use an F-test for teh equality of all treatment means: 

$$H_0:\mu_1=\mu_2=..=\mu_a$$  


$$H_a: not~al l~ \mu_i ~ are ~ equal $$  

$F=\frac{MSTR}{MSE}$  
where large values of F support $H_a$ (since MSTR will tend to exceed MSE when $H_a$ holds)  
and F near 1 support $H_0$ (upper tail test)  

**Equivalently**, when $H_0$ is true, $F \sim f_{(a-1,N-a)}$  

 * If $F \leq f_{(a-1,N-a;1-\alpha)}$, we cannot reject $H_0$  
 * If $F \geq f_{(a-1,N-a;1-\alpha)}$, we reject $H_0$  

 Note: If a = 2 (2 treatments), F-test = two sample t-test
 
<br>

#### Treatment Effects (Factor Effects)
Besides Cell means model, we have another way to formalize  one-way ANOVA: 
$$Y_{ij} = \mu + \tau_i + \epsilon_{ij}$$
where  

 * $Y_{ij}$ is the j-th response for the i-th treatment  
 * $\tau_i$ i-th treatment effect  
 * $\mu$ constant component, common to all observations  
 * $\epsilon_{ij}$   independent random errors ~   $N(0,\sigma^2)$   


<br>



For example, a = 3, $n_1=n_2=n_3=2$  


<br>



\begin{equation} 
\begin{split}
\left(\begin{array}{c} 
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &= 
\left(\begin{array}{cccc} 
1 & 1 & 0 & 0 \\ 
1 & 1 & 0 & 0 \\ 
1 & 0 & 1 & 0 \\ 
1 & 0 & 1 & 0 \\ 
1 & 0 & 0 & 1 \\ 
1 & 0 & 0 & 1 \\ 
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_1 \\
\tau_2 \\
\tau_3\\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &= \mathbf{X\beta} +\mathbf{\epsilon} 
\end{split}
(\#eq:unsolvable)
\end{equation} 


<br>


However, 


$$
\mathbf{X'X} = \left(\begin{array}{cccc}
\sum_{i}n_i & n_1 & n_2 & n_3 \\
n_1 & n_1 & 0 & 0 \\
n_2 & 0 & n_2 & 0 \\
n_3 & 0 & 0 & n_3 \\
\end{array}\right)
$$

is **singular** thus does not exist, $\mathbf{b}$ is insolvable (infinite solutions)  

Hence, we have to impose restrictions on the parameters to a model matrix $\mathbf{X}$ of full rank.  

Whatever restriction we use, we still have:  

$E(Y_{ij})=\mu + \tau_i = \mu_i = mean ~ response ~ for ~ i-th ~ treatment$  

##### Restriction on sum of tau

$\sum_{i=1}^{a}\tau_i=0$  

<br>


implies  


$$
\mu= \mu +\frac{1}{a}\sum_{i=1}^{a}(\mu+\tau_i)
$$

<br>


is the average of the treatment mean (grand mean) (overall mean) 

$$
\begin{split}
\tau_i  &=(\mu+\tau_i) -\mu = \mu_i-\mu \\
        &= (treatment ~ mean) -(grand~mean) \\
        &= treatment ~ effect
\end{split}
$$


<br>


$$
\tau_a=-\tau_1-\tau_2-...-\tau_{a-1}
$$


Hence, the mean for the a-th treatment is  

<br>



$$
\mu_a=\mu+\tau_a=\mu-\tau_1-\tau_2-...-\tau_{a-1}
$$

Hence, the model need only "a" parameters:  

<br>



$$
\mu,\tau_1,\tau_2,..,\tau_{a-1}
$$


Equation \@ref(eq:unsolvable) becomes 

<br>

\begin{equation}
\begin{split}
\left(\begin{array}{c} 
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &= 
\left(\begin{array}{cccc} 
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1 \\ 
1 & -1 & -1 \\ 
1 & -1 & -1 \\ 
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_1 \\
\tau_2 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &= \mathbf{X\beta} +\mathbf{\epsilon}
\end{split}
\end{equation}

where $\beta\equiv[\mu,\tau_1,\tau_2]'$  

<br>



Equation \@ref(eq:betaorigin) with $\sum_{i}\tau_i=0$ becomes  

<br>

$$
\begin{equation}
\begin{split}
\mathbf{b}= \left[\begin{array}{c}
\hat{\mu} \\
\hat{\tau_1} \\
\hat{\tau_2} \\
\end{array}\right] &= 
(\mathbf{x}'\mathbf{x})^{-1}\mathbf{x}'\mathbf{y} \\
& = 
\left[\begin{array}{ccc}
\sum_{i}n_i & n_1-n_3 & n_2-n_3\\
n_1-n_3 & n_1+n_3 & n_3\\
n_2-n_3 & n_3 & n_2-n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_{..}\\
Y_{1.}-Y_{3.}\\
Y_{2.}-Y_{3.}\\
\end{array}\right] \\
& =
\left[\begin{array}{c}
\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\bar{Y_{1.}}-\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\bar{Y_{2.}}-\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\end{array}\right]\\
& = 
\left[\begin{array}{c}
\hat{\mu}\\
\hat{\tau_1}\\
\hat{\tau_2}\\
\end{array}\right]
\end{split}
\end{equation}
$$

and $\hat{\tau_3}=-\hat{\tau_1}-\hat{\tau_2}=\bar{Y_3}-\frac{1}{3} \sum_{i}\bar{Y_{i.}}$  

##### Restriction on first tau
In R, `lm()` uses the restriction $\tau_1=0$  

For the previous example, for $n_1=n_2=n_3=2$, and $\tau_1=0$. Then the treatment means can be written as:

$$
\mu_1= \mu + \tau_1 = \mu + 0 = \mu  \\
\mu_2= \mu + \tau_2 \\
\mu_3 = \mu + \tau_3
$$
Hence, $\mu$ is the mean response for the first treatment

In the matrix form,

$$
\begin{equation}
\begin{split}
\left(\begin{array}{c} 
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &= 
\left(\begin{array}{cccc} 
1 & 0 & 0 \\ 
1 & 0 & 0 \\ 
1 & 1 & 0 \\ 
1 & 1 & 0 \\ 
1 & 0 & 1 \\ 
1 & 0 & 1 \\ 
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_2 \\
\tau_3 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &= \mathbf{X\beta} +\mathbf{\epsilon}
\end{split}
\end{equation}
$$

$\beta = [\mu,\tau_2,\tau_3]'$

$$
\begin{equation}
\begin{split}
\mathbf{b}= \left[\begin{array}{c}
\hat{\mu} \\
\hat{\tau_2} \\
\hat{\tau_3} \\
\end{array}\right] &= 
(\mathbf{x}'\mathbf{x})^{-1}\mathbf{x}'\mathbf{y} \\
& = 
\left[\begin{array}{ccc}
\sum_{i}n_i & n_2 & n_3\\
n_2 & n_2 & 0\\
n_3 & 0 & n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_{..}\\
Y_{2.}\\
Y_{3.}\\
\end{array}\right] \\
& = 
\left[
\begin{array}{c}
\bar{Y_{1.}} \\
\bar{Y_{2.}} - \bar{Y_{1.}} \\
\bar{Y_{3.}} - \bar{Y_{1.}}\\
\end{array}\right]
\end{split}
\end{equation}
$$

$$
E(\mathbf{b})= \beta = 
\left[\begin{array}{c}
{\mu}\\
{\tau_2}\\
{\tau_3}\\
\end{array}\right]
=
\left[\begin{array}{c}
\mu_1\\
\mu_2-\mu_1\\
\mu_3-\mu_1\\
\end{array}\right]
$$

$$
var(\mathbf{b}) = \sigma^2(\mathbf{X'X})^{-1} \\
var(\hat{\mu}) = var(\bar{Y_{1.}})=\sigma^2/n_1 \\
var(\hat{\tau_2}) = var(\bar{Y_{2.}}-\bar{Y_{1.}}) = \sigma^2/n_2 + \sigma^2/n_1 \\
var(\hat{\tau_3}) = var(\bar{Y_{3.}}-\bar{Y_{1.}}) = \sigma^2/n_3 + \sigma^2/n_1
$$

<br>

**Note** For all three parameterization, the ANOVA table is the same  

 * [Model 1][Cell means model]: $Y_{ij} = \mu_i + \epsilon_{ij}$
 * [Model 2][Restriction on sum of tau]: $Y_{ij} = \mu + \tau_i + \epsilon_{ij}$ where $\sum_{i} \tau_i=0$
 * [Model 3][Restriction on first tau]: $Y_{ij}= \mu + \tau_i + \epsilon_{ij}$ where $\tau_1=0$
 
All models have the same calculation for $\hat{Y}$ as 

$$
\mathbf{\hat{Y} = X(X'X)^{-1}X'Y=PY = Xb}
$$

**ANOVA Table**

Source of Variation | SS | df | MS | F
---|:-:|:-:|:-:|:-:
Between Treatments | $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2 = \mathbf{Y'(P-P_1)Y}$ | a-1 | SSTR/(a-1)| MSTR/MSE
Error (within treatments) | $\sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2=\mathbf{e'e}$| N-a | SSE/(N-a)|
Total (corrected) | $\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2=\mathbf{Y'Y - Y'P_1Y}$ | N-1 | |

where $\mathbf{P_1} = \frac{1}{n}\mathbf{J}$


The F-statistic here has (a-1,N-a) degrees of freedom, which gives the same value for all three parameterization, but the hypothesis test is written a bit different: 

$$
H_0 : \mu_1 = \mu_2 = ... = \mu_a \\
H_0 : \mu + \tau_1 = \mu + tau_2 = ... = \mu + \tau_a \\
H_0 : \tau_1 = \tau_2 = ...= \tau_a 
$$
The F-test here serves as a preliminary analysis, to see if there is any difference at different factors. For more in-depth analysis, we consider different testing of treatment effects.
 
#### Testing of Treatment Effects

 * A [Single Treatment Mean] $\mu_i$
 * A [Differences Between Treatment Means]
 * A contrast among treatment means
 * A linear combination of treatment means 

##### Single Treatment Mean

We have $\hat{\mu_i}=\bar{Y_{i.}}$ where  

 * $E(\bar{Y_{i.}})=\mu_i$
 * $var(\bar{Y_{i}})=\sigma^2/n_i$ estimated by $s^2(\bar{Y_{i.}})=MSE / n_i$
 
Since $\frac{\bar{Y_{i.}}-\mu_i}{s(\bar{Y_{i.}})} \sim t_{N-a}$ and the confidence interval for $\mu_i$ is $\bar{Y_{i.}} \pm t_{1-\alpha/2;N-a}s(\bar{Y_{i.}})$,  
then we can do a t-test for the means difference with some constant c

$$
H_0: \mu_i = c \\
H_1: \mu_i \neq c
$$

where 

$$
T =\frac{\bar{Y_{i.}}-c}{s(\bar{Y_{i.}})}
$$
follows $t_{N-a}$ when $H_0$ is true.  
If $|T| > t_{1-\alpha/2;N-a}$, we can reject $H_0$

##### Differences Between Treatment Means

Let $D=\mu_i - \mu_i'$, also known as **pairwise comparison**  
$D$ can be estimated by $\hat{D}=\bar{Y_{i}}-\bar{Y_{i}}'$ is unbiased ($E(\hat{D})=\mu_i-\mu_i'$)  

Since $\bar{Y_{i}}$ and $\bar{Y_{i}}'$ are independent, then 

$$
var(\hat{D})=var(\bar{Y_{i}}) + var(\bar{Y_{i'}}) = \sigma^2(1/n_i + 1/n_i')
$$
can be estimated with

$$
s^2(\hat{D}) = MSE(1/n_i + 1/n_i')
$$

slide 45


### Two Factor Fixed Effect ANOVA
#### Balanced

#### Unbalanced
