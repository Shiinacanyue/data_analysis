<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 17 Causal Inference | A Guide on Data Analysis</title>
<meta name="author" content="Mike Nguyen">
<meta name="description" content="After all of the mambo jumbo that we have learned so far, I want to now talk about the concept of causality. We usually say that correlation is not causation. Then, what is causation? This...">
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 17 Causal Inference | A Guide on Data Analysis">
<meta property="og:type" content="book">
<meta property="og:url" content="https://bookdown.org/mike/data_analysis/causal-inference.html">
<meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<meta property="og:description" content="After all of the mambo jumbo that we have learned so far, I want to now talk about the concept of causality. We usually say that correlation is not causation. Then, what is causation? This...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 17 Causal Inference | A Guide on Data Analysis">
<meta name="twitter:description" content="After all of the mambo jumbo that we have learned so far, I want to now talk about the concept of causality. We usually say that correlation is not causation. Then, what is causation? This...">
<meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/proj4js-2.3.15/proj4.js"></script><link href="libs/highcharts-9.3.1/css/motion.css" rel="stylesheet">
<script src="libs/highcharts-9.3.1/highcharts.js"></script><script src="libs/highcharts-9.3.1/highcharts-3d.js"></script><script src="libs/highcharts-9.3.1/highcharts-more.js"></script><script src="libs/highcharts-9.3.1/modules/stock.js"></script><script src="libs/highcharts-9.3.1/modules/map.js"></script><script src="libs/highcharts-9.3.1/modules/data.js"></script><script src="libs/highcharts-9.3.1/modules/exporting.js"></script><script src="libs/highcharts-9.3.1/modules/offline-exporting.js"></script><script src="libs/highcharts-9.3.1/modules/drilldown.js"></script><script src="libs/highcharts-9.3.1/modules/item-series.js"></script><script src="libs/highcharts-9.3.1/modules/overlapping-datalabels.js"></script><script src="libs/highcharts-9.3.1/modules/annotations.js"></script><script src="libs/highcharts-9.3.1/modules/export-data.js"></script><script src="libs/highcharts-9.3.1/modules/funnel.js"></script><script src="libs/highcharts-9.3.1/modules/heatmap.js"></script><script src="libs/highcharts-9.3.1/modules/treemap.js"></script><script src="libs/highcharts-9.3.1/modules/sankey.js"></script><script src="libs/highcharts-9.3.1/modules/dependency-wheel.js"></script><script src="libs/highcharts-9.3.1/modules/organization.js"></script><script src="libs/highcharts-9.3.1/modules/solid-gauge.js"></script><script src="libs/highcharts-9.3.1/modules/streamgraph.js"></script><script src="libs/highcharts-9.3.1/modules/sunburst.js"></script><script src="libs/highcharts-9.3.1/modules/vector.js"></script><script src="libs/highcharts-9.3.1/modules/wordcloud.js"></script><script src="libs/highcharts-9.3.1/modules/xrange.js"></script><script src="libs/highcharts-9.3.1/modules/tilemap.js"></script><script src="libs/highcharts-9.3.1/modules/venn.js"></script><script src="libs/highcharts-9.3.1/modules/gantt.js"></script><script src="libs/highcharts-9.3.1/modules/timeline.js"></script><script src="libs/highcharts-9.3.1/modules/parallel-coordinates.js"></script><script src="libs/highcharts-9.3.1/modules/bullet.js"></script><script src="libs/highcharts-9.3.1/modules/coloraxis.js"></script><script src="libs/highcharts-9.3.1/modules/dumbbell.js"></script><script src="libs/highcharts-9.3.1/modules/lollipop.js"></script><script src="libs/highcharts-9.3.1/modules/series-label.js"></script><script src="libs/highcharts-9.3.1/plugins/motion.js"></script><script src="libs/highcharts-9.3.1/custom/reset.js"></script><script src="libs/highcharts-9.3.1/modules/boost.js"></script><script src="libs/highchart-binding-0.9.4/highchart.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<!-- Global site tag (gtag.js) - Google Analytics --><script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script><script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){window.dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-DMNX2X65HQ');
    </script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS -->
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">A Guide on Data Analysis</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Preface</a></li>
<li><a class="" href="introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="prerequisites.html"><span class="header-section-number">2</span> Prerequisites</a></li>
<li class="book-part">I. BASIC</li>
<li><a class="" href="descriptive-stat.html"><span class="header-section-number">3</span> Descriptive Statistics</a></li>
<li><a class="" href="basic-statistical-inference.html"><span class="header-section-number">4</span> Basic Statistical Inference</a></li>
<li class="book-part">II. REGRESSION</li>
<li><a class="" href="linear-regression.html"><span class="header-section-number">5</span> Linear Regression</a></li>
<li><a class="" href="non-linear-regression.html"><span class="header-section-number">6</span> Non-linear Regression</a></li>
<li><a class="" href="generalized-linear-models.html"><span class="header-section-number">7</span> Generalized Linear Models</a></li>
<li><a class="" href="linear-mixed-models.html"><span class="header-section-number">8</span> Linear Mixed Models</a></li>
<li><a class="" href="nonlinear-and-generalized-linear-mixed-models.html"><span class="header-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a></li>
<li class="book-part">III. RAMIFICATIONS</li>
<li><a class="" href="model-specification.html"><span class="header-section-number">10</span> Model Specification</a></li>
<li><a class="" href="imputation-missing-data.html"><span class="header-section-number">11</span> Imputation (Missing Data)</a></li>
<li><a class="" href="data.html"><span class="header-section-number">12</span> Data</a></li>
<li><a class="" href="hypothesis-testing.html"><span class="header-section-number">13</span> Hypothesis Testing</a></li>
<li><a class="" href="prediction-and-estimation.html"><span class="header-section-number">14</span> Prediction and Estimation</a></li>
<li><a class="" href="moderation.html"><span class="header-section-number">15</span> Moderation</a></li>
<li><a class="" href="bootstrap.html"><span class="header-section-number">16</span> Bootstrap</a></li>
<li class="book-part">IV. CAUSAL INFERENCE</li>
<li><a class="active" href="causal-inference.html"><span class="header-section-number">17</span> Causal Inference</a></li>
<li class="book-part">A. EXPERIMENTAL DESIGN</li>
<li><a class="" href="experimental-design.html"><span class="header-section-number">18</span> Experimental Design</a></li>
<li><a class="" href="sampling.html"><span class="header-section-number">19</span> Sampling</a></li>
<li><a class="" href="analysis-of-variance-anova.html"><span class="header-section-number">20</span> Analysis of Variance (ANOVA)</a></li>
<li><a class="" href="multivariate-methods.html"><span class="header-section-number">21</span> Multivariate Methods</a></li>
<li class="book-part">B. QUASI-EXPERIMENTAL DESIGN</li>
<li><a class="" href="quasi-experimental.html"><span class="header-section-number">22</span> Quasi-experimental</a></li>
<li><a class="" href="regression-discontinuity.html"><span class="header-section-number">23</span> Regression Discontinuity</a></li>
<li><a class="" href="difference-in-differences.html"><span class="header-section-number">24</span> Difference-in-differences</a></li>
<li><a class="" href="synthetic-control.html"><span class="header-section-number">25</span> Synthetic Control</a></li>
<li><a class="" href="panel-data-methods.html"><span class="header-section-number">26</span> Panel Data Methods</a></li>
<li><a class="" href="event-studies.html"><span class="header-section-number">27</span> Event Studies</a></li>
<li><a class="" href="matching-methods.html"><span class="header-section-number">28</span> Matching Methods</a></li>
<li><a class="" href="interrupted-time-series.html"><span class="header-section-number">29</span> Interrupted Time Series</a></li>
<li class="book-part">C. OTHER CONCERNS</li>
<li><a class="" href="doubly-robust-estimator.html"><span class="header-section-number">30</span> Doubly Robust Estimator</a></li>
<li><a class="" href="endogeneity.html"><span class="header-section-number">31</span> Endogeneity</a></li>
<li><a class="" href="mediation.html"><span class="header-section-number">32</span> Mediation</a></li>
<li><a class="" href="directed-acyclic-graph.html"><span class="header-section-number">33</span> Directed Acyclic Graph</a></li>
<li class="book-part">V. MISCELLANEOUS</li>
<li><a class="" href="report.html"><span class="header-section-number">34</span> Report</a></li>
<li><a class="" href="exploratory-data-analysis.html"><span class="header-section-number">35</span> Exploratory Data Analysis</a></li>
<li><a class="" href="sensitivity-analysis-robustness-check.html"><span class="header-section-number">36</span> Sensitivity Analysis/ Robustness Check</a></li>
<li class="book-part">APPENDIX</li>
<li><a class="" href="appendix.html"><span class="header-section-number">A</span> Appendix</a></li>
<li><a class="" href="bookdown-cheat-sheet.html"><span class="header-section-number">B</span> Bookdown cheat sheet</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/mikenguyen13/data_analysis">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="causal-inference" class="section level1" number="17">
<h1>
<span class="header-section-number">17</span> Causal Inference<a class="anchor" aria-label="anchor" href="#causal-inference"><i class="fas fa-link"></i></a>
</h1>
<p>After all of the mambo jumbo that we have learned so far, I want to now talk about the concept of causality. We usually say that correlation is not causation. Then, what is causation?</p>
<p>This question has been the focus of many disciplines since the 1920s as the field of causal inference garnered interest in econometrics <span class="citation">(<a href="references.html#ref-imbens2020" role="doc-biblioref">G. W. Imbens 2020, 1129</a>)</span>. Even though using somewhat similar terminologies, there are two main frameworks to approach causal inference: potential outcome framework, and directed cyclic graph (DAG).</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="15%">
<col width="50%">
<col width="34%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>Potential Outcome</th>
<th>Directed Acyclic Graph</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Origin</td>
<td>
<p>Randomized controlled trials (RCT)</p>
<p>Demand and supply framework (Jan Tinbergen)</p>
</td>
<td>Path analysis (Philip Wright</td>
</tr>
<tr class="even">
<td>Originators</td>
<td>
<p>Ronald Fisher</p>
<p>Jerzey Nyman</p>
</td>
<td>Judea pearl</td>
</tr>
<tr class="odd">
<td>Field</td>
<td>Economics, Econometrics</td>
<td>Computer Science</td>
</tr>
<tr class="even">
<td>Focus</td>
<td>Estimation, Inference</td>
<td>Identification</td>
</tr>
</tbody>
</table></div>
<div id="intro-to-dag-framework" class="section level2" number="17.1">
<h2>
<span class="header-section-number">17.1</span> Intro to DAG Framework<a class="anchor" aria-label="anchor" href="#intro-to-dag-framework"><i class="fas fa-link"></i></a>
</h2>
<p>One of my favorite books has explained this concept beautifully <span class="citation">(<a href="references.html#ref-Pearl_2018" role="doc-biblioref">Mackenzie and Pearl 2018</a>)</span>. And I am just going to quickly summarize the gist of it from my understanding. I hope that it can give you an initial grasp on the concept so that later you can continue to read up and develop a deeper understanding.</p>
<p>It’s important to have a deep understanding regarding the method research. However, one needs to be aware of its limitation. As mentioned in various sections throughout the book, we see that we need to ask experts for number as our baseline or visit literature to gain insight from past research.</p>
<p>Here, we dive in a more conceptual side statistical analysis as a whole, regardless of particular approach.</p>
<p>You probably heard scientists say correlation doesn’t mean causation. There are ridiculous <a href="http://www.tylervigen.com/spurious-correlations">spurious correlations</a> that give a firm grip on what the previous phrase means. The pioneer who tried to use regression to infer causation in social science was <span class="citation">Yule (<a href="references.html#ref-yule1899" role="doc-biblioref">1899</a>)</span> (but it was a fatal attempt where he found relief policy increases poverty). To make a causal inference from statistics, <strong>the equation (function form) must be stable</strong> under intervention (i.e., variables are manipulated). Statistics is used to be a causality-free enterprise in the past.</p>
<p>Not until the development of path analysis by Sewall Wright in the 1920s that the discipline started to pay attention to causation. Then, it remained dormant until the Causal Revolution (quoted Judea Pearl’s words). This revolution introduced the calculus of causation which includes (1) causal diagrams), and (2) a symbolic language</p>
<p>The world has been using <span class="math inline">\(P(Y|X)\)</span> (statistics use to derive this), but what we want is to compare the difference between</p>
<ul>
<li><p><span class="math inline">\(P(Y|do(X))\)</span>: treatment group</p></li>
<li><p><span class="math inline">\(P(Y|do(not-X))\)</span>: control group</p></li>
</ul>
<p>Hence, we can see a clear difference between <span class="math inline">\(P(Y|X) \neq P(Y|do(X))\)</span></p>
<p>The conclusion we want to make from data is counterfactuals: <strong>What would have happened had we not do X?</strong></p>
<p>To teach a robot to make inference, we need inference engine</p>
<div class="figure">
<img src="images/Figure%20I.png" title="Inference Engine" style="display: block; margin: 1em auto" alt=""><p class="caption">p. 12 <span class="citation">(<a href="references.html#ref-Pearl_2018" role="doc-biblioref">Mackenzie and Pearl 2018</a>)</span></p>
</div>
<p>Levels of cognitive ability to be a causal learner:</p>
<ol style="list-style-type: decimal">
<li>Seeing</li>
<li>Doing</li>
<li>Imagining</li>
</ol>
<p>Ladder of causation (associated with levels of cognitive ability as well):</p>
<ol style="list-style-type: decimal">
<li>Association: conditional probability, correlation, regression</li>
<li>Intervention</li>
<li>Counterfactuals</li>
</ol>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="13%">
<col width="10%">
<col width="32%">
<col width="44%">
</colgroup>
<thead><tr class="header">
<th>Level</th>
<th>Activity</th>
<th>Questions</th>
<th>Examples</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>
<p>Association</p>
<p><span class="math inline">\(P(y|x)\)</span></p>
</td>
<td>Seeing</td>
<td>
<p>What is?</p>
<p>How would seeing X change my belief in Y?</p>
</td>
<td>What does a symptom tell me about a disease?</td>
</tr>
<tr class="even">
<td>
<p>Intervention</p>
<p><span class="math inline">\(P(y|do(x),z)\)</span></p>
</td>
<td>
<p>Doing</p>
<p>Intervening</p>
</td>
<td>
<p>What if?</p>
<p>What if I do X?</p>
</td>
<td>What if I spend more time learning, will my result change?</td>
</tr>
<tr class="odd">
<td>
<p>Counterfactuals</p>
<p><span class="math inline">\(P(y_x|x',y')\)</span></p>
</td>
<td>Imagining</td>
<td>
<p>Why?<br>
was it X that caused Y?</p>
<p>What if I had acted differently</p>
</td>
<td>What if I stopped smoking a year ago?</td>
</tr>
</tbody>
</table></div>
<p>Table by <span class="citation">(<a href="references.html#ref-pearl2019" role="doc-biblioref">Pearl 2019, 2</a>)</span></p>
<p>You cannot define causation from probability alone</p>
<p>If you say X causes Y if X raises the probability of Y. On the surface, it might sound intuitively right. But when we translate it to probability notation: <span class="math inline">\(P(Y|X) &gt;P(Y)\)</span> , it can’t be more wrong. Just because you are seeing X (1st level), it <strong>doesn’t mean</strong> the probability of Y increases.</p>
<p>It could be either that (1) X causes Y, or (2) Z affects both X and Y. Hence, people might use <strong>control variables</strong>, which translate: <span class="math inline">\(P(Y|X, Z=z) &gt; P(Y|Z=z)\)</span>, then you can be more confident in your probabilistic observation. However, the question is how can you choose <span class="math inline">\(Z\)</span></p>
<p>With the invention of the do-operator, now you can represent X causes Y as</p>
<p><span class="math display">\[
P(Y|do(X)) &gt; P(Y)
\]</span></p>
<p>and with the help of causal diagram, now you can answer questions at the 2nd level (Intervention)</p>
<p>Note: people under econometrics might still use “Granger causality” and “vector autoregression” to use the probability language to represent causality (but it’s not).</p>
<p><br></p>
<p>The 7 tools for Structural Causal Model framework <span class="citation">(<a href="references.html#ref-pearl2019" role="doc-biblioref">Pearl 2019</a>)</span>:</p>
<ol style="list-style-type: decimal">
<li><p>Encoding Causal Assumptions - transparency and testability (with graphical representation)</p></li>
<li><p>Do-calculus and the control of confounding: “back-door”</p></li>
<li><p>The algorithmization of Counterfactuals</p></li>
<li><p>Mediation Analysis and the Assessment of Direct and Indirect Effects</p></li>
<li><p>Adaptability, External validity and Sample Selection Bias: are still researched under “domain adaptation”, “transfer learning”</p></li>
<li><p>Recovering from missing data</p></li>
<li>
<p>Causal Discovery:</p>
<ol style="list-style-type: decimal">
<li><p>d-separation</p></li>
<li><p>Functional decomposition <span class="citation">(<a href="references.html#ref-hoyer2008" role="doc-biblioref">Hoyer et al. 2008</a>; <a href="references.html#ref-shimizu2009" role="doc-biblioref">Shimizu, Hoyer, and Hyvärinen 2009</a>; <a href="references.html#ref-chen2012a" role="doc-biblioref">Z. Chen and Chan 2012</a>)</span></p></li>
<li><p>Spontaneous local changes <span class="citation">(<a href="references.html#ref-pearla" role="doc-biblioref">Pearl 2013</a>)</span></p></li>
</ol>
</li>
</ol>
<p><br></p>
<p>Simpson’s Paradox:</p>
<ul>
<li>A statistical association seen in an entire population is reversed in sub-population.</li>
</ul>
<p>Structural Causal Model accompanies graphical causal model to create more efficient language to represent causality</p>
<p>Structural Causal Model is the solution to the curse of dimensionality (i.e., large numbers of variable <span class="math inline">\(p\)</span>, and small dataset <span class="math inline">\(n\)</span>) thanks to product decomposition. It allows us to solve problems without knowing the function, parameters, or distributions of the error terms.</p>
<p>Suppose you have a causal chain <span class="math inline">\(X \to Y \to Z\)</span>:</p>
<p><span class="math display">\[
P(X=x,Y=y, Z=z) = P(X=x)P(Y=y|X=x)P(Z=z|Y=y)
\]</span></p>
<p><br></p>
<p>The three basic paths in DAG are</p>
<div class="figure">
<img src="images/dag.PNG" style="width:100.0%" alt=""><p class="caption">simple dags</p>
</div>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="21%">
<col width="39%">
<col width="39%">
</colgroup>
<thead><tr class="header">
<th>
<p>The Chain</p>
(Mediation)</th>
<th>
<p>The Fork</p>
(Backdoor)</th>
<th>The Collider</th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(A \to C \to B\)</span></td>
<td><span class="math inline">\(A \leftarrow C \rightarrow B\)</span></td>
<td><span class="math inline">\(A \rightarrow C \leftarrow B\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(A \not\perp B\)</span></td>
<td><span class="math inline">\(A \not\perp B\)</span></td>
<td><span class="math inline">\(A \perp B\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(A \perp B | C\)</span></td>
<td><span class="math inline">\(A \perp B | C\)</span></td>
<td><span class="math inline">\(A \not\perp B | C\)</span></td>
</tr>
</tbody>
</table></div>
<p>Hence, we can see that only in the collider’s case that we can open the dependence path between A and B by conditioning on the collider C. More general, a path can be blocked iff:</p>
<ul>
<li><p>For collider path, the collider (or its descendants) is not conditioned on.</p></li>
<li><p>For non-collider path, the connector (either mediator or confounder) is conditioned on.</p></li>
</ul>
<p><span class="math inline">\(C\)</span> d-seperates <span class="math inline">\(A\)</span> from <span class="math inline">\(B\)</span> if it blocks all paths from <span class="math inline">\(A \to B\)</span></p>
<p>d-seperation means that <span class="math inline">\(A \perp B | C\)</span></p>
<p><br></p>
</div>
<div id="intro-to-po-framework" class="section level2" number="17.2">
<h2>
<span class="header-section-number">17.2</span> Intro to PO Framework<a class="anchor" aria-label="anchor" href="#intro-to-po-framework"><i class="fas fa-link"></i></a>
</h2>
<p>The origin of the potential outcomes framework can be traced back to <span class="citation">(<a href="references.html#ref-rubin1974" role="doc-biblioref">Rubin 1974</a>)</span></p>
<p>Let <span class="math inline">\(i = 1, \dots, n\)</span> be a set of i.i.d subjects where we observe</p>
<ul>
<li>
<span class="math inline">\(X_i \in R^p\)</span> (feature vector)</li>
</ul>
<p><span class="math display">\[
T_i =
\begin{cases}
1 &amp; \text{if unit i is treated} \\
0 &amp; \text{if unit i is untreated}
\end{cases}
\]</span></p>
<p>Conventionally, people usually use <span class="math inline">\(T\)</span> or <span class="math inline">\(D\)</span> to denote treatment assignment, sometimes even <span class="math inline">\(W\)</span></p>
<p><span class="math inline">\(Y_i \in R\)</span> (observed outcome) is the variable of interest where we have the fundamental problem of causal inference presents itself. Until we have the time machine to travel back in time or dimensional portal to travel between parallel universes, we will never observe <strong>potential outcome</strong> (outcome that would have happened if the untreated unit was treated or if the treated unit was untreated)</p>
<ul>
<li><p>Potential outcome that happened is called <strong>factual</strong>.</p></li>
<li><p>Potential outcome that didn’t occur is <strong>counterfactual</strong>.</p></li>
</ul>
<p><span class="math display">\[
\text{potential outcome} =
\begin{cases}
Y_i(1) = Y_{1i} \text{ if } T_i = 1 \\
Y_i(0) = Y_{0i} \text{ if } T_i = 0
\end{cases}
\]</span></p>
<p>Note: the two notations are equivalent</p>
<p>We only observe is the outcome given treatment assignment</p>
<p><span class="math display">\[
Y_i = Y_i (T_i)= Y_{1i} T_i + Y_{0i} (1 - T_i)
\]</span></p>
<p>Then, the individual causal treatment effect is</p>
<p><span class="math display">\[
Y_i(1) - Y_i(0)
\]</span></p>
<p>Our goal is usually to estimate the [Average Treatment Effect]</p>
<p><span class="math display">\[
\tau = E[Y_i(1)- Y_i(0)]
\]</span></p>
<p>Since we only observe one realization of <span class="math inline">\(Y_i = Y_i(T_i)\)</span> (under we either have a time-machine, or dimensional portal to travel between parallel universes), this is a fundamental problem in causal inference (people also think of this as “missing data” problem).</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="49%">
<col width="50%">
</colgroup>
<thead><tr class="header">
<th>Experimental Design</th>
<th>Quasi-experimental Design</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Experimentalist</td>
<td>Observationalist</td>
</tr>
<tr class="even">
<td>Experimental Data</td>
<td>Observational Data</td>
</tr>
<tr class="odd">
<td>Random Assignment (reduce treatment imbalance)</td>
<td>Random Sampling (reduce sample selection error)</td>
</tr>
</tbody>
</table></div>
<p>Tools in a hierarchical order</p>
<ol style="list-style-type: decimal">
<li><p><a href="experimental-design.html#experimental-design">Experimental Design</a>: Randomized Control Trials (Gold standard): Tier 1</p></li>
<li>
<p><a href="quasi-experimental.html#quasi-experimental">Quasi-experimental</a></p>
<ol style="list-style-type: decimal">
<li><p><a href="regression-discontinuity.html#regression-discontinuity">Regression Discontinuity</a> Tier 1A</p></li>
<li><p><a href="difference-in-differences.html#difference-in-differences">Difference-In-Differences</a> Tier 2</p></li>
<li><p><a href="synthetic-control.html#synthetic-control">Synthetic Control</a> Tier 2A</p></li>
<li><p><a href="event-studies.html#event-studies">Event Studies</a> Tier 2B</p></li>
<li><p>Fixed Effects Estimator <a href="data.html#fixed-effects-estimator">12.4.2.2</a>: Tier 3</p></li>
<li><p><a href="endogeneity.html#endogenous-treatment">Endogenous Treatment</a>: mostly <a href="endogeneity.html#instrumental-variable">Instrumental Variable</a>: Tier 3A</p></li>
<li><p><a href="matching-methods.html#matching-methods">Matching Methods</a> Tier 4</p></li>
<li><p><a href="interrupted-time-series.html#interrupted-time-series">Interrupted Time Series</a> Tier 4A</p></li>
<li><p>Endogenous Sample Selection <a href="endogeneity.html#endogenous-sample-selection">31.4</a>: mostly Heckman’s correction</p></li>
<li><p><a href="doubly-robust-estimator.html#doubly-robust-estimator">Doubly Robust Estimator</a></p></li>
</ol>
</li>
</ol>
<p>Internal vs. External Validity</p>
<ul>
<li><p>Internal Validity: Economists and applied scientists mostly care about</p></li>
<li><p>External Validity: Localness might affect your external validity</p></li>
</ul>
<p>For many economic policies, there is a difference between <strong>treatment</strong> and <strong>intention to treat</strong>.</p>
<p>For example, we might have an effective vaccine (i.e., intention to treat), but it does not mean that everybody will take it (i.e., treatment).</p>
<p>There are four types of subjects that we deal with:</p>
<ul>
<li>
<p><strong>Non-switchers</strong>: we don’t care about non-switchers because even if we introduce or don’t introduce the intervention, it won’t affect them.</p>
<ul>
<li><p><strong>Always takers</strong></p></li>
<li><p><strong>Never takers</strong></p></li>
</ul>
</li>
<li>
<p><strong>Switchers</strong></p>
<ul>
<li>
<p><strong>Compliers</strong>: defined as those who respect the intervention.</p>
<ul>
<li><p>We only care about compliers because when we introduce the intervention, they will do something. When we don’t have any interventions, they won’t do it.</p></li>
<li><p>Tools above are used to identify the causal impact of an intervention on compliers</p></li>
<li><p>If we have only <strong>compliers</strong> in our dataset, then <strong>intention to treatment = treatment effect</strong>.</p></li>
</ul>
</li>
<li>
<p><strong>Defiers</strong>: those who will go to the opposite direction of your treatment.</p>
<ul>
<li>We typically aren’t interested in defiers because they will do the opposite of what we want them to do. And they are typically a small group; hence, we just assume they don’t exist.</li>
</ul>
</li>
</ul>
</li>
</ul>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th></th>
<th>Treatment Assignment</th>
<th>Control Assignment</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Compliers</td>
<td>Treated</td>
<td>No Treated</td>
</tr>
<tr class="even">
<td>Always-takers</td>
<td>Treated</td>
<td>Treated</td>
</tr>
<tr class="odd">
<td>Never-takers</td>
<td>Not treated</td>
<td>No treated</td>
</tr>
<tr class="even">
<td>Defiers</td>
<td>Not treated</td>
<td>Treated</td>
</tr>
</tbody>
</table></div>
<p><br></p>
<p>Directional Bias due to selection into treatment comes from 2 general opposite sources</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="3%">
<col width="47%">
<col width="48%">
</colgroup>
<thead><tr class="header">
<th></th>
<th><strong>Mitigation-based</strong></th>
<th><strong>Preference-based</strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Reason</td>
<td>Units select into treatment to combat a problem</td>
<td>Units select into treatment because units like that kind of treatment</td>
</tr>
<tr class="even">
<td>Notation</td>
<td><span class="math inline">\(E(Y_0 | T=1) &lt; E(Y_0|T=0)\)</span></td>
<td><span class="math inline">\(E(Y_0 |T=1) &gt; E(Y_0 |T=0)\)</span></td>
</tr>
<tr class="odd">
<td>In words</td>
<td>Units in the treated group without the treatment is already worse than units in the control group without the treatment.</td>
<td>Units in the treated group without the treatment is already better than units in the control group without the treatment.</td>
</tr>
</tbody>
</table></div>
<p><br></p>
<div id="typical-assumptions" class="section level3" number="17.2.1">
<h3>
<span class="header-section-number">17.2.1</span> Typical Assumptions<a class="anchor" aria-label="anchor" href="#typical-assumptions"><i class="fas fa-link"></i></a>
</h3>
<div id="sutva" class="section level4" number="17.2.1.1">
<h4>
<span class="header-section-number">17.2.1.1</span> SUTVA<a class="anchor" aria-label="anchor" href="#sutva"><i class="fas fa-link"></i></a>
</h4>
<ul>
<li>Stable Unit Treatment Values Assumption</li>
</ul>
<ol style="list-style-type: decimal">
<li>The potential outcomes for any unit are not affected by the treatment assignment/exposure of another unit (also known as no interference)</li>
<li>There are no hidden variations of treatment</li>
</ol>
<p>Violations include</p>
<ul>
<li>Spillover between units in different treatment groups</li>
</ul>
<p>There are several hypotheses regarding spillovers:</p>
<ul>
<li><p>Contagion (e.g., vaccine)</p></li>
<li><p>Displacement (e.g., police intervention displace criminals)</p></li>
<li><p>Communication (e.g., viral products)</p></li>
<li><p>Social comparison (e.g., housing assistance can also affect how control group evaluates their homes)</p></li>
<li><p>Signalling</p></li>
<li><p>Persistence and memory: individuals can remember, and their treatment effect can be carried over.</p></li>
</ul>
</div>
<div id="independence-assumption" class="section level4" number="17.2.1.2">
<h4>
<span class="header-section-number">17.2.1.2</span> Independence Assumption<a class="anchor" aria-label="anchor" href="#independence-assumption"><i class="fas fa-link"></i></a>
</h4>
<p><span class="math display">\[
\{Y_i(0)), Y_i(1)\} \perp T_i
\]</span></p>
<p>Potential outcomes are independent of the treatment status.</p>
<p>Random assignment under <a href="experimental-design.html#experimental-design">Experimental Design</a> can introduce Independence between treatment status and potential outcomes</p>
</div>
<div id="unconfoundedness" class="section level4" number="17.2.1.3">
<h4>
<span class="header-section-number">17.2.1.3</span> Unconfoundedness<a class="anchor" aria-label="anchor" href="#unconfoundedness"><i class="fas fa-link"></i></a>
</h4>
<p><span class="math display">\[
[\{Y_i(0)), Y_i(1)\} \perp T_i] | X_i
\]</span></p>
<p>Potential outcomes given some characteristics are independent of the treatment</p>
<p>This is a weaker form of the <a href="causal-inference.html#independence-assumption">Independence Assumption</a> where under <a href="quasi-experimental.html#quasi-experimental">Quasi-experimental</a> design, we typically have this assumption.</p>
</div>
<div id="bounded-propensity-score" class="section level4" number="17.2.1.4">
<h4>
<span class="header-section-number">17.2.1.4</span> Bounded propensity score<a class="anchor" aria-label="anchor" href="#bounded-propensity-score"><i class="fas fa-link"></i></a>
</h4>
<p>Also known as overlap: <span class="math inline">\(e(X) \in (0,1)\)</span> (i.e., the propensity scores are bounded for all possible value of <span class="math inline">\(X\)</span>).</p>
<p><br></p>
</div>
</div>
<div id="treatment-effect-types" class="section level3" number="17.2.2">
<h3>
<span class="header-section-number">17.2.2</span> Treatment effect types<a class="anchor" aria-label="anchor" href="#treatment-effect-types"><i class="fas fa-link"></i></a>
</h3>
<p>Terminology:</p>
<ul>
<li><p>Quantities of causal interest (i.e., treatment effect types)</p></li>
<li><p>Estimands: parameters of interest</p></li>
<li><p>Estimators: procedures to calculate hesitates for the parameters of interest</p></li>
</ul>
<p>Sources of bias (<a href="https://www.youtube.com/watch?v=CjZnQ3ToJjg">according to prof. Luke Keele</a>)</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{Estimator - True Causal Effect} \\
&amp;= \text{Hidden bias + Misspecification bias + Statistical Noise} \\
&amp;= \text{Due to design + Due to modeling + Due to finite sample}
\end{aligned}
\]</span></p>
<p><br></p>
<div id="average-treatment-effects" class="section level4" number="17.2.2.1">
<h4>
<span class="header-section-number">17.2.2.1</span> Average Treatment Effects<a class="anchor" aria-label="anchor" href="#average-treatment-effects"><i class="fas fa-link"></i></a>
</h4>
<p>Average treatment effect (ATE) is the difference in means of the treated and control groups</p>
<p><strong>Randomization</strong> under <a href="experimental-design.html#experimental-design">Experimental Design</a> can provide an unbiased estimate of ATE.</p>
<p>Let <span class="math inline">\(Y_i(1)\)</span> denote the outcome of individual <span class="math inline">\(i\)</span> under treatment and</p>
<p><span class="math inline">\(Y_i(0)\)</span> denote the outcome of individual <span class="math inline">\(i\)</span> under control</p>
<p>Then, the treatment effect for individual <span class="math inline">\(i\)</span> is the difference between her outcome under treatment and control</p>
<p><span class="math display">\[
\tau_i = Y_i(1) - Y_i(0)
\]</span></p>
<p>Without a time machine or dimension portal, we can only observe one of the two event: either individual <span class="math inline">\(i\)</span> experiences the treatment or she doesn’t.</p>
<p>Then, the ATE as a quantity of interest can come in handy since we can observe across all individuals</p>
<p><span class="math display">\[
ATE = \frac{1}{N} \sum_{i=1}^N \tau_i = \frac{\sum_1^N Y_i(1)}{N} - \frac{\sum_i^N Y_i(0)}{N}
\]</span></p>
<p>With random assignment (i.e., treatment assignment is independent of potential outcome and observables and unobservables), the observed means difference between the two groups is an unbiased estimator of the average treatment effect</p>
<p><span class="math display">\[
E(Y_i (1) |D = 1) = E(Y_i(1)|D=0) = E(Y_i(1)) \\
E(Y_i(0) |D = 1) = E(Y_i(0)|D = 0 ) = E(Y_i(0))
\]</span></p>
<p><span class="math display">\[
ATE = E(Y_i(1)) - E(Y_i(0))
\]</span></p>
</div>
<div id="conditional-average-treatment-effects" class="section level4" number="17.2.2.2">
<h4>
<span class="header-section-number">17.2.2.2</span> Conditional Average Treatment Effects<a class="anchor" aria-label="anchor" href="#conditional-average-treatment-effects"><i class="fas fa-link"></i></a>
</h4>
<p>Treatment effects can be different for different groups of people. In words, treatment effects can vary across subgroups.</p>
<p>To examine the heterogeneity across groups (e.g., men vs. women), we can estimate the conditional average treatment effects (CATE) for each subgroup</p>
<p><span class="math display">\[
\begin{aligned}
CATE &amp;= E[Y(1) - Y(0) |X] \\
&amp;= E[Y_i(1)|X_i = x , T_i = 1] - E[Y_i(0)|X_i = x , T_i = 0] \\
&amp;= E[Y_i | X_i = x, T_i = 1] - E[Y_i |X_i = x, T_i = 0] &amp;&amp; \text{unconfoundedness} \\
&amp;= \mu_1 (X) - \mu_0(X)
\end{aligned}
\]</span></p>
<p>To estimate CATE, we need 2 identification assumptions:</p>
<ol style="list-style-type: decimal">
<li><p><a href="causal-inference.html#unconfoundedness">Unconfoundedness</a></p></li>
<li>
</ol>
<p>Approaches to CATE:</p>
<ol style="list-style-type: decimal">
<li>Learner methods (e.g., T-, S-, X-learners)</li>
<li>Transformed outcome <span class="citation">(<a href="references.html#ref-athey2016" role="doc-biblioref">Athey and Imbens 2016</a>)</span>. Causal tree is a regression tree developed to minimize expected MSE of treatment effect.</li>
</ol>
<p>Why estimating CATE is difficult?</p>
<ul>
<li><p>Treatment effects can be weak. Hence, estimating its heterogeneity is even harder than <a href="causal-inference.html#average-treatment-effects">ATE</a></p></li>
<li><p>Selection on observables <span class="math inline">\(X_i\)</span> which might violate <a href="%24(Y(1)%20,%20Y(0))%20%5Cperp%20T%20%7C%20X%24">Unconfoundedness</a></p></li>
<li><p>Selection on unobservables <span class="math inline">\(U_i\)</span> which might violate <a href="%24(Y(1)%20,%20Y(0))%20%5Cperp%20T%20%7C%20X%24">Unconfoundedness</a></p></li>
<li><p>Interference across units (violate <a href="causal-inference.html#sutva">SUTVA</a>)</p></li>
</ul>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="3%">
<col width="41%">
<col width="13%">
<col width="41%">
</colgroup>
<thead><tr class="header">
<th></th>
<th><a href="causal-inference.html#t-learners">T-learners</a></th>
<th><a href="causal-inference.html#s-learners">S-learners</a></th>
<th><a href="causal-inference.html#x-learners">X-learners</a></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Good</td>
<td>
<p>When there are no common trends in the response under control and treatment</p>
<p>When the treatment effect is very complicated</p>
</td>
<td>When CATE is mostly 0.</td>
<td>
<p>CATE is mostly 0</p>
<p>CATE is linear</p>
<p>When the number of units in one group is much larger than that of the other</p>
</td>
</tr>
<tr class="even">
<td>Bad</td>
<td>When the treatment effect is simple</td>
<td>Can be biased toward 0</td>
<td>
<p>When CATE is 0, it’s better than T, but worse than S</p>
<p>When CATE is complex, it’s better than S, and T</p>
</td>
</tr>
</tbody>
</table></div>
<p>Rule of thumb by <span class="citation">(<a href="references.html#ref-k%C3%BCnzel2019" role="doc-biblioref">Künzel et al. 2019</a>)</span> is that unless you know that CATE is mostly 0, use <a href="causal-inference.html#x-learners">X-learners</a> with</p>
<ul>
<li><p>BART in small data sets</p></li>
<li><p>RF in big data sets</p></li>
</ul>
<p>These meta-learners algorithms were introduced by <span class="citation">(<a href="references.html#ref-k%C3%BCnzel2019" role="doc-biblioref">Künzel et al. 2019</a>)</span> to estimate <a href="causal-inference.html#conditional-average-treatment-effects">Conditional Average Treatment Effects</a></p>
<p>Since there is no package in <code>R</code> yet, the <code>causalml</code> module in <code>python</code> is an implementation of these learners’ algorithms. <a href="https://causalml.readthedocs.io/en/latest/examples.html">Examples</a></p>
<div class="sourceCode" id="cb318"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/grf-labs/grf">grf</a></span><span class="op">)</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>
<span class="co"># Generate data</span>

<span class="co"># randomized trial</span>
<span class="va">n</span> <span class="op">&lt;-</span> <span class="fl">2000</span> <span class="co"># sample size</span>
<span class="va">p</span> <span class="op">&lt;-</span> <span class="fl">10</span> <span class="co"># number of variables (dimensions)</span>
<span class="va">X</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span> <span class="op">*</span> <span class="va">p</span><span class="op">)</span>, <span class="va">n</span>, <span class="va">p</span><span class="op">)</span> <span class="co"># feature matrix</span>
<span class="va">treat.prob</span> <span class="op">=</span> <span class="fl">0.5</span>
<span class="va">W</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span><span class="va">n</span>, <span class="fl">1</span> , <span class="va">treat.prob</span><span class="op">)</span>
<span class="va">tau</span> <span class="op">&lt;-</span> <span class="fl">1</span><span class="op">/</span><span class="op">(</span><span class="fl">1</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">X</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span><span class="op">)</span><span class="op">)</span>
<span class="va">Y</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">pmax</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="va">X</span><span class="op">[</span>,<span class="fl">2</span><span class="op">]</span> , <span class="fl">0</span><span class="op">)</span> <span class="op">+</span> <span class="va">W</span> <span class="op">*</span> <span class="va">tau</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="va">n</span><span class="op">)</span></code></pre></div>
<div id="t-learners" class="section level5" number="17.2.2.2.1">
<h5>
<span class="header-section-number">17.2.2.2.1</span> T-learners<a class="anchor" aria-label="anchor" href="#t-learners"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>This is the most common meta-algorithm approach</p></li>
<li><p>T here just means two as in two-tree learner under tree-based methods.</p></li>
</ul>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate the control response function <span class="math inline">\(\mu_0(X) = E(Y(0) |X)\)</span> using control units by either parametric or non-parametric methods</li>
<li>Estimate the treatment response function <span class="math inline">\(\mu_1(X) =E(Y(1)|X)\)</span> using treated units by either parametric or non-parametric methods (can be different from the first step)</li>
<li>Take the difference <span class="math inline">\(\hat{\tau} = \hat{\mu}_1 (X) - \hat{\mu}_0 (X)\)</span>
</li>
</ol>
<div class="sourceCode" id="cb319"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># codes from the grf package</span>
<span class="va">tf0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/grf/man/regression_forest.html">regression_forest</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">0</span>,<span class="op">]</span>, <span class="va">Y</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span><span class="op">)</span>
<span class="va">tf1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/grf/man/regression_forest.html">regression_forest</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">1</span>,<span class="op">]</span>, <span class="va">Y</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span><span class="op">)</span>

<span class="co"># predict mu_0 from the subset of obs with T_i = 0</span>
<span class="va">tf.preds.0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tf0</span>, <span class="va">X</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span>
<span class="co"># predict mu_1 from the subset of obs with T_i = 1</span>
<span class="va">tf.preds.1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tf1</span>, <span class="va">X</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span>

<span class="co"># out-of-bag predictions</span>
<span class="va">tf.preds.0</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tf0</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span> 
<span class="va">tf.preds.1</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">tf1</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span>

<span class="va">preds.tf</span> <span class="op">=</span> <span class="va">tf.preds.1</span> <span class="op">-</span> <span class="va">tf.preds.0</span>

<span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">X</span><span class="op">[</span>,<span class="fl">3</span><span class="op">]</span>, <span class="va">preds.tf</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="17-causality_files/figure-html/unnamed-chunk-2-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="s-learners" class="section level5" number="17.2.2.2.2">
<h5>
<span class="header-section-number">17.2.2.2.2</span> S-learners<a class="anchor" aria-label="anchor" href="#s-learners"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>S here means single as single estimator</p></li>
<li><p>Consider treatment variable <span class="math inline">\(T\)</span> as another covariate in the feature matrix <span class="math inline">\(X\)</span></p></li>
<li><p>Use a single model to model</p></li>
</ul>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate one combined response function <span class="math inline">\(\mu(X,W) = E(Y^{obs}|X, W)\)</span> using either parametric or non-parametric methods on the entire dataset</li>
<li>Take the difference between predicted values when a unit takes treatment versus control: <span class="math inline">\(\hat{\tau} = \hat{\mu}(X,1) - \hat{\mu}(X,0)\)</span>
</li>
</ol>
<div class="sourceCode" id="cb320"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># codes from the grf package</span>
<span class="co"># using random forest to implement S-learner</span>
<span class="va">sf</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/pkg/grf/man/regression_forest.html">regression_forest</a></span><span class="op">(</span><span class="fu"><a href="https://amices.org/mice/reference/cbind.html">cbind</a></span><span class="op">(</span><span class="va">X</span>,<span class="va">W</span><span class="op">)</span>, <span class="va">Y</span><span class="op">)</span>

<span class="va">pred.sf.0</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">sf</span>, <span class="fu"><a href="https://amices.org/mice/reference/cbind.html">cbind</a></span><span class="op">(</span><span class="va">X</span>,<span class="fl">0</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span>
<span class="va">pred.sf.1</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">sf</span>, <span class="fu"><a href="https://amices.org/mice/reference/cbind.html">cbind</a></span><span class="op">(</span><span class="va">X</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span>

<span class="co"># out-of-bag predcitions</span>
<span class="va">preds.sf.oob</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">sf</span><span class="op">)</span><span class="op">$</span><span class="va">predictions</span>
<span class="va">pred.sf.0</span><span class="op">[</span><span class="va">W</span><span class="op">==</span><span class="fl">0</span><span class="op">]</span> <span class="op">=</span> <span class="va">preds.sf.oob</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">0</span><span class="op">]</span>
<span class="va">pred.sf.1</span><span class="op">[</span><span class="va">W</span><span class="op">==</span><span class="fl">1</span><span class="op">]</span> <span class="op">=</span> <span class="va">preds.sf.oob</span><span class="op">[</span><span class="va">W</span> <span class="op">==</span> <span class="fl">1</span><span class="op">]</span>

<span class="va">preds.sf</span> <span class="op">=</span> <span class="va">pred.sf.1</span> <span class="op">-</span> <span class="va">pred.sf.0</span></code></pre></div>
</div>
<div id="x-learners" class="section level5" number="17.2.2.2.3">
<h5>
<span class="header-section-number">17.2.2.2.3</span> X-learners<a class="anchor" aria-label="anchor" href="#x-learners"><i class="fas fa-link"></i></a>
</h5>
<p>Good with</p>
<ul>
<li><p>Unbalanced design (e.g., control or treatment group is much larger than the other one)</p></li>
<li><p>Prior knowledge of CATE structure (e.g., smoothness, sparsity, lots of 0, or approximately linear)</p></li>
</ul>
<p>Steps:</p>
<ol style="list-style-type: decimal">
<li>Estimate the control response function <span class="math inline">\(\mu_0(X) = E(Y(0) |X)\)</span> using control units by either parametric or non-parametric methods</li>
<li>Estimate the treatment response function <span class="math inline">\(\mu_1(X) =E(Y(1)|X)\)</span> using treated units by either parametric or non-parametric methods (can be different from the first step)</li>
<li>Impute the treatment effects for treated units based on the control outcome estimator <span class="math inline">\(\tilde{D}_i^1 = Y_i^1 - \hat{\mu}_0(X_i^1)\)</span>
</li>
<li>Impute the treatment effects for control units based on the treatment outcome estimator <span class="math inline">\(\tilde{D}_i^0 = \hat{\mu}_1 (X_i^0)- Y_i^0\)</span>
</li>
<li>Using the imputed treatment effects as the response variable in the treatment group to obtain <span class="math inline">\(\hat{\tau}_1(X)\)</span>
</li>
<li>Using the imputed treatment effects as the response variable in the control group to obtain <span class="math inline">\(\hat{\tau}_0(X)\)</span>
</li>
<li>Estimate CATE by the weighted average of the two estimates in 5 and 6: <span class="math inline">\(\hat{\tau}(X) = g(X) \hat{\tau}_0(X) + (1- g(X)) \hat{\tau}_1(X)\)</span> where <span class="math inline">\(g \in [0,1]\)</span>
</li>
</ol>
<p>Now here you have to choice of <span class="math inline">\(g\)</span></p>
<ol style="list-style-type: decimal">
<li>Use estimate of the propensity score</li>
<li>Use <span class="math inline">\(g=1\)</span> if the number of treated units is very large compared to the number of control units</li>
<li>Use <span class="math inline">\(g=0\)</span> if the number of treated units is very small compared to the number of control units</li>
</ol>
</div>
<div id="other-learner" class="section level5" number="17.2.2.2.4">
<h5>
<span class="header-section-number">17.2.2.2.4</span> Other-learner<a class="anchor" aria-label="anchor" href="#other-learner"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>R-learner: <span class="citation">(<a href="references.html#ref-nie2021quasi" role="doc-biblioref">Nie and Wager 2021</a>)</span> uses the CV out-of-fold estimates of outcomes and propensity scores to minimize the R-loss function.</p></li>
<li><p>Doubly Robust (DR) learner <span class="citation">(<a href="references.html#ref-kennedy2020optimal" role="doc-biblioref">Kennedy 2020</a>)</span> uses a doubly robust score function to estimate the CATE</p></li>
<li><p>Doubly Robust Instrumental Variable (DRIV) learner combines the DR-learner with doubly robust score function for LATE to estimate conditional LATE <span class="citation">(<a href="references.html#ref-chernozhukov2018" role="doc-biblioref">Chernozhukov et al. 2018</a>)</span></p></li>
</ul>
</div>
<div id="robust-estimation-of-heterogeneous-treatment-effect" class="section level5" number="17.2.2.2.5">
<h5>
<span class="header-section-number">17.2.2.2.5</span> Robust Estimation of Heterogeneous Treatment Effect<a class="anchor" aria-label="anchor" href="#robust-estimation-of-heterogeneous-treatment-effect"><i class="fas fa-link"></i></a>
</h5>
<p>Assume that we have <a href="causal-inference.html#sutva">SUTVA</a> and <a href="%24(Y(1)%20,%20Y(0))%20%5Cperp%20T%20%7C%20X%24">Unconfoundedness</a></p>
<p>This section studies how treatment effects vary across units. But knowing the individual treatment effect is impossible. Hence, we move our goal to understand how treatment effect vary across group of units (i.e., units that share the same covariate value)</p>
</div>
</div>
<div id="intent-to-treat-effects" class="section level4" number="17.2.2.3">
<h4>
<span class="header-section-number">17.2.2.3</span> Intent-to-treat Effects<a class="anchor" aria-label="anchor" href="#intent-to-treat-effects"><i class="fas fa-link"></i></a>
</h4>
<p>When we encounter non-compliance (either people suppose to receive treatment don’t receive it, or people suppose to be in the control group receive the treatment), treatment receipt is not independent of potential outcomes and confounders.</p>
<p>In this case, the difference in observed means between the treatment and control groups is not <a href="causal-inference.html#average-treatment-effects">Average Treatment Effects</a>, but <a href="causal-inference.html#intent-to-treat-effects">Intent-to-treat Effects</a> (ITT). In words, ITT is the treatment effect on those who <strong>receive</strong> the treatment</p>
<p><br></p>
</div>
<div id="local-average-treatment-effects" class="section level4" number="17.2.2.4">
<h4>
<span class="header-section-number">17.2.2.4</span> Local Average Treatment Effects<a class="anchor" aria-label="anchor" href="#local-average-treatment-effects"><i class="fas fa-link"></i></a>
</h4>
<p>Instead of estimating the treatment effects of those who <strong>receive</strong> the treatment (i.e., <a href="causal-inference.html#intent-to-treat-effects">Intent-to-treat Effects</a>), you want to estimate the treatment effect of those who actually <strong>comply</strong> with the treatment. This is the local average treatment effects (LATE) or complier average causal effects (CACE). I assume we don’t use CATE to denote complier average treatment effect because it was reserved for conditional average treatment effects.</p>
<ul>
<li>Using random treatment assignment as an instrument, we can recover the effect of treatment on compliers.</li>
</ul>
<div class="inline-figure"><img src="images/iv_late.PNG" style="width:100.0%"></div>
<ul>
<li><p>As the percent of compliers increases, <a href="causal-inference.html#intent-to-treat-effects">Intent-to-treat Effects</a> and <a href="causal-inference.html#local-average-treatment-effects">Local Average Treatment Effects</a> converge</p></li>
<li><p>Rule of thumb: SE(LATE) = SE(ITT)/(share of compliers)</p></li>
<li><p>LATE estimate is always greater than the ITT estimate</p></li>
<li><p>LATE can also be estimated using a pure placebo group <span class="citation">(<a href="references.html#ref-gerber2010" role="doc-biblioref">Gerber et al. 2010</a>)</span>.</p></li>
<li><p>Partial compliance is hard to study, and IV/2SLS estimator is biased, we have to use Bayesian <span class="citation">(<a href="references.html#ref-long2010" role="doc-biblioref">Long, Little, and Lin 2010</a>; <a href="references.html#ref-jin2009" role="doc-biblioref">Jin and Rubin 2009</a>; <a href="references.html#ref-jin2008" role="doc-biblioref">Jin and Rubin 2008</a>)</span>.</p></li>
</ul>
<div id="one-sided-noncompliance" class="section level5" number="17.2.2.4.1">
<h5>
<span class="header-section-number">17.2.2.4.1</span> One-sided noncompliance<a class="anchor" aria-label="anchor" href="#one-sided-noncompliance"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>One-sided noncompliance is when in the sample, we only have compliers and never-takers</p></li>
<li><p>With the exclusion restriction (i.e., excludability), never-takers have the same results in the treatment or control group (i.e., never treated)</p></li>
<li><p>With random assignment, we can have the same number of never-takers in the treatment and control groups</p></li>
<li><p>Hence,</p></li>
</ul>
<p><span class="math display">\[
LATE = \frac{ITT}{\text{share of compliers}}
\]</span></p>
</div>
<div id="two-sided-noncompliance" class="section level5" number="17.2.2.4.2">
<h5>
<span class="header-section-number">17.2.2.4.2</span> Two-sided noncompliance<a class="anchor" aria-label="anchor" href="#two-sided-noncompliance"><i class="fas fa-link"></i></a>
</h5>
<ul>
<li><p>Two-sided noncompliance is when in the sample, we have compliers, never-takers, and always-takers</p></li>
<li><p>To estimate LATE, beyond excludability like in the <a href="causal-inference.html#one-sided-noncompliance">One-sided noncompliance</a> case, we need to assume that there is no defiers (i.e., monotonicity assumption) (this is excusable in practical studies)</p></li>
</ul>
<p><span class="math display">\[
LATE = \frac{ITT}{\text{share of compliers}}
\]</span></p>
</div>
</div>
<div id="population-vs.-sample-average-treatment-effects" class="section level4" number="17.2.2.5">
<h4>
<span class="header-section-number">17.2.2.5</span> Population vs. Sample Average Treatment Effects<a class="anchor" aria-label="anchor" href="#population-vs.-sample-average-treatment-effects"><i class="fas fa-link"></i></a>
</h4>
<p>See <span class="citation">(<a href="references.html#ref-imai2008" role="doc-biblioref">Imai, King, and Stuart 2008</a>)</span> for when the sample average treatment effect (SATE) diverges from the population average treatment effect (PATE).</p>
<p>To stay consistent, this section uses notations from <span class="citation">(<a href="references.html#ref-imai2008" role="doc-biblioref">Imai, King, and Stuart 2008</a>)</span>’s paper.</p>
<p>In a finite population <span class="math inline">\(N\)</span>, we observe <span class="math inline">\(n\)</span> observations (<span class="math inline">\(N&gt;&gt;n\)</span>), where half is in the control and half is in the treatment group.</p>
<p>With unknown data generating process, we have</p>
<p><span class="math display">\[
I_i =
\begin{cases}
1 \text{ if unit i is in the sample} \\
0 \text{ otherwise}
\end{cases}
\]</span></p>
<p><span class="math display">\[
T_i =
\begin{cases}
1 \text{ if unit i is in the treatment group} \\
0 \text{ if unit i is in the control group}
\end{cases}
\]</span></p>
<p><span class="math display">\[
\text{potential outcome} =
\begin{cases}
Y_i(1) \text{ if } T_i = 1 \\
Y_i(0) \text{ if } T_i = 0
\end{cases}
\]</span></p>
<p>Observed outcome is</p>
<p><span class="math display">\[
Y_i | I_i = 1= T_i Y_i(1) + (1-T_i)Y_i(0)
\]</span></p>
<p>Since we can never observed both outcome for the same individual, the treatment effect is always unobserved for unit <span class="math inline">\(i\)</span></p>
<p><span class="math display">\[
TE_i = Y_i(1) - Y_i(0)
\]</span></p>
<p>Sample average treatment effect is</p>
<p><span class="math display">\[
SATE = \frac{1}{n}\sum_{i \in \{I_i = 1\}} TE_i
\]</span></p>
<p>Population average treatment effect is</p>
<p><span class="math display">\[
PATE = \frac{1}{N}\sum_{i=1}^N TE_i
\]</span></p>
<p>Let <span class="math inline">\(X_i\)</span> be observables and <span class="math inline">\(U_i\)</span> be unobservables for unit <span class="math inline">\(i\)</span></p>
<p>The baseline estimator for SATE and PATE is</p>
<p><span class="math display">\[
\begin{aligned}
D &amp;= \frac{1}{n/2} \sum_{i \in (I_i = 1, T_i = 1)} Y_i - \frac{1}{n/2} \sum_{i \in (I_i = 1 , T_i = 0)} Y_i \\
&amp;= \text{observed sample mean of the treatment group} \\
&amp;- \text{observed sample mean of the control group}
\end{aligned}
\]</span></p>
<p>Let <span class="math inline">\(\Delta\)</span> be the estimation error (deviation from the truth), under an additive model</p>
<p><span class="math display">\[
Y_i(t) = g_t(X_i) + h_t(U_i)
\]</span></p>
<p>The decomposition of the estimation error is</p>
<p><span class="math display">\[
\begin{aligned}
PATE - D = \Delta &amp;= \Delta_S + \Delta_T \\
&amp;= (PATE - SATE) + (SATE - D)\\
&amp;= \text{sample selection}+ \text{treatment imbalance} \\
&amp;= (\Delta_{S_X} + \Delta_{S_U}) + (\Delta_{T_X} + \Delta_{T_U}) \\
&amp;= \text{(selection on observed + selection on unobserved)} \\
&amp;+ (\text{treatment imbalance in observed + unobserved})
\end{aligned}
\]</span></p>
<div id="estimation-error-from-sample-selection" class="section level5" number="17.2.2.5.1">
<h5>
<span class="header-section-number">17.2.2.5.1</span> Estimation Error from Sample Selection<a class="anchor" aria-label="anchor" href="#estimation-error-from-sample-selection"><i class="fas fa-link"></i></a>
</h5>
<p>Also known as sample selection error</p>
<p><span class="math display">\[
\Delta_S = PATE - SATE = \frac{N - n}{N}(NATE - SATE)
\]</span></p>
<p>where NATE is the non-sample average treatment effect (i.e., average treatment effect for those in the population but not in your sample:</p>
<p><span class="math display">\[
NATE = \sum_{i\in (I_i = 0)} \frac{TE_i}{N-n}
\]</span></p>
<p>From the equation, to have zero sample selection error (i.e., <span class="math inline">\(\Delta_S = 0\)</span>), we can either</p>
<ul>
<li><p>Get <span class="math inline">\(N = n\)</span> by redefining your sample as the population of interest</p></li>
<li><p><span class="math inline">\(NATE = SATE\)</span> (e.g., <span class="math inline">\(TE_i\)</span> is constant over <span class="math inline">\(i\)</span> in both your selected sample, and those in the population that you did not select)</p></li>
</ul>
<p>Note</p>
<ul>
<li><p>When you have heterogeneous treatment effects, <strong>random sampling</strong> can only warrant <strong>sample selection bias</strong>, not <strong>sample selection error</strong>.</p></li>
<li>
<p>Since we can rarely know the true underlying distributions of the observables (<span class="math inline">\(X\)</span>) and unobservables (<span class="math inline">\(U\)</span>), we cannot verify whether the empirical distributions of your observables and unobservables for those in your sample is identical to that of your population (to reduce <span class="math inline">\(\Delta_S\)</span>). For special case,</p>
<ul>
<li><p>Say you have census of your population, you can adjust for the observables <span class="math inline">\(X\)</span> to reduce <span class="math inline">\(\Delta_{S_X}\)</span>, but still you cannot adjust your unobservables (<span class="math inline">\(U\)</span>)</p></li>
<li>
<p>Say you are willing to assume <span class="math inline">\(TE_i\)</span> is constant over</p>
<ul>
<li><p><span class="math inline">\(X_i\)</span>, then <span class="math inline">\(\Delta_{S_X} = 0\)</span></p></li>
<li><p><span class="math inline">\(U_i\)</span>, then <span class="math inline">\(\Delta_{U}=0\)</span></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div id="estimation-error-from-treatment-imbalance" class="section level5" number="17.2.2.5.2">
<h5>
<span class="header-section-number">17.2.2.5.2</span> Estimation Error from Treatment Imbalance<a class="anchor" aria-label="anchor" href="#estimation-error-from-treatment-imbalance"><i class="fas fa-link"></i></a>
</h5>
<p>Also known as treatment imbalance error</p>
<p><span class="math display">\[
\Delta_T = SATE - D
\]</span></p>
<p><span class="math inline">\(\Delta_T \to 0\)</span> when treatment and control groups are balanced (i.e., identical empirical distributions) for both observables (<span class="math inline">\(X\)</span>) and unobservables (<span class="math inline">\(U\)</span>)</p>
<p>However, in reality, we can only readjust for observables, not unobservables.</p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="10%">
<col width="29%">
<col width="60%">
</colgroup>
<thead><tr class="header">
<th></th>
<th><a href="analysis-of-variance-anova.html#randomized-block-designs">Randomized Block Designs</a></th>
<th><strong><a href="matching-methods.html#matching-methods">Matching Methods</a></strong></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Definition</td>
<td>Random assignment within strata based on pre-treatment observables</td>
<td>Dropping, repeating or grouping observations to balance covariates between the treatment and control group <span class="citation">(<a href="references.html#ref-rubin1973" role="doc-biblioref">Rubin 1973</a>)</span>
</td>
</tr>
<tr class="even">
<td>Time</td>
<td>Before randomization of treatments</td>
<td>After randomization of treatments</td>
</tr>
<tr class="odd">
<td>
<p>What if the set of covariates used to adjust is irrelevant?</p>
<p><span class="citation">(<a href="references.html#ref-imai2008" role="doc-biblioref">Imai, King, and Stuart 2008, 489</a>, para. 4)</span></p>
</td>
<td>Nothing happens (still caution by <span class="citation">(<a href="references.html#ref-pashley2021" role="doc-biblioref">Pashley and Miratrix 2021</a>)</span>)</td>
<td>In the worst case scenario (e.g., these variables are uncorrelated with the treatment assignment, but correlated with the post-treatment variables), matching induces bias that is greater than just using the unadjusted difference in means</td>
</tr>
<tr class="even">
<td>Benefits</td>
<td>
<p><span class="math inline">\(\Delta_{T_X}=0\)</span> (no imbalance on observables). But we don’t know its effect on unobservables imbalance (might reduce if the unobservables are correlated with the observables).</p>
<p>Increase efficiency because it achieves <span class="math inline">\(\Delta_{T_x}=0\)</span>, instead of <span class="math inline">\(E(\Delta_{T_X}) = 0\)</span> if we just use random assignment.</p>
</td>
<td>Reduce model dependence, bias, variance, mean-square error <span class="citation">(<a href="references.html#ref-ho2007" role="doc-biblioref">Ho et al. 2007</a>)</span>
</td>
</tr>
<tr class="odd">
<td>Dangers</td>
<td>No hypothesis can check for balance within strata. You can only check for how your randomization was <span class="citation">(<a href="references.html#ref-imai2008" role="doc-biblioref">Imai, King, and Stuart 2008, 494</a>, para. 3)</span>
</td>
<td>
<p>Hypothesis test on covariates balance between treated and control groups should not be trusted because these tests (e.g., t-test K-S test) are based on not only the balance between the two groups, but also on the statistical power (function of your sample size) <span class="citation">(<a href="references.html#ref-imai2008" role="doc-biblioref">Imai, King, and Stuart 2008, 495–98</a>)</span>. As you drop observations, your statistical power monotonically decreases.</p>
<p><span class="citation">(<a href="references.html#ref-imai2008" role="doc-biblioref">Imai, King, and Stuart 2008, 498</a>)</span> advocate for non-parametric density plots, porepensity score summary statistics <span class="citation">(<a href="references.html#ref-austin2006" role="doc-biblioref">Austin and Mamdani 2006</a>)</span> <span class="citation">(<a href="references.html#ref-rubin" role="doc-biblioref">Rubin 2012</a>)</span>, and quantile-quantile plots</p>
<p>Matching on irrelevant variables is okay (small increase in variance). <span class="citation">(<a href="references.html#ref-ho2007" role="doc-biblioref">Ho et al. 2007</a>)</span></p>
</td>
</tr>
</tbody>
</table></div>
<div class="inline-table"><table class="table table-sm">
<caption>Effects of design choices and assumptions on estimation error</caption>
<colgroup>
<col width="24%">
<col width="18%">
<col width="18%">
<col width="19%">
<col width="19%">
</colgroup>
<thead><tr class="header">
<th></th>
<th>Observables Sample selection estimation error (<span class="math inline">\(\Delta_{S_X}\)</span>)</th>
<th>Unobservables Sample selection estimation error (<span class="math inline">\(\Delta_{S_U}\)</span>)</th>
<th>Observables treatment imbalance estimation error (<span class="math inline">\(\Delta_{T_X}\)</span>)</th>
<th>Unobservables Treatment imbalance estimation error (<span class="math inline">\(\Delta_{T_U}\)</span>)</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Design Feature</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Random Sampling</td>
<td><span class="math inline">\(E(\Delta_{S_X}) = 0\)</span></td>
<td><span class="math inline">\(E(\Delta_{S_U}) =0\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>SATE as quantity of interest (not PATE)</td>
<td><span class="math inline">\(\Delta_{S_X}=0\)</span></td>
<td><span class="math inline">\(\Delta_{S_U}=0\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Weighting for non-random sampling</td>
<td><span class="math inline">\(\Delta_{S_X}=0\)</span></td>
<td><span class="math inline">\(\Delta_{S_u}=?\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(n\to \infty\)</span></td>
<td>
<p><span class="math inline">\(E(\Delta_{S_X}) = 0\)</span></p>
<p><span class="math inline">\(\lim_{n \to \infty}(var(\Delta_{S_X}) = 0\)</span></p>
</td>
<td>
<p><span class="math inline">\(E(\Delta_{S_U}) = 0\)</span></p>
<p><span class="math inline">\(\lim_{n \to \infty}(var(\Delta_{S_U}) = 0\)</span></p>
</td>
<td>
<p><span class="math inline">\(E(\Delta_{T_X}) = 0\)</span></p>
<p><span class="math inline">\(\lim_{n \to \infty}(var(\Delta_{T_X}) = 0\)</span></p>
</td>
<td>
<p><span class="math inline">\(E(\Delta_{T_U}) = 0\)</span></p>
<p><span class="math inline">\(\lim_{n \to \infty}(var(\Delta_{T_U}) = 0\)</span></p>
</td>
</tr>
<tr class="even">
<td>
<p>Random assignment</p>
<p><span class="math inline">\(E(\Delta_{T_X}) = E(\Delta_{T_U}) =0\)</span></p>
</td>
<td></td>
<td></td>
<td><span class="math inline">\(E(\Delta_{T_X}) =0\)</span></td>
<td><span class="math inline">\(E(\Delta_{T_U})=0\)</span></td>
</tr>
<tr class="odd">
<td><a href="analysis-of-variance-anova.html#randomized-block-designs">Randomized Block Designs</a></td>
<td></td>
<td></td>
<td><span class="math inline">\(\Delta_{T_X}=0\)</span></td>
<td><span class="math inline">\(\Delta_{T_U}=?\)</span></td>
</tr>
<tr class="even">
<td>
<a href="matching-methods.html#coarsened-exact-matching">Exact Matching</a> (for studies that estimate PATT or SATT)</td>
<td></td>
<td></td>
<td><span class="math inline">\(\Delta_{T_X}=0\)</span></td>
<td><span class="math inline">\(\Delta_{T_U}=?\)</span></td>
</tr>
<tr class="odd">
<td></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Assumption</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>No Selection Bias</td>
<td><span class="math inline">\(E(\Delta_{S_X}) =0\)</span></td>
<td><span class="math inline">\(E(\Delta_{S_U})=0\)</span></td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>Ignorability</td>
<td></td>
<td></td>
<td></td>
<td><span class="math inline">\(E(\Delta_{T_U}) = 0\)</span></td>
</tr>
<tr class="odd">
<td>No omitted variables (<span class="math inline">\(X\perp U\)</span> or <span class="math inline">\(U | X \nrightarrow Y\)</span>)</td>
<td></td>
<td></td>
<td></td>
<td><span class="math inline">\(\Delta_{T_U}=0\)</span></td>
</tr>
</tbody>
</table></div>
<p>This table was modified from Table 1 in <span class="citation">(<a href="references.html#ref-imai2008" role="doc-biblioref">Imai, King, and Stuart 2008, 488</a>)</span></p>
</div>
</div>
<div id="average-treatment-effects-on-the-treated-and-control" class="section level4" number="17.2.2.6">
<h4>
<span class="header-section-number">17.2.2.6</span> Average Treatment Effects on the Treated and Control<a class="anchor" aria-label="anchor" href="#average-treatment-effects-on-the-treated-and-control"><i class="fas fa-link"></i></a>
</h4>
<p>Average Effect of treatment on the Treated (ATT) is</p>
<p><span class="math display">\[
\begin{aligned}
ATT &amp;= E(Y_i(1) - Y_i(0)|D_i = 1) \\
&amp;= E(Y_i(1)|D_i = 1) - E(Y_i(0) |D_i = 1)
\end{aligned}
\]</span></p>
<p>Average Effect of treatment on the Control (ATC) (i.e., the effect <strong>would be</strong> for those weren’t treated) is</p>
<p><span class="math display">\[
\begin{aligned}
ATC &amp;= E(Y_i(1) - Y_i (0) |D_i =0) \\
&amp;= E(Y_i(1)|D_i = 0) - E(Y_i(0)|D_i = 0)
\end{aligned}
\]</span></p>
<p>Under random assignment and full compliance,</p>
<p><span class="math display">\[
ATE = ATT = ATC
\]</span></p>
<p><strong>Sample average treatment effect on the treated</strong> is</p>
<p><span class="math display">\[
SATT = \frac{1}{n} \sum_i TE_i
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(TE_i\)</span> is the treatment effect for unit <span class="math inline">\(i\)</span></p></li>
<li><p><span class="math inline">\(n\)</span> is the number of treated units in the sample</p></li>
<li><p><span class="math inline">\(i\)</span> belongs the subset (i.e., sample) of the population of interest that is treated.</p></li>
</ul>
<p><strong>Population average treatment effect on the treated</strong> is</p>
<p><span class="math display">\[
PATT = \frac{1}{N} \sum_i TE_i
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(TE_i\)</span> is the treatment effect for unit <span class="math inline">\(i\)</span></p></li>
<li><p><span class="math inline">\(N\)</span> is the number of treated units in the population</p></li>
<li><p><span class="math inline">\(i\)</span> belongs to the population of interest that is treated.</p></li>
</ul>
</div>
<div id="quantile-average-treatment-effects" class="section level4" number="17.2.2.7">
<h4>
<span class="header-section-number">17.2.2.7</span> Quantile Average Treatment Effects<a class="anchor" aria-label="anchor" href="#quantile-average-treatment-effects"><i class="fas fa-link"></i></a>
</h4>
<p>Instead of the middle point estimate (ATE), we can also understand the changes in the distribution the outcome variable due to the treatment.</p>
<p>Using quantile regression and more assumptions <span class="citation">(<a href="references.html#ref-abadie2002" role="doc-biblioref">Abadie, Angrist, and Imbens 2002</a>; <a href="references.html#ref-chernozhukov2005" role="doc-biblioref">Chernozhukov and Hansen 2005</a>)</span>, we can have consistent estimate of quantile treatment effects (QTE), with which we can make inference regarding a given quantile.</p>
</div>
<div id="mediation-effects" class="section level4" number="17.2.2.8">
<h4>
<span class="header-section-number">17.2.2.8</span> Mediation Effects<a class="anchor" aria-label="anchor" href="#mediation-effects"><i class="fas fa-link"></i></a>
</h4>
<p>With additional assumptions (i.e., sequential ignorability <span class="citation">(<a href="references.html#ref-Imai_2010_6060" role="doc-biblioref">Imai, Keele, and Yamamoto 2010</a>; <a href="references.html#ref-bullock2010" role="doc-biblioref">Bullock, Green, and Ha 2010</a>)</span>), we can examine the mechanism of the treatment on the outcome.</p>
<p>Under the causal framework,</p>
<ul>
<li><p>the indirect effect of treatment via a mediator is called average causal mediation effect (ACME)</p></li>
<li><p>the direct effect of treatment on outcome is the average direct effect (ADE)</p></li>
</ul>
<p>More in the <a href="mediation.html#mediation">Mediation</a> Section <a href="mediation.html#mediation">32</a></p>
</div>
<div id="log-odds-treatment-effects" class="section level4" number="17.2.2.9">
<h4>
<span class="header-section-number">17.2.2.9</span> Log-odds Treatment Effects<a class="anchor" aria-label="anchor" href="#log-odds-treatment-effects"><i class="fas fa-link"></i></a>
</h4>
<p>For binary outcome variable, we might be interested in the log-odds of success. See <span class="citation">(<a href="references.html#ref-freedman2008" role="doc-biblioref">Freedman 2008</a>)</span> on how to estimate a consistent causal effect.</p>
<p>Alternatively, attributable effects <span class="citation">(<a href="references.html#ref-rosenbaum2002" role="doc-biblioref">Paul R. Rosenbaum 2002</a>)</span> can also be appropriate for binary outcome.</p>
</div>
</div>
</div>
<div id="controls-under-causal-inference" class="section level2" number="17.3">
<h2>
<span class="header-section-number">17.3</span> Controls under causal inference<a class="anchor" aria-label="anchor" href="#controls-under-causal-inference"><i class="fas fa-link"></i></a>
</h2>
<p>Under prediction, adding as many controls as you like is fine. And you can always be better off with some more advanced machine learning methods (which is covered in the second version of this book - <a href="https://bookdown.org/mike/advanced_data_analysis/">Advanced Data Analysis</a>).</p>
<p>However, under causal inference, there are good controls and there are bad controls.</p>
<div class="figure">
<img src="images/bad_control.PNG" alt="green = good; red = bad" style="width:100.0%"><p class="caption">green = good; red = bad</p>
</div>
<p>In the perfect world, we only need to randomize the treatment and care only about the treatment and control. But since we don’t live in such a world, we need to be careful to whether you want to include or exclude certain variables.</p>
<p>From the DAGs literature, controls are determined based on assessing the path between <span class="math inline">\(X \to Y\)</span></p>
<ul>
<li><p>Good controls: Block all spurious paths between <span class="math inline">\(X \to Y\)</span></p></li>
<li><p>Bad controls: Do not block any causal paths between <span class="math inline">\(X \to Y\)</span></p></li>
</ul>
<p>Technically there are 3 types of control:</p>
<ul>
<li><p>Good control: ATE bias reduction</p></li>
<li><p>Bad control: ATE bias increase</p></li>
<li><p>Neutral control: does not change the asymptotic bias</p></li>
</ul>
<p>Code for numerical simulations are taken from <a href="https://www.kaggle.com/code/carloscinelli/crash-course-in-good-and-bad-controls-linear-r/notebook">Carlos Cinelli</a>’s notebook</p>
<div id="good-controls" class="section level3" number="17.3.1">
<h3>
<span class="header-section-number">17.3.1</span> Good Controls<a class="anchor" aria-label="anchor" href="#good-controls"><i class="fas fa-link"></i></a>
</h3>
<p>Those that are added to eliminate omitted variable bias and are unaffected by the treatment</p>
<p>Two types of good controls:</p>
<ol style="list-style-type: decimal">
<li>Confounders (i.e., those that affect both the treatment and outcome).</li>
<li>Those that can help predict outcome</li>
</ol>
<p>Good controls help explain variability in the outcome variable (i.e., account for variability in the outcome variable). In statistical terms, they help predict the outcome variable and increase <span class="math inline">\(R^2\)</span> under OLS regression. This way we can think that conditioning on the control variables, it’s easier to detect the effect of your causal variable.</p>
<p>Hence, always add control variables that help predict the outcome variables, even if they are not confounders.</p>
<div class="sourceCode" id="cb321"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Load packages</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="http://www.dagitty.net">dagitty</a></span><span class="op">)</span>
<span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/malcolmbarrett/ggdag">ggdag</a></span><span class="op">)</span></code></pre></div>
<div class="sourceCode" id="cb322"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># cleans workspace</span>
<span class="fu"><a href="https://rdrr.io/r/base/rm.html">rm</a></span><span class="op">(</span>list <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/ls.html">ls</a></span><span class="op">(</span><span class="op">)</span><span class="op">)</span>

<span class="co"># DAG</span>

<span class="co">## specify edges</span>
<span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/dagitty/man/dagitty.html">dagitty</a></span><span class="op">(</span><span class="st">"dag{x-&gt;y; z-&gt;x; z-&gt;y}"</span><span class="op">)</span>

<span class="co">## coordinates for plotting</span>
<span class="fu"><a href="https://rdrr.io/pkg/dagitty/man/coordinates.html">coordinates</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span> <span class="op">&lt;-</span>  <span class="fu"><a href="https://rdrr.io/pkg/gsubfn/man/list.html">list</a></span><span class="op">(</span>
  x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>x<span class="op">=</span><span class="fl">1</span>, y<span class="op">=</span><span class="fl">3</span>, z<span class="op">=</span><span class="fl">2</span><span class="op">)</span>,
  y <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span>x<span class="op">=</span><span class="fl">1</span>, y<span class="op">=</span><span class="fl">1</span>, z<span class="op">=</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span>

<span class="co">## ggplot</span>
<span class="fu"><a href="https://rdrr.io/pkg/ggdag/man/ggdag.html">ggdag</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://rdrr.io/pkg/ggdag/man/theme_dag_blank.html">theme_dag</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="17-causality_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;"></div>
</div>
<div id="bad-controls" class="section level3" number="17.3.2">
<h3>
<span class="header-section-number">17.3.2</span> Bad Controls<a class="anchor" aria-label="anchor" href="#bad-controls"><i class="fas fa-link"></i></a>
</h3>
<ol style="list-style-type: decimal">
<li>Mediator 1: those are good predictors of the treatment (not outcome)
<ul>
<li><p>If you control for both the confounder and mediator 1, variance of treatment causal estimate will increase (more likely to contain 0). Hence, it will make it harder for your model to detect the effect of the treatment on the outcome.</p></li>
<li><p>In this case, regressing the model with only the confounder and the treatment on the outcome is sufficient.</p></li>
</ul>
</li>
<li>Mediator 2: those that are mediators between the treatment and outcome
<ul>
<li>Recall from <a href="causal-inference.html#intro-to-dag-framework">Intro to DAG Framework</a> that if we close the path between treatment and outcome by conditioning on this mediator, then treatment and outcome will be independent.</li>
</ul>
</li>
<li>Common effect: those are the joint consequences of both the treatment and outcomes</li>
</ol>
<p>Mediator 2 and common effect are similar in the sense that they are basic <a href="mediation.html#mediation">Mediation</a> analysis (i.e., <span class="math inline">\(X \to M \to Y\)</span>). But in the <a href="mediation.html#mediation">Mediation</a> analysis, we have to readjust the standard error for the treatment <span class="math inline">\(X\)</span>. However, if you just include these two variables into your model as controls, your treatment effect’s standard error will explode</p>
</div>
</div>
<div id="sensitivity-analysis" class="section level2" number="17.4">
<h2>
<span class="header-section-number">17.4</span> Sensitivity Analysis<a class="anchor" aria-label="anchor" href="#sensitivity-analysis"><i class="fas fa-link"></i></a>
</h2>
<p>Recommended by <span class="citation">(<a href="references.html#ref-athey2017" role="doc-biblioref">Athey et al. 2017</a>)</span>, we should report</p>
<ul>
<li><p>Simple difference</p></li>
<li><p>OLS estimator</p></li>
<li><p>Double selection estimator (DSE)</p></li>
<li><p>Approximate residual balancing estimator (ARBE)</p></li>
<li><p>Doubly robust estimator (DRE)</p></li>
<li><p>Double machine learning estimator (DMLE)</p></li>
</ul>
<p>for standard errors:</p>
<ul>
<li><p>simple bootstrap SE</p></li>
<li><p>scaled bootstrap bias</p></li>
</ul>
</div>
</div>



<div class="chapter-nav">
<div class="prev"><a href="bootstrap.html"><span class="header-section-number">16</span> Bootstrap</a></div>
<div class="next"><a href="experimental-design.html"><span class="header-section-number">18</span> Experimental Design</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#causal-inference"><span class="header-section-number">17</span> Causal Inference</a></li>
<li><a class="nav-link" href="#intro-to-dag-framework"><span class="header-section-number">17.1</span> Intro to DAG Framework</a></li>
<li>
<a class="nav-link" href="#intro-to-po-framework"><span class="header-section-number">17.2</span> Intro to PO Framework</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#typical-assumptions"><span class="header-section-number">17.2.1</span> Typical Assumptions</a></li>
<li><a class="nav-link" href="#treatment-effect-types"><span class="header-section-number">17.2.2</span> Treatment effect types</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#controls-under-causal-inference"><span class="header-section-number">17.3</span> Controls under causal inference</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#good-controls"><span class="header-section-number">17.3.1</span> Good Controls</a></li>
<li><a class="nav-link" href="#bad-controls"><span class="header-section-number">17.3.2</span> Bad Controls</a></li>
</ul>
</li>
<li><a class="nav-link" href="#sensitivity-analysis"><span class="header-section-number">17.4</span> Sensitivity Analysis</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/mikenguyen13/data_analysis/blob/main/17-causality.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/mikenguyen13/data_analysis/edit/main/17-causality.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>
</div>
  

  

</div>
 <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>A Guide on Data Analysis</strong>" was written by Mike Nguyen. It was last built on 2022-09-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
