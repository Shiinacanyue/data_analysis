<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>20.1 Completely Randomized Design (CRD) | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="20.1 Completely Randomized Design (CRD) | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://bookdown.org/mike/data_analysis/" />
  <meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />
  <meta property="og:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="20.1 Completely Randomized Design (CRD) | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2022-09-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="logo.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="analysis-of-variance-anova.html"/>
<link rel="next" href="nonparametric-anova.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-9.3.1/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-9.3.1/highcharts.js"></script>
<script src="libs/highcharts-9.3.1/highcharts-3d.js"></script>
<script src="libs/highcharts-9.3.1/highcharts-more.js"></script>
<script src="libs/highcharts-9.3.1/modules/stock.js"></script>
<script src="libs/highcharts-9.3.1/modules/map.js"></script>
<script src="libs/highcharts-9.3.1/modules/data.js"></script>
<script src="libs/highcharts-9.3.1/modules/exporting.js"></script>
<script src="libs/highcharts-9.3.1/modules/offline-exporting.js"></script>
<script src="libs/highcharts-9.3.1/modules/drilldown.js"></script>
<script src="libs/highcharts-9.3.1/modules/item-series.js"></script>
<script src="libs/highcharts-9.3.1/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-9.3.1/modules/annotations.js"></script>
<script src="libs/highcharts-9.3.1/modules/export-data.js"></script>
<script src="libs/highcharts-9.3.1/modules/funnel.js"></script>
<script src="libs/highcharts-9.3.1/modules/heatmap.js"></script>
<script src="libs/highcharts-9.3.1/modules/treemap.js"></script>
<script src="libs/highcharts-9.3.1/modules/sankey.js"></script>
<script src="libs/highcharts-9.3.1/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-9.3.1/modules/organization.js"></script>
<script src="libs/highcharts-9.3.1/modules/solid-gauge.js"></script>
<script src="libs/highcharts-9.3.1/modules/streamgraph.js"></script>
<script src="libs/highcharts-9.3.1/modules/sunburst.js"></script>
<script src="libs/highcharts-9.3.1/modules/vector.js"></script>
<script src="libs/highcharts-9.3.1/modules/wordcloud.js"></script>
<script src="libs/highcharts-9.3.1/modules/xrange.js"></script>
<script src="libs/highcharts-9.3.1/modules/tilemap.js"></script>
<script src="libs/highcharts-9.3.1/modules/venn.js"></script>
<script src="libs/highcharts-9.3.1/modules/gantt.js"></script>
<script src="libs/highcharts-9.3.1/modules/timeline.js"></script>
<script src="libs/highcharts-9.3.1/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-9.3.1/modules/bullet.js"></script>
<script src="libs/highcharts-9.3.1/modules/coloraxis.js"></script>
<script src="libs/highcharts-9.3.1/modules/dumbbell.js"></script>
<script src="libs/highcharts-9.3.1/modules/lollipop.js"></script>
<script src="libs/highcharts-9.3.1/modules/series-label.js"></script>
<script src="libs/highcharts-9.3.1/plugins/motion.js"></script>
<script src="libs/highcharts-9.3.1/custom/reset.js"></script>
<script src="libs/highcharts-9.3.1/modules/boost.js"></script>
<script src="libs/highchart-binding-0.9.4/highchart.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DMNX2X65HQ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li><a href="index.html#preface" id="toc-preface">Preface</a></li>
<li><a href="introduction.html#introduction" id="toc-introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="prerequisites.html#prerequisites" id="toc-prerequisites"><span class="toc-section-number">2</span> Prerequisites</a>
<ul>
<li><a href="matrix-theory.html#matrix-theory" id="toc-matrix-theory"><span class="toc-section-number">2.1</span> Matrix Theory</a>
<ul>
<li><a href="matrix-theory.html#rank" id="toc-rank"><span class="toc-section-number">2.1.1</span> Rank</a></li>
<li><a href="matrix-theory.html#inverse" id="toc-inverse"><span class="toc-section-number">2.1.2</span> Inverse</a></li>
<li><a href="matrix-theory.html#definiteness" id="toc-definiteness"><span class="toc-section-number">2.1.3</span> Definiteness</a></li>
<li><a href="matrix-theory.html#matrix-calculus" id="toc-matrix-calculus"><span class="toc-section-number">2.1.4</span> Matrix Calculus</a></li>
<li><a href="matrix-theory.html#optimization" id="toc-optimization"><span class="toc-section-number">2.1.5</span> Optimization</a></li>
</ul></li>
<li><a href="probability-theory.html#probability-theory" id="toc-probability-theory"><span class="toc-section-number">2.2</span> Probability Theory</a>
<ul>
<li><a href="probability-theory.html#axiom-and-theorems-of-probability" id="toc-axiom-and-theorems-of-probability"><span class="toc-section-number">2.2.1</span> Axiom and Theorems of Probability</a></li>
<li><a href="probability-theory.html#central-limit-theorem" id="toc-central-limit-theorem"><span class="toc-section-number">2.2.2</span> Central Limit Theorem</a></li>
<li><a href="probability-theory.html#random-variable" id="toc-random-variable"><span class="toc-section-number">2.2.3</span> Random variable</a></li>
<li><a href="probability-theory.html#moment-generating-function" id="toc-moment-generating-function"><span class="toc-section-number">2.2.4</span> Moment generating function</a></li>
<li><a href="probability-theory.html#moment" id="toc-moment"><span class="toc-section-number">2.2.5</span> Moment</a></li>
<li><a href="probability-theory.html#distributions" id="toc-distributions"><span class="toc-section-number">2.2.6</span> Distributions</a></li>
</ul></li>
<li><a href="general-math.html#general-math" id="toc-general-math"><span class="toc-section-number">2.3</span> General Math</a>
<ul>
<li><a href="general-math.html#law-of-large-numbers" id="toc-law-of-large-numbers"><span class="toc-section-number">2.3.1</span> Law of large numbers</a></li>
<li><a href="general-math.html#law-of-iterated-expectation" id="toc-law-of-iterated-expectation"><span class="toc-section-number">2.3.2</span> Law of Iterated Expectation</a></li>
<li><a href="general-math.html#convergence" id="toc-convergence"><span class="toc-section-number">2.3.3</span> Convergence</a></li>
<li><a href="general-math.html#sufficient-statistics" id="toc-sufficient-statistics"><span class="toc-section-number">2.3.4</span> Sufficient Statistics</a></li>
<li><a href="general-math.html#parameter-transformations" id="toc-parameter-transformations"><span class="toc-section-number">2.3.5</span> Parameter transformations</a></li>
</ul></li>
<li><a href="data-importexport.html#data-importexport" id="toc-data-importexport"><span class="toc-section-number">2.4</span> Data Import/Export</a>
<ul>
<li><a href="data-importexport.html#medium-size" id="toc-medium-size"><span class="toc-section-number">2.4.1</span> Medium size</a></li>
<li><a href="data-importexport.html#large-size" id="toc-large-size"><span class="toc-section-number">2.4.2</span> Large size</a></li>
</ul></li>
<li><a href="data-manipulation.html#data-manipulation" id="toc-data-manipulation"><span class="toc-section-number">2.5</span> Data Manipulation</a></li>
</ul></li>
<li><a href="#part-i.-basic" id="toc-part-i.-basic">(PART*) I. BASIC</a></li>
<li><a href="descriptive-stat.html#descriptive-stat" id="toc-descriptive-stat"><span class="toc-section-number">3</span> Descriptive Statistics</a>
<ul>
<li><a href="numerical-measures.html#numerical-measures" id="toc-numerical-measures"><span class="toc-section-number">3.1</span> Numerical Measures</a></li>
<li><a href="graphical-measures.html#graphical-measures" id="toc-graphical-measures"><span class="toc-section-number">3.2</span> Graphical Measures</a>
<ul>
<li><a href="graphical-measures.html#shape" id="toc-shape"><span class="toc-section-number">3.2.1</span> Shape</a></li>
<li><a href="graphical-measures.html#scatterplot" id="toc-scatterplot"><span class="toc-section-number">3.2.2</span> Scatterplot</a></li>
</ul></li>
<li><a href="normality-assessment.html#normality-assessment" id="toc-normality-assessment"><span class="toc-section-number">3.3</span> Normality Assessment</a>
<ul>
<li><a href="normality-assessment.html#graphical-assessment" id="toc-graphical-assessment"><span class="toc-section-number">3.3.1</span> Graphical Assessment</a></li>
<li><a href="normality-assessment.html#summary-statistics" id="toc-summary-statistics"><span class="toc-section-number">3.3.2</span> Summary Statistics</a></li>
</ul></li>
<li><a href="bivariate-statistics.html#bivariate-statistics" id="toc-bivariate-statistics"><span class="toc-section-number">3.4</span> Bivariate Statistics</a></li>
<li><a href="two-continuous.html#two-continuous" id="toc-two-continuous"><span class="toc-section-number">3.5</span> Two Continuous</a>
<ul>
<li><a href="two-continuous.html#pearson-correlation" id="toc-pearson-correlation"><span class="toc-section-number">3.5.1</span> Pearson Correlation</a></li>
<li><a href="two-continuous.html#spearman-correlation" id="toc-spearman-correlation"><span class="toc-section-number">3.5.2</span> Spearman Correlation</a></li>
</ul></li>
<li><a href="categorical-and-continuous.html#categorical-and-continuous" id="toc-categorical-and-continuous"><span class="toc-section-number">3.6</span> Categorical and Continuous</a>
<ul>
<li><a href="categorical-and-continuous.html#point-biserial-correlation" id="toc-point-biserial-correlation"><span class="toc-section-number">3.6.1</span> Point-Biserial Correlation</a></li>
<li><a href="categorical-and-continuous.html#logistic-regression" id="toc-logistic-regression"><span class="toc-section-number">3.6.2</span> Logistic Regression</a></li>
</ul></li>
<li><a href="two-discrete.html#two-discrete" id="toc-two-discrete"><span class="toc-section-number">3.7</span> Two Discrete</a>
<ul>
<li><a href="two-discrete.html#distance-metrics" id="toc-distance-metrics"><span class="toc-section-number">3.7.1</span> Distance Metrics</a></li>
<li><a href="two-discrete.html#statistical-metrics" id="toc-statistical-metrics"><span class="toc-section-number">3.7.2</span> Statistical Metrics</a></li>
<li><a href="two-discrete.html#ordinal-association-rank-correlation" id="toc-ordinal-association-rank-correlation"><span class="toc-section-number">3.7.3</span> Ordinal Association (Rank correlation)</a></li>
<li><a href="two-discrete.html#summary-1" id="toc-summary-1"><span class="toc-section-number">3.7.4</span> Summary</a></li>
<li><a href="two-discrete.html#visualization" id="toc-visualization"><span class="toc-section-number">3.7.5</span> Visualization</a></li>
</ul></li>
</ul></li>
<li><a href="basic-statistical-inference.html#basic-statistical-inference" id="toc-basic-statistical-inference"><span class="toc-section-number">4</span> Basic Statistical Inference</a>
<ul>
<li><a href="one-sample-inference.html#one-sample-inference" id="toc-one-sample-inference"><span class="toc-section-number">4.1</span> One Sample Inference</a>
<ul>
<li><a href="one-sample-inference.html#the-mean" id="toc-the-mean"><span class="toc-section-number">4.1.1</span> The Mean</a></li>
<li><a href="one-sample-inference.html#single-variance" id="toc-single-variance"><span class="toc-section-number">4.1.2</span> Single Variance</a></li>
<li><a href="one-sample-inference.html#single-proportion-p" id="toc-single-proportion-p"><span class="toc-section-number">4.1.3</span> Single Proportion (p)</a></li>
<li><a href="one-sample-inference.html#power" id="toc-power"><span class="toc-section-number">4.1.4</span> Power</a></li>
<li><a href="one-sample-inference.html#sample-size" id="toc-sample-size"><span class="toc-section-number">4.1.5</span> Sample Size</a></li>
<li><a href="one-sample-inference.html#note" id="toc-note"><span class="toc-section-number">4.1.6</span> Note</a></li>
<li><a href="one-sample-inference.html#one-sample-non-parametric-methods" id="toc-one-sample-non-parametric-methods"><span class="toc-section-number">4.1.7</span> One-sample Non-parametric Methods</a></li>
</ul></li>
<li><a href="two-sample-inference.html#two-sample-inference" id="toc-two-sample-inference"><span class="toc-section-number">4.2</span> Two Sample Inference</a>
<ul>
<li><a href="two-sample-inference.html#means" id="toc-means"><span class="toc-section-number">4.2.1</span> Means</a></li>
<li><a href="two-sample-inference.html#variances" id="toc-variances"><span class="toc-section-number">4.2.2</span> Variances</a></li>
<li><a href="two-sample-inference.html#power-1" id="toc-power-1"><span class="toc-section-number">4.2.3</span> Power</a></li>
<li><a href="two-sample-inference.html#sample-size-1" id="toc-sample-size-1"><span class="toc-section-number">4.2.4</span> Sample Size</a></li>
<li><a href="two-sample-inference.html#matched-pair-designs" id="toc-matched-pair-designs"><span class="toc-section-number">4.2.5</span> Matched Pair Designs</a></li>
<li><a href="two-sample-inference.html#nonparametric-tests-for-two-samples" id="toc-nonparametric-tests-for-two-samples"><span class="toc-section-number">4.2.6</span> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li><a href="categorical-data-analysis.html#categorical-data-analysis" id="toc-categorical-data-analysis"><span class="toc-section-number">4.3</span> Categorical Data Analysis</a>
<ul>
<li><a href="categorical-data-analysis.html#inferences-for-small-samples" id="toc-inferences-for-small-samples"><span class="toc-section-number">4.3.1</span> Inferences for Small Samples</a></li>
<li><a href="categorical-data-analysis.html#test-of-association" id="toc-test-of-association"><span class="toc-section-number">4.3.2</span> Test of Association</a></li>
<li><a href="categorical-data-analysis.html#ordinal-association" id="toc-ordinal-association"><span class="toc-section-number">4.3.3</span> Ordinal Association</a></li>
</ul></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#divergence-metrics-and-test-for-comparing-distributions" id="toc-divergence-metrics-and-test-for-comparing-distributions"><span class="toc-section-number">4.4</span> Divergence Metrics and Test for Comparing Distributions</a>
<ul>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#kullback-leibler-divergence" id="toc-kullback-leibler-divergence"><span class="toc-section-number">4.4.1</span> Kullback-Leibler Divergence</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#jensen-shannon-divergence" id="toc-jensen-shannon-divergence"><span class="toc-section-number">4.4.2</span> Jensen-Shannon Divergence</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#wasserstein-distance" id="toc-wasserstein-distance"><span class="toc-section-number">4.4.3</span> Wasserstein Distance</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#kolmogorov-smirnov-test-1" id="toc-kolmogorov-smirnov-test-1"><span class="toc-section-number">4.4.4</span> Kolmogorov-Smirnov Test</a></li>
</ul></li>
</ul></li>
<li><a href="#part-ii.-regression" id="toc-part-ii.-regression">(PART*) II. REGRESSION</a></li>
<li><a href="linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">5</span> Linear Regression</a>
<ul>
<li><a href="ordinary-least-squares.html#ordinary-least-squares" id="toc-ordinary-least-squares"><span class="toc-section-number">5.1</span> Ordinary Least Squares</a>
<ul>
<li><a href="ordinary-least-squares.html#simple-regression-basic-model" id="toc-simple-regression-basic-model"><span class="toc-section-number">5.1.1</span> Simple Regression (Basic Model)</a></li>
<li><a href="ordinary-least-squares.html#multiple-linear-regression" id="toc-multiple-linear-regression"><span class="toc-section-number">5.1.2</span> Multiple Linear Regression</a></li>
<li><a href="ordinary-least-squares.html#ols-assumptions" id="toc-ols-assumptions"><span class="toc-section-number">5.1.3</span> OLS Assumptions</a></li>
<li><a href="ordinary-least-squares.html#theorems" id="toc-theorems"><span class="toc-section-number">5.1.4</span> Theorems</a></li>
<li><a href="ordinary-least-squares.html#variable-selection" id="toc-variable-selection"><span class="toc-section-number">5.1.5</span> Variable Selection</a></li>
<li><a href="ordinary-least-squares.html#diagnostics-1" id="toc-diagnostics-1"><span class="toc-section-number">5.1.6</span> Diagnostics</a></li>
<li><a href="ordinary-least-squares.html#model-validation" id="toc-model-validation"><span class="toc-section-number">5.1.7</span> Model Validation</a></li>
<li><a href="ordinary-least-squares.html#finite-sample-properties" id="toc-finite-sample-properties"><span class="toc-section-number">5.1.8</span> Finite Sample Properties</a></li>
<li><a href="ordinary-least-squares.html#large-sample-properties" id="toc-large-sample-properties"><span class="toc-section-number">5.1.9</span> Large Sample Properties</a></li>
</ul></li>
<li><a href="feasible-generalized-least-squares.html#feasible-generalized-least-squares" id="toc-feasible-generalized-least-squares"><span class="toc-section-number">5.2</span> Feasible Generalized Least Squares</a>
<ul>
<li><a href="feasible-generalized-least-squares.html#heteroskedasticity" id="toc-heteroskedasticity"><span class="toc-section-number">5.2.1</span> Heteroskedasticity</a></li>
<li><a href="feasible-generalized-least-squares.html#serial-correlation" id="toc-serial-correlation"><span class="toc-section-number">5.2.2</span> Serial Correlation</a></li>
</ul></li>
<li><a href="weighted-least-squares.html#weighted-least-squares" id="toc-weighted-least-squares"><span class="toc-section-number">5.3</span> Weighted Least Squares</a></li>
<li><a href="generalized-least-squares.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">5.4</span> Generalized Least Squares</a></li>
<li><a href="feasiable-prais-winsten.html#feasiable-prais-winsten" id="toc-feasiable-prais-winsten"><span class="toc-section-number">5.5</span> Feasiable Prais Winsten</a></li>
<li><a href="feasible-group-level-random-effects.html#feasible-group-level-random-effects" id="toc-feasible-group-level-random-effects"><span class="toc-section-number">5.6</span> Feasible group level Random Effects</a></li>
<li><a href="ridge-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">5.7</span> Ridge Regression</a></li>
<li><a href="principal-component-regression.html#principal-component-regression" id="toc-principal-component-regression"><span class="toc-section-number">5.8</span> Principal Component Regression</a></li>
<li><a href="robust-regression.html#robust-regression" id="toc-robust-regression"><span class="toc-section-number">5.9</span> Robust Regression</a>
<ul>
<li><a href="robust-regression.html#least-absolute-residuals-lar-regression" id="toc-least-absolute-residuals-lar-regression"><span class="toc-section-number">5.9.1</span> Least Absolute Residuals (LAR) Regression</a></li>
<li><a href="robust-regression.html#least-median-of-squares-lms-regression" id="toc-least-median-of-squares-lms-regression"><span class="toc-section-number">5.9.2</span> Least Median of Squares (LMS) Regression</a></li>
<li><a href="robust-regression.html#iteratively-reweighted-least-squares-irls-robust-regression" id="toc-iteratively-reweighted-least-squares-irls-robust-regression"><span class="toc-section-number">5.9.3</span> Iteratively Reweighted Least Squares (IRLS) Robust Regression</a></li>
</ul></li>
<li><a href="maximum-likelihood-regression.html#maximum-likelihood-regression" id="toc-maximum-likelihood-regression"><span class="toc-section-number">5.10</span> Maximum Likelihood</a>
<ul>
<li><a href="maximum-likelihood-regression.html#motivation-for-mle" id="toc-motivation-for-mle"><span class="toc-section-number">5.10.1</span> Motivation for MLE</a></li>
<li><a href="maximum-likelihood-regression.html#assumption" id="toc-assumption"><span class="toc-section-number">5.10.2</span> Assumption</a></li>
<li><a href="maximum-likelihood-regression.html#properties" id="toc-properties"><span class="toc-section-number">5.10.3</span> Properties</a></li>
<li><a href="maximum-likelihood-regression.html#compare-to-ols" id="toc-compare-to-ols"><span class="toc-section-number">5.10.4</span> Compare to OLS</a></li>
<li><a href="maximum-likelihood-regression.html#application" id="toc-application"><span class="toc-section-number">5.10.5</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="non-linear-regression.html#non-linear-regression" id="toc-non-linear-regression"><span class="toc-section-number">6</span> Non-linear Regression</a>
<ul>
<li><a href="inference-1.html#inference-1" id="toc-inference-1"><span class="toc-section-number">6.1</span> Inference</a>
<ul>
<li><a href="inference-1.html#linear-function-of-the-parameters" id="toc-linear-function-of-the-parameters"><span class="toc-section-number">6.1.1</span> Linear Function of the Parameters</a></li>
<li><a href="inference-1.html#nonlinear" id="toc-nonlinear"><span class="toc-section-number">6.1.2</span> Nonlinear</a></li>
</ul></li>
<li><a href="non-linear-least-squares.html#non-linear-least-squares" id="toc-non-linear-least-squares"><span class="toc-section-number">6.2</span> Non-linear Least Squares</a>
<ul>
<li><a href="non-linear-least-squares.html#alternative-of-gauss-newton-algorithm" id="toc-alternative-of-gauss-newton-algorithm"><span class="toc-section-number">6.2.1</span> Alternative of Gauss-Newton Algorithm</a></li>
<li><a href="non-linear-least-squares.html#practical-considerations" id="toc-practical-considerations"><span class="toc-section-number">6.2.2</span> Practical Considerations</a></li>
<li><a href="non-linear-least-squares.html#modelestiamtion-adequcy" id="toc-modelestiamtion-adequcy"><span class="toc-section-number">6.2.3</span> Model/Estiamtion Adequcy</a></li>
<li><a href="non-linear-least-squares.html#application-1" id="toc-application-1"><span class="toc-section-number">6.2.4</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="generalized-linear-models.html#generalized-linear-models" id="toc-generalized-linear-models"><span class="toc-section-number">7</span> Generalized Linear Models</a>
<ul>
<li><a href="logistic-regression-1.html#logistic-regression-1" id="toc-logistic-regression-1"><span class="toc-section-number">7.1</span> Logistic Regression</a>
<ul>
<li><a href="logistic-regression-1.html#application-2" id="toc-application-2"><span class="toc-section-number">7.1.1</span> Application</a></li>
</ul></li>
<li><a href="probit-regression.html#probit-regression" id="toc-probit-regression"><span class="toc-section-number">7.2</span> Probit Regression</a></li>
<li><a href="binomial-regression.html#binomial-regression" id="toc-binomial-regression"><span class="toc-section-number">7.3</span> Binomial Regression</a></li>
<li><a href="poisson-regression.html#poisson-regression" id="toc-poisson-regression"><span class="toc-section-number">7.4</span> Poisson Regression</a>
<ul>
<li><a href="poisson-regression.html#application-3" id="toc-application-3"><span class="toc-section-number">7.4.1</span> Application</a></li>
</ul></li>
<li><a href="negative-binomial-regression.html#negative-binomial-regression" id="toc-negative-binomial-regression"><span class="toc-section-number">7.5</span> Negative Binomial Regression</a></li>
<li><a href="multinomial.html#multinomial" id="toc-multinomial"><span class="toc-section-number">7.6</span> Multinomial</a></li>
<li><a href="generalization.html#generalization" id="toc-generalization"><span class="toc-section-number">7.7</span> Generalization</a>
<ul>
<li><a href="generalization.html#estimation-1" id="toc-estimation-1"><span class="toc-section-number">7.7.1</span> Estimation</a></li>
<li><a href="generalization.html#inference-2" id="toc-inference-2"><span class="toc-section-number">7.7.2</span> Inference</a></li>
<li><a href="generalization.html#deviance" id="toc-deviance"><span class="toc-section-number">7.7.3</span> Deviance</a></li>
<li><a href="generalization.html#diagnostic-plots" id="toc-diagnostic-plots"><span class="toc-section-number">7.7.4</span> Diagnostic Plots</a></li>
<li><a href="generalization.html#goodness-of-fit" id="toc-goodness-of-fit"><span class="toc-section-number">7.7.5</span> Goodness of Fit</a></li>
<li><a href="generalization.html#over-dispersion" id="toc-over-dispersion"><span class="toc-section-number">7.7.6</span> Over-Dispersion</a></li>
</ul></li>
</ul></li>
<li><a href="linear-mixed-models.html#linear-mixed-models" id="toc-linear-mixed-models"><span class="toc-section-number">8</span> Linear Mixed Models</a>
<ul>
<li><a href="dependent-data.html#dependent-data" id="toc-dependent-data"><span class="toc-section-number">8.1</span> Dependent Data</a>
<ul>
<li><a href="dependent-data.html#random-intercepts-model" id="toc-random-intercepts-model"><span class="toc-section-number">8.1.1</span> Random-Intercepts Model</a></li>
<li><a href="dependent-data.html#covariance-models" id="toc-covariance-models"><span class="toc-section-number">8.1.2</span> Covariance Models</a></li>
</ul></li>
<li><a href="estimation-2.html#estimation-2" id="toc-estimation-2"><span class="toc-section-number">8.2</span> Estimation</a>
<ul>
<li><a href="estimation-2.html#estimating-mathbfv" id="toc-estimating-mathbfv"><span class="toc-section-number">8.2.1</span> Estimating <span class="math inline">\(\mathbf{V}\)</span></a></li>
</ul></li>
<li><a href="inference-3.html#inference-3" id="toc-inference-3"><span class="toc-section-number">8.3</span> Inference</a>
<ul>
<li><a href="inference-3.html#parameters-beta" id="toc-parameters-beta"><span class="toc-section-number">8.3.1</span> Parameters <span class="math inline">\(\beta\)</span></a></li>
<li><a href="inference-3.html#variance-components" id="toc-variance-components"><span class="toc-section-number">8.3.2</span> Variance Components</a></li>
</ul></li>
<li><a href="information-criteria.html#information-criteria" id="toc-information-criteria"><span class="toc-section-number">8.4</span> Information Criteria</a>
<ul>
<li><a href="information-criteria.html#akaikes-information-criteria-aic" id="toc-akaikes-information-criteria-aic"><span class="toc-section-number">8.4.1</span> Akaike’s Information Criteria (AIC)</a></li>
<li><a href="information-criteria.html#corrected-aic-aicc" id="toc-corrected-aic-aicc"><span class="toc-section-number">8.4.2</span> Corrected AIC (AICC)</a></li>
<li><a href="information-criteria.html#bayesian-information-criteria-bic" id="toc-bayesian-information-criteria-bic"><span class="toc-section-number">8.4.3</span> Bayesian Information Criteria (BIC)</a></li>
</ul></li>
<li><a href="split-plot-designs.html#split-plot-designs" id="toc-split-plot-designs"><span class="toc-section-number">8.5</span> Split-Plot Designs</a>
<ul>
<li><a href="split-plot-designs.html#application-4" id="toc-application-4"><span class="toc-section-number">8.5.1</span> Application</a></li>
</ul></li>
<li><a href="repeated-measures-in-mixed-models.html#repeated-measures-in-mixed-models" id="toc-repeated-measures-in-mixed-models"><span class="toc-section-number">8.6</span> Repeated Measures in Mixed Models</a></li>
<li><a href="unbalanced-or-unequally-spaced-data.html#unbalanced-or-unequally-spaced-data" id="toc-unbalanced-or-unequally-spaced-data"><span class="toc-section-number">8.7</span> Unbalanced or Unequally Spaced Data</a></li>
<li><a href="application-5.html#application-5" id="toc-application-5"><span class="toc-section-number">8.8</span> Application</a>
<ul>
<li><a href="application-5.html#example-1-pulps" id="toc-example-1-pulps"><span class="toc-section-number">8.8.1</span> Example 1 (Pulps)</a></li>
<li><a href="application-5.html#example-2-rats" id="toc-example-2-rats"><span class="toc-section-number">8.8.2</span> Example 2 (Rats)</a></li>
<li><a href="application-5.html#example-3-agridat" id="toc-example-3-agridat"><span class="toc-section-number">8.8.3</span> Example 3 (Agridat)</a></li>
</ul></li>
</ul></li>
<li><a href="nonlinear-and-generalized-linear-mixed-models.html#nonlinear-and-generalized-linear-mixed-models" id="toc-nonlinear-and-generalized-linear-mixed-models"><span class="toc-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li><a href="estimation-3.html#estimation-3" id="toc-estimation-3"><span class="toc-section-number">9.1</span> Estimation</a>
<ul>
<li><a href="estimation-3.html#estimation-by-numerical-integration" id="toc-estimation-by-numerical-integration"><span class="toc-section-number">9.1.1</span> Estimation by Numerical Integration</a></li>
<li><a href="estimation-3.html#estimation-by-linearization" id="toc-estimation-by-linearization"><span class="toc-section-number">9.1.2</span> Estimation by Linearization</a></li>
<li><a href="estimation-3.html#estimation-by-bayesian-hierarchical-models" id="toc-estimation-by-bayesian-hierarchical-models"><span class="toc-section-number">9.1.3</span> Estimation by Bayesian Hierarchical Models</a></li>
</ul></li>
<li><a href="application-6.html#application-6" id="toc-application-6"><span class="toc-section-number">9.2</span> Application</a>
<ul>
<li><a href="application-6.html#binomial-cbpp-data" id="toc-binomial-cbpp-data"><span class="toc-section-number">9.2.1</span> Binomial (CBPP Data)</a></li>
<li><a href="application-6.html#count-owl-data" id="toc-count-owl-data"><span class="toc-section-number">9.2.2</span> Count (Owl Data)</a></li>
<li><a href="application-6.html#binomial-1" id="toc-binomial-1"><span class="toc-section-number">9.2.3</span> Binomial</a></li>
<li><a href="application-6.html#example-from-schabenberger_2001-section-8.4.1" id="toc-example-from-schabenberger_2001-section-8.4.1"><span class="toc-section-number">9.2.4</span> Example from <span class="citation">(<span>Schabenberger and Pierce 2001</span>)</span> section 8.4.1</a></li>
</ul></li>
<li><a href="summary-2.html#summary-2" id="toc-summary-2"><span class="toc-section-number">9.3</span> Summary</a></li>
</ul></li>
<li><a href="#part-iii.-ramifications" id="toc-part-iii.-ramifications">(PART*) III. RAMIFICATIONS</a></li>
<li><a href="model-specification.html#model-specification" id="toc-model-specification"><span class="toc-section-number">10</span> Model Specification</a>
<ul>
<li><a href="nested-model.html#nested-model" id="toc-nested-model"><span class="toc-section-number">10.1</span> Nested Model</a>
<ul>
<li><a href="nested-model.html#chow-test" id="toc-chow-test"><span class="toc-section-number">10.1.1</span> Chow test</a></li>
</ul></li>
<li><a href="non-nested-model.html#non-nested-model" id="toc-non-nested-model"><span class="toc-section-number">10.2</span> Non-Nested Model</a>
<ul>
<li><a href="non-nested-model.html#davidson-mackinnon-test" id="toc-davidson-mackinnon-test"><span class="toc-section-number">10.2.1</span> Davidson-Mackinnon test</a></li>
</ul></li>
<li><a href="heteroskedasticity-1.html#heteroskedasticity-1" id="toc-heteroskedasticity-1"><span class="toc-section-number">10.3</span> Heteroskedasticity</a>
<ul>
<li><a href="heteroskedasticity-1.html#breusch-pagan-test" id="toc-breusch-pagan-test"><span class="toc-section-number">10.3.1</span> Breusch-Pagan test</a></li>
<li><a href="heteroskedasticity-1.html#white-test" id="toc-white-test"><span class="toc-section-number">10.3.2</span> White test</a></li>
</ul></li>
</ul></li>
<li><a href="imputation-missing-data.html#imputation-missing-data" id="toc-imputation-missing-data"><span class="toc-section-number">11</span> Imputation (Missing Data)</a>
<ul>
<li><a href="assumptions-1.html#assumptions-1" id="toc-assumptions-1"><span class="toc-section-number">11.1</span> Assumptions</a>
<ul>
<li><a href="assumptions-1.html#missing-completely-at-random-mcar" id="toc-missing-completely-at-random-mcar"><span class="toc-section-number">11.1.1</span> Missing Completely at Random (MCAR)</a></li>
<li><a href="assumptions-1.html#missing-at-random-mar" id="toc-missing-at-random-mar"><span class="toc-section-number">11.1.2</span> Missing at Random (MAR)</a></li>
<li><a href="assumptions-1.html#ignorable" id="toc-ignorable"><span class="toc-section-number">11.1.3</span> Ignorable</a></li>
<li><a href="assumptions-1.html#nonignorable" id="toc-nonignorable"><span class="toc-section-number">11.1.4</span> Nonignorable</a></li>
</ul></li>
<li><a href="solutions-to-missing-data.html#solutions-to-missing-data" id="toc-solutions-to-missing-data"><span class="toc-section-number">11.2</span> Solutions to Missing data</a>
<ul>
<li><a href="solutions-to-missing-data.html#listwise-deletion" id="toc-listwise-deletion"><span class="toc-section-number">11.2.1</span> Listwise Deletion</a></li>
<li><a href="solutions-to-missing-data.html#pairwise-deletion" id="toc-pairwise-deletion"><span class="toc-section-number">11.2.2</span> Pairwise Deletion</a></li>
<li><a href="solutions-to-missing-data.html#dummy-variable-adjustment" id="toc-dummy-variable-adjustment"><span class="toc-section-number">11.2.3</span> Dummy Variable Adjustment</a></li>
<li><a href="solutions-to-missing-data.html#imputation" id="toc-imputation"><span class="toc-section-number">11.2.4</span> Imputation</a></li>
<li><a href="solutions-to-missing-data.html#other-methods" id="toc-other-methods"><span class="toc-section-number">11.2.5</span> Other methods</a></li>
</ul></li>
<li><a href="criteria-for-choosing-an-effective-approach.html#criteria-for-choosing-an-effective-approach" id="toc-criteria-for-choosing-an-effective-approach"><span class="toc-section-number">11.3</span> Criteria for Choosing an Effective Approach</a></li>
<li><a href="another-perspective.html#another-perspective" id="toc-another-perspective"><span class="toc-section-number">11.4</span> Another Perspective</a></li>
<li><a href="diagnosing-the-mechanism.html#diagnosing-the-mechanism" id="toc-diagnosing-the-mechanism"><span class="toc-section-number">11.5</span> Diagnosing the Mechanism</a>
<ul>
<li><a href="diagnosing-the-mechanism.html#mar-vs.-mnar" id="toc-mar-vs.-mnar"><span class="toc-section-number">11.5.1</span> MAR vs. MNAR</a></li>
<li><a href="diagnosing-the-mechanism.html#mcar-vs.-mar" id="toc-mcar-vs.-mar"><span class="toc-section-number">11.5.2</span> MCAR vs. MAR</a></li>
</ul></li>
<li><a href="application-7.html#application-7" id="toc-application-7"><span class="toc-section-number">11.6</span> Application</a>
<ul>
<li><a href="application-7.html#imputation-with-mean-median-mode" id="toc-imputation-with-mean-median-mode"><span class="toc-section-number">11.6.1</span> Imputation with mean / median / mode</a></li>
<li><a href="application-7.html#knn" id="toc-knn"><span class="toc-section-number">11.6.2</span> KNN</a></li>
<li><a href="application-7.html#rpart" id="toc-rpart"><span class="toc-section-number">11.6.3</span> rpart</a></li>
<li><a href="application-7.html#mice-multivariate-imputation-via-chained-equations" id="toc-mice-multivariate-imputation-via-chained-equations"><span class="toc-section-number">11.6.4</span> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li><a href="application-7.html#amelia" id="toc-amelia"><span class="toc-section-number">11.6.5</span> Amelia</a></li>
<li><a href="application-7.html#missforest" id="toc-missforest"><span class="toc-section-number">11.6.6</span> missForest</a></li>
<li><a href="application-7.html#hmisc" id="toc-hmisc"><span class="toc-section-number">11.6.7</span> Hmisc</a></li>
<li><a href="application-7.html#mi" id="toc-mi"><span class="toc-section-number">11.6.8</span> mi</a></li>
</ul></li>
</ul></li>
<li><a href="data.html#data" id="toc-data"><span class="toc-section-number">12</span> Data</a>
<ul>
<li><a href="cross-sectional.html#cross-sectional" id="toc-cross-sectional"><span class="toc-section-number">12.1</span> Cross-Sectional</a></li>
<li><a href="time-series-1.html#time-series-1" id="toc-time-series-1"><span class="toc-section-number">12.2</span> Time Series</a>
<ul>
<li><a href="time-series-1.html#deterministic-time-trend" id="toc-deterministic-time-trend"><span class="toc-section-number">12.2.1</span> Deterministic Time trend</a></li>
<li><a href="time-series-1.html#feedback-effect" id="toc-feedback-effect"><span class="toc-section-number">12.2.2</span> Feedback Effect</a></li>
<li><a href="time-series-1.html#dynamic-specification" id="toc-dynamic-specification"><span class="toc-section-number">12.2.3</span> Dynamic Specification</a></li>
<li><a href="time-series-1.html#dynamically-complete" id="toc-dynamically-complete"><span class="toc-section-number">12.2.4</span> Dynamically Complete</a></li>
<li><a href="time-series-1.html#highly-persistent-data" id="toc-highly-persistent-data"><span class="toc-section-number">12.2.5</span> Highly Persistent Data</a></li>
</ul></li>
<li><a href="repeated-cross-sections.html#repeated-cross-sections" id="toc-repeated-cross-sections"><span class="toc-section-number">12.3</span> Repeated Cross Sections</a>
<ul>
<li><a href="repeated-cross-sections.html#pooled-cross-section" id="toc-pooled-cross-section"><span class="toc-section-number">12.3.1</span> Pooled Cross Section</a></li>
</ul></li>
<li><a href="panel-data.html#panel-data" id="toc-panel-data"><span class="toc-section-number">12.4</span> Panel Data</a>
<ul>
<li><a href="panel-data.html#pooled-ols-estimator" id="toc-pooled-ols-estimator"><span class="toc-section-number">12.4.1</span> Pooled OLS Estimator</a></li>
<li><a href="panel-data.html#individual-specific-effects-model" id="toc-individual-specific-effects-model"><span class="toc-section-number">12.4.2</span> Individual-specific effects model</a></li>
<li><a href="panel-data.html#tests-for-assumptions" id="toc-tests-for-assumptions"><span class="toc-section-number">12.4.3</span> Tests for Assumptions</a></li>
<li><a href="panel-data.html#model-selection" id="toc-model-selection"><span class="toc-section-number">12.4.4</span> Model Selection</a></li>
<li><a href="panel-data.html#summary-3" id="toc-summary-3"><span class="toc-section-number">12.4.5</span> Summary</a></li>
<li><a href="panel-data.html#application-8" id="toc-application-8"><span class="toc-section-number">12.4.6</span> Application</a></li>
<li><a href="panel-data.html#other-estimators" id="toc-other-estimators"><span class="toc-section-number">12.4.7</span> Other Estimators</a></li>
</ul></li>
</ul></li>
<li><a href="hypothesis-testing.html#hypothesis-testing" id="toc-hypothesis-testing"><span class="toc-section-number">13</span> Hypothesis Testing</a>
<ul>
<li><a href="types-of-hypothesis-testing.html#types-of-hypothesis-testing" id="toc-types-of-hypothesis-testing"><span class="toc-section-number">13.1</span> Types of hypothesis testing</a></li>
<li><a href="wald-test.html#wald-test" id="toc-wald-test"><span class="toc-section-number">13.2</span> Wald test</a>
<ul>
<li><a href="wald-test.html#multiple-hypothesis" id="toc-multiple-hypothesis"><span class="toc-section-number">13.2.1</span> Multiple Hypothesis</a></li>
<li><a href="wald-test.html#linear-combination" id="toc-linear-combination"><span class="toc-section-number">13.2.2</span> Linear Combination</a></li>
<li><a href="wald-test.html#estimate-difference-in-coefficients" id="toc-estimate-difference-in-coefficients"><span class="toc-section-number">13.2.3</span> Estimate Difference in Coefficients</a></li>
<li><a href="wald-test.html#application-9" id="toc-application-9"><span class="toc-section-number">13.2.4</span> Application</a></li>
<li><a href="wald-test.html#nonlinear-1" id="toc-nonlinear-1"><span class="toc-section-number">13.2.5</span> Nonlinear</a></li>
</ul></li>
<li><a href="the-likelihood-ratio-test.html#the-likelihood-ratio-test" id="toc-the-likelihood-ratio-test"><span class="toc-section-number">13.3</span> The likelihood ratio test</a></li>
<li><a href="lagrange-multiplier-score.html#lagrange-multiplier-score" id="toc-lagrange-multiplier-score"><span class="toc-section-number">13.4</span> Lagrange Multiplier (Score)</a></li>
</ul></li>
<li><a href="prediction-and-estimation.html#prediction-and-estimation" id="toc-prediction-and-estimation"><span class="toc-section-number">14</span> Prediction and Estimation</a></li>
<li><a href="moderation.html#moderation" id="toc-moderation"><span class="toc-section-number">15</span> Moderation</a>
<ul>
<li><a href="emmeans-package.html#emmeans-package" id="toc-emmeans-package"><span class="toc-section-number">15.1</span> emmeans package</a>
<ul>
<li><a href="emmeans-package.html#continuous-by-continuous" id="toc-continuous-by-continuous"><span class="toc-section-number">15.1.1</span> Continuous by continuous</a></li>
<li><a href="emmeans-package.html#continuous-by-categorical" id="toc-continuous-by-categorical"><span class="toc-section-number">15.1.2</span> Continuous by categorical</a></li>
<li><a href="emmeans-package.html#categorical-by-categorical" id="toc-categorical-by-categorical"><span class="toc-section-number">15.1.3</span> Categorical by categorical</a></li>
</ul></li>
<li><a href="probmod-package.html#probmod-package" id="toc-probmod-package"><span class="toc-section-number">15.2</span> probmod package</a></li>
<li><a href="interactions-package.html#interactions-package" id="toc-interactions-package"><span class="toc-section-number">15.3</span> interactions package</a>
<ul>
<li><a href="interactions-package.html#continuous-interaction" id="toc-continuous-interaction"><span class="toc-section-number">15.3.1</span> Continuous interaction</a></li>
<li><a href="interactions-package.html#categorical-interaction" id="toc-categorical-interaction"><span class="toc-section-number">15.3.2</span> Categorical interaction</a></li>
</ul></li>
<li><a href="interactionr-package.html#interactionr-package" id="toc-interactionr-package"><span class="toc-section-number">15.4</span> interactionR package</a></li>
<li><a href="sjplot-package.html#sjplot-package" id="toc-sjplot-package"><span class="toc-section-number">15.5</span> sjPlot package</a></li>
</ul></li>
<li><a href="bootstrap.html#bootstrap" id="toc-bootstrap"><span class="toc-section-number">16</span> Bootstrap</a></li>
<li><a href="#part-iv.-causal-inference" id="toc-part-iv.-causal-inference">(PART*) IV. CAUSAL INFERENCE</a></li>
<li><a href="causal-inference.html#causal-inference" id="toc-causal-inference"><span class="toc-section-number">17</span> Causal Inference</a>
<ul>
<li><a href="intro-to-dag-framework.html#intro-to-dag-framework" id="toc-intro-to-dag-framework"><span class="toc-section-number">17.1</span> Intro to DAG Framework</a></li>
<li><a href="intro-to-po-framework.html#intro-to-po-framework" id="toc-intro-to-po-framework"><span class="toc-section-number">17.2</span> Intro to PO Framework</a>
<ul>
<li><a href="intro-to-po-framework.html#typical-assumptions" id="toc-typical-assumptions"><span class="toc-section-number">17.2.1</span> Typical Assumptions</a></li>
<li><a href="intro-to-po-framework.html#treatment-effect-types" id="toc-treatment-effect-types"><span class="toc-section-number">17.2.2</span> Treatment effect types</a></li>
</ul></li>
<li><a href="controls-under-causal-inference.html#controls-under-causal-inference" id="toc-controls-under-causal-inference"><span class="toc-section-number">17.3</span> Controls under causal inference</a>
<ul>
<li><a href="controls-under-causal-inference.html#good-controls" id="toc-good-controls"><span class="toc-section-number">17.3.1</span> Good Controls</a></li>
<li><a href="controls-under-causal-inference.html#bad-controls" id="toc-bad-controls"><span class="toc-section-number">17.3.2</span> Bad Controls</a></li>
</ul></li>
<li><a href="sensitivity-analysis.html#sensitivity-analysis" id="toc-sensitivity-analysis"><span class="toc-section-number">17.4</span> Sensitivity Analysis</a></li>
</ul></li>
<li><a href="#part-a.-experimental-design" id="toc-part-a.-experimental-design">(PART*) A. EXPERIMENTAL DESIGN</a></li>
<li><a href="experimental-design.html#experimental-design" id="toc-experimental-design"><span class="toc-section-number">18</span> Experimental Design</a>
<ul>
<li><a href="simulation.html#simulation" id="toc-simulation"><span class="toc-section-number">18.1</span> Simulation</a></li>
<li><a href="semi-random-experiment.html#semi-random-experiment" id="toc-semi-random-experiment"><span class="toc-section-number">18.2</span> Semi-random Experiment</a></li>
<li><a href="rerandomization.html#rerandomization" id="toc-rerandomization"><span class="toc-section-number">18.3</span> Rerandomization</a></li>
</ul></li>
<li><a href="sampling.html#sampling" id="toc-sampling"><span class="toc-section-number">19</span> Sampling</a>
<ul>
<li><a href="simple-sampling.html#simple-sampling" id="toc-simple-sampling"><span class="toc-section-number">19.1</span> Simple Sampling</a></li>
<li><a href="stratified-sampling.html#stratified-sampling" id="toc-stratified-sampling"><span class="toc-section-number">19.2</span> Stratified Sampling</a></li>
<li><a href="unequal-probability-sampling.html#unequal-probability-sampling" id="toc-unequal-probability-sampling"><span class="toc-section-number">19.3</span> Unequal Probability Sampling</a></li>
<li><a href="balanced-sampling.html#balanced-sampling" id="toc-balanced-sampling"><span class="toc-section-number">19.4</span> Balanced Sampling</a>
<ul>
<li><a href="balanced-sampling.html#cube" id="toc-cube"><span class="toc-section-number">19.4.1</span> Cube</a></li>
<li><a href="balanced-sampling.html#stratification" id="toc-stratification"><span class="toc-section-number">19.4.2</span> Stratification</a></li>
<li><a href="balanced-sampling.html#cluster-1" id="toc-cluster-1"><span class="toc-section-number">19.4.3</span> Cluster</a></li>
<li><a href="balanced-sampling.html#two-stage" id="toc-two-stage"><span class="toc-section-number">19.4.4</span> Two-stage</a></li>
</ul></li>
</ul></li>
<li><a href="analysis-of-variance-anova.html#analysis-of-variance-anova" id="toc-analysis-of-variance-anova"><span class="toc-section-number">20</span> Analysis of Variance (ANOVA)</a>
<ul>
<li><a href="completely-randomized-design-crd.html#completely-randomized-design-crd" id="toc-completely-randomized-design-crd"><span class="toc-section-number">20.1</span> Completely Randomized Design (CRD)</a>
<ul>
<li><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model" id="toc-single-factor-fixed-effects-model"><span class="toc-section-number">20.1.1</span> Single Factor Fixed Effects Model</a></li>
<li><a href="completely-randomized-design-crd.html#single-factor-random-effects-model" id="toc-single-factor-random-effects-model"><span class="toc-section-number">20.1.2</span> Single Factor Random Effects Model</a></li>
<li><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova" id="toc-two-factor-fixed-effect-anova"><span class="toc-section-number">20.1.3</span> Two Factor Fixed Effect ANOVA</a></li>
<li><a href="completely-randomized-design-crd.html#two-way-random-effects-anova" id="toc-two-way-random-effects-anova"><span class="toc-section-number">20.1.4</span> Two-Way Random Effects ANOVA</a></li>
<li><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova" id="toc-two-way-mixed-effects-anova"><span class="toc-section-number">20.1.5</span> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li><a href="nonparametric-anova.html#nonparametric-anova" id="toc-nonparametric-anova"><span class="toc-section-number">20.2</span> Nonparametric ANOVA</a>
<ul>
<li><a href="nonparametric-anova.html#kruskal-wallis" id="toc-kruskal-wallis"><span class="toc-section-number">20.2.1</span> Kruskal-Wallis</a></li>
<li><a href="nonparametric-anova.html#friedman-test" id="toc-friedman-test"><span class="toc-section-number">20.2.2</span> Friedman Test</a></li>
</ul></li>
<li><a href="sample-size-planning-for-anova.html#sample-size-planning-for-anova" id="toc-sample-size-planning-for-anova"><span class="toc-section-number">20.3</span> Sample Size Planning for ANOVA</a>
<ul>
<li><a href="sample-size-planning-for-anova.html#balanced-designs" id="toc-balanced-designs"><span class="toc-section-number">20.3.1</span> Balanced Designs</a></li>
<li><a href="sample-size-planning-for-anova.html#randomized-block-experiments" id="toc-randomized-block-experiments"><span class="toc-section-number">20.3.2</span> Randomized Block Experiments</a></li>
</ul></li>
<li><a href="randomized-block-designs.html#randomized-block-designs" id="toc-randomized-block-designs"><span class="toc-section-number">20.4</span> Randomized Block Designs</a>
<ul>
<li><a href="randomized-block-designs.html#tukey-test-of-additivity" id="toc-tukey-test-of-additivity"><span class="toc-section-number">20.4.1</span> Tukey Test of Additivity</a></li>
</ul></li>
<li><a href="nested-designs.html#nested-designs" id="toc-nested-designs"><span class="toc-section-number">20.5</span> Nested Designs</a>
<ul>
<li><a href="nested-designs.html#two-factor-nested-designs" id="toc-two-factor-nested-designs"><span class="toc-section-number">20.5.1</span> Two-Factor Nested Designs</a></li>
</ul></li>
<li><a href="single-factor-covariance-model.html#single-factor-covariance-model" id="toc-single-factor-covariance-model"><span class="toc-section-number">20.6</span> Single Factor Covariance Model</a></li>
</ul></li>
<li><a href="multivariate-methods.html#multivariate-methods" id="toc-multivariate-methods"><span class="toc-section-number">21</span> Multivariate Methods</a>
<ul>
<li><a href="multivariate-methods.html#properties-of-mvn" id="toc-properties-of-mvn"><span class="toc-section-number">21.0.1</span> Properties of MVN</a></li>
<li><a href="multivariate-methods.html#mean-vector-inference" id="toc-mean-vector-inference"><span class="toc-section-number">21.0.2</span> Mean Vector Inference</a></li>
<li><a href="multivariate-methods.html#general-hypothesis-testing" id="toc-general-hypothesis-testing"><span class="toc-section-number">21.0.3</span> General Hypothesis Testing</a></li>
<li><a href="manova.html#manova" id="toc-manova"><span class="toc-section-number">21.1</span> MANOVA</a>
<ul>
<li><a href="manova.html#testing-general-hypotheses" id="toc-testing-general-hypotheses"><span class="toc-section-number">21.1.1</span> Testing General Hypotheses</a></li>
<li><a href="manova.html#profile-analysis" id="toc-profile-analysis"><span class="toc-section-number">21.1.2</span> Profile Analysis</a></li>
<li><a href="manova.html#summary-5" id="toc-summary-5"><span class="toc-section-number">21.1.3</span> Summary</a></li>
</ul></li>
<li><a href="principal-components.html#principal-components" id="toc-principal-components"><span class="toc-section-number">21.2</span> Principal Components</a>
<ul>
<li><a href="principal-components.html#population-principal-components" id="toc-population-principal-components"><span class="toc-section-number">21.2.1</span> Population Principal Components</a></li>
<li><a href="principal-components.html#sample-principal-components" id="toc-sample-principal-components"><span class="toc-section-number">21.2.2</span> Sample Principal Components</a></li>
<li><a href="principal-components.html#application-10" id="toc-application-10"><span class="toc-section-number">21.2.3</span> Application</a></li>
</ul></li>
<li><a href="factor-analysis.html#factor-analysis" id="toc-factor-analysis"><span class="toc-section-number">21.3</span> Factor Analysis</a>
<ul>
<li><a href="factor-analysis.html#methods-of-estimation" id="toc-methods-of-estimation"><span class="toc-section-number">21.3.1</span> Methods of Estimation</a></li>
<li><a href="factor-analysis.html#factor-rotation" id="toc-factor-rotation"><span class="toc-section-number">21.3.2</span> Factor Rotation</a></li>
<li><a href="factor-analysis.html#estimation-of-factor-scores" id="toc-estimation-of-factor-scores"><span class="toc-section-number">21.3.3</span> Estimation of Factor Scores</a></li>
<li><a href="factor-analysis.html#model-diagnostic" id="toc-model-diagnostic"><span class="toc-section-number">21.3.4</span> Model Diagnostic</a></li>
<li><a href="factor-analysis.html#application-11" id="toc-application-11"><span class="toc-section-number">21.3.5</span> Application</a></li>
</ul></li>
<li><a href="discriminant-analysis.html#discriminant-analysis" id="toc-discriminant-analysis"><span class="toc-section-number">21.4</span> Discriminant Analysis</a>
<ul>
<li><a href="discriminant-analysis.html#known-populations" id="toc-known-populations"><span class="toc-section-number">21.4.1</span> Known Populations</a></li>
<li><a href="discriminant-analysis.html#probabilities-of-misclassification" id="toc-probabilities-of-misclassification"><span class="toc-section-number">21.4.2</span> Probabilities of Misclassification</a></li>
<li><a href="discriminant-analysis.html#unknown-populations-nonparametric-discrimination" id="toc-unknown-populations-nonparametric-discrimination"><span class="toc-section-number">21.4.3</span> Unknown Populations/ Nonparametric Discrimination</a></li>
<li><a href="discriminant-analysis.html#application-12" id="toc-application-12"><span class="toc-section-number">21.4.4</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="#part-b.-quasi-experimental-design" id="toc-part-b.-quasi-experimental-design">(PART*) B. QUASI-EXPERIMENTAL DESIGN</a></li>
<li><a href="quasi-experimental.html#quasi-experimental" id="toc-quasi-experimental"><span class="toc-section-number">22</span> Quasi-experimental</a></li>
<li><a href="regression-discontinuity.html#regression-discontinuity" id="toc-regression-discontinuity"><span class="toc-section-number">23</span> Regression Discontinuity</a>
<ul>
<li><a href="specification-checks.html#specification-checks" id="toc-specification-checks"><span class="toc-section-number">23.1</span> Specification Checks</a>
<ul>
<li><a href="specification-checks.html#balance-checks" id="toc-balance-checks"><span class="toc-section-number">23.1.1</span> Balance Checks</a></li>
<li><a href="specification-checks.html#sortingbunchingmanipulation" id="toc-sortingbunchingmanipulation"><span class="toc-section-number">23.1.2</span> Sorting/Bunching/Manipulation</a></li>
<li><a href="specification-checks.html#placebo-tests" id="toc-placebo-tests"><span class="toc-section-number">23.1.3</span> Placebo Tests</a></li>
<li><a href="specification-checks.html#sensitivity-to-bandwidth-choice" id="toc-sensitivity-to-bandwidth-choice"><span class="toc-section-number">23.1.4</span> Sensitivity to Bandwidth Choice</a></li>
<li><a href="specification-checks.html#fuzzy-rd-design" id="toc-fuzzy-rd-design"><span class="toc-section-number">23.1.5</span> Fuzzy RD Design</a></li>
<li><a href="specification-checks.html#regression-kink-design" id="toc-regression-kink-design"><span class="toc-section-number">23.1.6</span> Regression Kink Design</a></li>
<li><a href="specification-checks.html#mutli-cutoff-multi-score-geographic-rd" id="toc-mutli-cutoff-multi-score-geographic-rd"><span class="toc-section-number">23.1.7</span> Mutli-cutoff, Multi-score, geographic RD</a></li>
</ul></li>
<li><a href="steps-for-sharp-rd.html#steps-for-sharp-rd" id="toc-steps-for-sharp-rd"><span class="toc-section-number">23.2</span> Steps for Sharp RD</a></li>
<li><a href="steps-for-fuzzy-rd.html#steps-for-fuzzy-rd" id="toc-steps-for-fuzzy-rd"><span class="toc-section-number">23.3</span> Steps for Fuzzy RD</a></li>
<li><a href="steps-for-rdit-regression-discontinuity-in-time.html#steps-for-rdit-regression-discontinuity-in-time" id="toc-steps-for-rdit-regression-discontinuity-in-time"><span class="toc-section-number">23.4</span> Steps for RDiT (Regression Discontinuity in Time)</a></li>
<li><a href="evaluation-of-an-rd.html#evaluation-of-an-rd" id="toc-evaluation-of-an-rd"><span class="toc-section-number">23.5</span> Evaluation of an RD</a></li>
<li><a href="applications.html#applications" id="toc-applications"><span class="toc-section-number">23.6</span> Applications</a>
<ul>
<li><a href="applications.html#example-1-1" id="toc-example-1-1"><span class="toc-section-number">23.6.1</span> Example 1</a></li>
<li><a href="applications.html#example-2" id="toc-example-2"><span class="toc-section-number">23.6.2</span> Example 2</a></li>
<li><a href="applications.html#example-3" id="toc-example-3"><span class="toc-section-number">23.6.3</span> Example 3</a></li>
<li><a href="applications.html#example-4" id="toc-example-4"><span class="toc-section-number">23.6.4</span> Example 4</a></li>
</ul></li>
</ul></li>
<li><a href="difference-in-differences.html#difference-in-differences" id="toc-difference-in-differences"><span class="toc-section-number">24</span> Difference-in-differences</a>
<ul>
<li><a href="simple-dif-n-dif.html#simple-dif-n-dif" id="toc-simple-dif-n-dif"><span class="toc-section-number">24.1</span> Simple Dif-n-dif</a>
<ul>
<li><a href="simple-dif-n-dif.html#assumptions-2" id="toc-assumptions-2"><span class="toc-section-number">24.1.1</span> Assumptions</a></li>
<li><a href="simple-dif-n-dif.html#examples" id="toc-examples"><span class="toc-section-number">24.1.2</span> Examples</a></li>
</ul></li>
<li><a href="multiple-periods-and-variation-in-treatment-timing.html#multiple-periods-and-variation-in-treatment-timing" id="toc-multiple-periods-and-variation-in-treatment-timing"><span class="toc-section-number">24.2</span> Multiple periods and variation in treatment timing</a>
<ul>
<li><a href="multiple-periods-and-variation-in-treatment-timing.html#staggered-dif-n-dif" id="toc-staggered-dif-n-dif"><span class="toc-section-number">24.2.1</span> Staggered Dif-n-dif</a></li>
</ul></li>
<li><a href="augmented-dif-n-dif.html#augmented-dif-n-dif" id="toc-augmented-dif-n-dif"><span class="toc-section-number">24.3</span> Augmented Dif-n-dif</a></li>
<li><a href="applications-1.html#applications-1" id="toc-applications-1"><span class="toc-section-number">24.4</span> Applications</a>
<ul>
<li><a href="applications-1.html#two-way-fixed-effects" id="toc-two-way-fixed-effects"><span class="toc-section-number">24.4.1</span> Two-way Fixed-effects</a></li>
</ul></li>
</ul></li>
<li><a href="synthetic-control.html#synthetic-control" id="toc-synthetic-control"><span class="toc-section-number">25</span> Synthetic Control</a>
<ul>
<li><a href="applications-2.html#applications-2" id="toc-applications-2"><span class="toc-section-number">25.1</span> Applications</a>
<ul>
<li><a href="applications-2.html#example-1-2" id="toc-example-1-2"><span class="toc-section-number">25.1.1</span> Example 1</a></li>
<li><a href="applications-2.html#example-2-1" id="toc-example-2-1"><span class="toc-section-number">25.1.2</span> Example 2</a></li>
<li><a href="applications-2.html#example-3-1" id="toc-example-3-1"><span class="toc-section-number">25.1.3</span> Example 3</a></li>
<li><a href="applications-2.html#example-4-1" id="toc-example-4-1"><span class="toc-section-number">25.1.4</span> Example 4</a></li>
</ul></li>
<li><a href="synthetic-difference-in-differences.html#synthetic-difference-in-differences" id="toc-synthetic-difference-in-differences"><span class="toc-section-number">25.2</span> Synthetic Difference-in-differences</a></li>
<li><a href="modified-synthetic-control.html#modified-synthetic-control" id="toc-modified-synthetic-control"><span class="toc-section-number">25.3</span> Modified Synthetic Control</a></li>
<li><a href="generalized-synthetic-control.html#generalized-synthetic-control" id="toc-generalized-synthetic-control"><span class="toc-section-number">25.4</span> Generalized Synthetic Control</a></li>
</ul></li>
<li><a href="panel-data-methods.html#panel-data-methods" id="toc-panel-data-methods"><span class="toc-section-number">26</span> Panel Data Methods</a></li>
<li><a href="event-studies.html#event-studies" id="toc-event-studies"><span class="toc-section-number">27</span> Event Studies</a>
<ul>
<li><a href="other-issues.html#other-issues" id="toc-other-issues"><span class="toc-section-number">27.1</span> Other Issues</a>
<ul>
<li><a href="other-issues.html#economic-significance" id="toc-economic-significance"><span class="toc-section-number">27.1.1</span> Economic significance</a></li>
<li><a href="other-issues.html#statistical-power" id="toc-statistical-power"><span class="toc-section-number">27.1.2</span> Statistical Power</a></li>
<li><a href="other-issues.html#testing" id="toc-testing"><span class="toc-section-number">27.1.3</span> Testing</a></li>
<li><a href="other-issues.html#confounders" id="toc-confounders"><span class="toc-section-number">27.1.4</span> Confounders</a></li>
<li><a href="other-issues.html#biases" id="toc-biases"><span class="toc-section-number">27.1.5</span> Biases</a></li>
<li><a href="other-issues.html#long-run-event-studies" id="toc-long-run-event-studies"><span class="toc-section-number">27.1.6</span> Long-run event studies</a></li>
</ul></li>
<li><a href="aggregation.html#aggregation" id="toc-aggregation"><span class="toc-section-number">27.2</span> Aggregation</a>
<ul>
<li><a href="aggregation.html#over-time" id="toc-over-time"><span class="toc-section-number">27.2.1</span> Over Time</a></li>
<li><a href="aggregation.html#across-firms-over-time" id="toc-across-firms-over-time"><span class="toc-section-number">27.2.2</span> Across Firms + Over Time</a></li>
</ul></li>
<li><a href="heterogeneity-in-the-event-effect.html#heterogeneity-in-the-event-effect" id="toc-heterogeneity-in-the-event-effect"><span class="toc-section-number">27.3</span> Heterogeneity in the event effect</a></li>
<li><a href="expected-return-calculation.html#expected-return-calculation" id="toc-expected-return-calculation"><span class="toc-section-number">27.4</span> Expected Return Calculation</a>
<ul>
<li><a href="expected-return-calculation.html#statistical-models" id="toc-statistical-models"><span class="toc-section-number">27.4.1</span> Statistical Models</a></li>
<li><a href="expected-return-calculation.html#economic-model" id="toc-economic-model"><span class="toc-section-number">27.4.2</span> Economic Model</a></li>
</ul></li>
<li><a href="application-13.html#application-13" id="toc-application-13"><span class="toc-section-number">27.5</span> Application</a></li>
</ul></li>
<li><a href="matching-methods.html#matching-methods" id="toc-matching-methods"><span class="toc-section-number">28</span> Matching Methods</a>
<ul>
<li><a href="matching-vs.-regression.html#matching-vs.-regression" id="toc-matching-vs.-regression"><span class="toc-section-number">28.1</span> Matching vs. Regression</a></li>
<li><a href="weighting-vs.-balancing.html#weighting-vs.-balancing" id="toc-weighting-vs.-balancing"><span class="toc-section-number">28.2</span> Weighting vs. Balancing</a></li>
<li><a href="matchit.html#matchit" id="toc-matchit"><span class="toc-section-number">28.3</span> MatchIt</a></li>
<li><a href="matchingfrontier.html#matchingfrontier" id="toc-matchingfrontier"><span class="toc-section-number">28.4</span> MatchingFrontier</a></li>
<li><a href="propensity-scores.html#propensity-scores" id="toc-propensity-scores"><span class="toc-section-number">28.5</span> Propensity Scores</a></li>
<li><a href="mahalanobis-distance.html#mahalanobis-distance" id="toc-mahalanobis-distance"><span class="toc-section-number">28.6</span> Mahalanobis Distance</a></li>
<li><a href="coarsened-exact-matching.html#coarsened-exact-matching" id="toc-coarsened-exact-matching"><span class="toc-section-number">28.7</span> Coarsened Exact Matching</a></li>
<li><a href="genetic-matching.html#genetic-matching" id="toc-genetic-matching"><span class="toc-section-number">28.8</span> Genetic Matching</a></li>
<li><a href="matching-for-time-series-cross-section-data.html#matching-for-time-series-cross-section-data" id="toc-matching-for-time-series-cross-section-data"><span class="toc-section-number">28.9</span> Matching for time series-cross-section data</a></li>
</ul></li>
<li><a href="interrupted-time-series.html#interrupted-time-series" id="toc-interrupted-time-series"><span class="toc-section-number">29</span> Interrupted Time Series</a></li>
<li><a href="#part-c.-other-concerns" id="toc-part-c.-other-concerns">(PART*) C. OTHER CONCERNS</a></li>
<li><a href="doubly-robust-estimator.html#doubly-robust-estimator" id="toc-doubly-robust-estimator"><span class="toc-section-number">30</span> Doubly Robust Estimator</a>
<ul>
<li><a href="regression-adjustments.html#regression-adjustments" id="toc-regression-adjustments"><span class="toc-section-number">30.1</span> Regression Adjustments</a></li>
<li><a href="inverse-propensity-weighting.html#inverse-propensity-weighting" id="toc-inverse-propensity-weighting"><span class="toc-section-number">30.2</span> Inverse Propensity Weighting</a></li>
<li><a href="augmented-inverse-propensity-weighting.html#augmented-inverse-propensity-weighting" id="toc-augmented-inverse-propensity-weighting"><span class="toc-section-number">30.3</span> Augmented Inverse Propensity Weighting</a></li>
</ul></li>
<li><a href="endogeneity.html#endogeneity" id="toc-endogeneity"><span class="toc-section-number">31</span> Endogeneity</a>
<ul>
<li><a href="measurement-error.html#measurement-error" id="toc-measurement-error"><span class="toc-section-number">31.1</span> Measurement Error</a>
<ul>
<li><a href="measurement-error.html#classical-measurement-errors" id="toc-classical-measurement-errors"><span class="toc-section-number">31.1.1</span> Classical Measurement Errors</a></li>
<li><a href="measurement-error.html#non-classical-measurement-errors" id="toc-non-classical-measurement-errors"><span class="toc-section-number">31.1.2</span> Non-classical Measurement Errors</a></li>
<li><a href="measurement-error.html#solution-to-measurement-errors" id="toc-solution-to-measurement-errors"><span class="toc-section-number">31.1.3</span> Solution to Measurement Errors</a></li>
</ul></li>
<li><a href="simultaneity.html#simultaneity" id="toc-simultaneity"><span class="toc-section-number">31.2</span> Simultaneity</a></li>
<li><a href="endogenous-treatment.html#endogenous-treatment" id="toc-endogenous-treatment"><span class="toc-section-number">31.3</span> Endogenous Treatment</a>
<ul>
<li><a href="endogenous-treatment.html#instrumental-variable" id="toc-instrumental-variable"><span class="toc-section-number">31.3.1</span> Instrumental Variable</a></li>
<li><a href="endogenous-treatment.html#internal-instrumental-variable" id="toc-internal-instrumental-variable"><span class="toc-section-number">31.3.2</span> Internal instrumental variable</a></li>
<li><a href="endogenous-treatment.html#proxy-variables" id="toc-proxy-variables"><span class="toc-section-number">31.3.3</span> Proxy Variables</a></li>
</ul></li>
<li><a href="endogenous-sample-selection.html#endogenous-sample-selection" id="toc-endogenous-sample-selection"><span class="toc-section-number">31.4</span> Endogenous Sample Selection</a>
<ul>
<li><a href="endogenous-sample-selection.html#tobit-2" id="toc-tobit-2"><span class="toc-section-number">31.4.1</span> Tobit-2</a></li>
<li><a href="endogenous-sample-selection.html#tobit-5" id="toc-tobit-5"><span class="toc-section-number">31.4.2</span> Tobit-5</a></li>
</ul></li>
</ul></li>
<li><a href="mediation.html#mediation" id="toc-mediation"><span class="toc-section-number">32</span> Mediation</a>
<ul>
<li><a href="traditional.html#traditional" id="toc-traditional"><span class="toc-section-number">32.1</span> Traditional</a>
<ul>
<li><a href="traditional.html#example-1-mediation-traditional" id="toc-example-1-mediation-traditional"><span class="toc-section-number">32.1.1</span> Example 1</a></li>
</ul></li>
<li><a href="model-based-causal-mediation-analysis.html#model-based-causal-mediation-analysis" id="toc-model-based-causal-mediation-analysis"><span class="toc-section-number">32.2</span> Model-based causal mediation analysis</a></li>
</ul></li>
<li><a href="directed-acyclic-graph.html#directed-acyclic-graph" id="toc-directed-acyclic-graph"><span class="toc-section-number">33</span> Directed Acyclic Graph</a></li>
<li><a href="#part-v.-miscellaneous" id="toc-part-v.-miscellaneous">(PART*) V. MISCELLANEOUS</a></li>
<li><a href="report.html#report" id="toc-report"><span class="toc-section-number">34</span> Report</a>
<ul>
<li><a href="one-summary-table.html#one-summary-table" id="toc-one-summary-table"><span class="toc-section-number">34.1</span> One summary table</a></li>
<li><a href="model-comparison.html#model-comparison" id="toc-model-comparison"><span class="toc-section-number">34.2</span> Model Comparison</a></li>
<li><a href="changes-in-an-estimate.html#changes-in-an-estimate" id="toc-changes-in-an-estimate"><span class="toc-section-number">34.3</span> Changes in an estimate</a></li>
</ul></li>
<li><a href="exploratory-data-analysis.html#exploratory-data-analysis" id="toc-exploratory-data-analysis"><span class="toc-section-number">35</span> Exploratory Data Analysis</a></li>
<li><a href="sensitivity-analysis-robustness-check.html#sensitivity-analysis-robustness-check" id="toc-sensitivity-analysis-robustness-check"><span class="toc-section-number">36</span> Sensitivity Analysis/ Robustness Check</a>
<ul>
<li><a href="specification-curve.html#specification-curve" id="toc-specification-curve"><span class="toc-section-number">36.1</span> Specification curve</a>
<ul>
<li><a href="specification-curve.html#starbility" id="toc-starbility"><span class="toc-section-number">36.1.1</span> starbility</a></li>
<li><a href="specification-curve.html#rdfanalysis" id="toc-rdfanalysis"><span class="toc-section-number">36.1.2</span> rdfanalysis</a></li>
</ul></li>
<li><a href="coefficient-stability.html#coefficient-stability" id="toc-coefficient-stability"><span class="toc-section-number">36.2</span> Coefficient stability</a></li>
</ul></li>
<li><a href="#appendix-appendix" id="toc-appendix-appendix">(APPENDIX) APPENDIX</a></li>
<li><a href="appendix.html#appendix" id="toc-appendix"><span class="toc-section-number">37</span> Appendix</a>
<ul>
<li><a href="git.html#git" id="toc-git"><span class="toc-section-number">37.1</span> Git</a></li>
<li><a href="short-cut.html#short-cut" id="toc-short-cut"><span class="toc-section-number">37.2</span> Short-cut</a></li>
<li><a href="function-short-cut.html#function-short-cut" id="toc-function-short-cut"><span class="toc-section-number">37.3</span> Function short-cut</a></li>
<li><a href="citation.html#citation" id="toc-citation"><span class="toc-section-number">37.4</span> Citation</a></li>
<li><a href="install-all-necessary-packageslibaries-on-your-local-machine.html#install-all-necessary-packageslibaries-on-your-local-machine" id="toc-install-all-necessary-packageslibaries-on-your-local-machine"><span class="toc-section-number">37.5</span> Install all necessary packages/libaries on your local machine</a></li>
</ul></li>
<li><a href="bookdown-cheat-sheet.html#bookdown-cheat-sheet" id="toc-bookdown-cheat-sheet"><span class="toc-section-number">38</span> Bookdown cheat sheet</a>
<ul>
<li><a href="operation.html#operation" id="toc-operation"><span class="toc-section-number">38.1</span> Operation</a></li>
<li><a href="math-expresssion-syntax.html#math-expresssion-syntax" id="toc-math-expresssion-syntax"><span class="toc-section-number">38.2</span> Math Expresssion/ Syntax</a>
<ul>
<li><a href="math-expresssion-syntax.html#statistics-notation" id="toc-statistics-notation"><span class="toc-section-number">38.2.1</span> Statistics Notation</a></li>
</ul></li>
<li><a href="table.html#table" id="toc-table"><span class="toc-section-number">38.3</span> Table</a></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="completely-randomized-design-crd" class="section level2" number="20.1">
<h2><span class="header-section-number">20.1</span> Completely Randomized Design (CRD)</h2>
<p>Treatment factor A with <span class="math inline">\(a\ge2\)</span> treatments levels. Experimental units are randomly assinged to each treatment. The number of experiemntal units in each group can be</p>
<ul>
<li>equal (balanced): n</li>
<li>unequal (unbalanced): <span class="math inline">\(n_i\)</span> for the i-th group (i = 1,…,a).</li>
</ul>
<p>The total sample size is <span class="math inline">\(N=\sum_{i=1}^{a}n_i\)</span></p>
<p>Possible assignments of units to treatments are <span class="math inline">\(k=\frac{N!}{n_1!n_2!...n_a!}\)</span></p>
<p>Each has probability 1/k of being selected. Each experimental unit is measured with a response <span class="math inline">\(Y_{ij}\)</span>, in which j denotes unit and i denotes treatment.</p>
<p>Treatment</p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">1</th>
<th align="center">2</th>
<th align="center">…</th>
<th align="center">a</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center"><span class="math inline">\(Y_{11}\)</span></td>
<td align="center"><span class="math inline">\(Y_{21}\)</span></td>
<td align="center">…</td>
<td align="center"><span class="math inline">\(Y_{a1}\)</span></td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="center"><span class="math inline">\(Y_{12}\)</span></td>
<td align="center">…</td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="center">…</td>
<td align="center">…</td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
<tr class="even">
<td align="left">Sample Mean</td>
<td align="center"><span class="math inline">\(\bar{Y_{1.}}\)</span></td>
<td align="center"><span class="math inline">\(\bar{Y_{2.}}\)</span></td>
<td align="center">…</td>
<td align="center"><span class="math inline">\(\bar{Y_{a.}}\)</span></td>
</tr>
<tr class="odd">
<td align="left">Sample SD</td>
<td align="center"><span class="math inline">\(s_1\)</span></td>
<td align="center"><span class="math inline">\(s_2\)</span></td>
<td align="center">…</td>
<td align="center"><span class="math inline">\(s_a\)</span></td>
</tr>
</tbody>
</table>
<p>where <span class="math inline">\(\bar{Y_{i.}}=\frac{1}{n_i}\sum_{j=1}^{n_i}Y_{ij}\)</span></p>
<p><span class="math inline">\(s_i^2=\frac{1}{n_i-1}\sum_{j=1}^{n_i}(Y_{ij}-\bar{Y_i})^2\)</span></p>
<p>And the grand mean is <span class="math inline">\(\bar{Y_{..}}=\frac{1}{N}\sum_{i}\sum_{j}Y_{ij}\)</span></p>
<div id="single-factor-fixed-effects-model" class="section level3" number="20.1.1">
<h3><span class="header-section-number">20.1.1</span> Single Factor Fixed Effects Model</h3>
<p>also known as Single Factor (One-Way) ANOVA or ANOVA Type I model.</p>
<p>Partitioning the Variance</p>
<p>The total variability of the <span class="math inline">\(Y_{ij}\)</span> observation can be measured as the deviation of <span class="math inline">\(Y_{ij}\)</span> around the overall mean <span class="math inline">\(\bar{Y_{..}}\)</span>: <span class="math inline">\(Y_{ij} - \bar{Y_{..}}\)</span></p>
<p>This can be rewritten as: <span class="math display">\[
\begin{split}
Y_{ij} - \bar{Y_{..}}&amp;=Y_{ij} - \bar{Y_{..}} + \bar{Y_{i.}} - \bar{Y_{i.}} \\
&amp;= (\bar{Y_{i.}}-\bar{Y_{..}})+(Y_{ij}-\bar{Y_{i.}})
\end{split}
\]</span> where</p>
<ul>
<li>the first term is the <em>between</em> treatment differences (i.e., the deviation of the treatment mean from the overall mean)<br />
</li>
<li>the second term is <em>within</em> treatment differences (i.e., the deviation of the observation around its treatment mean)</li>
</ul>
<p><br></p>
<p><span class="math display">\[
\begin{split}
\sum_{i}\sum_{j}(Y_{ij} - \bar{Y_{..}})^2 &amp;=  \sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2+\sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2 \\
SSTO &amp;= SSTR + SSE \\
total~SS &amp;= treatment~SS + error~SS \\
(N-1)~d.f. &amp;= (a-1)~d.f. + (N - a) ~ d.f.
\end{split}
\]</span></p>
<p>we lose a d.f. for the total corrected SSTO because of the estimation of the mean (<span class="math inline">\(\sum_{i}\sum_{j}(Y_{ij} - \bar{Y_{..}})=0\)</span>)<br />
And, for the SSTR <span class="math inline">\(\sum_{i}n_i(\bar{Y_{i.}}-\bar{Y_{..}})=0\)</span></p>
<p>Accordingly, <span class="math inline">\(MSTR= \frac{SST}{a-1}\)</span> and <span class="math inline">\(MSR=\frac{SSE}{N-a}\)</span></p>
<p><strong>ANOVA Table</strong></p>
<table>
<colgroup>
<col width="28%" />
<col width="46%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th>Source of Variation</th>
<th align="center">SS</th>
<th align="center">df</th>
<th align="center">MS</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Between Treatments</td>
<td align="center"><span class="math inline">\(\sum_{i}n_i (\bar{Y_{i.}}-\bar{Y_{..}})^2\)</span></td>
<td align="center">a-1</td>
<td align="center">SSTR/(a-1)</td>
</tr>
<tr class="even">
<td>Error (within treatments)</td>
<td align="center"><span class="math inline">\(\sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2\)</span></td>
<td align="center">N-a</td>
<td align="center">SSE/(N-a)</td>
</tr>
<tr class="odd">
<td>Total (corrected)</td>
<td align="center"><span class="math inline">\(\sum_{i}n_i (\bar{Y_{i.}}-\bar{Y_{..}})^2\)</span></td>
<td align="center">N-1</td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>Linear Model Explanation of ANOVA</p>
<div id="cell-means-model" class="section level4" number="20.1.1.1">
<h4><span class="header-section-number">20.1.1.1</span> Cell means model</h4>
<p><span class="math display">\[
Y_{ij}=\mu_i+\epsilon\_{ij}
\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(Y_{ij}\)</span> response variable in j-th subject for the i-th treatment<br />
</p></li>
<li><p><span class="math inline">\(\mu_i\)</span>: parameters (fixed) representing the unknown population mean for the i-th treatment<br />
</p></li>
<li><p><span class="math inline">\(\epsilon_{ij}\)</span> independent <span class="math inline">\(N(0,\sigma^2)\)</span> errors</p></li>
<li><p><span class="math inline">\(E(Y_{ij})=\mu_i\)</span> <span class="math inline">\(var(Y_{ij})=var(\epsilon_{ij})=\sigma^2\)</span><br />
</p></li>
<li><p>All observations have the same variance</p></li>
</ul>
<p>Example:</p>
<p>a = 3 (3 treatments) <span class="math inline">\(n_1=n_2=n_3=2\)</span></p>
<p><br></p>
<p><span class="math display">\[
\begin{split}
\left(\begin{array}{c}
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &amp;=
\left(\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 1 \\
\end{array}\right)
\left(\begin{array}{c}
\mu_1 \\
\mu_2 \\
\mu_3 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &amp;= \mathbf{X\beta} +\mathbf{\epsilon}
\end{split}
\]</span></p>
<p><span class="math inline">\(X_{k,ij}=1\)</span> if the k-th treatment is used</p>
<p><span class="math inline">\(X_{k,ij}=0\)</span> Otherwise</p>
<p><br></p>
<p>Note: no intercept term.</p>
<span class="math display" id="eq:betaorigin">\[\begin{equation}
\begin{split}
\mathbf{b}= \left[\begin{array}{c}
\mu_1 \\
\mu_2 \\
\mu_3 \\
\end{array}\right] &amp;=
(\mathbf{x}&#39;\mathbf{x})^{-1}\mathbf{x}&#39;\mathbf{y} \\
&amp; =
\left[\begin{array}{ccc}
n_1 &amp; 0 &amp; 0\\
0 &amp; n_2 &amp; 0\\
0 &amp; 0 &amp; n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_1\\
Y_2\\
Y_3\\
\end{array}\right] \\
&amp; =
\left[\begin{array}{c}
\bar{Y_1}\\
\bar{Y_2}\\
\bar{Y_3}\\
\end{array}\right]
\end{split}
\tag{20.1}
\end{equation}\]</span>
<p>is the BLUE (best linear unbiased estimator) for <span class="math inline">\(\beta=[\mu_1 \mu_2\mu_3]&#39;\)</span></p>
<p><br></p>
<p><span class="math display">\[
E(\mathbf{b})=\beta
\]</span></p>
<p><span class="math display">\[
var(\mathbf{b})=\sigma^2(\mathbf{X&#39;X})^{-1}=\sigma^2
\left[\begin{array}{ccc}
1/n_1 &amp; 0 &amp; 0\\
0 &amp; 1/n_2 &amp; 0\\
0 &amp; 0 &amp; 1/n_3\\
\end{array}\right]
\]</span></p>
<p><span class="math inline">\(var(b_i)=var(\hat{\mu_i})=\sigma^2/n_i\)</span> where <span class="math inline">\(\mathbf{b} \sim N(\beta,\sigma^2(\mathbf{X&#39;X})^{-1})\)</span></p>
<p><span class="math display">\[
\begin{split}
MSE &amp;= \frac{1}{N-a} \sum_{i}\sum_{j}(Y_{ij}-\bar{Y_{i.}})^2 \\
    &amp;= \frac{1}{N-a} \sum_{i}[(n_i-1)\frac{\sum_{i}(Y_{ij}-\bar{Y_{i.}})^2}{n_i-1}] \\
    &amp;= \frac{1}{N-a} \sum_{i}(n_i-1)s_1^2
\end{split}
\]</span></p>
<p>We have <span class="math inline">\(E(s_i^2)=\sigma^2\)</span></p>
<p><span class="math inline">\(E(MSE)=\frac{1}{N-a}\sum_{i}(n_i-1)\sigma^2=\sigma^2\)</span></p>
<p>Hence, MSE is an unbiased estimator of <span class="math inline">\(\sigma^2\)</span>, regardless of whether the treatment means are equal or not.</p>
<p><span class="math inline">\(E(MSTR)=\sigma^2+\frac{\sum_{i}n_i(\mu_i-\mu_.)^2}{a-1}\)</span><br />
where <span class="math inline">\(\mu_.=\frac{\sum_{i=1}^{a}n_i\mu_i}{\sum_{i=1}^{a}n_i}\)</span><br />
If all treatment means are equals (=<span class="math inline">\(\mu_.\)</span>), <span class="math inline">\(E(MSTR)=\sigma^2\)</span>.</p>
<p>Then we can use an F-test for teh equality of all treatment means:</p>
<p><span class="math display">\[H_0:\mu_1=\mu_2=..=\mu_a\]</span></p>
<p><span class="math display">\[H_a: not~al l~ \mu_i ~ are ~ equal \]</span></p>
<p><span class="math inline">\(F=\frac{MSTR}{MSE}\)</span><br />
where large values of F support <span class="math inline">\(H_a\)</span> (since MSTR will tend to exceed MSE when <span class="math inline">\(H_a\)</span> holds)<br />
and F near 1 support <span class="math inline">\(H_0\)</span> (upper tail test)</p>
<p><strong>Equivalently</strong>, when <span class="math inline">\(H_0\)</span> is true, <span class="math inline">\(F \sim f_{(a-1,N-a)}\)</span></p>
<ul>
<li>If <span class="math inline">\(F \leq f_{(a-1,N-a;1-\alpha)}\)</span>, we cannot reject <span class="math inline">\(H_0\)</span><br />
</li>
<li>If <span class="math inline">\(F \geq f_{(a-1,N-a;1-\alpha)}\)</span>, we reject <span class="math inline">\(H_0\)</span></li>
</ul>
<p>Note: If a = 2 (2 treatments), F-test = two sample t-test</p>
<p><br></p>
</div>
<div id="treatment-effects-factor-effects" class="section level4" number="20.1.1.2">
<h4><span class="header-section-number">20.1.1.2</span> Treatment Effects (Factor Effects)</h4>
<p>Besides Cell means model, we have another way to formalize one-way ANOVA: <span class="math display">\[Y_{ij} = \mu + \tau_i + \epsilon_{ij}\]</span> where</p>
<ul>
<li><span class="math inline">\(Y_{ij}\)</span> is the j-th response for the i-th treatment<br />
</li>
<li><span class="math inline">\(\tau_i\)</span> i-th treatment effect<br />
</li>
<li><span class="math inline">\(\mu\)</span> constant component, common to all observations<br />
</li>
<li><span class="math inline">\(\epsilon_{ij}\)</span> independent random errors ~ <span class="math inline">\(N(0,\sigma^2)\)</span></li>
</ul>
<p><br></p>
<p>For example, a = 3, <span class="math inline">\(n_1=n_2=n_3=2\)</span></p>
<p><br></p>
<span class="math display" id="eq:unsolvable">\[\begin{equation}
\begin{split}
\left(\begin{array}{c}
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &amp;=
\left(\begin{array}{cccc}
1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 0 &amp; 1 \\
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_1 \\
\tau_2 \\
\tau_3\\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &amp;= \mathbf{X\beta} +\mathbf{\epsilon}
\end{split}
\tag{20.2}
\end{equation}\]</span>
<p><br></p>
<p>However,</p>
<p><span class="math display">\[
\mathbf{X&#39;X} =
\left(
\begin{array}
{cccc}
\sum_{i}n_i &amp; n_1 &amp; n_2 &amp; n_3 \\
n_1 &amp; n_1 &amp; 0 &amp; 0 \\
n_2 &amp; 0 &amp; n_2 &amp; 0 \\
n_3 &amp; 0 &amp; 0 &amp; n_3 \\
\end{array}
\right)
\]</span></p>
<p>is <strong>singular</strong> thus does not exist, <span class="math inline">\(\mathbf{b}\)</span> is insolvable (infinite solutions)</p>
<p>Hence, we have to impose restrictions on the parameters to a model matrix <span class="math inline">\(\mathbf{X}\)</span> of full rank.</p>
<p>Whatever restriction we use, we still have:</p>
<p><span class="math inline">\(E(Y_{ij})=\mu + \tau_i = \mu_i = mean ~ response ~ for ~ i-th ~ treatment\)</span></p>
<div id="restriction-on-sum-of-tau" class="section level5" number="20.1.1.2.1">
<h5><span class="header-section-number">20.1.1.2.1</span> Restriction on sum of tau</h5>
<p><span class="math inline">\(\sum_{i=1}^{a}\tau_i=0\)</span></p>
<p><br></p>
<p>implies</p>
<p><span class="math display">\[
\mu= \mu +\frac{1}{a}\sum_{i=1}^{a}(\mu+\tau_i)
\]</span></p>
<p><br></p>
<p>is the average of the treatment mean (grand mean) (overall mean)</p>
<p><span class="math display">\[
\begin{split}
\tau_i  &amp;=(\mu+\tau_i) -\mu = \mu_i-\mu \\
        &amp;= \text{treatment  mean} - \text{grand~mean} \\
        &amp;= \text{treatment  effect}
\end{split}
\]</span></p>
<p><br></p>
<p><span class="math display">\[
\tau_a=-\tau_1-\tau_2-...-\tau_{a-1}
\]</span></p>
<p>Hence, the mean for the a-th treatment is</p>
<p><br></p>
<p><span class="math display">\[
\mu_a=\mu+\tau_a=\mu-\tau_1-\tau_2-...-\tau_{a-1}
\]</span></p>
<p>Hence, the model need only “a” parameters:</p>
<p><br></p>
<p><span class="math display">\[
\mu,\tau_1,\tau_2,..,\tau_{a-1}
\]</span></p>
<p>Equation <a href="completely-randomized-design-crd.html#eq:unsolvable">(20.2)</a> becomes</p>
<p><br></p>
<span class="math display">\[\begin{equation}
\begin{split}
\left(\begin{array}{c}
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &amp;=
\left(\begin{array}{ccc}
1 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 1 \\
1 &amp; -1 &amp; -1 \\
1 &amp; -1 &amp; -1 \\
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_1 \\
\tau_2 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &amp;= \mathbf{X\beta} +\mathbf{\epsilon}
\end{split}
\end{equation}\]</span>
<p>where <span class="math inline">\(\beta\equiv[\mu,\tau_1,\tau_2]&#39;\)</span></p>
<p><br></p>
<p>Equation <a href="completely-randomized-design-crd.html#eq:betaorigin">(20.1)</a> with <span class="math inline">\(\sum_{i}\tau_i=0\)</span> becomes</p>
<p><br></p>
<p><span class="math display">\[
\begin{split}
\mathbf{b}= \left[\begin{array}{c}
\hat{\mu} \\
\hat{\tau_1} \\
\hat{\tau_2} \\
\end{array}\right] &amp;=
(\mathbf{x}&#39;\mathbf{x})^{-1}\mathbf{x}&#39;\mathbf{y} \\
&amp; =
\left[\begin{array}{ccc}
\sum_{i}n_i &amp; n_1-n_3 &amp; n_2-n_3\\
n_1-n_3 &amp; n_1+n_3 &amp; n_3\\
n_2-n_3 &amp; n_3 &amp; n_2-n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_{..}\\
Y_{1.}-Y_{3.}\\
Y_{2.}-Y_{3.}\\
\end{array}\right] \\
&amp; =
\left[\begin{array}{c}
\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\bar{Y_{1.}}-\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\bar{Y_{2.}}-\frac{1}{3}\sum_{i=1}^{3}\bar{Y_{i.}}\\
\end{array}\right]\\
&amp; =
\left[\begin{array}{c}
\hat{\mu}\\
\hat{\tau_1}\\
\hat{\tau_2}\\
\end{array}\right]
\end{split}
\]</span></p>
<p>and <span class="math inline">\(\hat{\tau_3}=-\hat{\tau_1}-\hat{\tau_2}=\bar{Y_3}-\frac{1}{3} \sum_{i}\bar{Y_{i.}}\)</span></p>
</div>
<div id="restriction-on-first-tau" class="section level5" number="20.1.1.2.2">
<h5><span class="header-section-number">20.1.1.2.2</span> Restriction on first tau</h5>
<p>In R, <code>lm()</code> uses the restriction <span class="math inline">\(\tau_1=0\)</span></p>
<p>For the previous example, for <span class="math inline">\(n_1=n_2=n_3=2\)</span>, and <span class="math inline">\(\tau_1=0\)</span>. Then the treatment means can be written as:</p>
<p><span class="math display">\[
\mu_1= \mu + \tau_1 = \mu + 0 = \mu  \\
\mu_2= \mu + \tau_2 \\
\mu_3 = \mu + \tau_3
\]</span></p>
<p>Hence, <span class="math inline">\(\mu\)</span> is the mean response for the first treatment</p>
<p>In the matrix form,</p>
<p><span class="math display">\[
\begin{split}
\left(\begin{array}{c}
Y_{11}\\
Y_{12}\\
Y_{21}\\
Y_{22}\\
Y_{31}\\
Y_{32}\\
\end{array}\right) &amp;=
\left(\begin{array}{ccc}
1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 \\
1 &amp; 1 &amp; 0 \\
1 &amp; 1 &amp; 0 \\
1 &amp; 0 &amp; 1 \\
1 &amp; 0 &amp; 1 \\
\end{array}\right)
\left(\begin{array}{c}
\mu \\
\tau_2 \\
\tau_3 \\
\end{array}\right) + \left(\begin{array}{c}
\epsilon_{11} \\
\epsilon_{12} \\
\epsilon_{21} \\
\epsilon_{22} \\
\epsilon_{31} \\
\epsilon_{32} \\
\end{array}\right)\\
\mathbf{y} &amp;= \mathbf{X\beta} +\mathbf{\epsilon}
\end{split}
\]</span></p>
<p><span class="math inline">\(\beta = [\mu,\tau_2,\tau_3]&#39;\)</span></p>
<p><span class="math display">\[
\begin{split}
\mathbf{b}= \left[\begin{array}{c}
\hat{\mu} \\
\hat{\tau_2} \\
\hat{\tau_3} \\
\end{array}\right] &amp;=
(\mathbf{x}&#39;\mathbf{x})^{-1}\mathbf{x}&#39;\mathbf{y} \\
&amp; =
\left[\begin{array}{ccc}
\sum_{i}n_i &amp; n_2 &amp; n_3\\
n_2 &amp; n_2 &amp; 0\\
n_3 &amp; 0 &amp; n_3 \\
\end{array}\right]^{-1}
\left[\begin{array}{c}
Y_{..}\\
Y_{2.}\\
Y_{3.}\\
\end{array}\right] \\
&amp; =
\left[
\begin{array}{c}
\bar{Y_{1.}} \\
\bar{Y_{2.}} - \bar{Y_{1.}} \\
\bar{Y_{3.}} - \bar{Y_{1.}}\\
\end{array}\right]
\end{split}
\]</span></p>
<p><span class="math display">\[
E(\mathbf{b})= \beta =
\left[\begin{array}{c}
{\mu}\\
{\tau_2}\\
{\tau_3}\\
\end{array}\right]
=
\left[\begin{array}{c}
\mu_1\\
\mu_2-\mu_1\\
\mu_3-\mu_1\\
\end{array}\right]
\]</span></p>
<p><span class="math display">\[
var(\mathbf{b}) = \sigma^2(\mathbf{X&#39;X})^{-1} \\
var(\hat{\mu}) = var(\bar{Y_{1.}})=\sigma^2/n_1 \\
var(\hat{\tau_2}) = var(\bar{Y_{2.}}-\bar{Y_{1.}}) = \sigma^2/n_2 + \sigma^2/n_1 \\
var(\hat{\tau_3}) = var(\bar{Y_{3.}}-\bar{Y_{1.}}) = \sigma^2/n_3 + \sigma^2/n_1
\]</span></p>
<p><br></p>
<p><strong>Note</strong> For all three parameterization, the ANOVA table is the same</p>
<ul>
<li><a href="completely-randomized-design-crd.html#cell-means-model-1">Model 1</a>: <span class="math inline">\(Y_{ij} = \mu_i + \epsilon_{ij}\)</span></li>
<li><a href="completely-randomized-design-crd.html#restriction-on-sum-of-tau">Model 2</a>: <span class="math inline">\(Y_{ij} = \mu + \tau_i + \epsilon_{ij}\)</span> where <span class="math inline">\(\sum_{i} \tau_i=0\)</span></li>
<li><a href="completely-randomized-design-crd.html#restriction-on-first-tau">Model 3</a>: <span class="math inline">\(Y_{ij}= \mu + \tau_i + \epsilon_{ij}\)</span> where <span class="math inline">\(\tau_1=0\)</span></li>
</ul>
<p>All models have the same calculation for <span class="math inline">\(\hat{Y}\)</span> as</p>
<p><span class="math display">\[
\mathbf{\hat{Y} = X(X&#39;X)^{-1}X&#39;Y=PY = Xb}
\]</span></p>
<p><strong>ANOVA Table</strong></p>
<table>
<colgroup>
<col width="14%" />
<col width="51%" />
<col width="6%" />
<col width="13%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th>Source of Variation</th>
<th align="center">SS</th>
<th align="center">df</th>
<th align="center">MS</th>
<th align="center">F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Between Treatments</td>
<td align="center"><span class="math inline">\(\sum_{i} n _ i (\bar { Y_ {i .} } -\bar{Y_{..}})^2 = \mathbf{Y &#39; (P-P_1)Y}\)</span></td>
<td align="center">a-1</td>
<td align="center"><span class="math inline">\(\frac{SSTR}{a-1}\)</span></td>
<td align="center"><span class="math inline">\(\frac{MSTR}{MSE}\)</span></td>
</tr>
<tr class="even">
<td><p>Error</p>
<p>(within treatments)</p></td>
<td align="center"><span class="math inline">\(\sum_{i}\sum_{j}(Y_{ij} -\bar{Y_{i.}})^2=\mathbf{e&#39;e}\)</span></td>
<td align="center">N-a</td>
<td align="center"><span class="math inline">\(\frac{SSE}{N-a}\)</span></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td>Total (corrected)</td>
<td align="center"><span class="math inline">\(\sum_{i } n_i(\bar{Y_{i.}}-\bar{Y_{..}})^2=\mathbf{Y&#39;Y - Y&#39;P_1Y}\)</span></td>
<td align="center">N-1</td>
<td align="center"></td>
<td align="center"></td>
</tr>
</tbody>
</table>
<p>where <span class="math inline">\(\mathbf{P_1} = \frac{1}{n}\mathbf{J}\)</span></p>
<p>The F-statistic here has (a-1,N-a) degrees of freedom, which gives the same value for all three parameterization, but the hypothesis test is written a bit different:</p>
<p><span class="math display">\[
H_0 : \mu_1 = \mu_2 = ... = \mu_a \\
H_0 : \mu + \tau_1 = \mu + tau_2 = ... = \mu + \tau_a \\
H_0 : \tau_1 = \tau_2 = ...= \tau_a
\]</span></p>
<p>The F-test here serves as a preliminary analysis, to see if there is any difference at different factors. For more in-depth analysis, we consider different testing of treatment effects.</p>
</div>
</div>
<div id="testing-of-treatment-effects" class="section level4" number="20.1.1.3">
<h4><span class="header-section-number">20.1.1.3</span> Testing of Treatment Effects</h4>
<ul>
<li>A <a href="completely-randomized-design-crd.html#single-treatment-mean">Single Treatment Mean</a> <span class="math inline">\(\mu_i\)</span></li>
<li>A <a href="completely-randomized-design-crd.html#differences-between-treatment-means">Differences Between Treatment Means</a></li>
<li>A <a href="completely-randomized-design-crd.html#contrast-among-treatment-means">Contrast Among Treatment Means</a></li>
<li>A <a href="completely-randomized-design-crd.html#linear-combination-of-treatment-means">Linear Combination of Treatment Means</a></li>
</ul>
<div id="single-treatment-mean" class="section level5" number="20.1.1.3.1">
<h5><span class="header-section-number">20.1.1.3.1</span> Single Treatment Mean</h5>
<p>We have <span class="math inline">\(\hat{\mu_i}=\bar{Y_{i.}}\)</span> where</p>
<ul>
<li><span class="math inline">\(E(\bar{Y_{i.}})=\mu_i\)</span></li>
<li><span class="math inline">\(var(\bar{Y_{i}})=\sigma^2/n_i\)</span> estimated by <span class="math inline">\(s^2(\bar{Y_{i.}})=MSE / n_i\)</span></li>
</ul>
<p>Since <span class="math inline">\(\frac{\bar{Y_{i.}}-\mu_i}{s(\bar{Y_{i.}})} \sim t_{N-a}\)</span> and the confidence interval for <span class="math inline">\(\mu_i\)</span> is <span class="math inline">\(\bar{Y_{i.}} \pm t_{1-\alpha/2;N-a}s(\bar{Y_{i.}})\)</span>,<br />
then we can do a t-test for the means difference with some constant c</p>
<p><span class="math display">\[
H_0: \mu_i = c \\
H_1: \mu_i \neq c
\]</span></p>
<p>where</p>
<p><span class="math display">\[
T =\frac{\bar{Y_{i.}}-c}{s(\bar{Y_{i.}})}
\]</span></p>
<p>follows <span class="math inline">\(t_{N-a}\)</span> when <span class="math inline">\(H_0\)</span> is true.<br />
If <span class="math inline">\(|T| &gt; t_{1-\alpha/2;N-a}\)</span>, we can reject <span class="math inline">\(H_0\)</span></p>
</div>
<div id="differences-between-treatment-means" class="section level5" number="20.1.1.3.2">
<h5><span class="header-section-number">20.1.1.3.2</span> Differences Between Treatment Means</h5>
<p>Let <span class="math inline">\(D=\mu_i - \mu_i&#39;\)</span>, also known as <strong>pairwise comparison</strong><br />
<span class="math inline">\(D\)</span> can be estimated by <span class="math inline">\(\hat{D}=\bar{Y_{i}}-\bar{Y_{i}}&#39;\)</span> is unbiased (<span class="math inline">\(E(\hat{D})=\mu_i-\mu_i&#39;\)</span>)</p>
<p>Since <span class="math inline">\(\bar{Y_{i}}\)</span> and <span class="math inline">\(\bar{Y_{i}}&#39;\)</span> are independent, then</p>
<p><span class="math display">\[
var(\hat{D})=var(\bar{Y_{i}}) + var(\bar{Y_{i&#39;}}) = \sigma^2(1/n_i + 1/n_i&#39;)
\]</span></p>
<p>can be estimated with</p>
<p><span class="math display">\[
s^2(\hat{D}) = MSE(1/n_i + 1/n_i&#39;)
\]</span></p>
<p>With the single treatment inference,</p>
<p><span class="math display">\[
\frac{\hat{D}-D}{s(\hat{D})} \sim t_{N-a}
\]</span></p>
<p>hence,</p>
<p><span class="math display">\[
\hat{D} \pm t_{(1-\alpha/2;N-a)}s(\hat{D})
\]</span></p>
<p>Hypothesis tests:</p>
<p><span class="math display">\[
H_0: \mu_i = \mu_i&#39; \\
H_a: \mu_i \neq \mu_i&#39;
\]</span></p>
<p>can be tested by the following statistic</p>
<p><span class="math display">\[
T = \frac{\hat{D}}{s(\hat{D})} \sim t_{1-\alpha/2;N-a}
\]</span></p>
<p>reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|T| &gt; t_{1-\alpha/2;N-a}\)</span></p>
</div>
<div id="contrast-among-treatment-means" class="section level5" number="20.1.1.3.3">
<h5><span class="header-section-number">20.1.1.3.3</span> Contrast Among Treatment Means</h5>
<p>generalize the comparison of two means, we have <strong>contrasts</strong></p>
<p>A contrast is a linear combination of treatment means:</p>
<p><span class="math display">\[
L = \sum_{i=1}^{a}c_i \mu_i
\]</span></p>
<p>where each <span class="math inline">\(c_i\)</span> is non-random constant and sum to 0:</p>
<p><span class="math display">\[
\sum_{i=1}^{a} c_i = 0
\]</span></p>
<p>An unbiased estimator of a contrast L is</p>
<p><span class="math display">\[
\hat{L} = \sum_{i=1}^{a}c_i \bar{Y}_{i.}
\]</span></p>
<p>and <span class="math inline">\(E(\hat{L}) = L\)</span>. Since the <span class="math inline">\(\bar{Y}_{i.}\)</span>, i = 1,…, a are independent.</p>
<p><span class="math display">\[
var(\hat{L}) = var(\sum_{i=1}^a c_i \bar{Y}_{i.}) = \sum_{i=1}^a var(c_i \bar{Y}_i)  \\
= \sum_{i=1}^a c_i^2 var(\bar{Y}_i) = \sum_{i=1}^a c_i^2 \sigma^2 /n_i \\
= \sigma^2 \sum_{i=1}^{a} c_i^2 /n_i
\]</span></p>
<p>Estimation of the variance:</p>
<p><span class="math display">\[
s^2(\hat{L}) = MSE \sum_{i=1}^{a} \frac{c_i^2}{n_i}
\]</span></p>
<p><span class="math inline">\(\hat{L}\)</span> is normally distributed (since it is a linear combination of independent normal random variables).</p>
<p>Then, since <span class="math inline">\(SSE/\sigma^2\)</span> is <span class="math inline">\(\chi_{N-a}^2\)</span></p>
<p><span class="math display">\[
\frac{\hat{L}-L}{s(\hat{L})} \sim t_{N-a}
\]</span></p>
<p>A <span class="math inline">\(1-\alpha\)</span> confidence limits are given by</p>
<p><span class="math display">\[
\hat{L} \pm t_{1-\alpha/2; N-a}s(\hat{L})
\]</span></p>
<p>Hypothesis testing</p>
<p><span class="math display">\[
H_0: L = 0 \\
H_a: L \neq 0
\]</span></p>
<p>with</p>
<p><span class="math display">\[
T = \frac{\hat{L}}{s(\hat{L})}
\]</span></p>
<p>reject H_0 if <span class="math inline">\(|T| &gt; t_{1-\alpha/2;N-a}\)</span></p>
</div>
<div id="linear-combination-of-treatment-means" class="section level5" number="20.1.1.3.4">
<h5><span class="header-section-number">20.1.1.3.4</span> Linear Combination of Treatment Means</h5>
<p>just like contrast <span class="math inline">\(L = \sum_{i=1}^a c_i \mu_i\)</span> but no restrictions on the <span class="math inline">\(c_i\)</span> coefficients.</p>
<p>Tests og a single treatment mean, two treatment means, and contrasts can all be considered form the same perspective.</p>
<p><span class="math display">\[
H_0: \sum c_i \mu_i = c \\
H_a: \sum c_i \mu_i \neq c
\]</span></p>
<p>The test statistics (t-stat) can be considered equivalently as F-tests; <span class="math inline">\(F = (T)^2\)</span> where <span class="math inline">\(F \sim F_{1,N-a}\)</span>. Since the numerator degrees of freedom is always 1 in these cases, we refer to them as single-degree-of-freedom tests.</p>
<p><br></p>
<p><strong>Multiple Contrasts</strong></p>
<p>To test simultaneously <span class="math inline">\(k \ge 2\)</span> contrasts, let <span class="math inline">\(T_1,...,T_k\)</span> be the t-stat. The joint distribution of these random variables is a multivariate t-distribution (the tests are dependent since they re based on the same data).</p>
<p>Limitations for comparing multiple contrasts:</p>
<ol style="list-style-type: decimal">
<li><p>The confidence coefficient <span class="math inline">\(1-\alpha\)</span> only applies to a particular estimate, not a series of estimates; similarly, the Type I error rate, <span class="math inline">\(\alpha\)</span>, applies to a particular test, not a series of tests. Example: 3 t-tests at <span class="math inline">\(\alpha = 0.05\)</span>, if tests are independent (which they are not), <span class="math inline">\(0.95^3 = 0.857\)</span> (thus <span class="math inline">\(\alpha - 0.143\)</span> not 0.05)<br />
</p></li>
<li><p>The confidence coefficient <span class="math inline">\(1-\alpha\)</span> and significance level <span class="math inline">\(\alpha\)</span> are appropriate only if the test was not suggest by the data.</p>
<ul>
<li>often, the results of an experiment suggest important (ie..g, potential significant) relationships.<br />
</li>
<li>the process of studying effects suggests by the data is called <strong>data snooping</strong></li>
</ul></li>
</ol>
<p><br></p>
<p>Multiple Comparison Procedures:</p>
<ul>
<li><a href="completely-randomized-design-crd.html#tukey">Tukey</a></li>
<li><a href="completely-randomized-design-crd.html#scheffe">Scheffe</a></li>
<li><a href="completely-randomized-design-crd.html#bonferroni">Bonferroni</a></li>
</ul>
<div id="tukey" class="section level6" number="20.1.1.3.4.1">
<h6><span class="header-section-number">20.1.1.3.4.1</span> Tukey</h6>
<p>All pairwise comparisons of factor level means. All pairs <span class="math inline">\(D = \mu_i - \mu_i&#39;\)</span> or all tests of the form:</p>
<p><span class="math display">\[
H_0: \mu_i -\mu_i&#39; = 0 \\
H_a: \mu_i - \mu_i&#39; \neq 0
\]</span></p>
<ul>
<li>When all sample sizes are equal (<span class="math inline">\(n_1 = n_2 = ... = n_a\)</span>) then the Tukey method family confidence coefficient is exactly <span class="math inline">\(1-\alpha\)</span> and the significance level is exactly <span class="math inline">\(\alpha\)</span><br />
</li>
<li>When the sample sizes are not equal, the family confidence coefficient is greater than <span class="math inline">\(1-\alpha\)</span> (i.e., the significance level is less than <span class="math inline">\(\alpha\)</span>) so the test i<strong>conservative</strong><br />
</li>
<li>Tukey considers the <strong>studentized range distribution</strong>. If we have <span class="math inline">\(Y_1,..,Y_r\)</span>, observations from a normal distribution with mean <span class="math inline">\(\alpha\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. Define: <span class="math display">\[
w = max(Y_i) - min(Y_i)
\]</span> as the range of the observations. Let <span class="math inline">\(s^2\)</span> be an estimate of <span class="math inline">\(\sigma^2\)</span> with v degrees of freedom. Then, <span class="math display">\[
q(r,v) = \frac{w}{s}
\]</span> is called the studentized range. The distribution of q uses a special table.</li>
</ul>
<p><br></p>
<p><strong>Notes</strong></p>
<ul>
<li>when we are not interested in testing all pairwise comparison,s the confidence coefficient for the family of comparisons under consideration will be greater than <span class="math inline">\(1-\alpha\)</span> (with the significance level less than <span class="math inline">\(\alpha\)</span>)<br />
</li>
<li>Tukey can be used for “data snooping” as long as the effects to be studied on the basis of preliminary data analysis are pairwise comparisons.</li>
</ul>
</div>
<div id="scheffe" class="section level6" number="20.1.1.3.4.2">
<h6><span class="header-section-number">20.1.1.3.4.2</span> Scheffe</h6>
<p>This method applies when the family of interest is the set of possible contrasts among the treatment means:</p>
<p><span class="math display">\[
L = \sum_{i=1}^a c_i \mu_i
\]</span></p>
<p>where <span class="math inline">\(\sum_{i=1}^a c_i =0\)</span></p>
<p>That is, the family of all possible contrasts L or</p>
<p><span class="math display">\[
H_0: L = 0 \\
H_a: L \neq 0
\]</span></p>
<p>The family confidence level for the Scheffe procedure is exactly <span class="math inline">\(1-\alpha\)</span> (i.e., significance level = <span class="math inline">\(\alpha\)</span>) whether the sample sizes are equal or not.</p>
<p>For simultaneous confidence intervals,</p>
<p><span class="math display">\[
\hat{L} \pm Ss(\hat{L})
\]</span></p>
<p>where <span class="math inline">\(\hat{L}=\sum c_i \bar{Y}_{i.},s^2(\hat{L}) = MSE \sum c_i^2/n_i\)</span> and <span class="math inline">\(S^2 = (a-1)f_{1-\alpha;a-1,N-a}\)</span></p>
<p>The Scheffe procedure considers</p>
<p><span class="math display">\[
F = \frac{\hat{L}^2}{(a-1)s^2(\hat{L})}
\]</span></p>
<p>where we reject <span class="math inline">\(H_0\)</span> at the family significance level <span class="math inline">\(\alpha\)</span> if <span class="math inline">\(F &gt; f_{(1-\alpha;a-1,N-a)}\)</span></p>
<p><strong>Note</strong></p>
<ul>
<li>Since applications of the Scheffe never involve all conceivable contrasts, the <strong>finite family</strong> confidence coefficient will be larger than <span class="math inline">\(1-\alpha\)</span>, so <span class="math inline">\(1-\alpha\)</span> is a lower bound. Thus, people often consider a larger <span class="math inline">\(\alpha\)</span> (e.g., 90% confidence interval)<br />
</li>
<li>Scheffe can be used for “data scooping” since the family of statements contains all possible contrasts.<br />
</li>
<li>If only pairwise comparisons are to be considered, The Tukey procedure gives narrower confidence limits.</li>
</ul>
</div>
<div id="bonferroni" class="section level6" number="20.1.1.3.4.3">
<h6><span class="header-section-number">20.1.1.3.4.3</span> Bonferroni</h6>
<p>Applicable whether the sample sizes are equal or unequal.</p>
<p>For the confidence intervals,</p>
<p><span class="math display">\[
\hat{L} \pm B s(\hat{L})
\]</span></p>
<p>where <span class="math inline">\(B= t_{(1-\alpha/(2g);N-a)}\)</span> and g is the number of comparisons in the family.</p>
<p>Hypothesis testing</p>
<p><span class="math display">\[
H_0: L = 0 \\
H_a: L \neq 0
\]</span></p>
<p>Let <span class="math inline">\(T= \frac{\hat{L}}{s(\hat{L})}\)</span> and reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|T|&gt;t_{1-\alpha/(2g),N-a}\)</span></p>
<p><strong>Notes</strong></p>
<ul>
<li>If all pairwise comparisons are of interest, the Tukey procedure is superior (narrower confidence intervals). If not, Bonferroni may be better.</li>
<li>Bonferroni is better than Scheffe when the number of contrasts is about the same as the treatment levels (or less).</li>
<li>Recommendation: compute all threes and pick the smallest.</li>
<li>Bonferroni can’t be used for <strong>data snooping</strong></li>
</ul>
</div>
<div id="fishers-lsd" class="section level6" number="20.1.1.3.4.4">
<h6><span class="header-section-number">20.1.1.3.4.4</span> Fisher’s LSD</h6>
<p>does not control for family error rate</p>
<p>use t-stat for testing</p>
<p><span class="math display">\[
H_0: \mu_i = \mu_j
\]</span></p>
<p>t-stat</p>
<p><span class="math display">\[
t = \frac{\bar{y}_i - \bar{y}_j}{\sqrt{MSE(\frac{1}{n_i}+ \frac{1}{n_j})}}
\]</span></p>
</div>
<div id="newman-keuls" class="section level6" number="20.1.1.3.4.5">
<h6><span class="header-section-number">20.1.1.3.4.5</span> Newman-Keuls</h6>
<p>Do not recommend using this test since it has less power than ANOVA.</p>
</div>
</div>
<div id="multiple-comparisons-with-a-control" class="section level5" number="20.1.1.3.5">
<h5><span class="header-section-number">20.1.1.3.5</span> Multiple comparisons with a control</h5>
<div id="dunnett" class="section level6" number="20.1.1.3.5.1">
<h6><span class="header-section-number">20.1.1.3.5.1</span> Dunnett</h6>
<p>We have <span class="math inline">\(a\)</span> groups where the last group is the control group, and the <span class="math inline">\(a-1\)</span> treatment groups.</p>
<p>Then, we compare treatment groups to the control group. Hence, we have <span class="math inline">\(a-1\)</span> contrasts (i.e., <span class="math inline">\(a-1\)</span> pairwise comparisons)</p>
</div>
</div>
<div id="summary-4" class="section level5" number="20.1.1.3.6">
<h5><span class="header-section-number">20.1.1.3.6</span> Summary</h5>
<p>When choosing a multiple contrast method:</p>
<ul>
<li><p>Pairwise</p>
<ul>
<li>Equal groups sizes: <a href="completely-randomized-design-crd.html#tukey">Tukey</a><br />
</li>
<li>Unequal groups sizes: <a href="completely-randomized-design-crd.html#tukey">Tukey</a>, <a href="completely-randomized-design-crd.html#scheffe">Scheffe</a><br />
</li>
</ul></li>
<li><p>Not pairwise</p>
<ul>
<li>with control: <a href="completely-randomized-design-crd.html#dunnett">Dunnett</a><br />
</li>
<li>general: <a href="completely-randomized-design-crd.html#bonferroni">Bonferroni</a>, <a href="completely-randomized-design-crd.html#scheffe">Scheffe</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div id="single-factor-random-effects-model" class="section level3" number="20.1.2">
<h3><span class="header-section-number">20.1.2</span> Single Factor Random Effects Model</h3>
<p>Also known as ANOVA Type II models.</p>
<p>Treatments are chosen at from from larger population. We extend inference to all treatments in the population and not restrict our inference to those treatments that happened to be selected for the study.</p>
<div id="random-cell-means" class="section level4" number="20.1.2.1">
<h4><span class="header-section-number">20.1.2.1</span> Random Cell Means</h4>
<p><span class="math display">\[
Y_{ij} = \mu_i + \epsilon_{ij}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mu_i \sim N(\mu, \sigma^2_{\mu})\)</span> and independent<br />
</li>
<li><span class="math inline">\(\epsilon_{ij} \sim N(0,\sigma^2)\)</span> and independent</li>
</ul>
<p><span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\epsilon_{ij}\)</span> are mutually independent for <span class="math inline">\(i =1,...,a; j = 1,...,n\)</span></p>
<p>With all treatment sample sizes are equal</p>
<p><span class="math display">\[
E(Y_{ij}) = E(\mu_i) = \mu \\
var(Y_{ij}) = var(\mu_i) + var(\epsilon_i) = \sigma^2_{\mu} + \sigma^2
\]</span></p>
<p>Since <span class="math inline">\(Y_{ij}\)</span> are not independent</p>
<p><span class="math display">\[
\begin{aligned}
cov(Y_{ij},Y_{ij&#39;}) &amp;= E(Y_{ij}Y_{ij&#39;}) - E(Y_{ij})E(Y_{ij&#39;})  \\
&amp;= E(\mu_i^2 + \mu_i \epsilon_{ij&#39;} + \mu_i \epsilon_{ij} + \epsilon_{ij}\epsilon_{ij&#39;}) - \mu^2 \\
&amp;= \sigma^2_{\mu} + \mu^2 - \mu^2 &amp; \text{if} j \neq j&#39; \\
&amp;= \sigma^2_{\mu} &amp; \text{if} j \neq j&#39;
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
cov(Y_{ij},Y_{i&#39;j&#39;}) &amp;= E(\mu_i \mu_{i&#39;} + \mu_i \epsilon_{i&#39;j&#39;}+ \mu_{i&#39;}\epsilon_{ij}+ \epsilon_{ij}\epsilon_{i&#39;j&#39;}) - \mu^2 \\
&amp;= \mu^2 - \mu^2 &amp; \text{if } i \neq i&#39; \\
&amp;= 0 \\
\end{aligned}
\]</span></p>
<p>Hence,</p>
<ul>
<li>all observations have the same variance<br />
</li>
<li>any two observations from the same treatment have covariance <span class="math inline">\(\sigma^2_{\mu}\)</span><br />
</li>
<li>The correlation between any two responses from the same treatment:<br />
<span class="math display">\[
\begin{aligned}
\rho(Y_{ij},Y_{ij&#39;}) &amp;= \frac{\sigma^2_{\mu}}{\sigma^2_{\mu}+ \sigma^2} &amp;&amp; \text{$j \neq j&#39;$}
\end{aligned}
\]</span></li>
</ul>
<p><strong>Inference</strong></p>
<p><strong>Intraclass Correlation Coefficient</strong></p>
<p><span class="math display">\[
\frac{\sigma^2_{\mu}}{\sigma^2 + \sigma^2_{\mu}}
\]</span></p>
<p>which measures the proportion of total variability of <span class="math inline">\(Y_{ij}\)</span> accounted for by the variance of <span class="math inline">\(\mu_i\)</span></p>
<p><span class="math display">\[
H_0: \sigma_{\mu}^2 = 0 \\
H_a: \sigma_{\mu}^2 \neq 0
\]</span></p>
<p><span class="math inline">\(H_0\)</span> implies <span class="math inline">\(\mu_i = \mu\)</span> for all i, which can be tested by the F-test in ANOVA.</p>
<p>The understandings of the <a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model">Single Factor Fixed Effects Model</a> and the <a href="completely-randomized-design-crd.html#single-factor-random-effects-model">Single Factor Random Effects Model</a> are different, the ANOVA is same for the one factor model. The difference is in the expected mean squares</p>
<table>
<colgroup>
<col width="38%" />
<col width="61%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Random Effects</strong> Model</th>
<th><strong>Fixed Effects</strong> Model</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(E(MSE) = \sigma^2\)</span></td>
<td><span class="math inline">\(E(MSE) = \sigma^2\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(E(M STR) = \sigma^2 - n \sigma^2_\mu\)</span></td>
<td><span class="math inline">\(E(MSTR) = \sigma^2 + \frac{ \sum_i n_i (\mu_i - \mu)^2}{a-1}\)</span></td>
</tr>
</tbody>
</table>
<p>If <span class="math inline">\(\sigma^2_\mu\)</span>, then MSE and MSTR have the same expectation (<span class="math inline">\(\sigma^2\)</span>). Otherwise, <span class="math inline">\(E(MSTR) &gt;E(MSE)\)</span>. Large values of the statistic</p>
<p><span class="math display">\[
F = \frac{MSTR}{MSE}
\]</span></p>
<p>suggest we reject <span class="math inline">\(H_0\)</span>.</p>
<p>Since <span class="math inline">\(F \sim F_{(a-1,a(n-1))}\)</span> when <span class="math inline">\(H_0\)</span> holds. If <span class="math inline">\(F &gt; f_{(1-\alpha;a-1,a(n-1))}\)</span> we reject <span class="math inline">\(H_0\)</span>. If sample sizes are not equal, F-test can still be used, but the df are <span class="math inline">\(a-1\)</span> and <span class="math inline">\(N-a\)</span>.</p>
<div id="estimation-of-mu" class="section level5" number="20.1.2.1.1">
<h5><span class="header-section-number">20.1.2.1.1</span> Estimation of <span class="math inline">\(\mu\)</span></h5>
<p>An unbiased estimator of <span class="math inline">\(E(Y_{ij})=\mu\)</span> is the grand mean: <span class="math inline">\(\hat{\mu} = \hat{Y}_{..}\)</span></p>
<p>The variance of this estimator is</p>
<p><span class="math display">\[
\begin{aligned}
var(\bar{Y}_{..}) &amp;= var(\sum_i \bar{Y}_{i.}/a) \\
&amp;= \frac{1}{a^2}\sum_ivar(\bar{Y}_{i.}) \\
&amp;= \frac{1}{a^2}\sum_i(\sigma^2_\mu+\sigma^2/n) \\
&amp;= \frac{1}{a^2}(\sigma^2_{\mu}+\sigma^2/n) \\
&amp;= \frac{n\sigma^2_{\mu}+ \sigma^2}{an}
\end{aligned}
\]</span></p>
<p>An unbiased estimator of this variance is <span class="math inline">\(s^2(\bar{Y})=\frac{MSTR}{an}\)</span>. Thus <span class="math inline">\(\frac{\bar{Y}_{..}-\mu}{s(\bar{Y}_{..})} \sim t_{a-1}\)</span></p>
<p>A <span class="math inline">\(1-\alpha\)</span> confidence interval is <span class="math inline">\(\bar{Y}_{..} \pm t_{(1-\alpha/2;a-1)}s(\bar{Y}_{..})\)</span></p>
</div>
<div id="estimation-of-sigma2_musigma2_musigma2" class="section level5" number="20.1.2.1.2">
<h5><span class="header-section-number">20.1.2.1.2</span> Estimation of <span class="math inline">\(\sigma^2_\mu/(\sigma^2_{\mu}+\sigma^2)\)</span></h5>
<p>In the random and fixed effects model, MSTR and MSE are independent. When the sample sizes are equal (<span class="math inline">\(n_i = n\)</span> for all i),</p>
<p><span class="math display">\[
\frac{\frac{MSTR}{n\sigma^2_\mu+ \sigma^2}}{\frac{MSE}{\sigma^2}} \sim f_{(a-1,a(n-1))}
\]</span></p>
<p><span class="math display">\[
P(f_{(\alpha/2;a-1,a(n-1))}\le \frac{\frac{MSTR}{n\sigma^2_\mu+ \sigma^2}}{\frac{MSE}{\sigma^2}} \le f_{(1-\alpha/2;a-1,a(n-1))}) = 1-\alpha
\]</span></p>
<p><span class="math display">\[
L = \frac{1}{n}(\frac{MSTR}{MSE}(\frac{1}{f_{(1-\alpha/2;a-1,a(n-1))}})-1) \\
U = \frac{1}{n}(\frac{MSTR}{MSE}(\frac{1}{f_{(\alpha/2;a-1,a(n-1))}})-1)
\]</span></p>
<p>The lower and upper <span class="math inline">\((L^*,U^*)\)</span> confidence limits for <span class="math inline">\(\frac{\sigma^2_\mu}{\sigma^2_\mu + \sigma^2}\)</span></p>
<p><span class="math display">\[
L^* = \frac{L}{1+L} \\
U^* = \frac{U}{1+U}
\]</span></p>
<p>If the lower limit for <span class="math inline">\(\frac{\sigma^2_\mu}{\sigma^2}\)</span> is negative, it is customary to set L = 0.</p>
</div>
<div id="estimation-of-sigma2" class="section level5" number="20.1.2.1.3">
<h5><span class="header-section-number">20.1.2.1.3</span> Estimation of <span class="math inline">\(\sigma^2\)</span></h5>
<p><span class="math inline">\(a(n-1)MSE/\sigma^2 \sim \chi^2_{a(n-1)}\)</span>, the <span class="math inline">\((1-\alpha)\)</span> confidence interval for <span class="math inline">\(\sigma^2\)</span>:</p>
<p><span class="math display">\[
\frac{a(n-1)MSE}{\chi^2_{1-\alpha/2;a(n-1)}} \le \sigma^2 \le \frac{a(n-1)MSE}{\chi^2_{\alpha/2;a(n-1)}}
\]</span></p>
<p>can also be used in case sample sizes are not equal - then df is N-a.</p>
</div>
<div id="estimation-of-sigma2_mu" class="section level5" number="20.1.2.1.4">
<h5><span class="header-section-number">20.1.2.1.4</span> Estimation of <span class="math inline">\(\sigma^2_\mu\)</span></h5>
<p><span class="math inline">\(E(MSE) = \sigma^2\)</span> <span class="math inline">\(E(MSTR) = \sigma^2 + n\sigma^2_\mu\)</span>. Hence,</p>
<p><span class="math display">\[
\sigma^2_{\mu} = \frac{E(MSTR)- E(MSE)}{n}
\]</span></p>
<p>An unbiased estimator of <span class="math inline">\(\sigma^2_\mu\)</span> is given by</p>
<p><span class="math display">\[
s^2_\mu =\frac{MSTR-MSE}{n}
\]</span></p>
<p>if <span class="math inline">\(s^2_\mu &lt; 0\)</span>, set <span class="math inline">\(s^2_\mu = 0\)</span></p>
<p>If sample sizes are not equal,</p>
<p><span class="math display">\[
s^2_\mu = \frac{MSTR - MSE}{n&#39;}
\]</span></p>
<p>where <span class="math inline">\(n&#39; = \frac{1}{a-1}(\sum_i n_i- \frac{\sum_i n^2_i}{\sum_i n_i})\)</span></p>
<p>no exact confidence intervals for <span class="math inline">\(\sigma^2_\mu\)</span>, but we can approximate intervals.</p>
<p><strong>Satterthewaite Procedure</strong> can be used to construct approximate confidence intervals for linear combination of expected mean squares<br />
A linear combination:</p>
<p><span class="math display">\[
\sigma^2_\mu = \frac{1}{n} E(MSTR) + (-\frac{1}{n}) E(MSE)
\]</span></p>
<p><span class="math display">\[
S = d_1 E(MS_1) + ..+ d_h E(MS_h)
\]</span></p>
<p>where <span class="math inline">\(d_i\)</span> are coefficients.</p>
<p>An unbiased estimator of S is</p>
<p><span class="math display">\[
\hat{S} = d_1 MS_1 + ...+ d_h  MS_h
\]</span></p>
<p>Let <span class="math inline">\(df_i\)</span> be the degrees of freedom associated with teh mean square <span class="math inline">\(MS_i\)</span>. The <strong>Satterthwaite</strong> approximation:</p>
<p><span class="math display">\[
\frac{(df)\hat{S}}{S} \sim \chi^2_{df}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
df = \frac{(d_1MS_1+...+d_hMS_h)^2}{(d_1MS_1)^2/df_1 + ...+ (d_hMS_h)^2/df_h}
\]</span></p>
<p>An approximate <span class="math inline">\(1-\alpha\)</span> confidence interval for S:</p>
<p><span class="math display">\[
\frac{(df)\hat{S}}{\chi^2_{1-\alpha/2;df}} \le S \le \frac{(df)\hat{S}}{\chi^2_{\alpha/2;df}}
\]</span></p>
<p>For the single factor random effects model</p>
<p><span class="math display">\[
\frac{(df)s^2_\mu}{\chi^2_{1-\alpha/2;df}} \le \sigma^2_\mu \le \frac{(df)s^2_\mu}{\chi^2_{\alpha/2;df}}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
df = \frac{(sn^2_\mu)^2}{\frac{(MSTR)^2}{a-1}+ \frac{(MSE)^2}{a(n-1)}}
\]</span></p>
</div>
</div>
<div id="random-treatment-effects-model" class="section level4" number="20.1.2.2">
<h4><span class="header-section-number">20.1.2.2</span> Random Treatment Effects Model</h4>
<p><span class="math display">\[
\tau_i = \mu_i - E(\mu_i) = \mu_i - \mu
\]</span></p>
<p>we have <span class="math inline">\(\mu_i = \mu + \tau_i\)</span> and</p>
<p><span class="math display">\[
Y_{ij} = \mu + \tau_i + \epsilon_{ij}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mu\)</span> = constant, common to all observations<br />
</li>
<li><span class="math inline">\(\tau_i \sim N(0,\sigma^2_\tau)\)</span> independent (random variables)<br />
</li>
<li><span class="math inline">\(\epsilon_{ij} \sim N(0,\sigma^2)\)</span> independent.<br />
</li>
<li><span class="math inline">\(\tau_{i}, \epsilon_{ij}\)</span> are independent (i=1,…,a; j =1,..,n)</li>
<li>our model is concerned with only balanced single factor ANOVA.</li>
</ul>
<p><br></p>
<p><strong>Diagnostics Measures</strong></p>
<ul>
<li>Non-constant error variance (plots, Levene test, Hartley test).<br />
</li>
<li>Non-independence of errors (plots, Durban-Watson test).<br />
</li>
<li>Outliers (plots, regression methods).<br />
</li>
<li>Non-normality of error terms (plots, Shapiro-Wilk, Anderson-Darling).<br />
</li>
<li>Omitted Variable Bias (plots)</li>
</ul>
<p><strong>Remedial</strong></p>
<ul>
<li><a href="weighted-least-squares.html#weighted-least-squares">Weighted Least Squares</a><br />
</li>
<li><a href="ordinary-least-squares.html#transformations">Transformations</a></li>
<li>Non-parametric Procedures.</li>
</ul>
<p><strong>Note</strong></p>
<ul>
<li><p>Fixed effect ANOVA is relatively robust to</p>
<ul>
<li>non-normality<br />
</li>
<li>unequal variances when sample sizes are approximately equal; at least the F-test and multiple comparisons. However, single comparisons of treatment means are sensitive to unequal variances.<br />
</li>
</ul></li>
<li><p>Lack of independence can seriously affect both fixed and random effect ANVOA.</p></li>
</ul>
</div>
</div>
<div id="two-factor-fixed-effect-anova" class="section level3" number="20.1.3">
<h3><span class="header-section-number">20.1.3</span> Two Factor Fixed Effect ANOVA</h3>
<p>The multi-factor experiment is</p>
<ul>
<li>more efficient</li>
<li>provides more info<br />
</li>
<li>gives more validity to the findings.</li>
</ul>
<div id="balanced" class="section level4" number="20.1.3.1">
<h4><span class="header-section-number">20.1.3.1</span> Balanced</h4>
<p>Assumption:</p>
<ul>
<li>All treatment sample sizes are equal<br />
</li>
<li>All treatment means are of equal importance</li>
</ul>
<p>Assume:</p>
<ul>
<li>Factor A has <code>a</code> levels and Factor B has <code>b</code> levels. All a x b factor levels are considered.<br />
</li>
<li>The number of treatments for each level is n. <span class="math inline">\(N = abn\)</span> observations in the study.</li>
</ul>
<div id="cell-means-model-1" class="section level5" number="20.1.3.1.1">
<h5><span class="header-section-number">20.1.3.1.1</span> Cell Means Model</h5>
<p><span class="math display">\[
Y_{ijk} = \mu_{ij} + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mu_{ij}\)</span> are fixed parameters (cell means)<br />
</li>
<li><span class="math inline">\(i = 1,...,a\)</span> = the levels of Factor A<br />
</li>
<li><span class="math inline">\(j = 1,...,b\)</span> = the levels of Factor B.<br />
</li>
<li><span class="math inline">\(\epsilon_{ijk} \sim \text{indep } N(0,\sigma^2)\)</span> for <span class="math inline">\(i = 1,...,a\)</span>, <span class="math inline">\(j = 1,..,b\)</span> and <span class="math inline">\(k = 1,..,n\)</span></li>
</ul>
<p>And</p>
<p><span class="math display">\[
E(Y_{ijk}) = \mu_{ij} \\
var(Y_{ijk}) = var(\epsilon_{ijk}) = \sigma^2
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
Y_{ijk} \sim \text{indep } N(\mu_{ij},\sigma^2)
\]</span></p>
<p>And the model is<br />
</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{X} \beta + \epsilon
\]</span></p>
<p>Thus,</p>
<p><span class="math display">\[
E(\mathbf{Y}) = \mathbf{X}\beta \\
var(\mathbf{Y}) = \sigma^2 \mathbf{I}
\]</span></p>
<p><strong>Interaction</strong></p>
<p><span class="math display">\[
(\alpha \beta)_{ij} = \mu_{ij} - (\mu_{..}+ \alpha_i + \beta_j)
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mu_{..} = \sum_i \sum_j \mu_{ij}/ab\)</span> is the grand mean<br />
</li>
<li><span class="math inline">\(\alpha_i = \mu_{i.}-\mu_{..}\)</span> is the main effect for factor A at the i-th level<br />
</li>
<li><span class="math inline">\(\beta_j = \mu_{.j} - \mu_{..}\)</span> is the main effect for factor B at the j-th level<br />
</li>
<li><span class="math inline">\((\alpha \beta)_{ij}\)</span> is the interaction effect when factor A is at the i-th level and factor B is at the j-th level.<br />
</li>
<li><span class="math inline">\((\alpha \beta)_{ij} = \mu_{ij} - \mu_{i.}-\mu_{.j}+ \mu_{..}\)</span></li>
</ul>
<p>Examine interactions:</p>
<ul>
<li>Examine whether all <span class="math inline">\(\mu_{ij}\)</span> can be expressed as the sums <span class="math inline">\(\mu_{..} + \alpha_i + \beta_j\)</span><br />
</li>
<li>Examine whether the difference between the mean responses for any two levels of factor B is the same for all levels of factor A.<br />
</li>
<li>Examine whether the difference between the mean response for any two levels of factor A is the same for all levels of factor B<br />
</li>
<li>Examine whether the treatment mean curves for the different factor levels in a treatment plot are parallel.</li>
</ul>
<p>For <span class="math inline">\(j = 1,...,b\)</span></p>
<p><span class="math display">\[
\begin{aligned}
\sum_i(\alpha \beta)_{ij} &amp;= \sum_i (\mu_{ij} - \mu_{..} - \alpha_i - \beta_j) \\
&amp;= \sum_i \mu_{ij} - a \mu_{..} - \sum_i \alpha_i - a \beta_j \\
&amp;= a \mu_{.j} - a \mu_{..}- \sum_i (\mu_{i.} - \mu_{..}) - a(\mu_{.j}-\mu_{..}) \\
&amp;= a \mu_{.j} - a \mu_{..} - a \mu_{..}+ a \mu_{..} - a (\mu_{.j} - \mu_{..}) \\
&amp;= 0
\end{aligned}
\]</span></p>
<p>Similarly, <span class="math inline">\(\sum_j (\alpha \beta) = 0, i = 1,...,a\)</span> and <span class="math inline">\(\sum_i \sum_j (\alpha \beta)_{ij} =0\)</span>, <span class="math inline">\(\sum_i \alpha_i = 0\)</span>, <span class="math inline">\(\sum_j \beta_j = 0\)</span></p>
</div>
<div id="factor-effects-model" class="section level5" number="20.1.3.1.2">
<h5><span class="header-section-number">20.1.3.1.2</span> Factor Effects Model</h5>
<p><span class="math display">\[
\mu_{ij} = \mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij} \\
Y_{ijk} = \mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mu_{..}\)</span> is a constant</li>
<li><span class="math inline">\(\alpha_i\)</span> are constants subject to the restriction <span class="math inline">\(\sum_i \alpha_i=0\)</span></li>
<li><span class="math inline">\(\beta_j\)</span> are constants subject to the restriction <span class="math inline">\(\sum_j \beta_j = 0\)</span></li>
<li><span class="math inline">\((\alpha \beta)_{ij}\)</span> are constants subject to the restriction <span class="math inline">\(\sum_i(\alpha \beta)_{ij} = 0\)</span> for <span class="math inline">\(j=1,...,b\)</span> and <span class="math inline">\(\sum_j(\alpha \beta)_{ij} = 0\)</span> for <span class="math inline">\(i = 1,...,a\)</span></li>
<li><span class="math inline">\(\epsilon_{ijk} \sim \text{indep } N(0,\sigma^2)\)</span> for <span class="math inline">\(k = 1,..,n\)</span></li>
</ul>
<p>We have</p>
<p><span class="math display">\[
E(Y_{ijk}) = \mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij}\\
var(Y_{ijk}) = \sigma^2 \\
Y_{ijk} \sim N (\mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij}, \sigma^2)
\]</span></p>
<p>We have <span class="math inline">\(1+a+b+ab\)</span> parameters. But there are <span class="math inline">\(ab\)</span> parameters in the <a href="completely-randomized-design-crd.html#cell-means-model-1">Cell Means Model</a>. In the <a href="completely-randomized-design-crd.html#factor-effects-model">Factor Effects Model</a>, the restrictions limit the number of parameters that can be estimated:</p>
<p><span class="math display">\[
1 \text{ for } \mu_{..} \\
(a-1) \text{ for } \alpha_i \\
(b-1) \text{ for } \beta_j \\
(a-1)(b-1) \text{ for } (\alpha \beta)_{ij}
\]</span></p>
<p>Hence, there are</p>
<p><span class="math display">\[
1 + a - 1 + b - 1 + ab - a- b + 1 = ab
\]</span></p>
<p>parameters in the model.</p>
<p>We can have several restrictions when considering the model in the form <span class="math inline">\(\mathbf{Y} = \mathbf{X} \beta + \epsilon\)</span></p>
<p>One way:</p>
<p><span class="math display">\[
\alpha_a  = \alpha_1 - \alpha_2 - ... - \alpha_{a-1} \\
\beta_b = -\beta_1 - \beta_2 - ... - \beta_{b-1} \\
(\alpha \beta)_{ib} = -(\alpha \beta)_{i1} -(\alpha \beta)_{i2} -...-(\alpha \beta)_{i,b-1} ; i = 1,..,a \\
(\alpha \beta)_{aj} = -(\alpha \beta)_{1j}-(\alpha \beta)_{2j} - ... -(\alpha \beta)_{a-1,j}; j = 1,..,b
\]</span></p>
<p>We can fit the model by least squares or maximum likelihood</p>
<p><strong>Cell Means Model</strong><br />
minimize<br />
</p>
<p><span class="math display">\[
Q = \sum_i \sum_j \sum_k (Y_{ijk}-\mu_{ij})^2
\]</span></p>
<p>estimators</p>
<p><span class="math display">\[
\hat{\mu}_{ij}= \bar{Y}_{ij} \\
\hat{Y}_{ijk} = \bar{Y}_{ij} \\
e_{ijk} = Y_{ijk} - \hat{Y}_{ijk} = Y_{ijk} - \bar{Y}_{ij}
\]</span></p>
<p><strong>Factor Effects Model</strong></p>
<p><span class="math display">\[
Q = \sum_i \sum_j \sum_k (Y_{ijk} - \mu_{..}-\alpha_i = \beta_j - (\alpha \beta)_{ij})^2
\]</span></p>
<p>subject to the restrictions</p>
<p><span class="math display">\[
\sum_i \alpha_i = 0 \\
\sum_j \beta_j = 0 \\
\sum_i (\alpha \beta)_{ij} = 0 \\
\sum_j (\alpha \beta)_{ij} = 0
\]</span></p>
<p>estimators</p>
<p><span class="math display">\[
\hat{\mu}_{..} = \bar{Y}_{...} \\
\hat{\alpha}_i = \bar{Y}_{i..} - \bar{Y}_{...} \\
\hat{\beta}_j = \bar{Y}_{.j.}-\bar{Y}_{...} \\
(\hat{\alpha \beta})_{ij} = \bar{Y}_{ij.} - \bar{Y}_{i..} - \bar{Y}_{.j.}+ \bar{Y}_{...}
\]</span></p>
<p>The fitted values</p>
<p><span class="math display">\[
\hat{Y}_{ijk} = \bar{Y}_{...}+ (\bar{Y}_{i..}- \bar{Y}_{...})+ (\bar{Y}_{.j.}- \bar{Y}_{...}) + (\bar{Y}_{ij.} - \bar{Y}_{i..}-\bar{Y}_{.j.}+\bar{Y}_{...}) = \bar{Y}_{ij.}
\]</span></p>
<p>where</p>
<p><span class="math display">\[
e_{ijk} = Y_{ijk} - \bar{Y}_{ij.} \\
e_{ijk} \sim \text{ indep } (0,\sigma^2)
\]</span></p>
<p>and</p>
<p><span class="math display">\[
s^2_{\hat{\mu}..} = \frac{MSE}{nab} \\
s^2_{\hat{\alpha}_i} = MSE(\frac{1}{nb} - \frac{1}{nab}) \\
s^2_{\hat{\beta}_j} = MSE(\frac{1}{na} - \frac{1}{nab}) \\
s^2_{(\hat{\alpha\beta})_{ij}} = MSE (\frac{1}{n} - \frac{1}{na}- \frac{1}{nb} + \frac{1}{nab})
\]</span></p>
<div id="partitioning-the-total-sum-of-squares" class="section level6" number="20.1.3.1.2.1">
<h6><span class="header-section-number">20.1.3.1.2.1</span> Partitioning the Total Sum of Squares</h6>
<p><span class="math display">\[
Y_{ijk} - \bar{Y}_{...} = \bar{Y}_{ij.} - \bar{Y}_{...} + Y_{ijk} - \bar{Y}_{ij.}
\]</span></p>
<p><span class="math inline">\(Y_{ijk} - \bar{Y}_{...}\)</span>: Total deviation<br />
<span class="math inline">\(\bar{Y}_{ij.} - \bar{Y}_{...}\)</span>: Deviation of treatment mean from overall mean<br />
<span class="math inline">\(Y_{ijk} - \bar{Y}_{ij.}\)</span>: Deviation of observation around treatment mean (residual).</p>
<p><span class="math display">\[
\begin{aligned}
\sum_i \sum_j \sum_k (Y_{ijk} - \bar{Y}_{...})^2 &amp;= n \sum_i \sum_j (\bar{Y}_{ij.}- \bar{Y}_{...})^2+ \sum_i \sum_j sum_k (Y_{ijk} - \bar{ij.})^2 \\
SSTO &amp;= SSTR + SSE
\end{aligned}
\]</span></p>
<p>(cross product terms are 0)</p>
<p><span class="math display">\[
\bar{Y}_{ij.}- \bar{Y}_{...} = \bar{Y}_{i..}-\bar{Y}_{...} + \bar{Y}_{.j.}-\bar{Y}_{...} + \bar{Y}_{ij.} - \bar{Y}_{i..} - \bar{Y}_{.j.} + \bar{Y}_{...}
\]</span></p>
<p>squaring and summing:<br />
</p>
<p><span class="math display">\[
\begin{aligned}
n\sum_i \sum_j (\bar{Y}_{ij.}-\bar{Y}_{...})^2 &amp;= nb\sum_i (\bar{Y}_{i..}-\bar{Y}_{...})^2 + na \sum_j (\bar{Y}_{.j.}-\bar{Y}_{...})^2 + n \sum_i \sum_j (\bar{Y}_{ij.}-\bar{Y}_{i..}- \bar{Y}_{.j.}+ \bar{Y}_{...})^2 \\
SSTR &amp;= SSA + SSB + SSAB
\end{aligned}
\]</span></p>
<p>The interaction term from</p>
<p><span class="math display">\[
SSAB = SSTO - SSE - SSA - SSB \\
SSAB = SSTR - SSA - SSB
\]</span></p>
<p>where</p>
<ul>
<li>SSA is the factor A sum of squares (measures the variability of the estimated factor A level means <span class="math inline">\(\bar{Y}_{i..}\)</span>)- the more variable, the larger SSA<br />
</li>
<li>SSB is the factor B sum of squares<br />
</li>
<li>SSAB is the interaction sum of squares, measuring the variability of the estimated interactions.</li>
</ul>
</div>
<div id="partitioning-the-df" class="section level6" number="20.1.3.1.2.2">
<h6><span class="header-section-number">20.1.3.1.2.2</span> Partitioning the df</h6>
<p><span class="math inline">\(N = abn\)</span> cases and <span class="math inline">\(ab\)</span> treatments.</p>
<p>For one-way ANOVA and regression, the partition has df:</p>
<p><span class="math display">\[
SS: SSTO = SSTR + SSE \\
df: N-1 = (ab-1) + (N-ab)
\]</span></p>
<p>we must further partition the <span class="math inline">\(ab-1\)</span> df with SSTR</p>
<p><span class="math display">\[
SSTR = SSA + SSB + SSAB \\
ab-1 = (a-1) + (b-1) + (a-1)(b-1)
\]</span></p>
<ul>
<li><span class="math inline">\(df_{SSA} = a-1\)</span>: a treatment deviations but 1 df is lost due to the restriction <span class="math inline">\(\sum (\bar{Y}_{i..}- \bar{Y}_{...})=0\)</span><br />
</li>
<li><span class="math inline">\(df_{SSB} = b-1\)</span>: b treatment deviations but 1 df is lost due to the restriction <span class="math inline">\(\sum (\bar{Y}_{.j.}- \bar{Y}_{...})=0\)</span><br />
</li>
<li><span class="math inline">\(df_{SSAB} = (a-1)(b-1)= (ab-1)-(a-1)-(b-1)\)</span>: ab interactions, there are (a+b-1) restrictions, so df = ab-a-(b-1)= (a-1)(b-1)</li>
</ul>
</div>
<div id="mean-squares" class="section level6" number="20.1.3.1.2.3">
<h6><span class="header-section-number">20.1.3.1.2.3</span> Mean Squares</h6>
<p><span class="math display">\[
MSA = \frac{SSA}{a-1}\\
MSB = \frac{SSB}{b-1}\\
MSAB = \frac{SSAB}{(a-1)(b-1)}
\]</span></p>
<p>The expected mean squares are</p>
<p><span class="math display">\[
E(MSE) = \sigma^2 \\
E(MSA) = \sigma^2 + nb \frac{\sum \alpha_i^2}{a-1} = \sigma^2 + nb \frac{\sum(\sum_{i.}-\mu_{..})^2}{a-1}  \\
E(MSB) = \sigma^2 + na \frac{\sum \beta_i^2}{b-1} = \sigma^2 + na \frac{\sum(\sum_{.j}-\mu_{..})^2}{b-1} \\
E(MSAB) = \sigma^2 + n \frac{\sum \sum (\alpha \beta)_{ij}^2}{(a-1)(b-1)} = \sigma^2 + n \frac{\sum (\mu_{ij}- \mu_{i.}- \mu_{.j}+ \mu_{..} )^2}{(a-1)(b-1)}
\]</span></p>
<p>If there are no factor A main effects (all <span class="math inline">\(\mu_{i.} = 0\)</span> or <span class="math inline">\(\alpha_i = 0\)</span>) the MSA and MSE have the same expectation; otherwise MSA &gt; MSE. Same for factor B, and interaction effects. which case we can examine F-statistics.</p>
<p><strong>Interaction</strong></p>
<p><span class="math display">\[
\begin{aligned}
H_0: \mu_{ij}- \mu_{i.} - \mu_{.j} + \mu_{..} = 0 &amp;&amp; \text{for all i,j} \\
H_a: \mu_{ij}- \mu_{i.} - \mu_{.j} + \mu_{..} \neq 0 &amp;&amp; \text{for some i,j}
\end{aligned}
\]</span></p>
<p>or</p>
<p><span class="math display">\[
H_0: \text{All}(\alpha \beta)_{ij} = 0 \\
H_a: \text{Not all} (\alpha \beta) = 0
\]</span></p>
<p>Let <span class="math inline">\(F = \frac{MSAB}{MSE}\)</span>. When <span class="math inline">\(H_0\)</span> is true <span class="math inline">\(F \sim f_{((a-1)(b-1),ab(n-1))}\)</span>. So reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(F &gt; f_{((a-1)(b-1),ab(n-1))}\)</span></p>
<p>Factor A main effects:<br />
</p>
<p><span class="math display">\[
H_0: \mu_{1.} = \mu_{2.} = ... = \mu_{a.} \\
H_a: \text{Not all $\mu_{i.}$ are equal}
\]</span></p>
<p>or</p>
<p><span class="math display">\[
H_0: \alpha_1 = ... = \alpha_a = 0 \\
H_a: \text{Not all $\alpha_i$ are equal to 0}
\]</span></p>
<p><span class="math inline">\(F= \frac{MSA}{MSE}\)</span> and reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(F&gt;f_{(1-\alpha;a-1,ab(n-1))}\)</span></p>
</div>
<div id="two-way-anova" class="section level6" number="20.1.3.1.2.4">
<h6><span class="header-section-number">20.1.3.1.2.4</span> Two-way ANOVA</h6>
<table>
<colgroup>
<col width="27%" />
<col width="16%" />
<col width="16%" />
<col width="24%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th>Source of Variation</th>
<th>SS</th>
<th>df</th>
<th>MS</th>
<th>F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Factor A</td>
<td>SSA</td>
<td>a-1</td>
<td>MSA = SSA/(a-1)</td>
<td>MSA/MSE</td>
</tr>
<tr class="even">
<td>Factor B</td>
<td>SSB</td>
<td>b-1</td>
<td>MSB = SSB/(b-1)</td>
<td>MSB/MSE</td>
</tr>
<tr class="odd">
<td>AB interactions</td>
<td>SSAB</td>
<td>(a-1)(b-1)</td>
<td>MSAB = SSAB /MSE</td>
<td></td>
</tr>
<tr class="even">
<td>Error</td>
<td>SSE</td>
<td>ab(n-1)</td>
<td>MSE = SSE/ab(n-1)</td>
<td></td>
</tr>
<tr class="odd">
<td>Total (corrected)</td>
<td>SSTO</td>
<td>abn - 1</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p>Doing 2-way ANOVA means you always check interaction first, because if there are significant interactions, checking the significance of the main effects becomes moot.</p>
<p>The main effects concern the mean responses for levels of one factor averaged over the levels of the other factor. WHen interaction is present, we can’t conclude that a given factor has no effect, even if these averages are the same. It means that the effect of the factor depends on the level of the other factor.</p>
<p>On the other hand, if you can establish that there is no interaction, then you can consider inference on the factor main effects, which are then said to be <strong>additive</strong>.<br />
And we can also compare factor means like the <a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model">Single Factor Fixed Effects Model</a> using <a href="completely-randomized-design-crd.html#tukey">Tukey</a>, <a href="completely-randomized-design-crd.html#scheffe">Scheffe</a>, <a href="completely-randomized-design-crd.html#bonferroni">Bonferroni</a>.</p>
<p>We can also consider contrasts in the 2-way model</p>
<p><span class="math display">\[
L = \sum c_i \mu_i
\]</span></p>
<p>where <span class="math inline">\(\sum c_i =0\)</span><br />
which is estimated by</p>
<p><span class="math display">\[
\hat{L} = \sum c_i \bar{Y}_{i..}
\]</span></p>
<p>with variance</p>
<p><span class="math display">\[
\sigma^2(\hat{L}) = \frac{\sigma^2}{bn} \sum c_i^2
\]</span></p>
<p>and variance estimate</p>
<p><span class="math display">\[
\frac{MSE}{bn} \sum c_i^2
\]</span></p>
<p><strong>Orthogonal Contrasts</strong></p>
<p><span class="math display">\[
L_1 = \sum c_i \mu_i, \sum c_i = 0 \\
L_2 = \sum d_i \mu_i , \sum d_i = 0
\]</span></p>
<p>these contrasts are said to be <strong>orthogonal</strong> if</p>
<p><span class="math display">\[
\sum \frac{c_i d_i}{n_i} = 0
\]</span></p>
<p>in balanced case <span class="math inline">\(\sum c_i d_i =0\)</span></p>
<p><span class="math display">\[
\begin{aligned}
cov(\hat{L}_1, \hat{L}_2) &amp;= cov(\sum_i c_i \bar{Y}_{i..}, \sum_l d_l \bar{Y}_{l..}) \\
&amp;= \sum_i \sum_l c_i d_l cov(\bar{Y}_{i..},\bar{Y}_{l..}) \\
&amp;= \sum_i c_i d_i \frac{\sigma^2}{bn} = 0
\end{aligned}
\]</span></p>
<p>Orthogonal contrasts can be used to further partition the model sum of squares. There are many sets of orthogonal contrasts and thus, many ways to partition the sum of squares.</p>
<p>A special set of orthogonal contrasts that are used when the levels of a factor can be assigned values on a metric scale are called <strong>orthogonal polynomials</strong></p>
<p>Coefficients can be found for the special case of</p>
<ul>
<li>equal spaced levels (e.g., (0 15 30 45 60))<br />
</li>
<li>equal sample sizes (<span class="math inline">\(n_1 = n_2 = ... = n_{ab}\)</span>)</li>
</ul>
<p>We can define the SS for a given contrast:</p>
<p><span class="math display">\[
SS_L = \frac{\hat{L}^2}{\sum_{i=1}^a (c^2_i/bn_i)}
\]</span></p>
<p><span class="math display">\[
T = \frac{\hat{L}}{\sqrt{MSE\sum_{i=1}^a(c_i^2/bn_i)}} \sim t
\]</span></p>
<p>Moreover,</p>
<p><span class="math display">\[
t^2_{(1-\alpha/2;df)}=F_{(1-\alpha;1,df)}
\]</span></p>
<p>So,</p>
<p><span class="math display">\[
\frac{SS_L}{MSE} \sim F_{(1-\alpha;1,df_{MSE})}
\]</span></p>
<p>all contrasts have d.f = 1</p>
</div>
</div>
</div>
<div id="unbalanced" class="section level4" number="20.1.3.2">
<h4><span class="header-section-number">20.1.3.2</span> Unbalanced</h4>
<p>We could have unequal numbers of replications for all treatment combinations:</p>
<ul>
<li>observational studies<br />
</li>
<li>dropouts in designed studies<br />
</li>
<li>larger sample sizes for inexpensive treatments<br />
</li>
<li>Sample sizes to match population makeup.</li>
</ul>
<p>Assume that each factor combination has at least 1 observation (no empty cells)</p>
<p>Consider the same model as:</p>
<p><span class="math display">\[
Y_{ijk} = \mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \epsilon_{ijk}
\]</span></p>
<p>where sample sizes are: <span class="math inline">\(n_{ij}\)</span>:</p>
<p><span class="math display">\[
n_{i.} = \sum_j n_{ij} \\
n_{.j} = \sum_i n_{ij} \\
n_T = \sum_i \sum_j n_{ij}
\]</span></p>
<p>Problem here is that</p>
<p><span class="math display">\[
SSTO \neq SSA + SSB + SSAB + SSE
\]</span></p>
<p>(the design is <strong>non-orthogonal</strong>)</p>
<ul>
<li>For <span class="math inline">\(i = 1,...,a-1,\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
u_i =
\begin{cases}
+1 &amp; \text{if the obs is from the i-th level of Factor 1} \\
-1 &amp; \text{if the obs is from the a-th level of Factor 1} \\
0 &amp; \text{otherwise}
\end{cases}
\end{equation}\]</span></p>
<ul>
<li>For <span class="math inline">\(j=1,...,b-1\)</span></li>
</ul>
<p><span class="math display">\[\begin{equation}
v_i =
\begin{cases}
+1 &amp; \text{if the obs is from the j-th level of Factor 1} \\
-1 &amp; \text{if the obs is from the b-th level of Factor 1} \\
0 &amp; \text{otherwise}
\end{cases}
\end{equation}\]</span></p>
<p>We can use these indicator variables as predictor variables and <span class="math inline">\(\mu_{..}, \alpha_i ,\beta_j, (\alpha \beta)_{ij}\)</span> as unknown parameters.</p>
<p><span class="math display">\[
Y = \mu_{..} + \sum_{i=1}^{a-1} \alpha_i u_i + \sum_{j=1}^{b-1} \beta_j v_j + \sum_{i=1}^{a-1} \sum_{j=1}^{b-1}(\alpha \beta)_{ij} u_i v_j + \epsilon
\]</span></p>
<p>To test hypotheses, we use the extra sum of squares idea.</p>
<p>For interaction effects</p>
<p><span class="math display">\[
H_0: all (\alpha \beta)_{ij} = 0 \\
H_a: \text{not all }(\alpha \beta)_{ij} =0
\]</span></p>
<p>Or to test</p>
<p><span class="math display">\[
H_0: \beta_1 = \beta_2 = \beta_3 = 0 \\
H_a: \text{not all } \beta_j = 0
\]</span></p>
<p><strong>Analysis of Factor Means</strong></p>
<p>(e.g., contrasts) is analogous to the balanced case, with modifications in the formulas for means and standard errors to account for unequal sample sizes.</p>
<p>Or , we can fit the cell means model and consider it from a regression perspective</p>
<p>If you have empty cells (i.e., some factor combinations have no observation), then the equivalent regression approach can’t be used. But you can still do partial analyses</p>
</div>
</div>
<div id="two-way-random-effects-anova" class="section level3" number="20.1.4">
<h3><span class="header-section-number">20.1.4</span> Two-Way Random Effects ANOVA</h3>
<p><span class="math display">\[
Y_{ijk} = \mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \epsilon_{ij}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mu_{..}\)</span>: constant<br />
</li>
<li><span class="math inline">\(\alpha_i \sim N(0,\sigma^2_{\alpha}), i = 1,..,a\)</span> (independent)<br />
</li>
<li><span class="math inline">\(\beta_j \sim N(0,\sigma^2_{\beta}), j = 1,..,b\)</span> (independent)<br />
</li>
<li><span class="math inline">\((\alpha \beta)_{ij} \sim N(0,\sigma^2_{\alpha \beta}),i=1,...,a,j=1,..,b\)</span> (independent)<br />
</li>
<li><span class="math inline">\(\epsilon_{ijk} \sim N(0,\sigma^2)\)</span> (independent)</li>
</ul>
<p>All <span class="math inline">\(\alpha_i, \beta_j, (\alpha \beta)_{ij}\)</span> are pairwise independent</p>
<p>Theoretical means, variances, and covariances are</p>
<p><span class="math display">\[
E(Y_{ijk}) = \mu_{..} \\
var(Y_{ijk}) = \sigma^2_Y= \sigma^2_\alpha + \sigma^2_\beta +  \sigma^2_{\alpha \beta} + \sigma^2
\]</span></p>
<p>So</p>
<p><span class="math inline">\(Y_{ijk} \sim N(\mu_{..},\sigma^2_\alpha + \sigma^2_\beta + \sigma^2_{\alpha \beta} + \sigma^2)\)</span></p>
<p><span class="math display">\[
cov(Y_{ijk},Y_{ij&#39;k&#39;}) = \sigma^2_{\alpha}, j \neq j&#39; \\
cov(Y_{ijk},Y_{i&#39;jk&#39;}) = \sigma^2_{\beta}, i \neq i&#39;\\
cov(Y_{ijk},Y_{ijk&#39;}) = \sigma^2_\alpha + \sigma^2_{\beta} + \sigma^2_{\alpha \beta}, k \neq k&#39; \\
cov(Y_{ijk},Y_{i&#39;j&#39;k&#39;}) = , i \neq i&#39;, j \neq j&#39;
\]</span></p>
</div>
<div id="two-way-mixed-effects-anova" class="section level3" number="20.1.5">
<h3><span class="header-section-number">20.1.5</span> Two-Way Mixed Effects ANOVA</h3>
<div id="balanced-1" class="section level4" number="20.1.5.1">
<h4><span class="header-section-number">20.1.5.1</span> Balanced</h4>
<p>One fixed factor, while other is random treatment levels, we have a <strong>mixed effects model</strong> or a <strong>mixed model</strong></p>
<p><strong>Restricted mixed model</strong> for 2-way ANOVA:</p>
<p><span class="math display">\[
Y_{ijk} = \mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \epsilon_{ijk}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mu_{..}\)</span>: constant<br />
</li>
<li><span class="math inline">\(\alpha_i\)</span>: fixed effects with constraints subject to restriction <span class="math inline">\(\sum \alpha_i = 0\)</span><br />
</li>
<li><span class="math inline">\(\beta_j \sim indep N(0,\sigma^2_\beta)\)</span><br />
</li>
<li><span class="math inline">\((\alpha \beta)_{ij} \sim N(0,\frac{a-1}{a}\sigma^2_{\alpha \beta})\)</span> subject to restriction <span class="math inline">\(\sum_i (\alpha \beta)_{ij} = 0\)</span> for all j, the variance here is written as the proportion for convenience; it makes the expected mean squares simpler (other assumed <span class="math inline">\(var((\alpha \beta)_{ij}= \sigma^2_{\alpha \beta}\)</span>)<br />
</li>
<li><span class="math inline">\(cov((\alpha \beta)_{ij},(\alpha \beta)_{i&#39;j&#39;}) = - \frac{1}{a} \sigma^2_{\alpha \beta}, i \neq i&#39;\)</span><br />
</li>
<li><span class="math inline">\(\epsilon_{ijk}\sim indepN(0,\sigma^2)\)</span><br />
</li>
<li><span class="math inline">\(\beta_j, (\alpha \beta)_{ij}, \epsilon_{ijk}\)</span> are pairwise independent</li>
</ul>
<p>Two-way mixed models are written in an “unrestricted” form, with no restrictions on the interaction effects <span class="math inline">\((\alpha \beta)_{ij}\)</span>, they are pairwise independent. Let <span class="math inline">\(\beta^*, (\alpha \beta)^*_{ij}\)</span> be the unrestricted random effects, and <span class="math inline">\((\bar{\alpha \beta})_{ij}^*\)</span> the means averaged over the fixed factor for each level of random factor B.</p>
<p><span class="math display">\[
\beta_j = \beta_j^* + (\bar{\alpha \beta})_{ij}^* \\
(\alpha \beta)_{ij} = (\alpha \beta)_{ij}^* - (\bar{\alpha \beta})_{ij}^*
\]</span></p>
<p>Some consider the restricted model to be more general. but here we consider the restricted form.</p>
<p><span class="math display">\[
E(Y_{ijk}) = \mu_{..} + \alpha_i \\
var(Y_{ijk}) = \sigma^2_\beta + \frac{a-1}{a} \sigma^2_{\alpha \beta} + \sigma^2
\]</span></p>
<p>Responses from the same random factor (B) level are correlated</p>
<p><span class="math display">\[
cov(Y_{ijk},Y_{ijk&#39;}) = E(Y_{ijk}Y_{ijk&#39;}) - E(Y_{ijk})E(Y_{ijk&#39;}) \\
= \sigma^2_\beta + \frac{a-1}{a} \sigma^2_{\alpha \beta} , k \neq k&#39;
\]</span></p>
<p>Similarly,</p>
<p><span class="math display">\[
cov(Y_{ijk},Y_{i&#39;jk&#39;}) = \sigma^2_\beta - \frac{1}{a} \sigma^2_{\alpha\ \beta}, i \neq i&#39; \\
cov(Y_{ijk},Y_{i&#39;j&#39;k&#39;}) = 0,  j \neq j&#39;
\]</span></p>
<p>Hence, you can see that the only way you don’t have dependence in the Y is when they don’t share the same random effect.</p>
<p>An advantage of the <strong>restricted mixed model</strong> is that 2 observations from the same random factor b level can be positively or negatively correlated. In the <strong>unrestricted model</strong>, they can only be positively correlated.</p>
<table>
<colgroup>
<col width="8%" />
<col width="9%" />
<col width="43%" />
<col width="38%" />
</colgroup>
<thead>
<tr class="header">
<th>Mean Square</th>
<th><p>Fixed ANOVA</p>
(A, B Fixed)</th>
<th><p>Random ANOVA</p>
(A,B random)</th>
<th><p>Mixed ANVOA</p>
(A fixed, B random)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>MSA</td>
<td>a - 1</td>
<td><span class="math inline">\(\sigma ^2+ n b \frac{\sum\alpha_i^2}{a-1}\)</span></td>
<td><span class="math inline">\(\sigma^2 + nb\sigma^ 2_ \alpha +n \sigma^ 2_{\alpha \beta}\)</span></td>
</tr>
<tr class="even">
<td>MSB</td>
<td>b-1</td>
<td><span class="math inline">\(\sigma^2 + n a \frac{\sum\beta ^2_j}{b-1}\)</span></td>
<td><span class="math inline">\(\sigma^ 2 + na\sigma^2_ \beta +n \sigma^ 2_{\alpha \beta}\)</span></td>
</tr>
<tr class="odd">
<td>MSAB</td>
<td>( a-1)(b-1)</td>
<td><span class="math inline">\(\sigma^2 + n \frac{\sum \sum(\alpha \beta )^2_ {ij}} { ( a-1)(b-1)}\)</span></td>
<td><span class="math inline">\(\sigma^2+n \sigma^2_{\alpha \beta}\)</span></td>
</tr>
<tr class="even">
<td>MSE</td>
<td>(n-1)ab</td>
<td><span class="math inline">\(\sigma^2\)</span></td>
<td><span class="math inline">\(\sigma^2\)</span></td>
</tr>
</tbody>
</table>
<p>For fixed, random, and mixed models (balanced), the ANOVA table sums of squares calculations are identical. (also true for df and mean squares). The only difference is with the expected mean squares, thus the test statistics.</p>
<p>In Random ANOVA, we test</p>
<p><span class="math display">\[
H_0: \sigma^2 = 0 \\
H_a: \sigma^2 &gt; 0
\]</span></p>
<p>by considering <span class="math inline">\(F= \frac{MSA}{MSAB} \sim F_{a-1;(a-1)(b-1)}\)</span></p>
<p>The same test statistic is used for mixed models, but in that case we are testing null hypothesis that all of the <span class="math inline">\(\alpha_i = 0\)</span></p>
<p>The test statistic different for the same null hypothesis under the fixed effects model.</p>
<table>
<colgroup>
<col width="25%" />
<col width="24%" />
<col width="24%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Test for effects of</th>
<th><p>Fixed ANOVA</p>
(A&amp;B fixed)</th>
<th><p>Random ANOVA</p>
(A&amp;B random)</th>
<th><p>Mixed ANOVA</p>
(A fixed, B random)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Factor A</td>
<td><span class="math inline">\(\frac{MSA}{MSE}\)</span></td>
<td><span class="math inline">\(\frac{MSA}{MSAB}\)</span></td>
<td><span class="math inline">\(\frac{MSA}{MSAB}\)</span></td>
</tr>
<tr class="even">
<td>Factor B</td>
<td><span class="math inline">\(\frac{MSB}{MSE}\)</span></td>
<td><span class="math inline">\(\frac{MSB}{MSAB}\)</span></td>
<td><span class="math inline">\(\frac{MSB}{MSE}\)</span></td>
</tr>
<tr class="odd">
<td>AB interactions</td>
<td><span class="math inline">\(\frac{MSAB}{MSE}\)</span></td>
<td><span class="math inline">\(\frac{MSAB}{MSE}\)</span></td>
<td><span class="math inline">\(\frac{MSAB}{MSE}\)</span></td>
</tr>
</tbody>
</table>
<p><strong>Estimation Of Variance Components</strong></p>
<p>In random and mixed effects models, we are interested in estimating the <strong>variance components</strong><br />
Variance component <span class="math inline">\(\sigma^2_\beta\)</span> in the mixed ANOVA.</p>
<p><span class="math display">\[
E(\sigma^2_\beta) = \frac{E(MSB)-E(MSE)}{na} = \frac{\sigma^2 + na \sigma^2_\beta - \sigma^2}{na} = \sigma^2_\beta
\]</span></p>
<p>which can be estimated with</p>
<p><span class="math display">\[
\hat{\sigma}^2_\beta = \frac{MSB - MSE}{na}
\]</span></p>
<p>Confidence intervals for variance components can be constructed (approximately) by using the <strong>Satterthwaite</strong> procedure or the MLS procedure (like the 1-way random effects)</p>
<p><strong>Estimation of Fixed Effects in Mixed Models</strong></p>
<p><span class="math display">\[
\hat{\alpha}_i = \bar{Y}_{i..} - \bar{Y}_{...} \\
\hat{\mu}_{i.} = \bar{Y}_{...} + (\bar{Y}_{i..}- \bar{Y}_{...}) = \bar{Y}_{i..}  \\
\sigma^2(\hat{\alpha}_i) = \frac{\sigma^2 + n \sigma^2_{\alpha \beta}}{bn} = \frac{E(MSAB)}{bn} \\
s^2(\hat{\alpha}_i) = \frac{MSAB}{bn}
\]</span></p>
<p>Contrasts on the <strong>Fixed Effects</strong></p>
<p><span class="math display">\[
L = \sum c_i \alpha_i \\
\sum c_i = 0 \\
\hat{L} = \sum c_i \hat{\alpha}_i \\
\sigma^2(\hat{L}) = \sum c^2_i \sigma^2 (\hat{\alpha}_i) \\
s^2(\hat{L}) = \frac{MSAB}{bn} \sum c^2_i
\]</span></p>
<p>Confidence intervals and tests can be constructed as usual</p>
<p><br></p>
</div>
<div id="unbalanced-1" class="section level4" number="20.1.5.2">
<h4><span class="header-section-number">20.1.5.2</span> Unbalanced</h4>
<p>For a mixed model with a = 2, b = 4</p>
<p><span class="math display">\[
Y_{ijk} = \mu_{..} + \alpha_i + \beta_j + (\alpha \beta)_{ij} + \epsilon_{ijk} \\
var(\beta_j)= \sigma^2_\beta \\
var((\alpha \beta)_{ij})= \frac{2-1}{2}\sigma^2_{\alpha \beta} = \frac{\sigma^2_{\alpha \beta}}{2} \\
var(\epsilon_{ijk}) = \sigma^2 \\
E(Y_{ijk}) = \mu_{..} + \alpha_i \\
var(Y_{ijk}) = \sigma^2_{\beta} + \frac{\sigma^2_{\alpha \beta}}{2} + \sigma^2 \\
cov(Y_{ijk},Y_{ijk&#39;}) = \sigma^2 + \frac{\sigma^2_{\alpha \beta}}{2}, k \neq k&#39; \\
cov(Y_{ijk},Y_{i&#39;jk&#39;}) = \sigma^2_{\beta} - \frac{\sigma^2_{\alpha \beta}}{2}, i \neq i&#39; \\
cov(Y_{ijk},Y_{i&#39;j&#39;k&#39;}) = 0, j \neq j&#39;
\]</span></p>
<p>assume</p>
<p><span class="math display">\[
\mathbf{Y} \sim N(\mathbf{X}\beta, M)
\]</span></p>
<p>where <span class="math inline">\(M\)</span> is block diagonal</p>
<p>density function</p>
<p><span class="math display">\[
f(\mathbf{Y}) = \frac{1}{(2\pi)^{N/2}|M|^{1/2}}exp(-\frac{1}{2}\mathbf{(Y - X \beta)&#39; M^{-1}(Y-X\beta)})
\]</span></p>
<p>if we knew the variance components, we could use GLS:</p>
<p><span class="math display">\[
\hat{\beta}_{GLS} = \mathbf{(X&#39;M^{-1}X)^{-1}X&#39;M^{-1}Y}
\]</span></p>
<p>but we usually don’t know the variance components <span class="math inline">\(\sigma^2, \sigma^2_\beta, \sigma^2_{\alpha \beta}\)</span> that make up <span class="math inline">\(M\)</span><br />
Another way to get estimates is by <strong>Maximum likelihood estimation</strong></p>
<p>we try to maximize its log</p>
<p><span class="math display">\[
\ln L = - \frac{N}{2} \ln (2\pi) - \frac{1}{2}\ln|M| - \frac{1}{2} \mathbf{(Y-X \beta)&#39;\Sigma^{-1}(Y-X\beta)}
\]</span></p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="analysis-of-variance-anova.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="nonparametric-anova.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/20-ANOVA.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/mikenguyen13/data_analysis/blob/main/20-ANOVA.Rmd",
"text": null
},
"download": ["data_analysis.pdf", "data_analysis.epub", "data_analysis.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": "https://github.com/mikenguyen13/data_analysis/edit/main/%s"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
