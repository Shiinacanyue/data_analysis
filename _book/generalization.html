<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.7 Generalization | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="7.7 Generalization | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://bookdown.org/mike/data_analysis/" />
  <meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />
  <meta property="og:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.7 Generalization | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2022-09-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="logo.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="multinomial.html"/>
<link rel="next" href="linear-mixed-models.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-9.3.1/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-9.3.1/highcharts.js"></script>
<script src="libs/highcharts-9.3.1/highcharts-3d.js"></script>
<script src="libs/highcharts-9.3.1/highcharts-more.js"></script>
<script src="libs/highcharts-9.3.1/modules/stock.js"></script>
<script src="libs/highcharts-9.3.1/modules/map.js"></script>
<script src="libs/highcharts-9.3.1/modules/data.js"></script>
<script src="libs/highcharts-9.3.1/modules/exporting.js"></script>
<script src="libs/highcharts-9.3.1/modules/offline-exporting.js"></script>
<script src="libs/highcharts-9.3.1/modules/drilldown.js"></script>
<script src="libs/highcharts-9.3.1/modules/item-series.js"></script>
<script src="libs/highcharts-9.3.1/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-9.3.1/modules/annotations.js"></script>
<script src="libs/highcharts-9.3.1/modules/export-data.js"></script>
<script src="libs/highcharts-9.3.1/modules/funnel.js"></script>
<script src="libs/highcharts-9.3.1/modules/heatmap.js"></script>
<script src="libs/highcharts-9.3.1/modules/treemap.js"></script>
<script src="libs/highcharts-9.3.1/modules/sankey.js"></script>
<script src="libs/highcharts-9.3.1/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-9.3.1/modules/organization.js"></script>
<script src="libs/highcharts-9.3.1/modules/solid-gauge.js"></script>
<script src="libs/highcharts-9.3.1/modules/streamgraph.js"></script>
<script src="libs/highcharts-9.3.1/modules/sunburst.js"></script>
<script src="libs/highcharts-9.3.1/modules/vector.js"></script>
<script src="libs/highcharts-9.3.1/modules/wordcloud.js"></script>
<script src="libs/highcharts-9.3.1/modules/xrange.js"></script>
<script src="libs/highcharts-9.3.1/modules/tilemap.js"></script>
<script src="libs/highcharts-9.3.1/modules/venn.js"></script>
<script src="libs/highcharts-9.3.1/modules/gantt.js"></script>
<script src="libs/highcharts-9.3.1/modules/timeline.js"></script>
<script src="libs/highcharts-9.3.1/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-9.3.1/modules/bullet.js"></script>
<script src="libs/highcharts-9.3.1/modules/coloraxis.js"></script>
<script src="libs/highcharts-9.3.1/modules/dumbbell.js"></script>
<script src="libs/highcharts-9.3.1/modules/lollipop.js"></script>
<script src="libs/highcharts-9.3.1/modules/series-label.js"></script>
<script src="libs/highcharts-9.3.1/plugins/motion.js"></script>
<script src="libs/highcharts-9.3.1/custom/reset.js"></script>
<script src="libs/highcharts-9.3.1/modules/boost.js"></script>
<script src="libs/highchart-binding-0.9.4/highchart.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DMNX2X65HQ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li><a href="index.html#preface" id="toc-preface">Preface</a></li>
<li><a href="introduction.html#introduction" id="toc-introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="prerequisites.html#prerequisites" id="toc-prerequisites"><span class="toc-section-number">2</span> Prerequisites</a>
<ul>
<li><a href="matrix-theory.html#matrix-theory" id="toc-matrix-theory"><span class="toc-section-number">2.1</span> Matrix Theory</a>
<ul>
<li><a href="matrix-theory.html#rank" id="toc-rank"><span class="toc-section-number">2.1.1</span> Rank</a></li>
<li><a href="matrix-theory.html#inverse" id="toc-inverse"><span class="toc-section-number">2.1.2</span> Inverse</a></li>
<li><a href="matrix-theory.html#definiteness" id="toc-definiteness"><span class="toc-section-number">2.1.3</span> Definiteness</a></li>
<li><a href="matrix-theory.html#matrix-calculus" id="toc-matrix-calculus"><span class="toc-section-number">2.1.4</span> Matrix Calculus</a></li>
<li><a href="matrix-theory.html#optimization" id="toc-optimization"><span class="toc-section-number">2.1.5</span> Optimization</a></li>
</ul></li>
<li><a href="probability-theory.html#probability-theory" id="toc-probability-theory"><span class="toc-section-number">2.2</span> Probability Theory</a>
<ul>
<li><a href="probability-theory.html#axiom-and-theorems-of-probability" id="toc-axiom-and-theorems-of-probability"><span class="toc-section-number">2.2.1</span> Axiom and Theorems of Probability</a></li>
<li><a href="probability-theory.html#central-limit-theorem" id="toc-central-limit-theorem"><span class="toc-section-number">2.2.2</span> Central Limit Theorem</a></li>
<li><a href="probability-theory.html#random-variable" id="toc-random-variable"><span class="toc-section-number">2.2.3</span> Random variable</a></li>
<li><a href="probability-theory.html#moment-generating-function" id="toc-moment-generating-function"><span class="toc-section-number">2.2.4</span> Moment generating function</a></li>
<li><a href="probability-theory.html#moment" id="toc-moment"><span class="toc-section-number">2.2.5</span> Moment</a></li>
<li><a href="probability-theory.html#distributions" id="toc-distributions"><span class="toc-section-number">2.2.6</span> Distributions</a></li>
</ul></li>
<li><a href="general-math.html#general-math" id="toc-general-math"><span class="toc-section-number">2.3</span> General Math</a>
<ul>
<li><a href="general-math.html#law-of-large-numbers" id="toc-law-of-large-numbers"><span class="toc-section-number">2.3.1</span> Law of large numbers</a></li>
<li><a href="general-math.html#law-of-iterated-expectation" id="toc-law-of-iterated-expectation"><span class="toc-section-number">2.3.2</span> Law of Iterated Expectation</a></li>
<li><a href="general-math.html#convergence" id="toc-convergence"><span class="toc-section-number">2.3.3</span> Convergence</a></li>
<li><a href="general-math.html#sufficient-statistics" id="toc-sufficient-statistics"><span class="toc-section-number">2.3.4</span> Sufficient Statistics</a></li>
<li><a href="general-math.html#parameter-transformations" id="toc-parameter-transformations"><span class="toc-section-number">2.3.5</span> Parameter transformations</a></li>
</ul></li>
<li><a href="data-importexport.html#data-importexport" id="toc-data-importexport"><span class="toc-section-number">2.4</span> Data Import/Export</a>
<ul>
<li><a href="data-importexport.html#medium-size" id="toc-medium-size"><span class="toc-section-number">2.4.1</span> Medium size</a></li>
<li><a href="data-importexport.html#large-size" id="toc-large-size"><span class="toc-section-number">2.4.2</span> Large size</a></li>
</ul></li>
<li><a href="data-manipulation.html#data-manipulation" id="toc-data-manipulation"><span class="toc-section-number">2.5</span> Data Manipulation</a></li>
</ul></li>
<li><a href="#part-i.-basic" id="toc-part-i.-basic">(PART*) I. BASIC</a></li>
<li><a href="descriptive-stat.html#descriptive-stat" id="toc-descriptive-stat"><span class="toc-section-number">3</span> Descriptive Statistics</a>
<ul>
<li><a href="numerical-measures.html#numerical-measures" id="toc-numerical-measures"><span class="toc-section-number">3.1</span> Numerical Measures</a></li>
<li><a href="graphical-measures.html#graphical-measures" id="toc-graphical-measures"><span class="toc-section-number">3.2</span> Graphical Measures</a>
<ul>
<li><a href="graphical-measures.html#shape" id="toc-shape"><span class="toc-section-number">3.2.1</span> Shape</a></li>
<li><a href="graphical-measures.html#scatterplot" id="toc-scatterplot"><span class="toc-section-number">3.2.2</span> Scatterplot</a></li>
</ul></li>
<li><a href="normality-assessment.html#normality-assessment" id="toc-normality-assessment"><span class="toc-section-number">3.3</span> Normality Assessment</a>
<ul>
<li><a href="normality-assessment.html#graphical-assessment" id="toc-graphical-assessment"><span class="toc-section-number">3.3.1</span> Graphical Assessment</a></li>
<li><a href="normality-assessment.html#summary-statistics" id="toc-summary-statistics"><span class="toc-section-number">3.3.2</span> Summary Statistics</a></li>
</ul></li>
<li><a href="bivariate-statistics.html#bivariate-statistics" id="toc-bivariate-statistics"><span class="toc-section-number">3.4</span> Bivariate Statistics</a></li>
<li><a href="two-continuous.html#two-continuous" id="toc-two-continuous"><span class="toc-section-number">3.5</span> Two Continuous</a>
<ul>
<li><a href="two-continuous.html#pearson-correlation" id="toc-pearson-correlation"><span class="toc-section-number">3.5.1</span> Pearson Correlation</a></li>
<li><a href="two-continuous.html#spearman-correlation" id="toc-spearman-correlation"><span class="toc-section-number">3.5.2</span> Spearman Correlation</a></li>
</ul></li>
<li><a href="categorical-and-continuous.html#categorical-and-continuous" id="toc-categorical-and-continuous"><span class="toc-section-number">3.6</span> Categorical and Continuous</a>
<ul>
<li><a href="categorical-and-continuous.html#point-biserial-correlation" id="toc-point-biserial-correlation"><span class="toc-section-number">3.6.1</span> Point-Biserial Correlation</a></li>
<li><a href="categorical-and-continuous.html#logistic-regression" id="toc-logistic-regression"><span class="toc-section-number">3.6.2</span> Logistic Regression</a></li>
</ul></li>
<li><a href="two-discrete.html#two-discrete" id="toc-two-discrete"><span class="toc-section-number">3.7</span> Two Discrete</a>
<ul>
<li><a href="two-discrete.html#distance-metrics" id="toc-distance-metrics"><span class="toc-section-number">3.7.1</span> Distance Metrics</a></li>
<li><a href="two-discrete.html#statistical-metrics" id="toc-statistical-metrics"><span class="toc-section-number">3.7.2</span> Statistical Metrics</a></li>
<li><a href="two-discrete.html#ordinal-association-rank-correlation" id="toc-ordinal-association-rank-correlation"><span class="toc-section-number">3.7.3</span> Ordinal Association (Rank correlation)</a></li>
<li><a href="two-discrete.html#summary-1" id="toc-summary-1"><span class="toc-section-number">3.7.4</span> Summary</a></li>
<li><a href="two-discrete.html#visualization" id="toc-visualization"><span class="toc-section-number">3.7.5</span> Visualization</a></li>
</ul></li>
</ul></li>
<li><a href="basic-statistical-inference.html#basic-statistical-inference" id="toc-basic-statistical-inference"><span class="toc-section-number">4</span> Basic Statistical Inference</a>
<ul>
<li><a href="one-sample-inference.html#one-sample-inference" id="toc-one-sample-inference"><span class="toc-section-number">4.1</span> One Sample Inference</a>
<ul>
<li><a href="one-sample-inference.html#the-mean" id="toc-the-mean"><span class="toc-section-number">4.1.1</span> The Mean</a></li>
<li><a href="one-sample-inference.html#single-variance" id="toc-single-variance"><span class="toc-section-number">4.1.2</span> Single Variance</a></li>
<li><a href="one-sample-inference.html#single-proportion-p" id="toc-single-proportion-p"><span class="toc-section-number">4.1.3</span> Single Proportion (p)</a></li>
<li><a href="one-sample-inference.html#power" id="toc-power"><span class="toc-section-number">4.1.4</span> Power</a></li>
<li><a href="one-sample-inference.html#sample-size" id="toc-sample-size"><span class="toc-section-number">4.1.5</span> Sample Size</a></li>
<li><a href="one-sample-inference.html#note" id="toc-note"><span class="toc-section-number">4.1.6</span> Note</a></li>
<li><a href="one-sample-inference.html#one-sample-non-parametric-methods" id="toc-one-sample-non-parametric-methods"><span class="toc-section-number">4.1.7</span> One-sample Non-parametric Methods</a></li>
</ul></li>
<li><a href="two-sample-inference.html#two-sample-inference" id="toc-two-sample-inference"><span class="toc-section-number">4.2</span> Two Sample Inference</a>
<ul>
<li><a href="two-sample-inference.html#means" id="toc-means"><span class="toc-section-number">4.2.1</span> Means</a></li>
<li><a href="two-sample-inference.html#variances" id="toc-variances"><span class="toc-section-number">4.2.2</span> Variances</a></li>
<li><a href="two-sample-inference.html#power-1" id="toc-power-1"><span class="toc-section-number">4.2.3</span> Power</a></li>
<li><a href="two-sample-inference.html#sample-size-1" id="toc-sample-size-1"><span class="toc-section-number">4.2.4</span> Sample Size</a></li>
<li><a href="two-sample-inference.html#matched-pair-designs" id="toc-matched-pair-designs"><span class="toc-section-number">4.2.5</span> Matched Pair Designs</a></li>
<li><a href="two-sample-inference.html#nonparametric-tests-for-two-samples" id="toc-nonparametric-tests-for-two-samples"><span class="toc-section-number">4.2.6</span> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li><a href="categorical-data-analysis.html#categorical-data-analysis" id="toc-categorical-data-analysis"><span class="toc-section-number">4.3</span> Categorical Data Analysis</a>
<ul>
<li><a href="categorical-data-analysis.html#inferences-for-small-samples" id="toc-inferences-for-small-samples"><span class="toc-section-number">4.3.1</span> Inferences for Small Samples</a></li>
<li><a href="categorical-data-analysis.html#test-of-association" id="toc-test-of-association"><span class="toc-section-number">4.3.2</span> Test of Association</a></li>
<li><a href="categorical-data-analysis.html#ordinal-association" id="toc-ordinal-association"><span class="toc-section-number">4.3.3</span> Ordinal Association</a></li>
</ul></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#divergence-metrics-and-test-for-comparing-distributions" id="toc-divergence-metrics-and-test-for-comparing-distributions"><span class="toc-section-number">4.4</span> Divergence Metrics and Test for Comparing Distributions</a>
<ul>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#kullback-leibler-divergence" id="toc-kullback-leibler-divergence"><span class="toc-section-number">4.4.1</span> Kullback-Leibler Divergence</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#jensen-shannon-divergence" id="toc-jensen-shannon-divergence"><span class="toc-section-number">4.4.2</span> Jensen-Shannon Divergence</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#wasserstein-distance" id="toc-wasserstein-distance"><span class="toc-section-number">4.4.3</span> Wasserstein Distance</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#kolmogorov-smirnov-test-1" id="toc-kolmogorov-smirnov-test-1"><span class="toc-section-number">4.4.4</span> Kolmogorov-Smirnov Test</a></li>
</ul></li>
</ul></li>
<li><a href="#part-ii.-regression" id="toc-part-ii.-regression">(PART*) II. REGRESSION</a></li>
<li><a href="linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">5</span> Linear Regression</a>
<ul>
<li><a href="ordinary-least-squares.html#ordinary-least-squares" id="toc-ordinary-least-squares"><span class="toc-section-number">5.1</span> Ordinary Least Squares</a>
<ul>
<li><a href="ordinary-least-squares.html#simple-regression-basic-model" id="toc-simple-regression-basic-model"><span class="toc-section-number">5.1.1</span> Simple Regression (Basic Model)</a></li>
<li><a href="ordinary-least-squares.html#multiple-linear-regression" id="toc-multiple-linear-regression"><span class="toc-section-number">5.1.2</span> Multiple Linear Regression</a></li>
<li><a href="ordinary-least-squares.html#ols-assumptions" id="toc-ols-assumptions"><span class="toc-section-number">5.1.3</span> OLS Assumptions</a></li>
<li><a href="ordinary-least-squares.html#theorems" id="toc-theorems"><span class="toc-section-number">5.1.4</span> Theorems</a></li>
<li><a href="ordinary-least-squares.html#variable-selection" id="toc-variable-selection"><span class="toc-section-number">5.1.5</span> Variable Selection</a></li>
<li><a href="ordinary-least-squares.html#diagnostics-1" id="toc-diagnostics-1"><span class="toc-section-number">5.1.6</span> Diagnostics</a></li>
<li><a href="ordinary-least-squares.html#model-validation" id="toc-model-validation"><span class="toc-section-number">5.1.7</span> Model Validation</a></li>
<li><a href="ordinary-least-squares.html#finite-sample-properties" id="toc-finite-sample-properties"><span class="toc-section-number">5.1.8</span> Finite Sample Properties</a></li>
<li><a href="ordinary-least-squares.html#large-sample-properties" id="toc-large-sample-properties"><span class="toc-section-number">5.1.9</span> Large Sample Properties</a></li>
</ul></li>
<li><a href="feasible-generalized-least-squares.html#feasible-generalized-least-squares" id="toc-feasible-generalized-least-squares"><span class="toc-section-number">5.2</span> Feasible Generalized Least Squares</a>
<ul>
<li><a href="feasible-generalized-least-squares.html#heteroskedasticity" id="toc-heteroskedasticity"><span class="toc-section-number">5.2.1</span> Heteroskedasticity</a></li>
<li><a href="feasible-generalized-least-squares.html#serial-correlation" id="toc-serial-correlation"><span class="toc-section-number">5.2.2</span> Serial Correlation</a></li>
</ul></li>
<li><a href="weighted-least-squares.html#weighted-least-squares" id="toc-weighted-least-squares"><span class="toc-section-number">5.3</span> Weighted Least Squares</a></li>
<li><a href="generalized-least-squares.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">5.4</span> Generalized Least Squares</a></li>
<li><a href="feasiable-prais-winsten.html#feasiable-prais-winsten" id="toc-feasiable-prais-winsten"><span class="toc-section-number">5.5</span> Feasiable Prais Winsten</a></li>
<li><a href="feasible-group-level-random-effects.html#feasible-group-level-random-effects" id="toc-feasible-group-level-random-effects"><span class="toc-section-number">5.6</span> Feasible group level Random Effects</a></li>
<li><a href="ridge-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">5.7</span> Ridge Regression</a></li>
<li><a href="principal-component-regression.html#principal-component-regression" id="toc-principal-component-regression"><span class="toc-section-number">5.8</span> Principal Component Regression</a></li>
<li><a href="robust-regression.html#robust-regression" id="toc-robust-regression"><span class="toc-section-number">5.9</span> Robust Regression</a>
<ul>
<li><a href="robust-regression.html#least-absolute-residuals-lar-regression" id="toc-least-absolute-residuals-lar-regression"><span class="toc-section-number">5.9.1</span> Least Absolute Residuals (LAR) Regression</a></li>
<li><a href="robust-regression.html#least-median-of-squares-lms-regression" id="toc-least-median-of-squares-lms-regression"><span class="toc-section-number">5.9.2</span> Least Median of Squares (LMS) Regression</a></li>
<li><a href="robust-regression.html#iteratively-reweighted-least-squares-irls-robust-regression" id="toc-iteratively-reweighted-least-squares-irls-robust-regression"><span class="toc-section-number">5.9.3</span> Iteratively Reweighted Least Squares (IRLS) Robust Regression</a></li>
</ul></li>
<li><a href="maximum-likelihood-regression.html#maximum-likelihood-regression" id="toc-maximum-likelihood-regression"><span class="toc-section-number">5.10</span> Maximum Likelihood</a>
<ul>
<li><a href="maximum-likelihood-regression.html#motivation-for-mle" id="toc-motivation-for-mle"><span class="toc-section-number">5.10.1</span> Motivation for MLE</a></li>
<li><a href="maximum-likelihood-regression.html#assumption" id="toc-assumption"><span class="toc-section-number">5.10.2</span> Assumption</a></li>
<li><a href="maximum-likelihood-regression.html#properties" id="toc-properties"><span class="toc-section-number">5.10.3</span> Properties</a></li>
<li><a href="maximum-likelihood-regression.html#compare-to-ols" id="toc-compare-to-ols"><span class="toc-section-number">5.10.4</span> Compare to OLS</a></li>
<li><a href="maximum-likelihood-regression.html#application" id="toc-application"><span class="toc-section-number">5.10.5</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="non-linear-regression.html#non-linear-regression" id="toc-non-linear-regression"><span class="toc-section-number">6</span> Non-linear Regression</a>
<ul>
<li><a href="inference-1.html#inference-1" id="toc-inference-1"><span class="toc-section-number">6.1</span> Inference</a>
<ul>
<li><a href="inference-1.html#linear-function-of-the-parameters" id="toc-linear-function-of-the-parameters"><span class="toc-section-number">6.1.1</span> Linear Function of the Parameters</a></li>
<li><a href="inference-1.html#nonlinear" id="toc-nonlinear"><span class="toc-section-number">6.1.2</span> Nonlinear</a></li>
</ul></li>
<li><a href="non-linear-least-squares.html#non-linear-least-squares" id="toc-non-linear-least-squares"><span class="toc-section-number">6.2</span> Non-linear Least Squares</a>
<ul>
<li><a href="non-linear-least-squares.html#alternative-of-gauss-newton-algorithm" id="toc-alternative-of-gauss-newton-algorithm"><span class="toc-section-number">6.2.1</span> Alternative of Gauss-Newton Algorithm</a></li>
<li><a href="non-linear-least-squares.html#practical-considerations" id="toc-practical-considerations"><span class="toc-section-number">6.2.2</span> Practical Considerations</a></li>
<li><a href="non-linear-least-squares.html#modelestiamtion-adequcy" id="toc-modelestiamtion-adequcy"><span class="toc-section-number">6.2.3</span> Model/Estiamtion Adequcy</a></li>
<li><a href="non-linear-least-squares.html#application-1" id="toc-application-1"><span class="toc-section-number">6.2.4</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="generalized-linear-models.html#generalized-linear-models" id="toc-generalized-linear-models"><span class="toc-section-number">7</span> Generalized Linear Models</a>
<ul>
<li><a href="logistic-regression-1.html#logistic-regression-1" id="toc-logistic-regression-1"><span class="toc-section-number">7.1</span> Logistic Regression</a>
<ul>
<li><a href="logistic-regression-1.html#application-2" id="toc-application-2"><span class="toc-section-number">7.1.1</span> Application</a></li>
</ul></li>
<li><a href="probit-regression.html#probit-regression" id="toc-probit-regression"><span class="toc-section-number">7.2</span> Probit Regression</a></li>
<li><a href="binomial-regression.html#binomial-regression" id="toc-binomial-regression"><span class="toc-section-number">7.3</span> Binomial Regression</a></li>
<li><a href="poisson-regression.html#poisson-regression" id="toc-poisson-regression"><span class="toc-section-number">7.4</span> Poisson Regression</a>
<ul>
<li><a href="poisson-regression.html#application-3" id="toc-application-3"><span class="toc-section-number">7.4.1</span> Application</a></li>
</ul></li>
<li><a href="negative-binomial-regression.html#negative-binomial-regression" id="toc-negative-binomial-regression"><span class="toc-section-number">7.5</span> Negative Binomial Regression</a></li>
<li><a href="multinomial.html#multinomial" id="toc-multinomial"><span class="toc-section-number">7.6</span> Multinomial</a></li>
<li><a href="generalization.html#generalization" id="toc-generalization"><span class="toc-section-number">7.7</span> Generalization</a>
<ul>
<li><a href="generalization.html#estimation-1" id="toc-estimation-1"><span class="toc-section-number">7.7.1</span> Estimation</a></li>
<li><a href="generalization.html#inference-2" id="toc-inference-2"><span class="toc-section-number">7.7.2</span> Inference</a></li>
<li><a href="generalization.html#deviance" id="toc-deviance"><span class="toc-section-number">7.7.3</span> Deviance</a></li>
<li><a href="generalization.html#diagnostic-plots" id="toc-diagnostic-plots"><span class="toc-section-number">7.7.4</span> Diagnostic Plots</a></li>
<li><a href="generalization.html#goodness-of-fit" id="toc-goodness-of-fit"><span class="toc-section-number">7.7.5</span> Goodness of Fit</a></li>
<li><a href="generalization.html#over-dispersion" id="toc-over-dispersion"><span class="toc-section-number">7.7.6</span> Over-Dispersion</a></li>
</ul></li>
</ul></li>
<li><a href="linear-mixed-models.html#linear-mixed-models" id="toc-linear-mixed-models"><span class="toc-section-number">8</span> Linear Mixed Models</a>
<ul>
<li><a href="dependent-data.html#dependent-data" id="toc-dependent-data"><span class="toc-section-number">8.1</span> Dependent Data</a>
<ul>
<li><a href="dependent-data.html#random-intercepts-model" id="toc-random-intercepts-model"><span class="toc-section-number">8.1.1</span> Random-Intercepts Model</a></li>
<li><a href="dependent-data.html#covariance-models" id="toc-covariance-models"><span class="toc-section-number">8.1.2</span> Covariance Models</a></li>
</ul></li>
<li><a href="estimation-2.html#estimation-2" id="toc-estimation-2"><span class="toc-section-number">8.2</span> Estimation</a>
<ul>
<li><a href="estimation-2.html#estimating-mathbfv" id="toc-estimating-mathbfv"><span class="toc-section-number">8.2.1</span> Estimating <span class="math inline">\(\mathbf{V}\)</span></a></li>
</ul></li>
<li><a href="inference-3.html#inference-3" id="toc-inference-3"><span class="toc-section-number">8.3</span> Inference</a>
<ul>
<li><a href="inference-3.html#parameters-beta" id="toc-parameters-beta"><span class="toc-section-number">8.3.1</span> Parameters <span class="math inline">\(\beta\)</span></a></li>
<li><a href="inference-3.html#variance-components" id="toc-variance-components"><span class="toc-section-number">8.3.2</span> Variance Components</a></li>
</ul></li>
<li><a href="information-criteria.html#information-criteria" id="toc-information-criteria"><span class="toc-section-number">8.4</span> Information Criteria</a>
<ul>
<li><a href="information-criteria.html#akaikes-information-criteria-aic" id="toc-akaikes-information-criteria-aic"><span class="toc-section-number">8.4.1</span> Akaike’s Information Criteria (AIC)</a></li>
<li><a href="information-criteria.html#corrected-aic-aicc" id="toc-corrected-aic-aicc"><span class="toc-section-number">8.4.2</span> Corrected AIC (AICC)</a></li>
<li><a href="information-criteria.html#bayesian-information-criteria-bic" id="toc-bayesian-information-criteria-bic"><span class="toc-section-number">8.4.3</span> Bayesian Information Criteria (BIC)</a></li>
</ul></li>
<li><a href="split-plot-designs.html#split-plot-designs" id="toc-split-plot-designs"><span class="toc-section-number">8.5</span> Split-Plot Designs</a>
<ul>
<li><a href="split-plot-designs.html#application-4" id="toc-application-4"><span class="toc-section-number">8.5.1</span> Application</a></li>
</ul></li>
<li><a href="repeated-measures-in-mixed-models.html#repeated-measures-in-mixed-models" id="toc-repeated-measures-in-mixed-models"><span class="toc-section-number">8.6</span> Repeated Measures in Mixed Models</a></li>
<li><a href="unbalanced-or-unequally-spaced-data.html#unbalanced-or-unequally-spaced-data" id="toc-unbalanced-or-unequally-spaced-data"><span class="toc-section-number">8.7</span> Unbalanced or Unequally Spaced Data</a></li>
<li><a href="application-5.html#application-5" id="toc-application-5"><span class="toc-section-number">8.8</span> Application</a>
<ul>
<li><a href="application-5.html#example-1-pulps" id="toc-example-1-pulps"><span class="toc-section-number">8.8.1</span> Example 1 (Pulps)</a></li>
<li><a href="application-5.html#example-2-rats" id="toc-example-2-rats"><span class="toc-section-number">8.8.2</span> Example 2 (Rats)</a></li>
<li><a href="application-5.html#example-3-agridat" id="toc-example-3-agridat"><span class="toc-section-number">8.8.3</span> Example 3 (Agridat)</a></li>
</ul></li>
</ul></li>
<li><a href="nonlinear-and-generalized-linear-mixed-models.html#nonlinear-and-generalized-linear-mixed-models" id="toc-nonlinear-and-generalized-linear-mixed-models"><span class="toc-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li><a href="estimation-3.html#estimation-3" id="toc-estimation-3"><span class="toc-section-number">9.1</span> Estimation</a>
<ul>
<li><a href="estimation-3.html#estimation-by-numerical-integration" id="toc-estimation-by-numerical-integration"><span class="toc-section-number">9.1.1</span> Estimation by Numerical Integration</a></li>
<li><a href="estimation-3.html#estimation-by-linearization" id="toc-estimation-by-linearization"><span class="toc-section-number">9.1.2</span> Estimation by Linearization</a></li>
<li><a href="estimation-3.html#estimation-by-bayesian-hierarchical-models" id="toc-estimation-by-bayesian-hierarchical-models"><span class="toc-section-number">9.1.3</span> Estimation by Bayesian Hierarchical Models</a></li>
</ul></li>
<li><a href="application-6.html#application-6" id="toc-application-6"><span class="toc-section-number">9.2</span> Application</a>
<ul>
<li><a href="application-6.html#binomial-cbpp-data" id="toc-binomial-cbpp-data"><span class="toc-section-number">9.2.1</span> Binomial (CBPP Data)</a></li>
<li><a href="application-6.html#count-owl-data" id="toc-count-owl-data"><span class="toc-section-number">9.2.2</span> Count (Owl Data)</a></li>
<li><a href="application-6.html#binomial-1" id="toc-binomial-1"><span class="toc-section-number">9.2.3</span> Binomial</a></li>
<li><a href="application-6.html#example-from-schabenberger_2001-section-8.4.1" id="toc-example-from-schabenberger_2001-section-8.4.1"><span class="toc-section-number">9.2.4</span> Example from <span class="citation">(<span>Schabenberger and Pierce 2001</span>)</span> section 8.4.1</a></li>
</ul></li>
<li><a href="summary-2.html#summary-2" id="toc-summary-2"><span class="toc-section-number">9.3</span> Summary</a></li>
</ul></li>
<li><a href="#part-iii.-ramifications" id="toc-part-iii.-ramifications">(PART*) III. RAMIFICATIONS</a></li>
<li><a href="model-specification.html#model-specification" id="toc-model-specification"><span class="toc-section-number">10</span> Model Specification</a>
<ul>
<li><a href="nested-model.html#nested-model" id="toc-nested-model"><span class="toc-section-number">10.1</span> Nested Model</a>
<ul>
<li><a href="nested-model.html#chow-test" id="toc-chow-test"><span class="toc-section-number">10.1.1</span> Chow test</a></li>
</ul></li>
<li><a href="non-nested-model.html#non-nested-model" id="toc-non-nested-model"><span class="toc-section-number">10.2</span> Non-Nested Model</a>
<ul>
<li><a href="non-nested-model.html#davidson-mackinnon-test" id="toc-davidson-mackinnon-test"><span class="toc-section-number">10.2.1</span> Davidson-Mackinnon test</a></li>
</ul></li>
<li><a href="heteroskedasticity-1.html#heteroskedasticity-1" id="toc-heteroskedasticity-1"><span class="toc-section-number">10.3</span> Heteroskedasticity</a>
<ul>
<li><a href="heteroskedasticity-1.html#breusch-pagan-test" id="toc-breusch-pagan-test"><span class="toc-section-number">10.3.1</span> Breusch-Pagan test</a></li>
<li><a href="heteroskedasticity-1.html#white-test" id="toc-white-test"><span class="toc-section-number">10.3.2</span> White test</a></li>
</ul></li>
</ul></li>
<li><a href="imputation-missing-data.html#imputation-missing-data" id="toc-imputation-missing-data"><span class="toc-section-number">11</span> Imputation (Missing Data)</a>
<ul>
<li><a href="assumptions-1.html#assumptions-1" id="toc-assumptions-1"><span class="toc-section-number">11.1</span> Assumptions</a>
<ul>
<li><a href="assumptions-1.html#missing-completely-at-random-mcar" id="toc-missing-completely-at-random-mcar"><span class="toc-section-number">11.1.1</span> Missing Completely at Random (MCAR)</a></li>
<li><a href="assumptions-1.html#missing-at-random-mar" id="toc-missing-at-random-mar"><span class="toc-section-number">11.1.2</span> Missing at Random (MAR)</a></li>
<li><a href="assumptions-1.html#ignorable" id="toc-ignorable"><span class="toc-section-number">11.1.3</span> Ignorable</a></li>
<li><a href="assumptions-1.html#nonignorable" id="toc-nonignorable"><span class="toc-section-number">11.1.4</span> Nonignorable</a></li>
</ul></li>
<li><a href="solutions-to-missing-data.html#solutions-to-missing-data" id="toc-solutions-to-missing-data"><span class="toc-section-number">11.2</span> Solutions to Missing data</a>
<ul>
<li><a href="solutions-to-missing-data.html#listwise-deletion" id="toc-listwise-deletion"><span class="toc-section-number">11.2.1</span> Listwise Deletion</a></li>
<li><a href="solutions-to-missing-data.html#pairwise-deletion" id="toc-pairwise-deletion"><span class="toc-section-number">11.2.2</span> Pairwise Deletion</a></li>
<li><a href="solutions-to-missing-data.html#dummy-variable-adjustment" id="toc-dummy-variable-adjustment"><span class="toc-section-number">11.2.3</span> Dummy Variable Adjustment</a></li>
<li><a href="solutions-to-missing-data.html#imputation" id="toc-imputation"><span class="toc-section-number">11.2.4</span> Imputation</a></li>
<li><a href="solutions-to-missing-data.html#other-methods" id="toc-other-methods"><span class="toc-section-number">11.2.5</span> Other methods</a></li>
</ul></li>
<li><a href="criteria-for-choosing-an-effective-approach.html#criteria-for-choosing-an-effective-approach" id="toc-criteria-for-choosing-an-effective-approach"><span class="toc-section-number">11.3</span> Criteria for Choosing an Effective Approach</a></li>
<li><a href="another-perspective.html#another-perspective" id="toc-another-perspective"><span class="toc-section-number">11.4</span> Another Perspective</a></li>
<li><a href="diagnosing-the-mechanism.html#diagnosing-the-mechanism" id="toc-diagnosing-the-mechanism"><span class="toc-section-number">11.5</span> Diagnosing the Mechanism</a>
<ul>
<li><a href="diagnosing-the-mechanism.html#mar-vs.-mnar" id="toc-mar-vs.-mnar"><span class="toc-section-number">11.5.1</span> MAR vs. MNAR</a></li>
<li><a href="diagnosing-the-mechanism.html#mcar-vs.-mar" id="toc-mcar-vs.-mar"><span class="toc-section-number">11.5.2</span> MCAR vs. MAR</a></li>
</ul></li>
<li><a href="application-7.html#application-7" id="toc-application-7"><span class="toc-section-number">11.6</span> Application</a>
<ul>
<li><a href="application-7.html#imputation-with-mean-median-mode" id="toc-imputation-with-mean-median-mode"><span class="toc-section-number">11.6.1</span> Imputation with mean / median / mode</a></li>
<li><a href="application-7.html#knn" id="toc-knn"><span class="toc-section-number">11.6.2</span> KNN</a></li>
<li><a href="application-7.html#rpart" id="toc-rpart"><span class="toc-section-number">11.6.3</span> rpart</a></li>
<li><a href="application-7.html#mice-multivariate-imputation-via-chained-equations" id="toc-mice-multivariate-imputation-via-chained-equations"><span class="toc-section-number">11.6.4</span> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li><a href="application-7.html#amelia" id="toc-amelia"><span class="toc-section-number">11.6.5</span> Amelia</a></li>
<li><a href="application-7.html#missforest" id="toc-missforest"><span class="toc-section-number">11.6.6</span> missForest</a></li>
<li><a href="application-7.html#hmisc" id="toc-hmisc"><span class="toc-section-number">11.6.7</span> Hmisc</a></li>
<li><a href="application-7.html#mi" id="toc-mi"><span class="toc-section-number">11.6.8</span> mi</a></li>
</ul></li>
</ul></li>
<li><a href="data.html#data" id="toc-data"><span class="toc-section-number">12</span> Data</a>
<ul>
<li><a href="cross-sectional.html#cross-sectional" id="toc-cross-sectional"><span class="toc-section-number">12.1</span> Cross-Sectional</a></li>
<li><a href="time-series-1.html#time-series-1" id="toc-time-series-1"><span class="toc-section-number">12.2</span> Time Series</a>
<ul>
<li><a href="time-series-1.html#deterministic-time-trend" id="toc-deterministic-time-trend"><span class="toc-section-number">12.2.1</span> Deterministic Time trend</a></li>
<li><a href="time-series-1.html#feedback-effect" id="toc-feedback-effect"><span class="toc-section-number">12.2.2</span> Feedback Effect</a></li>
<li><a href="time-series-1.html#dynamic-specification" id="toc-dynamic-specification"><span class="toc-section-number">12.2.3</span> Dynamic Specification</a></li>
<li><a href="time-series-1.html#dynamically-complete" id="toc-dynamically-complete"><span class="toc-section-number">12.2.4</span> Dynamically Complete</a></li>
<li><a href="time-series-1.html#highly-persistent-data" id="toc-highly-persistent-data"><span class="toc-section-number">12.2.5</span> Highly Persistent Data</a></li>
</ul></li>
<li><a href="repeated-cross-sections.html#repeated-cross-sections" id="toc-repeated-cross-sections"><span class="toc-section-number">12.3</span> Repeated Cross Sections</a>
<ul>
<li><a href="repeated-cross-sections.html#pooled-cross-section" id="toc-pooled-cross-section"><span class="toc-section-number">12.3.1</span> Pooled Cross Section</a></li>
</ul></li>
<li><a href="panel-data.html#panel-data" id="toc-panel-data"><span class="toc-section-number">12.4</span> Panel Data</a>
<ul>
<li><a href="panel-data.html#pooled-ols-estimator" id="toc-pooled-ols-estimator"><span class="toc-section-number">12.4.1</span> Pooled OLS Estimator</a></li>
<li><a href="panel-data.html#individual-specific-effects-model" id="toc-individual-specific-effects-model"><span class="toc-section-number">12.4.2</span> Individual-specific effects model</a></li>
<li><a href="panel-data.html#tests-for-assumptions" id="toc-tests-for-assumptions"><span class="toc-section-number">12.4.3</span> Tests for Assumptions</a></li>
<li><a href="panel-data.html#model-selection" id="toc-model-selection"><span class="toc-section-number">12.4.4</span> Model Selection</a></li>
<li><a href="panel-data.html#summary-3" id="toc-summary-3"><span class="toc-section-number">12.4.5</span> Summary</a></li>
<li><a href="panel-data.html#application-8" id="toc-application-8"><span class="toc-section-number">12.4.6</span> Application</a></li>
<li><a href="panel-data.html#other-estimators" id="toc-other-estimators"><span class="toc-section-number">12.4.7</span> Other Estimators</a></li>
</ul></li>
</ul></li>
<li><a href="hypothesis-testing.html#hypothesis-testing" id="toc-hypothesis-testing"><span class="toc-section-number">13</span> Hypothesis Testing</a>
<ul>
<li><a href="types-of-hypothesis-testing.html#types-of-hypothesis-testing" id="toc-types-of-hypothesis-testing"><span class="toc-section-number">13.1</span> Types of hypothesis testing</a></li>
<li><a href="wald-test.html#wald-test" id="toc-wald-test"><span class="toc-section-number">13.2</span> Wald test</a>
<ul>
<li><a href="wald-test.html#multiple-hypothesis" id="toc-multiple-hypothesis"><span class="toc-section-number">13.2.1</span> Multiple Hypothesis</a></li>
<li><a href="wald-test.html#linear-combination" id="toc-linear-combination"><span class="toc-section-number">13.2.2</span> Linear Combination</a></li>
<li><a href="wald-test.html#estimate-difference-in-coefficients" id="toc-estimate-difference-in-coefficients"><span class="toc-section-number">13.2.3</span> Estimate Difference in Coefficients</a></li>
<li><a href="wald-test.html#application-9" id="toc-application-9"><span class="toc-section-number">13.2.4</span> Application</a></li>
<li><a href="wald-test.html#nonlinear-1" id="toc-nonlinear-1"><span class="toc-section-number">13.2.5</span> Nonlinear</a></li>
</ul></li>
<li><a href="the-likelihood-ratio-test.html#the-likelihood-ratio-test" id="toc-the-likelihood-ratio-test"><span class="toc-section-number">13.3</span> The likelihood ratio test</a></li>
<li><a href="lagrange-multiplier-score.html#lagrange-multiplier-score" id="toc-lagrange-multiplier-score"><span class="toc-section-number">13.4</span> Lagrange Multiplier (Score)</a></li>
</ul></li>
<li><a href="prediction-and-estimation.html#prediction-and-estimation" id="toc-prediction-and-estimation"><span class="toc-section-number">14</span> Prediction and Estimation</a></li>
<li><a href="moderation.html#moderation" id="toc-moderation"><span class="toc-section-number">15</span> Moderation</a>
<ul>
<li><a href="emmeans-package.html#emmeans-package" id="toc-emmeans-package"><span class="toc-section-number">15.1</span> emmeans package</a>
<ul>
<li><a href="emmeans-package.html#continuous-by-continuous" id="toc-continuous-by-continuous"><span class="toc-section-number">15.1.1</span> Continuous by continuous</a></li>
<li><a href="emmeans-package.html#continuous-by-categorical" id="toc-continuous-by-categorical"><span class="toc-section-number">15.1.2</span> Continuous by categorical</a></li>
<li><a href="emmeans-package.html#categorical-by-categorical" id="toc-categorical-by-categorical"><span class="toc-section-number">15.1.3</span> Categorical by categorical</a></li>
</ul></li>
<li><a href="probmod-package.html#probmod-package" id="toc-probmod-package"><span class="toc-section-number">15.2</span> probmod package</a></li>
<li><a href="interactions-package.html#interactions-package" id="toc-interactions-package"><span class="toc-section-number">15.3</span> interactions package</a>
<ul>
<li><a href="interactions-package.html#continuous-interaction" id="toc-continuous-interaction"><span class="toc-section-number">15.3.1</span> Continuous interaction</a></li>
<li><a href="interactions-package.html#categorical-interaction" id="toc-categorical-interaction"><span class="toc-section-number">15.3.2</span> Categorical interaction</a></li>
</ul></li>
<li><a href="interactionr-package.html#interactionr-package" id="toc-interactionr-package"><span class="toc-section-number">15.4</span> interactionR package</a></li>
<li><a href="sjplot-package.html#sjplot-package" id="toc-sjplot-package"><span class="toc-section-number">15.5</span> sjPlot package</a></li>
</ul></li>
<li><a href="#part-iv.-causal-inference" id="toc-part-iv.-causal-inference">(PART*) IV. CAUSAL INFERENCE</a></li>
<li><a href="causal-inference.html#causal-inference" id="toc-causal-inference"><span class="toc-section-number">16</span> Causal Inference</a>
<ul>
<li><a href="treatment-effect-types.html#treatment-effect-types" id="toc-treatment-effect-types"><span class="toc-section-number">16.1</span> Treatment effect types</a>
<ul>
<li><a href="treatment-effect-types.html#average-treatment-effects" id="toc-average-treatment-effects"><span class="toc-section-number">16.1.1</span> Average Treatment Effects</a></li>
<li><a href="treatment-effect-types.html#conditional-average-treatment-effects" id="toc-conditional-average-treatment-effects"><span class="toc-section-number">16.1.2</span> Conditional Average Treatment Effects</a></li>
<li><a href="treatment-effect-types.html#intent-to-treat-effects" id="toc-intent-to-treat-effects"><span class="toc-section-number">16.1.3</span> Intent-to-treat Effects</a></li>
<li><a href="treatment-effect-types.html#local-average-treatment-effects" id="toc-local-average-treatment-effects"><span class="toc-section-number">16.1.4</span> Local Average Treatment Effects</a></li>
<li><a href="treatment-effect-types.html#population-vs.-sample-average-treatment-effects" id="toc-population-vs.-sample-average-treatment-effects"><span class="toc-section-number">16.1.5</span> Population vs. Sample Average Treatment Effects</a></li>
<li><a href="treatment-effect-types.html#average-treatment-effects-on-the-treated-and-control" id="toc-average-treatment-effects-on-the-treated-and-control"><span class="toc-section-number">16.1.6</span> Average Treatment Effects on the Treated and Control</a></li>
<li><a href="treatment-effect-types.html#quantile-average-treatment-effects" id="toc-quantile-average-treatment-effects"><span class="toc-section-number">16.1.7</span> Quantile Average Treatment Effects</a></li>
<li><a href="treatment-effect-types.html#mediation-effects" id="toc-mediation-effects"><span class="toc-section-number">16.1.8</span> Mediation Effects</a></li>
<li><a href="treatment-effect-types.html#log-odds-treatment-effects" id="toc-log-odds-treatment-effects"><span class="toc-section-number">16.1.9</span> Log-odds Treatment Effects</a></li>
</ul></li>
</ul></li>
<li><a href="#part-a.-experimental-design" id="toc-part-a.-experimental-design">(PART*) A. EXPERIMENTAL DESIGN</a></li>
<li><a href="experimental-design.html#experimental-design" id="toc-experimental-design"><span class="toc-section-number">17</span> Experimental Design</a>
<ul>
<li><a href="semi-random-experiment.html#semi-random-experiment" id="toc-semi-random-experiment"><span class="toc-section-number">17.1</span> Semi-random Experiment</a></li>
<li><a href="rerandomization.html#rerandomization" id="toc-rerandomization"><span class="toc-section-number">17.2</span> Rerandomization</a></li>
</ul></li>
<li><a href="sampling.html#sampling" id="toc-sampling"><span class="toc-section-number">18</span> Sampling</a>
<ul>
<li><a href="simple-sampling.html#simple-sampling" id="toc-simple-sampling"><span class="toc-section-number">18.1</span> Simple Sampling</a></li>
<li><a href="stratified-sampling.html#stratified-sampling" id="toc-stratified-sampling"><span class="toc-section-number">18.2</span> Stratified Sampling</a></li>
<li><a href="unequal-probability-sampling.html#unequal-probability-sampling" id="toc-unequal-probability-sampling"><span class="toc-section-number">18.3</span> Unequal Probability Sampling</a></li>
<li><a href="balanced-sampling.html#balanced-sampling" id="toc-balanced-sampling"><span class="toc-section-number">18.4</span> Balanced Sampling</a>
<ul>
<li><a href="balanced-sampling.html#cube" id="toc-cube"><span class="toc-section-number">18.4.1</span> Cube</a></li>
<li><a href="balanced-sampling.html#stratification" id="toc-stratification"><span class="toc-section-number">18.4.2</span> Stratification</a></li>
<li><a href="balanced-sampling.html#cluster-1" id="toc-cluster-1"><span class="toc-section-number">18.4.3</span> Cluster</a></li>
<li><a href="balanced-sampling.html#two-stage" id="toc-two-stage"><span class="toc-section-number">18.4.4</span> Two-stage</a></li>
</ul></li>
</ul></li>
<li><a href="analysis-of-variance-anova.html#analysis-of-variance-anova" id="toc-analysis-of-variance-anova"><span class="toc-section-number">19</span> Analysis of Variance (ANOVA)</a>
<ul>
<li><a href="completely-randomized-design-crd.html#completely-randomized-design-crd" id="toc-completely-randomized-design-crd"><span class="toc-section-number">19.1</span> Completely Randomized Design (CRD)</a>
<ul>
<li><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model" id="toc-single-factor-fixed-effects-model"><span class="toc-section-number">19.1.1</span> Single Factor Fixed Effects Model</a></li>
<li><a href="completely-randomized-design-crd.html#single-factor-random-effects-model" id="toc-single-factor-random-effects-model"><span class="toc-section-number">19.1.2</span> Single Factor Random Effects Model</a></li>
<li><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova" id="toc-two-factor-fixed-effect-anova"><span class="toc-section-number">19.1.3</span> Two Factor Fixed Effect ANOVA</a></li>
<li><a href="completely-randomized-design-crd.html#two-way-random-effects-anova" id="toc-two-way-random-effects-anova"><span class="toc-section-number">19.1.4</span> Two-Way Random Effects ANOVA</a></li>
<li><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova" id="toc-two-way-mixed-effects-anova"><span class="toc-section-number">19.1.5</span> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li><a href="nonparametric-anova.html#nonparametric-anova" id="toc-nonparametric-anova"><span class="toc-section-number">19.2</span> Nonparametric ANOVA</a>
<ul>
<li><a href="nonparametric-anova.html#kruskal-wallis" id="toc-kruskal-wallis"><span class="toc-section-number">19.2.1</span> Kruskal-Wallis</a></li>
<li><a href="nonparametric-anova.html#friedman-test" id="toc-friedman-test"><span class="toc-section-number">19.2.2</span> Friedman Test</a></li>
</ul></li>
<li><a href="sample-size-planning-for-anova.html#sample-size-planning-for-anova" id="toc-sample-size-planning-for-anova"><span class="toc-section-number">19.3</span> Sample Size Planning for ANOVA</a>
<ul>
<li><a href="sample-size-planning-for-anova.html#balanced-designs" id="toc-balanced-designs"><span class="toc-section-number">19.3.1</span> Balanced Designs</a></li>
<li><a href="sample-size-planning-for-anova.html#randomized-block-experiments" id="toc-randomized-block-experiments"><span class="toc-section-number">19.3.2</span> Randomized Block Experiments</a></li>
</ul></li>
<li><a href="randomized-block-designs.html#randomized-block-designs" id="toc-randomized-block-designs"><span class="toc-section-number">19.4</span> Randomized Block Designs</a>
<ul>
<li><a href="randomized-block-designs.html#tukey-test-of-additivity" id="toc-tukey-test-of-additivity"><span class="toc-section-number">19.4.1</span> Tukey Test of Additivity</a></li>
</ul></li>
<li><a href="nested-designs.html#nested-designs" id="toc-nested-designs"><span class="toc-section-number">19.5</span> Nested Designs</a>
<ul>
<li><a href="nested-designs.html#two-factor-nested-designs" id="toc-two-factor-nested-designs"><span class="toc-section-number">19.5.1</span> Two-Factor Nested Designs</a></li>
</ul></li>
<li><a href="single-factor-covariance-model.html#single-factor-covariance-model" id="toc-single-factor-covariance-model"><span class="toc-section-number">19.6</span> Single Factor Covariance Model</a></li>
</ul></li>
<li><a href="multivariate-methods.html#multivariate-methods" id="toc-multivariate-methods"><span class="toc-section-number">20</span> Multivariate Methods</a>
<ul>
<li><a href="multivariate-methods.html#properties-of-mvn" id="toc-properties-of-mvn"><span class="toc-section-number">20.0.1</span> Properties of MVN</a></li>
<li><a href="multivariate-methods.html#mean-vector-inference" id="toc-mean-vector-inference"><span class="toc-section-number">20.0.2</span> Mean Vector Inference</a></li>
<li><a href="multivariate-methods.html#general-hypothesis-testing" id="toc-general-hypothesis-testing"><span class="toc-section-number">20.0.3</span> General Hypothesis Testing</a></li>
<li><a href="manova.html#manova" id="toc-manova"><span class="toc-section-number">20.1</span> MANOVA</a>
<ul>
<li><a href="manova.html#testing-general-hypotheses" id="toc-testing-general-hypotheses"><span class="toc-section-number">20.1.1</span> Testing General Hypotheses</a></li>
<li><a href="manova.html#profile-analysis" id="toc-profile-analysis"><span class="toc-section-number">20.1.2</span> Profile Analysis</a></li>
<li><a href="manova.html#summary-5" id="toc-summary-5"><span class="toc-section-number">20.1.3</span> Summary</a></li>
</ul></li>
<li><a href="principal-components.html#principal-components" id="toc-principal-components"><span class="toc-section-number">20.2</span> Principal Components</a>
<ul>
<li><a href="principal-components.html#population-principal-components" id="toc-population-principal-components"><span class="toc-section-number">20.2.1</span> Population Principal Components</a></li>
<li><a href="principal-components.html#sample-principal-components" id="toc-sample-principal-components"><span class="toc-section-number">20.2.2</span> Sample Principal Components</a></li>
<li><a href="principal-components.html#application-10" id="toc-application-10"><span class="toc-section-number">20.2.3</span> Application</a></li>
</ul></li>
<li><a href="factor-analysis.html#factor-analysis" id="toc-factor-analysis"><span class="toc-section-number">20.3</span> Factor Analysis</a>
<ul>
<li><a href="factor-analysis.html#methods-of-estimation" id="toc-methods-of-estimation"><span class="toc-section-number">20.3.1</span> Methods of Estimation</a></li>
<li><a href="factor-analysis.html#factor-rotation" id="toc-factor-rotation"><span class="toc-section-number">20.3.2</span> Factor Rotation</a></li>
<li><a href="factor-analysis.html#estimation-of-factor-scores" id="toc-estimation-of-factor-scores"><span class="toc-section-number">20.3.3</span> Estimation of Factor Scores</a></li>
<li><a href="factor-analysis.html#model-diagnostic" id="toc-model-diagnostic"><span class="toc-section-number">20.3.4</span> Model Diagnostic</a></li>
<li><a href="factor-analysis.html#application-11" id="toc-application-11"><span class="toc-section-number">20.3.5</span> Application</a></li>
</ul></li>
<li><a href="discriminant-analysis.html#discriminant-analysis" id="toc-discriminant-analysis"><span class="toc-section-number">20.4</span> Discriminant Analysis</a>
<ul>
<li><a href="discriminant-analysis.html#known-populations" id="toc-known-populations"><span class="toc-section-number">20.4.1</span> Known Populations</a></li>
<li><a href="discriminant-analysis.html#probabilities-of-misclassification" id="toc-probabilities-of-misclassification"><span class="toc-section-number">20.4.2</span> Probabilities of Misclassification</a></li>
<li><a href="discriminant-analysis.html#unknown-populations-nonparametric-discrimination" id="toc-unknown-populations-nonparametric-discrimination"><span class="toc-section-number">20.4.3</span> Unknown Populations/ Nonparametric Discrimination</a></li>
<li><a href="discriminant-analysis.html#application-12" id="toc-application-12"><span class="toc-section-number">20.4.4</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="#part-b.-quasi-experimental-design" id="toc-part-b.-quasi-experimental-design">(PART*) B. QUASI-EXPERIMENTAL DESIGN</a></li>
<li><a href="quasi-experimental.html#quasi-experimental" id="toc-quasi-experimental"><span class="toc-section-number">21</span> Quasi-experimental</a></li>
<li><a href="regression-discontinuity.html#regression-discontinuity" id="toc-regression-discontinuity"><span class="toc-section-number">22</span> Regression Discontinuity</a>
<ul>
<li><a href="specification-checks.html#specification-checks" id="toc-specification-checks"><span class="toc-section-number">22.1</span> Specification Checks</a>
<ul>
<li><a href="specification-checks.html#balance-checks" id="toc-balance-checks"><span class="toc-section-number">22.1.1</span> Balance Checks</a></li>
<li><a href="specification-checks.html#sortingbunchingmanipulation" id="toc-sortingbunchingmanipulation"><span class="toc-section-number">22.1.2</span> Sorting/Bunching/Manipulation</a></li>
<li><a href="specification-checks.html#placebo-tests" id="toc-placebo-tests"><span class="toc-section-number">22.1.3</span> Placebo Tests</a></li>
<li><a href="specification-checks.html#sensitivity-to-bandwidth-choice" id="toc-sensitivity-to-bandwidth-choice"><span class="toc-section-number">22.1.4</span> Sensitivity to Bandwidth Choice</a></li>
<li><a href="specification-checks.html#fuzzy-rd-design" id="toc-fuzzy-rd-design"><span class="toc-section-number">22.1.5</span> Fuzzy RD Design</a></li>
<li><a href="specification-checks.html#regression-kink-design" id="toc-regression-kink-design"><span class="toc-section-number">22.1.6</span> Regression Kink Design</a></li>
<li><a href="specification-checks.html#mutli-cutoff-multi-score-geographic-rd" id="toc-mutli-cutoff-multi-score-geographic-rd"><span class="toc-section-number">22.1.7</span> Mutli-cutoff, Multi-score, geographic RD</a></li>
</ul></li>
<li><a href="steps-for-sharp-rd.html#steps-for-sharp-rd" id="toc-steps-for-sharp-rd"><span class="toc-section-number">22.2</span> Steps for Sharp RD</a></li>
<li><a href="steps-for-fuzzy-rd.html#steps-for-fuzzy-rd" id="toc-steps-for-fuzzy-rd"><span class="toc-section-number">22.3</span> Steps for Fuzzy RD</a></li>
<li><a href="steps-for-rdit-regression-discontinuity-in-time.html#steps-for-rdit-regression-discontinuity-in-time" id="toc-steps-for-rdit-regression-discontinuity-in-time"><span class="toc-section-number">22.4</span> Steps for RDiT (Regression Discontinuity in Time)</a></li>
<li><a href="evaluation-of-an-rd.html#evaluation-of-an-rd" id="toc-evaluation-of-an-rd"><span class="toc-section-number">22.5</span> Evaluation of an RD</a></li>
<li><a href="applications.html#applications" id="toc-applications"><span class="toc-section-number">22.6</span> Applications</a>
<ul>
<li><a href="applications.html#example-1-1" id="toc-example-1-1"><span class="toc-section-number">22.6.1</span> Example 1</a></li>
<li><a href="applications.html#example-2" id="toc-example-2"><span class="toc-section-number">22.6.2</span> Example 2</a></li>
<li><a href="applications.html#example-3" id="toc-example-3"><span class="toc-section-number">22.6.3</span> Example 3</a></li>
<li><a href="applications.html#example-4" id="toc-example-4"><span class="toc-section-number">22.6.4</span> Example 4</a></li>
</ul></li>
</ul></li>
<li><a href="difference-in-differences.html#difference-in-differences" id="toc-difference-in-differences"><span class="toc-section-number">23</span> Difference-in-differences</a>
<ul>
<li><a href="simple-dif-n-dif.html#simple-dif-n-dif" id="toc-simple-dif-n-dif"><span class="toc-section-number">23.1</span> Simple Dif-n-dif</a>
<ul>
<li><a href="simple-dif-n-dif.html#assumptions-2" id="toc-assumptions-2"><span class="toc-section-number">23.1.1</span> Assumptions</a></li>
<li><a href="simple-dif-n-dif.html#examples" id="toc-examples"><span class="toc-section-number">23.1.2</span> Examples</a></li>
</ul></li>
<li><a href="multiple-periods-and-variation-in-treatment-timing.html#multiple-periods-and-variation-in-treatment-timing" id="toc-multiple-periods-and-variation-in-treatment-timing"><span class="toc-section-number">23.2</span> Multiple periods and variation in treatment timing</a></li>
<li><a href="staggered-dif-n-dif.html#staggered-dif-n-dif" id="toc-staggered-dif-n-dif"><span class="toc-section-number">23.3</span> Staggered Dif-n-dif</a>
<ul>
<li><a href="staggered-dif-n-dif.html#example-by-doleac2020" id="toc-example-by-doleac2020"><span class="toc-section-number">23.3.1</span> Example by <span class="citation">Doleac and Hansen (<span>2020</span>)</span></a></li>
</ul></li>
<li><a href="two-way-fixed-effects.html#two-way-fixed-effects" id="toc-two-way-fixed-effects"><span class="toc-section-number">23.4</span> Two-way Fixed-effects</a></li>
</ul></li>
<li><a href="synthetic-control.html#synthetic-control" id="toc-synthetic-control"><span class="toc-section-number">24</span> Synthetic Control</a>
<ul>
<li><a href="synthetic-control.html#example-1-2" id="toc-example-1-2"><span class="toc-section-number">24.0.1</span> Example 1</a></li>
<li><a href="synthetic-control.html#example-2-1" id="toc-example-2-1"><span class="toc-section-number">24.0.2</span> Example 2</a></li>
<li><a href="synthetic-control.html#example-3-1" id="toc-example-3-1"><span class="toc-section-number">24.0.3</span> Example 3</a></li>
<li><a href="synthetic-control.html#example-4-1" id="toc-example-4-1"><span class="toc-section-number">24.0.4</span> Example 4</a></li>
<li><a href="synthetic-difference-in-differences.html#synthetic-difference-in-differences" id="toc-synthetic-difference-in-differences"><span class="toc-section-number">24.1</span> Synthetic Difference-in-differences</a></li>
</ul></li>
<li><a href="event-studies.html#event-studies" id="toc-event-studies"><span class="toc-section-number">25</span> Event Studies</a>
<ul>
<li><a href="other-issues.html#other-issues" id="toc-other-issues"><span class="toc-section-number">25.1</span> Other Issues</a>
<ul>
<li><a href="other-issues.html#economic-significance" id="toc-economic-significance"><span class="toc-section-number">25.1.1</span> Economic significance</a></li>
<li><a href="other-issues.html#statistical-power" id="toc-statistical-power"><span class="toc-section-number">25.1.2</span> Statistical Power</a></li>
<li><a href="other-issues.html#testing" id="toc-testing"><span class="toc-section-number">25.1.3</span> Testing</a></li>
<li><a href="other-issues.html#confounders" id="toc-confounders"><span class="toc-section-number">25.1.4</span> Confounders</a></li>
<li><a href="other-issues.html#biases" id="toc-biases"><span class="toc-section-number">25.1.5</span> Biases</a></li>
<li><a href="other-issues.html#long-run-event-studies" id="toc-long-run-event-studies"><span class="toc-section-number">25.1.6</span> Long-run event studies</a></li>
</ul></li>
<li><a href="aggregation.html#aggregation" id="toc-aggregation"><span class="toc-section-number">25.2</span> Aggregation</a>
<ul>
<li><a href="aggregation.html#over-time" id="toc-over-time"><span class="toc-section-number">25.2.1</span> Over Time</a></li>
<li><a href="aggregation.html#across-firms-over-time" id="toc-across-firms-over-time"><span class="toc-section-number">25.2.2</span> Across Firms + Over Time</a></li>
</ul></li>
<li><a href="heterogeneity-in-the-event-effect.html#heterogeneity-in-the-event-effect" id="toc-heterogeneity-in-the-event-effect"><span class="toc-section-number">25.3</span> Heterogeneity in the event effect</a></li>
<li><a href="expected-return-calculation.html#expected-return-calculation" id="toc-expected-return-calculation"><span class="toc-section-number">25.4</span> Expected Return Calculation</a>
<ul>
<li><a href="expected-return-calculation.html#statistical-models" id="toc-statistical-models"><span class="toc-section-number">25.4.1</span> Statistical Models</a></li>
<li><a href="expected-return-calculation.html#economic-model" id="toc-economic-model"><span class="toc-section-number">25.4.2</span> Economic Model</a></li>
</ul></li>
<li><a href="application-13.html#application-13" id="toc-application-13"><span class="toc-section-number">25.5</span> Application</a></li>
</ul></li>
<li><a href="matching-methods.html#matching-methods" id="toc-matching-methods"><span class="toc-section-number">26</span> Matching Methods</a>
<ul>
<li><a href="matchit.html#matchit" id="toc-matchit"><span class="toc-section-number">26.1</span> MatchIt</a></li>
<li><a href="matchingfrontier.html#matchingfrontier" id="toc-matchingfrontier"><span class="toc-section-number">26.2</span> MatchingFrontier</a></li>
<li><a href="propensity-scores.html#propensity-scores" id="toc-propensity-scores"><span class="toc-section-number">26.3</span> Propensity Scores</a></li>
<li><a href="mahalanobis-distance.html#mahalanobis-distance" id="toc-mahalanobis-distance"><span class="toc-section-number">26.4</span> Mahalanobis Distance</a></li>
<li><a href="coarsened-exact-matching.html#coarsened-exact-matching" id="toc-coarsened-exact-matching"><span class="toc-section-number">26.5</span> Coarsened Exact Matching</a></li>
<li><a href="genetic-matching.html#genetic-matching" id="toc-genetic-matching"><span class="toc-section-number">26.6</span> Genetic Matching</a></li>
<li><a href="matching-for-time-series-cross-section-data.html#matching-for-time-series-cross-section-data" id="toc-matching-for-time-series-cross-section-data"><span class="toc-section-number">26.7</span> Matching for time series-cross-section data</a></li>
</ul></li>
<li><a href="interrupted-time-series.html#interrupted-time-series" id="toc-interrupted-time-series"><span class="toc-section-number">27</span> Interrupted Time Series</a></li>
<li><a href="#part-c.-other-concerns" id="toc-part-c.-other-concerns">(PART*) C. OTHER CONCERNS</a></li>
<li><a href="endogeneity.html#endogeneity" id="toc-endogeneity"><span class="toc-section-number">28</span> Endogeneity</a>
<ul>
<li><a href="measurement-error.html#measurement-error" id="toc-measurement-error"><span class="toc-section-number">28.1</span> Measurement Error</a>
<ul>
<li><a href="measurement-error.html#classical-measurement-errors" id="toc-classical-measurement-errors"><span class="toc-section-number">28.1.1</span> Classical Measurement Errors</a></li>
<li><a href="measurement-error.html#non-classical-measurement-errors" id="toc-non-classical-measurement-errors"><span class="toc-section-number">28.1.2</span> Non-classical Measurement Errors</a></li>
<li><a href="measurement-error.html#solution-to-measurement-errors" id="toc-solution-to-measurement-errors"><span class="toc-section-number">28.1.3</span> Solution to Measurement Errors</a></li>
</ul></li>
<li><a href="simultaneity.html#simultaneity" id="toc-simultaneity"><span class="toc-section-number">28.2</span> Simultaneity</a></li>
<li><a href="endogenous-treatment.html#endogenous-treatment" id="toc-endogenous-treatment"><span class="toc-section-number">28.3</span> Endogenous Treatment</a>
<ul>
<li><a href="endogenous-treatment.html#instrumental-variable" id="toc-instrumental-variable"><span class="toc-section-number">28.3.1</span> Instrumental Variable</a></li>
<li><a href="endogenous-treatment.html#internal-instrumental-variable" id="toc-internal-instrumental-variable"><span class="toc-section-number">28.3.2</span> Internal instrumental variable</a></li>
<li><a href="endogenous-treatment.html#proxy-variables" id="toc-proxy-variables"><span class="toc-section-number">28.3.3</span> Proxy Variables</a></li>
</ul></li>
<li><a href="endogenous-sample-selection.html#endogenous-sample-selection" id="toc-endogenous-sample-selection"><span class="toc-section-number">28.4</span> Endogenous Sample Selection</a>
<ul>
<li><a href="endogenous-sample-selection.html#tobit-2" id="toc-tobit-2"><span class="toc-section-number">28.4.1</span> Tobit-2</a></li>
<li><a href="endogenous-sample-selection.html#tobit-5" id="toc-tobit-5"><span class="toc-section-number">28.4.2</span> Tobit-5</a></li>
</ul></li>
</ul></li>
<li><a href="mediation.html#mediation" id="toc-mediation"><span class="toc-section-number">29</span> Mediation</a>
<ul>
<li><a href="traditional.html#traditional" id="toc-traditional"><span class="toc-section-number">29.1</span> Traditional</a>
<ul>
<li><a href="traditional.html#example-1-mediation-traditional" id="toc-example-1-mediation-traditional"><span class="toc-section-number">29.1.1</span> Example 1</a></li>
</ul></li>
<li><a href="model-based-causal-mediation-analysis.html#model-based-causal-mediation-analysis" id="toc-model-based-causal-mediation-analysis"><span class="toc-section-number">29.2</span> Model-based causal mediation analysis</a></li>
</ul></li>
<li><a href="directed-acyclic-graph.html#directed-acyclic-graph" id="toc-directed-acyclic-graph"><span class="toc-section-number">30</span> Directed Acyclic Graph</a></li>
<li><a href="#part-v.-miscellaneous" id="toc-part-v.-miscellaneous">(PART*) V. MISCELLANEOUS</a></li>
<li><a href="report.html#report" id="toc-report"><span class="toc-section-number">31</span> Report</a>
<ul>
<li><a href="one-summary-table.html#one-summary-table" id="toc-one-summary-table"><span class="toc-section-number">31.1</span> One summary table</a></li>
<li><a href="model-comparison.html#model-comparison" id="toc-model-comparison"><span class="toc-section-number">31.2</span> Model Comparison</a></li>
<li><a href="changes-in-an-estimate.html#changes-in-an-estimate" id="toc-changes-in-an-estimate"><span class="toc-section-number">31.3</span> Changes in an estimate</a></li>
</ul></li>
<li><a href="exploratory-data-analysis.html#exploratory-data-analysis" id="toc-exploratory-data-analysis"><span class="toc-section-number">32</span> Exploratory Data Analysis</a></li>
<li><a href="sensitivity-analysis-robustness-check.html#sensitivity-analysis-robustness-check" id="toc-sensitivity-analysis-robustness-check"><span class="toc-section-number">33</span> Sensitivity Analysis/ Robustness Check</a>
<ul>
<li><a href="specification-curve.html#specification-curve" id="toc-specification-curve"><span class="toc-section-number">33.1</span> Specification curve</a>
<ul>
<li><a href="specification-curve.html#starbility" id="toc-starbility"><span class="toc-section-number">33.1.1</span> starbility</a></li>
<li><a href="specification-curve.html#rdfanalysis" id="toc-rdfanalysis"><span class="toc-section-number">33.1.2</span> rdfanalysis</a></li>
</ul></li>
<li><a href="coefficient-stability.html#coefficient-stability" id="toc-coefficient-stability"><span class="toc-section-number">33.2</span> Coefficient stability</a></li>
</ul></li>
<li><a href="#appendix-appendix" id="toc-appendix-appendix">(APPENDIX) APPENDIX</a></li>
<li><a href="appendix.html#appendix" id="toc-appendix"><span class="toc-section-number">34</span> Appendix</a>
<ul>
<li><a href="git.html#git" id="toc-git"><span class="toc-section-number">34.1</span> Git</a></li>
<li><a href="short-cut.html#short-cut" id="toc-short-cut"><span class="toc-section-number">34.2</span> Short-cut</a></li>
<li><a href="function-short-cut.html#function-short-cut" id="toc-function-short-cut"><span class="toc-section-number">34.3</span> Function short-cut</a></li>
<li><a href="citation.html#citation" id="toc-citation"><span class="toc-section-number">34.4</span> Citation</a></li>
<li><a href="install-all-necessary-packageslibaries-on-your-local-machine.html#install-all-necessary-packageslibaries-on-your-local-machine" id="toc-install-all-necessary-packageslibaries-on-your-local-machine"><span class="toc-section-number">34.5</span> Install all necessary packages/libaries on your local machine</a></li>
</ul></li>
<li><a href="bookdown-cheat-sheet.html#bookdown-cheat-sheet" id="toc-bookdown-cheat-sheet"><span class="toc-section-number">35</span> Bookdown cheat sheet</a>
<ul>
<li><a href="operation.html#operation" id="toc-operation"><span class="toc-section-number">35.1</span> Operation</a></li>
<li><a href="math-expresssion-syntax.html#math-expresssion-syntax" id="toc-math-expresssion-syntax"><span class="toc-section-number">35.2</span> Math Expresssion/ Syntax</a>
<ul>
<li><a href="math-expresssion-syntax.html#statistics-notation" id="toc-statistics-notation"><span class="toc-section-number">35.2.1</span> Statistics Notation</a></li>
</ul></li>
<li><a href="table.html#table" id="toc-table"><span class="toc-section-number">35.3</span> Table</a></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generalization" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Generalization</h2>
<p>We can see that Poisson regression looks similar to logistic regression. Hence, we can generalize to a class of modeling. Thanks to <span class="citation">(<a href="#ref-Nelder_1972" role="doc-biblioref">Nelder and Wedderburn 1972</a>)</span>, we have the <strong>generalized linear models</strong> (GLMs). Estimation is generalize in these models.</p>
<p><strong>Exponential Family</strong><br />
The theory of GLMs is developed for data with distribution given y the <strong>exponential family</strong>.<br />
The form of the data distribution that is useful for GLMs is</p>
<p><span class="math display">\[
f(y;\theta, \phi) = \exp(\frac{\theta y - b(\theta)}{a(\phi)} + c(y, \phi))
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta\)</span> is called the natural parameter</li>
<li><span class="math inline">\(\phi\)</span> is called the dispersion parameter</li>
</ul>
<p><strong>Note</strong>:</p>
<p>This family includes the <span class="math display">\[Gamma\]</span>, <span class="math display">\[Normal\]</span>, <span class="math display">\[Poisson\]</span>, and other. For all parameterization of the exponential family, check this <a href="https://www.stat.purdue.edu/~tlzhang/stat526/logistic.pdf">link</a></p>
<p><strong>Example</strong></p>
<p>if we have <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
f(y; \mu, \sigma^2) &amp;= \frac{1}{(2\pi \sigma^2)^{1/2}}\exp(-\frac{1}{2\sigma^2}(y- \mu)^2) \\
&amp;= \exp(-\frac{1}{2\sigma^2}(y^2 - 2y \mu +\mu^2)- \frac{1}{2}\log(2\pi \sigma^2)) \\
&amp;= \exp(\frac{y \mu - \mu^2/2}{\sigma^2} - \frac{y^2}{2\sigma^2} - \frac{1}{2}\log(2\pi \sigma^2)) \\
&amp;= \exp(\frac{\theta y - b(\theta)}{a(\phi)} + c(y , \phi))
\end{aligned}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta = \mu\)</span></li>
<li><span class="math inline">\(b(\theta) = \frac{\mu^2}{2}\)</span></li>
<li><span class="math inline">\(a(\phi) = \sigma^2 = \phi\)</span></li>
<li><span class="math inline">\(c(y , \phi) = - \frac{1}{2}(\frac{y^2}{\phi}+\log(2\pi \sigma^2))\)</span></li>
</ul>
<p><strong>Properties of GLM exponential families</strong></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(E(Y) = b&#39; (\theta)\)</span> where <span class="math inline">\(b&#39;(\theta) = \frac{\partial b(\theta)}{\partial \theta}\)</span> (here <code>'</code> is “prime”, not transpose)</p></li>
<li><p><span class="math inline">\(var(Y) = a(\phi)b&#39;&#39;(\theta)= a(\phi)V(\mu)\)</span>.</p>
<ul>
<li><span class="math inline">\(V(\mu)\)</span> is the <em>variance function</em>; however, it is only the variance in the case that <span class="math inline">\(a(\phi) =1\)</span></li>
</ul></li>
<li><p>If <span class="math inline">\(a(), b(), c()\)</span> are identifiable, we will derive expected value and variance of Y.</p></li>
</ol>
<p>Example</p>
<p>Normal distribution</p>
<p><span class="math display">\[
b&#39;(\theta) = \frac{\partial b(\mu^2/2)}{\partial \mu} = \mu \\
V(\mu) = \frac{\partial^2 (\mu^2/2)}{\partial \mu^2} = 1 \\
\to var(Y) = a(\phi) = \sigma^2
\]</span></p>
<p>Poisson distribution</p>
<p><span class="math display">\[
\begin{aligned}
f(y, \theta, \phi) &amp;= \frac{\mu^y \exp(-\mu)}{y!} \\
&amp;= \exp(y\log(\mu) - \mu - \log(y!)) \\
&amp;= \exp(y\theta - \exp(\theta) - \log(y!))
\end{aligned}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta = \log(\mu)\)</span></li>
<li><span class="math inline">\(a(\phi) = 1\)</span></li>
<li><span class="math inline">\(b(\theta) = \exp(\theta)\)</span></li>
<li><span class="math inline">\(c(y, \phi) = \log(y!)\)</span></li>
</ul>
<p>Hence,</p>
<p><span class="math display">\[
E(Y) = \frac{\partial b(\theta)}{\partial \theta} = \exp(\theta) = \mu \\
var(Y) = \frac{\partial^2 b(\theta)}{\partial \theta^2} = \mu
\]</span></p>
<p>Since <span class="math inline">\(\mu = E(Y) = b&#39;(\theta)\)</span></p>
<p>In GLM, we take some monotone function (typically nonlinear) of <span class="math inline">\(\mu\)</span> to be linear in the set of covariates</p>
<p><span class="math display">\[
g(\mu) = g(b&#39;(\theta)) = \mathbf{x&#39;\beta}
\]</span></p>
<p>Equivalently,</p>
<p><span class="math display">\[
\mu = g^{-1}(\mathbf{x&#39;\beta})
\]</span></p>
<p>where <span class="math inline">\(g(.)\)</span> is the <strong>link function</strong> since it links mean response (<span class="math inline">\(\mu = E(Y)\)</span>) and a linear expression of the covariates</p>
<p>Some people use <span class="math inline">\(\eta = \mathbf{x&#39;\beta}\)</span> where <span class="math inline">\(\eta\)</span> = the “linear predictor”</p>
<p><strong>GLM is composed of 2 components</strong></p>
<p>The <strong>random component</strong>:</p>
<ul>
<li><p>is the distribution chosen to model the response variables <span class="math inline">\(Y_1,...,Y_n\)</span></p></li>
<li><p>is specified by the choice fo <span class="math inline">\(a(), b(), c()\)</span> in the exponential form</p></li>
<li><p>Notation:</p>
<ul>
<li>Assume that there are n <strong>independent</strong> response variables <span class="math inline">\(Y_1,...,Y_n\)</span> with densities<br />
<span class="math display">\[
f(y_i ; \theta_i, \phi) = \exp(\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi))
\]</span> notice each observation might have different densities</li>
<li>Assume that <span class="math inline">\(\phi\)</span> is constant for all <span class="math inline">\(i = 1,...,n\)</span>, but <span class="math inline">\(\theta_i\)</span> will vary. <span class="math inline">\(\mu_i = E(Y_i)\)</span> for all i.</li>
</ul></li>
</ul>
<p>The <strong>systematic component</strong></p>
<ul>
<li><p>is the portion of the model that gives the relation between <span class="math inline">\(\mu\)</span> and the covariates <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>consists of 2 parts:</p>
<ul>
<li>the <em>link</em> function, <span class="math inline">\(g(.)\)</span></li>
<li>the <em>linear predictor</em>, <span class="math inline">\(\eta = \mathbf{x&#39;\beta}\)</span></li>
</ul></li>
<li><p>Notation:</p>
<ul>
<li>assume <span class="math inline">\(g(\mu_i) = \mathbf{x&#39;\beta} = \eta_i\)</span> where <span class="math inline">\(\mathbf{\beta} = (\beta_1,..., \beta_p)&#39;\)</span></li>
<li>The parameters to be estimated are <span class="math inline">\(\beta_1,...\beta_p , \phi\)</span></li>
</ul></li>
</ul>
<p><strong>The Canonical Link</strong></p>
<p>To choose <span class="math inline">\(g(.)\)</span>, we can use <strong>canonical link function</strong> (Remember: Canonical link is just a special case of the link function)</p>
<p>If the link function <span class="math inline">\(g(.)\)</span> is such <span class="math inline">\(g(\mu_i) = \eta_i = \theta_i\)</span>, the natural parameter, then <span class="math inline">\(g(.)\)</span> is the canonical link.</p>
<p><img src="images/GLM.PNG" width="90%" style="display: block; margin: auto;" /></p>
<ul>
<li><span class="math inline">\(b(\theta)\)</span> = cumulant moment generating function</li>
<li><span class="math inline">\(g(\mu)\)</span> is the link function, which relates the linear predictor to the mean and is required to be monotone increasing, continuously differentiable and invertible.</li>
</ul>
<p>Equivalently, we can think of canonical link function as</p>
<p><span class="math display">\[
\gamma^{-1} \circ g^{-1} = I
\]</span> which is the identity. Hence,</p>
<p><span class="math display">\[
\theta = \eta
\]</span></p>
<p><strong>The inverse link</strong></p>
<p><span class="math inline">\(g^{-1}(.)\)</span> is also known as the mean function, take linear predictor output (ranging from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>) and transform it into a different scale.</p>
<ul>
<li><p><strong>Exponential</strong>: converts <span class="math inline">\(\mathbf{\beta X}\)</span> into a curve that is restricted between 0 and <span class="math inline">\(\infty\)</span> (which you can see that is useful in case you want to convert a linear predictor into a non-negative value). <span class="math inline">\(\lambda = \exp(y) = \mathbf{\beta X}\)</span></p></li>
<li><p><strong>Inverse Logit</strong> (also known as logistic): converts <span class="math inline">\(\mathbf{\beta X}\)</span> into a curve that is restricted between 0 and 1, which is useful in case you want to convert a linear predictor to a probability. <span class="math inline">\(\theta = \frac{1}{1 + \exp(-y)} = \frac{1}{1 + \exp(- \mathbf{\beta X})}\)</span></p>
<ul>
<li><span class="math inline">\(y\)</span> = linear predictor value</li>
<li><span class="math inline">\(\theta\)</span> = transformed value</li>
</ul></li>
</ul>
<p>The <strong>identity link</strong> is that</p>
<p><span class="math display">\[
\eta_i = g(\mu_i) = \mu_i \\
\mu_i = g^{-1}(\eta_i) = \eta_i
\]</span></p>
<p><img src="images/2-Table15.1-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Table 15.1 Generalized Linear Models 15.1 the Structure of Generalized Linear Models</p>
<p>More example on the link functions and their inverses can be found on <a href="https://www.sagepub.com/sites/default/files/upm-binaries/21121_Chapter_15.pdf">page 380</a></p>
<p>Example</p>
<p>Normal random component</p>
<ul>
<li><p>Mean Response: <span class="math inline">\(\mu_i = \theta_i\)</span></p></li>
<li><p>Canonical Link: <span class="math inline">\(g( \mu_i) = \mu_i\)</span> (the identity link)</p></li>
</ul>
<p>Binomial random component</p>
<ul>
<li><p>Mean Response: <span class="math inline">\(\mu_i = \frac{n_i \exp( \theta)}{1+\exp (\theta_i)}\)</span> and <span class="math inline">\(\theta(\mu_i) = \log(\frac{p_i }{1-p_i}) = \log (\frac{\mu_i} {n_i - \mu_i})\)</span></p></li>
<li><p>Canonical link: <span class="math inline">\(g(\mu_i) = \log(\frac{\mu_i} {n_i - \mu_i})\)</span> (logit link)</p></li>
</ul>
<p>Poisson random component</p>
<ul>
<li><p>Mean Response: <span class="math inline">\(\mu_i = \exp(\theta_i)\)</span></p></li>
<li><p>Canonical Link: <span class="math inline">\(g(\mu_i) = \log(\mu_i)\)</span></p></li>
</ul>
<p>Gamma random component:</p>
<ul>
<li><p>Mean response: <span class="math inline">\(\mu_i = -\frac{1}{\theta_i}\)</span> and <span class="math inline">\(\theta(\mu_i) = - \mu_i^{-1}\)</span></p></li>
<li><p>Canonical Link: <span class="math inline">\(g(\mu\_i) = - \frac{1}{\mu_i}\)</span></p></li>
</ul>
<p>Inverse Gaussian random</p>
<ul>
<li>Canonical Link: <span class="math inline">\(g(\mu_i) = \frac{1}{\mu_i^2}\)</span></li>
</ul>
<div id="estimation-1" class="section level3" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Estimation</h3>
<ul>
<li>MLE for parameters of the <strong>systematic component (</strong><span class="math inline">\(\beta\)</span>)<br />
</li>
<li>Unification of derivation and computation (thanks to the exponential forms)<br />
</li>
<li>No unification for estimation of the dispersion parameter (<span class="math inline">\(\phi\)</span>)</li>
</ul>
<div id="estimation-of-beta" class="section level4" number="7.7.1.1">
<h4><span class="header-section-number">7.7.1.1</span> Estimation of <span class="math inline">\(\beta\)</span></h4>
<p>We have</p>
<p><span class="math display">\[
f(y_i ; \theta_i, \phi) = \exp(\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi)) \\
E(Y_i) = \mu_i = b&#39;(\theta) \\
var(Y_i) = b&#39;&#39;(\theta)a(\phi) = V(\mu_i)a(\phi) \\
g(\mu_i) = \mathbf{x}_i&#39;\beta = \eta_i
\]</span></p>
<p>If the log-likelihood for a single observation is <span class="math inline">\(l_i (\beta,\phi)\)</span>. The log-likelihood for all n observations is</p>
<p><span class="math display">\[
\begin{aligned}
l(\beta,\phi) &amp;= \sum_{i=1}^n l_i (\beta,\phi) \\
&amp;= \sum_{i=1}^n (\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi))
\end{aligned}
\]</span></p>
<p>Using MLE to find <span class="math inline">\(\beta\)</span>, we use the chain rule to get the derivatives</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l_i (\beta,\phi)}{\partial \beta_j} &amp;=  \frac{\partial l_i (\beta, \phi)}{\partial \theta_i} \times \frac{\partial \theta_i}{\partial \mu_i} \times \frac{\partial \mu_i}{\partial \eta_i}\times \frac{\partial \eta_i}{\partial \beta_j} \\
&amp;= \sum_{i=1}^{n}(\frac{ y_i - \mu_i}{a(\phi)} \times \frac{1}{V(\mu_i)} \times \frac{\partial \mu_i}{\partial \eta_i} \times x_{ij})
\end{aligned}
\]</span></p>
<p>If we let</p>
<p><span class="math display">\[
w_i \equiv ((\frac{\partial \eta_i}{\partial \mu_i})^2 V(\mu_i))^{-1}
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\frac{\partial l_i (\beta,\phi)}{\partial \beta_j} = \sum_{i=1}^n (\frac{y_i \mu_i}{a(\phi)} \times w_i \times \frac{\partial \eta_i}{\partial \mu_i} \times x_{ij})
\]</span></p>
<p>We can also get the second derivatives using the chain rule.</p>
<p>Example:</p>
<p>For the <span class="math display">\[Newton-Raphson\]</span> algorithm, we need</p>
<p><span class="math display">\[
- E(\frac{\partial^2 l(\beta,\phi)}{\partial \beta_j \partial \beta_k})
\]</span></p>
<p>where <span class="math inline">\((j,k)\)</span>th element of the <strong>Fisher information matrix</strong> <span class="math inline">\(\mathbf{I}(\beta)\)</span></p>
<p>Hence,</p>
<p><span class="math display">\[
- E(\frac{\partial^2 l(\beta,\phi)}{\partial \beta_j \partial \beta_k}) = \sum_{i=1}^n \frac{w_i}{a(\phi)}x_{ij}x_{ik}
\]</span></p>
<p>for the (j,k)th element</p>
<p>If Bernoulli model with logit link function (which is the canonical link)</p>
<p><span class="math display">\[
b(\theta) = \log(1 + \exp(\theta)) = \log(1 + \exp(\mathbf{x&#39;\beta})) \\
a(\phi) = 1  \\
c(y_i, \phi) = 0 \\
E(Y) = b&#39;(\theta) = \frac{\exp(\theta)}{1 + \exp(\theta)} = \mu = p \\
\eta = g(\mu) = \log(\frac{\mu}{1-\mu}) = \theta = \log(\frac{p}{1-p}) = \mathbf{x&#39;\beta}
\]</span></p>
<p>For <span class="math inline">\(Y_i\)</span>, i = 1,.., the log-likelihood is</p>
<p><span class="math display">\[
l_i (\beta, \phi) = \frac{y_i \theta_i - b(\theta_i)}{a(\phi)} + c(y_i, \phi) = y_i \mathbf{x}&#39;_i \beta - \log(1+ \exp(\mathbf{x&#39;\beta}))
\]</span></p>
<p>Additionally,</p>
<p><span class="math display">\[
V(\mu_i) = \mu_i(1-\mu_i)= p_i (1-p_i) \\
\frac{\partial \mu_i}{\partial \eta_i} = p_i(1-p_i)
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l(\beta, \phi)}{\partial \beta_j} &amp;= \sum_{i=1}^n[\frac{y_i - \mu_i}{a(\phi)} \times \frac{1}{V(\mu_i)}\times \frac{\partial \mu_i}{\partial \eta_i} \times x_{ij}] \\
&amp;= \sum_{i=1}^n (y_i - p_i) \times \frac{1}{p_i(1-p_i)} \times p_i(1-p_i) \times x_{ij} \\
&amp;= \sum_{i=1}^n (y_i - p_i) x_{ij} \\
&amp;= \sum_{i=1}^n (y_i - \frac{\exp(\mathbf{x&#39;_i\beta})}{1+ \exp(\mathbf{x&#39;_i\beta})})x_{ij}
\end{aligned}
\]</span></p>
<p>then</p>
<p><span class="math display">\[
w_i = ((\frac{\partial \eta_i}{\partial \mu_i})^2 V(\mu_i))^{-1} = p_i (1-p_i)
\]</span></p>
<p><span class="math display">\[
\mathbf{I}_{jk}(\mathbf{\beta}) = \sum_{i=1}^n \frac{w_i}{a(\phi)} x_{ij}x_{ik} = \sum_{i=1}^n p_i (1-p_i)x_{ij}x_{ik}
\]</span></p>
<p>The <strong>Fisher-scoring</strong> algorithm for the MLE of <span class="math inline">\(\mathbf{\beta}\)</span> is</p>
<p><span class="math display">\[
\left(
\begin{array}
{c}
\beta_1 \\
\beta_2 \\
. \\
. \\
. \\
\beta_p \\
\end{array}
\right)^{(m+1)}
=
\left(
\begin{array}
{c}
\beta_1 \\
\beta_2 \\
. \\
. \\
. \\
\beta_p \\
\end{array}
\right)^{(m)} +
\mathbf{I}^{-1}(\mathbf{\beta})
\left(
\begin{array}
{c}
\frac{\partial l (\beta, \phi)}{\partial \beta_1} \\
\frac{\partial l (\beta, \phi)}{\partial \beta_2} \\
. \\
. \\
. \\
\frac{\partial l (\beta, \phi)}{\partial \beta_p} \\
\end{array}
\right)|_{\beta = \beta^{(m)}}
\]</span></p>
<p>Similar to <span class="math display">\[Newton-Raphson\]</span> expect the matrix of second derivatives by the expected value of the second derivative matrix.</p>
<p>In matrix notation,</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l }{\partial \beta} &amp;= \frac{1}{a(\phi)}\mathbf{X&#39;W\Delta(y - \mu)} \\
&amp;= \frac{1}{a(\phi)}\mathbf{F&#39;V^{-1}(y - \mu)} \\
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\mathbf{I}(\beta) = \frac{1}{a(\phi)}\mathbf{X&#39;WX} = \frac{1}{a(\phi)}\mathbf{F&#39;V^{-1}F} \\
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{X}\)</span> is an n x p matrix of covariates</li>
<li><span class="math inline">\(\mathbf{W}\)</span> is an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(w_i\)</span></li>
<li><span class="math inline">\(\mathbf{\Delta}\)</span> an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(\frac{\partial \eta_i}{\partial \mu_i}\)</span></li>
<li><span class="math inline">\(\mathbf{F} = \mathbf{\frac{\partial \mu}{\partial \beta}}\)</span> an n x p matrix with ith row <span class="math inline">\(\frac{\partial \mu_i}{\partial \beta} = (\frac{\partial \mu_i}{\partial \eta_i})\mathbf{x}&#39;_i\)</span></li>
<li><span class="math inline">\(\mathbf{V}\)</span> an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(V(\mu_i)\)</span></li>
</ul>
<p>Setting the derivative of the log-likelihood equal to 0, ML estimating equations are</p>
<p><span class="math display">\[
\mathbf{F&#39;V^{-1}y= F&#39;V^{-1}\mu}
\]</span></p>
<p>where all components of this equation expect y depends on the parameters <span class="math inline">\(\beta\)</span></p>
<p><strong>Special Cases</strong></p>
<p>If one has a canonical link, the estimating equations reduce to</p>
<p><span class="math display">\[
\mathbf{X&#39;y= X&#39;\mu}
\]</span></p>
<p>If one has an identity link, then</p>
<p><span class="math display">\[
\mathbf{X&#39;V^{-1}y = X&#39;V^{-1}X\hat{\beta}}
\]</span></p>
<p>which gives the generalized least squares estimator</p>
<p>Generally, we can rewrite the Fisher-scoring algorithm as</p>
<p><span class="math display">\[
\beta^{(m+1)} = \beta^{(m)} + \mathbf{(\hat{F}&#39;\hat{V}^{-1}\hat{F})^{-1}\hat{F}&#39;\hat{V}^{-1}(y- \hat{\mu})}
\]</span></p>
<p>Since <span class="math inline">\(\hat{F},\hat{V}, \hat{\mu}\)</span> depend on <span class="math inline">\(\beta\)</span>, we evaluate at <span class="math inline">\(\beta^{(m)}\)</span></p>
<p>From starting values <span class="math inline">\(\beta^{(0)}\)</span>, we can iterate until convergence.</p>
<p>Notes:</p>
<ul>
<li>if <span class="math inline">\(a(\phi)\)</span> is a constant or of the form <span class="math inline">\(m_i \phi\)</span> with known <span class="math inline">\(m_i\)</span>, then <span class="math inline">\(\phi\)</span> cancels.</li>
</ul>
</div>
<div id="estimation-of-phi" class="section level4" number="7.7.1.2">
<h4><span class="header-section-number">7.7.1.2</span> Estimation of <span class="math inline">\(\phi\)</span></h4>
<p>2 approaches:</p>
<ol style="list-style-type: decimal">
<li>MLE</li>
</ol>
<p><span class="math display">\[
\frac{\partial l_i}{\partial \phi} = \frac{(\theta_i y_i - b(\theta_i)a&#39;(\phi))}{a^2(\phi)} + \frac{\partial c(y_i,\phi)}{\partial \phi}
\]</span></p>
<p>the MLE of <span class="math inline">\(\phi\)</span> solves</p>
<p><span class="math display">\[
\frac{a^2(\phi)}{a&#39;(\phi)}\sum_{i=1}^n \frac{\partial c(y_i, \phi)}{\partial \phi} = \sum_{i=1}^n(\theta_i y_i - b(\theta_i))
\]</span></p>
<ul>
<li><p>Situation others than normal error case, expression for <span class="math inline">\(\frac{\partial c(y,\phi)}{\partial \phi}\)</span> are not simple</p></li>
<li><p>Even for the canonical link and <span class="math inline">\(a(\phi)\)</span> constant, there is no nice general expression for <span class="math inline">\(-E(\frac{\partial^2 l}{\partial \phi^2})\)</span>, so the unification GLMs provide for estimation of <span class="math inline">\(\beta\)</span> breaks down for <span class="math inline">\(\phi\)</span></p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>Moment Estimation (“Bias Corrected <span class="math inline">\(\chi^2\)</span>”)</p>
<ul>
<li>The MLE is not conventional approach to estimation of <span class="math inline">\(\phi\)</span> in GLMS.</li>
<li>For the exponential family <span class="math inline">\(var(Y) =V(\mu)a(\phi)\)</span>. This implies<br />
<span class="math display">\[
a(\phi) = \frac{var(Y)}{V(\mu)} = \frac{E(Y- \mu)^2}{V(\mu)} \\
a(\hat{\phi})  = \frac{1}{n-p} \sum_{i=1}^n \frac{(y_i -\hat{\mu}_i)^2}{V(\hat{\mu})}
\]</span> where p is the dimension of <span class="math inline">\(\beta\)</span></li>
<li>GLM with canonical link function <span class="math inline">\(g(.)= (b&#39;(.))^{-1}\)</span><br />
<span class="math display">\[
g(\mu) = \theta = \eta = \mathbf{x&#39;\beta} \\
\mu = g^{-1}(\eta)= b&#39;(\eta)
\]</span></li>
<li>so the method estimator for <span class="math inline">\(a(\phi)=\phi\)</span> is</li>
</ul></li>
</ol>
<p><span class="math display">\[
\hat{\phi} = \frac{1}{n-p} \sum_{i=1}^n \frac{(y_i - g^{-1}(\hat{\eta}_i))^2}{V(g^{-1}(\hat{\eta}_i))}
\]</span></p>
</div>
</div>
<div id="inference-2" class="section level3" number="7.7.2">
<h3><span class="header-section-number">7.7.2</span> Inference</h3>
<p>We have</p>
<p><span class="math display">\[
\hat{var}(\beta) = a(\phi)(\mathbf{\hat{F}&#39;\hat{V}\hat{F}})^{-1}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{V}\)</span> is an n x n diagonal matrix with diagonal elements given by <span class="math inline">\(V(\mu_i)\)</span></li>
<li><span class="math inline">\(\mathbf{F}\)</span> is an n x p matrix given by <span class="math inline">\(\mathbf{F} = \frac{\partial \mu}{\partial \beta}\)</span></li>
<li>Both <span class="math inline">\(\mathbf{V,F}\)</span> are dependent on the mean <span class="math inline">\(\mu\)</span>, and thus <span class="math inline">\(\beta\)</span>. Hence, their estimates (<span class="math inline">\(\mathbf{\hat{V},\hat{F}}\)</span>) depend on <span class="math inline">\(\hat{\beta}\)</span>.</li>
</ul>
<p><span class="math display">\[
H_0: \mathbf{L\beta = d}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{L}\)</span> is a q x p matrix with a <strong>Wald</strong> test</p>
<p><span class="math display">\[
W = \mathbf{(L \hat{\beta}-d)&#39;(a(\phi)L(\hat{F}&#39;\hat{V}^{-1}\hat{F})L&#39;)^{-1}(L \hat{\beta}-d)}
\]</span></p>
<p>which follows <span class="math inline">\(\chi_q^2\)</span> distribution (asymptotically), where q is the rank of <span class="math inline">\(\mathbf{L}\)</span></p>
<p>In the simple case <span class="math inline">\(H_0: \beta_j = 0\)</span> gives <span class="math inline">\(W = \frac{\hat{\beta}^2_j}{\hat{var}(\hat{\beta}_j)} \sim \chi^2_1\)</span> asymptotically</p>
<p>Likelihood ratio test</p>
<p><span class="math display">\[
\Lambda = 2 (l(\hat{\beta}_f)-l(\hat{\beta}_r)) \sim \chi^2_q
\]</span></p>
<p>where</p>
<ul>
<li>q is the number of constraints used to fit the reduced model <span class="math inline">\(\hat{\beta}_r\)</span>, and <span class="math inline">\(\hat{\beta}_r\)</span> is the fit under the full model.</li>
</ul>
<p>Wald test is easier to implement, but likelihood ratio test is better (especially for small samples).</p>
</div>
<div id="deviance" class="section level3" number="7.7.3">
<h3><span class="header-section-number">7.7.3</span> Deviance</h3>
<p><a href="generalization.html#deviance">Deviance</a> is necessary for goodness of fit, inference and for alternative estimation of the dispersion parameter. We define and consider <a href="generalization.html#deviance">Deviance</a> from a likelihood ratio perspective.</p>
<ul>
<li><p>Assume that <span class="math inline">\(\phi\)</span> is known. Let <span class="math inline">\(\tilde{\theta}\)</span> denote the full and <span class="math inline">\(\hat{\theta}\)</span> denote the reduced model MLEs. Then, the likelihood ratio (2 times the difference in log-likelihoods) is <span class="math display">\[
2\sum_{i=1}^{n} \frac{y_i (\tilde{\theta}_i- \hat{\theta}_i)-b(\tilde{\theta}_i) + b(\hat{\theta}_i)}{a_i(\phi)}
\]</span></p></li>
<li><p>For exponential families, <span class="math inline">\(\mu = E(y) = b&#39;(\theta)\)</span>, so the natural parameter is a function of <span class="math inline">\(\mu: \theta = \theta(\mu) = b&#39;^{-1}(\mu)\)</span>, and the likelihood ratio turns into<br />
<span class="math display">\[
2 \sum_{i=1}^m \frac{y_i\{\theta(\tilde{\mu}_i - \theta(\hat{\mu}_i)\} - b(\theta(\tilde{\mu}_i)) + b(\theta(\hat{\mu}_i))}{a_i(\phi)}
\]</span></p></li>
<li><p>Comparing a fitted model to “the fullest possible model”, which is the <strong>saturated model</strong>: <span class="math inline">\(\tilde{\mu}_i = y_i\)</span>, i = 1,..,n. If <span class="math inline">\(\tilde{\theta}_i^* = \theta(y_i), \hat{\theta}_i^* = \theta (\hat{\mu})\)</span>, the likelihood ratio is<br />
<span class="math display">\[
2 \sum_{i=1}^{n} \frac{y_i (\tilde{\theta}_i^* - \hat{\theta}_i^* + b(\hat{\theta}_i^*))}{a_i(\phi)}
\]</span></p></li>
<li><p><span class="citation">(<a href="#ref-McCullagh_2019" role="doc-biblioref">McCullagh and Nelder 2019</a>)</span> specify <span class="math inline">\(a(\phi) = \phi\)</span>, then the likelihood ratio can be written as<br />
<span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) = \frac{2}{\phi}\sum_{i=1}^n\{y_i (\tilde{\theta}_i^*- \hat{\theta}_i^*)- b(\tilde{\theta}_i^*) +b(\hat{\theta}_i^*)  \}  
\]</span> where</p></li>
<li><p><span class="math inline">\(D^*(\mathbf{y, \hat{\mu}})\)</span> = <strong>scaled deviance</strong></p></li>
<li><p><span class="math inline">\(D(\mathbf{y, \hat{\mu}}) = \phi D^*(\mathbf{y, \hat{\mu}})\)</span> = <strong>deviance</strong></p></li>
</ul>
<p><br></p>
<p><strong>Note</strong>:</p>
<ul>
<li><p>in some random component distributions, we can write <span class="math inline">\(a_i(\phi) = \phi m_i\)</span>, where</p>
<ul>
<li><span class="math inline">\(m_i\)</span> is some known scalar that may change with the observations. THen, the scaled deviance components are divided by <span class="math inline">\(m_i\)</span>:<br />
<span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) \equiv 2\sum_{i=1}^n\{y_i (\tilde{\theta}_i^*- \hat{\theta}_i^*)- b(\tilde{\theta}_i^*) +b(\hat{\theta}_i^*)\} / (\phi m_i)  
\]</span></li>
</ul></li>
<li><p><span class="math inline">\(D^*(\mathbf{y, \hat{\mu}}) = \sum_{i=1}^n d_i\)</span>m where <span class="math inline">\(d_i\)</span> is the deviance contribution from the ith observation.</p></li>
<li><p>D is used in model selection</p></li>
<li><p><span class="math inline">\(D^*\)</span> is used in goodness of fit tests (as it is a likelihood ratio statistic). <span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) = 2\{l(\mathbf{y,\tilde{\mu}})-l(\mathbf{y,\hat{\mu}})\}
\]</span></p></li>
<li><p><span class="math inline">\(d_i\)</span> are used to form <strong>deviance residuals</strong></p></li>
</ul>
<p><br></p>
<p><strong>Example</strong>:</p>
<p><br></p>
<p><strong>Normal</strong></p>
<p>We have</p>
<p><span class="math display">\[
\theta = \mu \\
\phi = \sigma^2 \\
b(\theta) = \frac{1}{2} \theta^2 \\
a(\phi) = \phi
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\tilde{\theta}_i = y_i \\
\hat{\theta}_i = \hat{\mu}_i = g^{-1}(\hat{\eta}_i)
\]</span></p>
<p>And</p>
<p><span class="math display">\[
\begin{aligned}
D &amp;= 2 \sum_{1=1}^n Y^2_i - y_i \hat{\mu}_i - \frac{1}{2}y^2_i + \frac{1}{2} \hat{\mu}_i^2 \\
&amp;= \sum_{i=1}^n y_i^2 - 2y_i \hat{\mu}_i + \hat{\mu}_i^2 \\
&amp;= \sum_{i=1}^n (y_i - \hat{\mu}_i)^2
\end{aligned}
\]</span></p>
<p>which is the <strong>residual sum of squares</strong></p>
<p><br></p>
<p><strong>Poisson</strong></p>
<p><span class="math display">\[
f(y) = \exp\{y\log(\mu) - \mu - \log(y!)\} \\
\theta = \log(\mu) \\
b(\theta) = \exp(\theta) \\
a(\phi) = 1 \\
\tilde{\theta}_i = \log(y_i) \\
\hat{\theta}_i = \log(\hat{\mu}_i) \\
\hat{\mu}_i = g^{-1}(\hat{\eta}_i)
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\begin{aligned}
D &amp;= 2 \sum_{i = 1}^n y_i \log(y_i) - y_i \log(\hat{\mu}_i) - y_i + \hat{\mu}_i \\
&amp;= 2 \sum_{i = 1}^n y_i \log(\frac{y_i}{\hat{\mu}_i}) - (y_i - \hat{\mu}_i)
\end{aligned}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
d_i = 2\{y_i \log(\frac{y_i}{\hat{\mu}})- (y_i - \hat{\mu}_i)\}
\]</span></p>
<p><br></p>
<div id="analysis-of-deviance" class="section level4" number="7.7.3.1">
<h4><span class="header-section-number">7.7.3.1</span> Analysis of Deviance</h4>
<p>The difference in deviance between a reduced and full model, where q is the difference in the number of free parameters, has an asymptotic <span class="math inline">\(\chi^2_q\)</span>. The likelihood ratio test</p>
<p><span class="math display">\[
D^*(\mathbf{y;\hat{\mu}_r}) - D^*(\mathbf{y;\hat{\mu}_f}) = 2\{l(\mathbf{y;\hat{\mu}_f})-l(\mathbf{y;\hat{\mu}_r})\}
\]</span></p>
<p>this comparison of models is <strong>Analysis of Deviance</strong>. <a href="generalized-linear-models.html#generalized-linear-models">GLM</a> uses this analysis for model selection.</p>
<p>An estimation of <span class="math inline">\(\phi\)</span> is</p>
<p><span class="math display">\[
\hat{\phi} = \frac{D(\mathbf{y, \hat{\mu}})}{n - p}
\]</span></p>
<p>where p = number of parameters fit.</p>
<p>Excessive use of <span class="math inline">\(\chi^2\)</span> test could be problematic since it is asymptotic <span class="citation">(<a href="#ref-McCullagh_2019" role="doc-biblioref">McCullagh and Nelder 2019</a>)</span></p>
<p><br></p>
</div>
<div id="deviance-residuals" class="section level4" number="7.7.3.2">
<h4><span class="header-section-number">7.7.3.2</span> Deviance Residuals</h4>
<p>We have <span class="math inline">\(D = \sum_{i=1}^{n}d_i\)</span>. Then, we define <strong>deviance residuals</strong></p>
<p><span class="math display">\[
r_{D_i} = \text{sign}(y_i -\hat{\mu}_i)\sqrt{d_i}
\]</span></p>
<p>Standardized version of deviance residuals is</p>
<p><span class="math display">\[
r_{s,i} = \frac{y_i -\hat{\mu}}{\hat{\sigma}(1-h_{ii})^{1/2}}
\]</span></p>
<p>Let <span class="math inline">\(\mathbf{H^{GLM} = W^{1/2}X(X&#39;WX)^{-1}X&#39;W^{-1/2}}\)</span>, where <span class="math inline">\(\mathbf{W}\)</span> is an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(w_i\)</span> (see <a href="generalization.html#estimation-of-beta">Estimation of <span class="math inline">\(\beta\)</span></a>). Then Standardized deviance residuals is equivalently</p>
<p><span class="math display">\[
r_{s, D_i} = \frac{r_{D_i}}{\{\hat{\phi}(1-h_{ii}^{glm}\}^{1/2}}
\]</span></p>
<p>where <span class="math inline">\(h_{ii}^{glm}\)</span> is the ith diagonal of <span class="math inline">\(\mathbf{H}^{GLM}\)</span></p>
<p><br></p>
</div>
<div id="pearson-chi-square-residuals" class="section level4" number="7.7.3.3">
<h4><span class="header-section-number">7.7.3.3</span> Pearson Chi-square Residuals</h4>
<p>Another <span class="math inline">\(\chi^2\)</span> statistic is <strong>Pearson</strong> <span class="math inline">\(\chi^2\)</span> statistics: (assume <span class="math inline">\(m_i = 1\)</span>)</p>
<p><span class="math display">\[
X^2 = \sum_{i=1}^{n} \frac{(y_i - \hat{\mu}_i)^2}{V(\hat{\mu}_i)}
\]</span></p>
<p>where <span class="math inline">\(\hat{\mu}_i\)</span> is the fitted mean response fo the model of interest.</p>
<p>The <strong>Scaled Pearson</strong> <span class="math inline">\(\chi^2\)</span> statistic is given by <span class="math inline">\(\frac{X^2}{\phi} \sim \chi^2_{n-p}\)</span> where p is the number of parameters estimated. Hence, the <strong>Pearson</strong> <span class="math inline">\(\chi^2\)</span> residuals are</p>
<p><span class="math display">\[
X^2_i = \frac{(y_i - \hat{\mu}_i)^2}{V(\hat{\mu}_i)}
\]</span></p>
<p>If we have the following assumptions:</p>
<ul>
<li>Independent samples<br />
</li>
<li>No over-dispersion: If <span class="math inline">\(\phi = 1\)</span>, <span class="math inline">\(\frac{D(\mathbf{y;\hat{\mu}})}{n-p}\)</span> and <span class="math inline">\(\frac{X^2}{n-p}\)</span> have a value substantially larger 1 indicates <strong>improperly specified model</strong> or <strong>overdispersion</strong><br />
</li>
<li>Multiple groups</li>
</ul>
<p>then <span class="math inline">\(\frac{X^2}{\phi}\)</span> and <span class="math inline">\(D^*(\mathbf{y; \hat{\mu}})\)</span> both follow <span class="math inline">\(\chi^2_{n-p}\)</span></p>
<p><br></p>
</div>
</div>
<div id="diagnostic-plots" class="section level3" number="7.7.4">
<h3><span class="header-section-number">7.7.4</span> Diagnostic Plots</h3>
<ul>
<li><p>Standardized residual Plots:</p>
<ul>
<li>plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(\hat{\mu}_i\)</span>) or plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(T(\hat{\mu}_i)\)</span>) where <span class="math inline">\(T(\hat{\mu}_i)\)</span> is transformation(<span class="math inline">\(\hat{\mu}_i\)</span>) called <strong>constant information scale</strong>:<br />
</li>
<li>plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(\hat{\eta}_i\)</span>)</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center">Random Component</th>
<th align="center"><span class="math inline">\(T(\hat{\mu}_i)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Normal</td>
<td align="center"><span class="math inline">\(\hat{\mu}\)</span></td>
</tr>
<tr class="even">
<td align="center">Poisson</td>
<td align="center"><span class="math inline">\(2\sqrt{\mu}\)</span></td>
</tr>
<tr class="odd">
<td align="center">Binomial</td>
<td align="center"><span class="math inline">\(2 \sin^{-1}(\sqrt{\hat{\mu}})\)</span></td>
</tr>
<tr class="even">
<td align="center">Gamma</td>
<td align="center"><span class="math inline">\(2 \log(\hat{\mu})\)</span></td>
</tr>
<tr class="odd">
<td align="center">Inverse Gaussian</td>
<td align="center"><span class="math inline">\(-2\hat{\mu}^{-1/2}\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li><p>If we see:</p>
<ul>
<li>Trend, it means we might have a wrong link function, or choice of scale<br />
</li>
<li>Systematic change in range of residuals with a change in <span class="math inline">\(T(\hat{\mu})\)</span> (incorrect random component) (systematic <span class="math inline">\(\neq\)</span> random)<br />
</li>
</ul></li>
<li><p>plot(<span class="math inline">\(|r_{D_i}|,\hat{\mu}_i\)</span>) to check <strong>Variance Function</strong>.</p></li>
</ul>
</div>
<div id="goodness-of-fit" class="section level3" number="7.7.5">
<h3><span class="header-section-number">7.7.5</span> Goodness of Fit</h3>
<p>To assess goodness of fit, we can use</p>
<ul>
<li><a href="generalization.html#deviance">Deviance</a><br />
</li>
<li><a href="generalization.html#pearson-chi-square-residuals">Pearson Chi-square Residuals</a></li>
</ul>
<p>In nested model, we could use likelihood-based information measures:</p>
<p><span class="math display">\[
AIC = -2l(\mathbf{\hat{\mu}}) + 2p \\
AICC = -2l(\mathbf{\hat{\mu}}) + 2p(\frac{n}{n-p-1}) \\
BIC = 2l(\hat{\mu}) + p \log(n)
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(l(\hat{\mu})\)</span> is the log-likelihood evaluated at the parameter estimates</li>
<li>p is the number of parameters</li>
<li>n is the number of observations.</li>
</ul>
<p>Note: you have to use the same data with the same model (i.e., same link function, same random underlying random distribution). but you can have different number of parameters.</p>
<p>Even though statisticians try to come up with measures that are similar to <span class="math inline">\(R^2\)</span>, in practice, it is not so appropriate. For example, they comapre the log-likelihood of the fitted model against the that of a model with jsut the intercept:</p>
<p><span class="math display">\[
R^2_p = 1 - \frac{l(\hat{\mu})}{l(\hat{\mu}_0)}
\]</span></p>
<p>For certain specific random components such as binary response model, we have **rescaled generalized <span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
\bar{R}^2 = \frac{R^2_*}{\max(R^2_*)} = \frac{1-\exp\{-\frac{2}{n}(l(\hat{\mu}) - l(\hat{\mu}_0) \}}{1 - \exp\{\frac{2}{n}l(\hat{\mu}_0)\}}
\]</span></p>
</div>
<div id="over-dispersion" class="section level3" number="7.7.6">
<h3><span class="header-section-number">7.7.6</span> Over-Dispersion</h3>
<table>
<colgroup>
<col width="20%" />
<col width="29%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Random Components</th>
<th><span class="math inline">\(var(Y)\)</span></th>
<th><span class="math inline">\(V(\mu)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomial</td>
<td><span class="math inline">\(var(Y) = n \mu (1- \mu)\)</span></td>
<td><span class="math inline">\(V(\mu) = \phi n \mu(1- \mu)\)</span> where <span class="math inline">\(m_i =n\)</span></td>
</tr>
<tr class="even">
<td>Poisson</td>
<td><span class="math inline">\(var(Y) = \mu\)</span></td>
<td><span class="math inline">\(V(\mu) = \phi \mu\)</span></td>
</tr>
</tbody>
</table>
<p>In both cases <span class="math inline">\(\phi = 1\)</span>. Recall <span class="math inline">\(b&#39;&#39;(\theta)= V(\mu)\)</span> check <a href="generalization.html#estimation-of-phi">Estimation of <span class="math inline">\(\phi\)</span></a>.</p>
<p>If we find</p>
<ul>
<li><span class="math inline">\(\phi &gt;1\)</span>: over-dispersion (i.e., too much variation for an independent binomial or Poisson distribution).</li>
<li><span class="math inline">\(\phi&lt;1\)</span>: under-dispersion (i.e., too little variation for an independent binomial or Poisson distribution).</li>
</ul>
<p>If we have either over or under-dispersion, it means we might have unspecified random component, we could</p>
<ul>
<li>Select a different random component distribution that can accommodate over or under-dispersion (e.g., negative binomial, Conway-Maxwell Poisson)</li>
<li>use <span class="math display">\[Generalized Linear Mixed Models\]</span><span class="math display">\[Nonlinear and Generalized Linear Mixed Models\]</span> to handle random effects in generalized linear models.</li>
</ul>

</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-McCullagh_2019" class="csl-entry">
McCullagh, P., and J. A. Nelder. 2019. <span>“An Outline of Generalized Linear Models,”</span> January, 21–47. <a href="https://doi.org/10.1201/9780203753736-2">https://doi.org/10.1201/9780203753736-2</a>.
</div>
<div id="ref-Nelder_1972" class="csl-entry">
Nelder, J. A., and R. W. M. Wedderburn. 1972. <span>“Generalized Linear Models.”</span> <em>Journal of the Royal Statistical Society. Series A (General)</em> 135 (3): 370. <a href="https://doi.org/10.2307/2344614">https://doi.org/10.2307/2344614</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multinomial.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-mixed-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/07-generalized-linear-models.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/mikenguyen13/data_analysis/blob/main/07-generalized-linear-models.Rmd",
"text": null
},
"download": ["data_analysis.pdf", "data_analysis.epub", "data_analysis.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": "https://github.com/mikenguyen13/data_analysis/edit/main/%s"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
