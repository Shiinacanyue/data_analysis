<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7.7 Generalization | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct data analysis" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="7.7 Generalization | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/cover.jpg" />
  <meta property="og:description" content="This is a guide on how to conduct data analysis" />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7.7 Generalization | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis" />
  <meta name="twitter:image" content="/images/cover.jpg" />

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2021-10-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="logo.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="multinomial.html"/>
<link rel="next" href="linear-mixed-models.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-8.1.2/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-8.1.2/highcharts.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-3d.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-more.js"></script>
<script src="libs/highcharts-8.1.2/modules/stock.js"></script>
<script src="libs/highcharts-8.1.2/modules/map.js"></script>
<script src="libs/highcharts-8.1.2/modules/annotations.js"></script>
<script src="libs/highcharts-8.1.2/modules/data.js"></script>
<script src="libs/highcharts-8.1.2/modules/drilldown.js"></script>
<script src="libs/highcharts-8.1.2/modules/item-series.js"></script>
<script src="libs/highcharts-8.1.2/modules/offline-exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-8.1.2/modules/exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/export-data.js"></script>
<script src="libs/highcharts-8.1.2/modules/funnel.js"></script>
<script src="libs/highcharts-8.1.2/modules/heatmap.js"></script>
<script src="libs/highcharts-8.1.2/modules/treemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/sankey.js"></script>
<script src="libs/highcharts-8.1.2/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-8.1.2/modules/organization.js"></script>
<script src="libs/highcharts-8.1.2/modules/solid-gauge.js"></script>
<script src="libs/highcharts-8.1.2/modules/streamgraph.js"></script>
<script src="libs/highcharts-8.1.2/modules/sunburst.js"></script>
<script src="libs/highcharts-8.1.2/modules/vector.js"></script>
<script src="libs/highcharts-8.1.2/modules/wordcloud.js"></script>
<script src="libs/highcharts-8.1.2/modules/xrange.js"></script>
<script src="libs/highcharts-8.1.2/modules/tilemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/venn.js"></script>
<script src="libs/highcharts-8.1.2/modules/gantt.js"></script>
<script src="libs/highcharts-8.1.2/modules/timeline.js"></script>
<script src="libs/highcharts-8.1.2/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-8.1.2/modules/bullet.js"></script>
<script src="libs/highcharts-8.1.2/modules/coloraxis.js"></script>
<script src="libs/highcharts-8.1.2/modules/dumbbell.js"></script>
<script src="libs/highcharts-8.1.2/modules/lollipop.js"></script>
<script src="libs/highcharts-8.1.2/modules/series-label.js"></script>
<script src="libs/highcharts-8.1.2/plugins/motion.js"></script>
<script src="libs/highcharts-8.1.2/custom/reset.js"></script>
<script src="libs/highcharts-8.1.2/modules/boost.js"></script>
<script src="libs/highchart-binding-0.8.2/highchart.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DMNX2X65HQ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="2.1" data-path="matrix-theory.html"><a href="matrix-theory.html"><i class="fa fa-check"></i><b>2.1</b> Matrix Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="matrix-theory.html"><a href="matrix-theory.html#rank"><i class="fa fa-check"></i><b>2.1.1</b> Rank</a></li>
<li class="chapter" data-level="2.1.2" data-path="matrix-theory.html"><a href="matrix-theory.html#inverse"><i class="fa fa-check"></i><b>2.1.2</b> Inverse</a></li>
<li class="chapter" data-level="2.1.3" data-path="matrix-theory.html"><a href="matrix-theory.html#definiteness"><i class="fa fa-check"></i><b>2.1.3</b> Definiteness</a></li>
<li class="chapter" data-level="2.1.4" data-path="matrix-theory.html"><a href="matrix-theory.html#matrix-calculus"><i class="fa fa-check"></i><b>2.1.4</b> Matrix Calculus</a></li>
<li class="chapter" data-level="2.1.5" data-path="matrix-theory.html"><a href="matrix-theory.html#optimization"><i class="fa fa-check"></i><b>2.1.5</b> Optimization</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2.2</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="probability-theory.html"><a href="probability-theory.html#axiom-and-theorems-of-probability"><i class="fa fa-check"></i><b>2.2.1</b> Axiom and Theorems of Probability</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-theory.html"><a href="probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.3" data-path="probability-theory.html"><a href="probability-theory.html#random-variable"><i class="fa fa-check"></i><b>2.2.3</b> Random variable</a></li>
<li class="chapter" data-level="2.2.4" data-path="probability-theory.html"><a href="probability-theory.html#moment-generating-function"><i class="fa fa-check"></i><b>2.2.4</b> Moment generating function</a></li>
<li class="chapter" data-level="2.2.5" data-path="probability-theory.html"><a href="probability-theory.html#moment"><i class="fa fa-check"></i><b>2.2.5</b> Moment</a></li>
<li class="chapter" data-level="2.2.6" data-path="probability-theory.html"><a href="probability-theory.html#distributions"><i class="fa fa-check"></i><b>2.2.6</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="general-math.html"><a href="general-math.html"><i class="fa fa-check"></i><b>2.3</b> General Math</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="general-math.html"><a href="general-math.html#law-of-large-numbers"><i class="fa fa-check"></i><b>2.3.1</b> Law of large numbers</a></li>
<li class="chapter" data-level="2.3.2" data-path="general-math.html"><a href="general-math.html#law-of-iterated-expectation"><i class="fa fa-check"></i><b>2.3.2</b> Law of Iterated Expectation</a></li>
<li class="chapter" data-level="2.3.3" data-path="general-math.html"><a href="general-math.html#convergence"><i class="fa fa-check"></i><b>2.3.3</b> Convergence</a></li>
<li class="chapter" data-level="2.3.4" data-path="general-math.html"><a href="general-math.html#sufficient-statistics"><i class="fa fa-check"></i><b>2.3.4</b> Sufficient Statistics</a></li>
<li class="chapter" data-level="2.3.5" data-path="general-math.html"><a href="general-math.html#parameter-transformations"><i class="fa fa-check"></i><b>2.3.5</b> Parameter transformations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>2.4</b> Methods</a></li>
<li class="chapter" data-level="2.5" data-path="data-importexport.html"><a href="data-importexport.html"><i class="fa fa-check"></i><b>2.5</b> Data Import/Export</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="data-importexport.html"><a href="data-importexport.html#medium-size"><i class="fa fa-check"></i><b>2.5.1</b> Medium size</a></li>
<li class="chapter" data-level="2.5.2" data-path="data-importexport.html"><a href="data-importexport.html#large-size"><i class="fa fa-check"></i><b>2.5.2</b> Large size</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>2.6</b> Data Manipulation</a></li>
</ul></li>
<li class="part"><span><b>I BASIC</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-stat.html"><a href="descriptive-stat.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="numerical-measures.html"><a href="numerical-measures.html"><i class="fa fa-check"></i><b>3.1</b> Numerical Measures</a></li>
<li class="chapter" data-level="3.2" data-path="graphical-measures.html"><a href="graphical-measures.html"><i class="fa fa-check"></i><b>3.2</b> Graphical Measures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="graphical-measures.html"><a href="graphical-measures.html#shape"><i class="fa fa-check"></i><b>3.2.1</b> Shape</a></li>
<li class="chapter" data-level="3.2.2" data-path="graphical-measures.html"><a href="graphical-measures.html#scatterplot"><i class="fa fa-check"></i><b>3.2.2</b> Scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="normality-assessment.html"><a href="normality-assessment.html"><i class="fa fa-check"></i><b>3.3</b> Normality Assessment</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="normality-assessment.html"><a href="normality-assessment.html#graphical-assessment"><i class="fa fa-check"></i><b>3.3.1</b> Graphical Assessment</a></li>
<li class="chapter" data-level="3.3.2" data-path="normality-assessment.html"><a href="normality-assessment.html#summary-statistics"><i class="fa fa-check"></i><b>3.3.2</b> Summary Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-statistical-inference.html"><a href="basic-statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>4.1</b> One Sample Inference</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#the-mean"><i class="fa fa-check"></i><b>4.1.1</b> The Mean</a></li>
<li class="chapter" data-level="4.1.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-variance"><i class="fa fa-check"></i><b>4.1.2</b> Single Variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-proportion-p"><i class="fa fa-check"></i><b>4.1.3</b> Single Proportion (p)</a></li>
<li class="chapter" data-level="4.1.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#power"><i class="fa fa-check"></i><b>4.1.4</b> Power</a></li>
<li class="chapter" data-level="4.1.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#sample-size"><i class="fa fa-check"></i><b>4.1.5</b> Sample Size</a></li>
<li class="chapter" data-level="4.1.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#note"><i class="fa fa-check"></i><b>4.1.6</b> Note</a></li>
<li class="chapter" data-level="4.1.7" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-non-parametric-methods"><i class="fa fa-check"></i><b>4.1.7</b> One-sample Non-parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>4.2</b> Two Sample Inference</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#means"><i class="fa fa-check"></i><b>4.2.1</b> Means</a></li>
<li class="chapter" data-level="4.2.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#variances"><i class="fa fa-check"></i><b>4.2.2</b> Variances</a></li>
<li class="chapter" data-level="4.2.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#power-1"><i class="fa fa-check"></i><b>4.2.3</b> Power</a></li>
<li class="chapter" data-level="4.2.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#sample-size-1"><i class="fa fa-check"></i><b>4.2.4</b> Sample Size</a></li>
<li class="chapter" data-level="4.2.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#matched-pair-designs"><i class="fa fa-check"></i><b>4.2.5</b> Matched Pair Designs</a></li>
<li class="chapter" data-level="4.2.6" data-path="two-sample-inference.html"><a href="two-sample-inference.html#nonparametric-tests-for-two-samples"><i class="fa fa-check"></i><b>4.2.6</b> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html"><i class="fa fa-check"></i><b>4.3</b> Categorical Data Analysis</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#inferences-for-small-samples"><i class="fa fa-check"></i><b>4.3.1</b> Inferences for Small Samples</a></li>
<li class="chapter" data-level="4.3.2" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#test-of-association"><i class="fa fa-check"></i><b>4.3.2</b> Test of Association</a></li>
<li class="chapter" data-level="4.3.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-association"><i class="fa fa-check"></i><b>4.3.3</b> Ordinal Association</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II REGRESSION</b></span></li>
<li class="chapter" data-level="5" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>5</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5.1</b> Ordinary Least Squares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#simple-regression-basic-model"><i class="fa fa-check"></i><b>5.1.1</b> Simple Regression (Basic Model)</a></li>
<li class="chapter" data-level="5.1.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="5.1.3" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#ols-assumptions"><i class="fa fa-check"></i><b>5.1.3</b> OLS Assumptions</a></li>
<li class="chapter" data-level="5.1.4" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#theorems"><i class="fa fa-check"></i><b>5.1.4</b> Theorems</a></li>
<li class="chapter" data-level="5.1.5" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#variable-selection"><i class="fa fa-check"></i><b>5.1.5</b> Variable Selection</a></li>
<li class="chapter" data-level="5.1.6" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#diagnostics-1"><i class="fa fa-check"></i><b>5.1.6</b> Diagnostics</a></li>
<li class="chapter" data-level="5.1.7" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#model-validation"><i class="fa fa-check"></i><b>5.1.7</b> Model Validation</a></li>
<li class="chapter" data-level="5.1.8" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#finite-sample-properties"><i class="fa fa-check"></i><b>5.1.8</b> Finite Sample Properties</a></li>
<li class="chapter" data-level="5.1.9" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#large-sample-properties"><i class="fa fa-check"></i><b>5.1.9</b> Large Sample Properties</a></li>
<li class="chapter" data-level="5.1.10" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#application"><i class="fa fa-check"></i><b>5.1.10</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html"><i class="fa fa-check"></i><b>5.2</b> Feasible Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#heteroskedasticity"><i class="fa fa-check"></i><b>5.2.1</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="5.2.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#serial-correlation"><i class="fa fa-check"></i><b>5.2.2</b> Serial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="weighted-least-squares.html"><a href="weighted-least-squares.html"><i class="fa fa-check"></i><b>5.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.4" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5.4</b> Generalized Least Squares</a></li>
<li class="chapter" data-level="5.5" data-path="feasiable-prais-winsten.html"><a href="feasiable-prais-winsten.html"><i class="fa fa-check"></i><b>5.5</b> Feasiable Prais Winsten</a></li>
<li class="chapter" data-level="5.6" data-path="feasible-group-level-random-effects.html"><a href="feasible-group-level-random-effects.html"><i class="fa fa-check"></i><b>5.6</b> Feasible group level Random Effects</a></li>
<li class="chapter" data-level="5.7" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>5.7</b> Ridge Regression</a></li>
<li class="chapter" data-level="5.8" data-path="principal-component-regression.html"><a href="principal-component-regression.html"><i class="fa fa-check"></i><b>5.8</b> Principal Component Regression</a></li>
<li class="chapter" data-level="5.9" data-path="robust-regression.html"><a href="robust-regression.html"><i class="fa fa-check"></i><b>5.9</b> Robust Regression</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="robust-regression.html"><a href="robust-regression.html#least-absolute-residuals-lar-regression"><i class="fa fa-check"></i><b>5.9.1</b> Least Absolute Residuals (LAR) Regression</a></li>
<li class="chapter" data-level="5.9.2" data-path="robust-regression.html"><a href="robust-regression.html#least-median-of-squares-lms-regression"><i class="fa fa-check"></i><b>5.9.2</b> Least Median of Squares (LMS) Regression</a></li>
<li class="chapter" data-level="5.9.3" data-path="robust-regression.html"><a href="robust-regression.html#iteratively-reweighted-least-squares-irls-robust-regression"><i class="fa fa-check"></i><b>5.9.3</b> Iteratively Reweighted Least Squares (IRLS) Robust Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html"><i class="fa fa-check"></i><b>5.10</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#motivation-for-mle"><i class="fa fa-check"></i><b>5.10.1</b> Motivation for MLE</a></li>
<li class="chapter" data-level="5.10.2" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#assumption"><i class="fa fa-check"></i><b>5.10.2</b> Assumption</a></li>
<li class="chapter" data-level="5.10.3" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#properties"><i class="fa fa-check"></i><b>5.10.3</b> Properties</a></li>
<li class="chapter" data-level="5.10.4" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#compare-to-ols"><i class="fa fa-check"></i><b>5.10.4</b> Compare to OLS</a></li>
<li class="chapter" data-level="5.10.5" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#application-1"><i class="fa fa-check"></i><b>5.10.5</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Non-linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference-1.html"><a href="inference-1.html"><i class="fa fa-check"></i><b>6.1</b> Inference</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="inference-1.html"><a href="inference-1.html#linear-function-of-the-parameters"><i class="fa fa-check"></i><b>6.1.1</b> Linear Function of the Parameters</a></li>
<li class="chapter" data-level="6.1.2" data-path="inference-1.html"><a href="inference-1.html#nonlinear"><i class="fa fa-check"></i><b>6.1.2</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html"><i class="fa fa-check"></i><b>6.2</b> Non-linear Least Squares</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#alternative-of-gauss-newton-algorithm"><i class="fa fa-check"></i><b>6.2.1</b> Alternative of Gauss-Newton Algorithm</a></li>
<li class="chapter" data-level="6.2.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#practical-considerations"><i class="fa fa-check"></i><b>6.2.2</b> Practical Considerations</a></li>
<li class="chapter" data-level="6.2.3" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#modelestiamtion-adequcy"><i class="fa fa-check"></i><b>6.2.3</b> Model/Estiamtion Adequcy</a></li>
<li class="chapter" data-level="6.2.4" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#application-2"><i class="fa fa-check"></i><b>6.2.4</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>7.1</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#application-3"><i class="fa fa-check"></i><b>7.1.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probit-regression.html"><a href="probit-regression.html"><i class="fa fa-check"></i><b>7.2</b> Probit Regression</a></li>
<li class="chapter" data-level="7.3" data-path="binomial-regression.html"><a href="binomial-regression.html"><i class="fa fa-check"></i><b>7.3</b> Binomial Regression</a></li>
<li class="chapter" data-level="7.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>7.4</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="poisson-regression.html"><a href="poisson-regression.html#application-4"><i class="fa fa-check"></i><b>7.4.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="negative-binomial-regression.html"><a href="negative-binomial-regression.html"><i class="fa fa-check"></i><b>7.5</b> Negative Binomial Regression</a></li>
<li class="chapter" data-level="7.6" data-path="multinomial.html"><a href="multinomial.html"><i class="fa fa-check"></i><b>7.6</b> Multinomial</a></li>
<li class="chapter" data-level="7.7" data-path="generalization.html"><a href="generalization.html"><i class="fa fa-check"></i><b>7.7</b> Generalization</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="generalization.html"><a href="generalization.html#estimation-1"><i class="fa fa-check"></i><b>7.7.1</b> Estimation</a></li>
<li class="chapter" data-level="7.7.2" data-path="generalization.html"><a href="generalization.html#inference-2"><i class="fa fa-check"></i><b>7.7.2</b> Inference</a></li>
<li class="chapter" data-level="7.7.3" data-path="generalization.html"><a href="generalization.html#deviance"><i class="fa fa-check"></i><b>7.7.3</b> Deviance</a></li>
<li class="chapter" data-level="7.7.4" data-path="generalization.html"><a href="generalization.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.7.4</b> Diagnostic Plots</a></li>
<li class="chapter" data-level="7.7.5" data-path="generalization.html"><a href="generalization.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.7.5</b> Goodness of Fit</a></li>
<li class="chapter" data-level="7.7.6" data-path="generalization.html"><a href="generalization.html#over-dispersion"><i class="fa fa-check"></i><b>7.7.6</b> Over-Dispersion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>8</b> Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dependent-data.html"><a href="dependent-data.html"><i class="fa fa-check"></i><b>8.1</b> Dependent Data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="dependent-data.html"><a href="dependent-data.html#random-intercepts-model"><i class="fa fa-check"></i><b>8.1.1</b> Random-Intercepts Model</a></li>
<li class="chapter" data-level="8.1.2" data-path="dependent-data.html"><a href="dependent-data.html#covariance-models"><i class="fa fa-check"></i><b>8.1.2</b> Covariance Models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="estimation-2.html"><a href="estimation-2.html"><i class="fa fa-check"></i><b>8.2</b> Estimation</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="estimation-2.html"><a href="estimation-2.html#estimating-mathbfv"><i class="fa fa-check"></i><b>8.2.1</b> Estimating <span class="math inline">\(\mathbf{V}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inference-3.html"><a href="inference-3.html"><i class="fa fa-check"></i><b>8.3</b> Inference</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="inference-3.html"><a href="inference-3.html#parameters-beta"><i class="fa fa-check"></i><b>8.3.1</b> Parameters <span class="math inline">\(\beta\)</span></a></li>
<li class="chapter" data-level="8.3.2" data-path="inference-3.html"><a href="inference-3.html#variance-components"><i class="fa fa-check"></i><b>8.3.2</b> Variance Components</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="information-criteria.html"><a href="information-criteria.html"><i class="fa fa-check"></i><b>8.4</b> Information Criteria</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="information-criteria.html"><a href="information-criteria.html#akaikes-information-criteria-aic"><i class="fa fa-check"></i><b>8.4.1</b> Akaike’s Information Criteria (AIC)</a></li>
<li class="chapter" data-level="8.4.2" data-path="information-criteria.html"><a href="information-criteria.html#corrected-aic-aicc"><i class="fa fa-check"></i><b>8.4.2</b> Corrected AIC (AICC)</a></li>
<li class="chapter" data-level="8.4.3" data-path="information-criteria.html"><a href="information-criteria.html#bayesian-information-criteria-bic"><i class="fa fa-check"></i><b>8.4.3</b> Bayesian Information Criteria (BIC)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="split-plot-designs.html"><a href="split-plot-designs.html"><i class="fa fa-check"></i><b>8.5</b> Split-Plot Designs</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="split-plot-designs.html"><a href="split-plot-designs.html#application-5"><i class="fa fa-check"></i><b>8.5.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="repeated-measures-in-mixed-models.html"><a href="repeated-measures-in-mixed-models.html"><i class="fa fa-check"></i><b>8.6</b> Repeated Measures in Mixed Models</a></li>
<li class="chapter" data-level="8.7" data-path="unbalanced-or-unequally-spaced-data.html"><a href="unbalanced-or-unequally-spaced-data.html"><i class="fa fa-check"></i><b>8.7</b> Unbalanced or Unequally Spaced Data</a></li>
<li class="chapter" data-level="8.8" data-path="application-6.html"><a href="application-6.html"><i class="fa fa-check"></i><b>8.8</b> Application</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="application-6.html"><a href="application-6.html#example-1-pulps"><i class="fa fa-check"></i><b>8.8.1</b> Example 1 (Pulps)</a></li>
<li class="chapter" data-level="8.8.2" data-path="application-6.html"><a href="application-6.html#example-2-rats"><i class="fa fa-check"></i><b>8.8.2</b> Example 2 (Rats)</a></li>
<li class="chapter" data-level="8.8.3" data-path="application-6.html"><a href="application-6.html#example-3-agridat"><i class="fa fa-check"></i><b>8.8.3</b> Example 3 (Agridat)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="nonlinear-and-generalized-linear-mixed-models.html"><a href="nonlinear-and-generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>9</b> Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="estimation-3.html"><a href="estimation-3.html"><i class="fa fa-check"></i><b>9.1</b> Estimation</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="estimation-3.html"><a href="estimation-3.html#estimation-by-numerical-integration"><i class="fa fa-check"></i><b>9.1.1</b> Estimation by Numerical Integration</a></li>
<li class="chapter" data-level="9.1.2" data-path="estimation-3.html"><a href="estimation-3.html#estimation-by-linearization"><i class="fa fa-check"></i><b>9.1.2</b> Estimation by Linearization</a></li>
<li class="chapter" data-level="9.1.3" data-path="estimation-3.html"><a href="estimation-3.html#estimation-by-bayesian-hierarchical-models"><i class="fa fa-check"></i><b>9.1.3</b> Estimation by Bayesian Hierarchical Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="application-7.html"><a href="application-7.html"><i class="fa fa-check"></i><b>9.2</b> Application</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="application-7.html"><a href="application-7.html#binomial-cbpp-data"><i class="fa fa-check"></i><b>9.2.1</b> Binomial (CBPP Data)</a></li>
<li class="chapter" data-level="9.2.2" data-path="application-7.html"><a href="application-7.html#count-owl-data"><i class="fa fa-check"></i><b>9.2.2</b> Count (Owl Data)</a></li>
<li class="chapter" data-level="9.2.3" data-path="application-7.html"><a href="application-7.html#binomial-1"><i class="fa fa-check"></i><b>9.2.3</b> Binomial</a></li>
<li class="chapter" data-level="9.2.4" data-path="application-7.html"><a href="application-7.html#example-from-schabenberger_2001-section-8.4.1"><i class="fa fa-check"></i><b>9.2.4</b> Example from <span class="citation">(<span>Schabenberger and Pierce 2001</span>)</span> section 8.4.1</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>9.3</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III RAMIFICATIONS</b></span></li>
<li class="chapter" data-level="10" data-path="model-specification.html"><a href="model-specification.html"><i class="fa fa-check"></i><b>10</b> Model Specification</a>
<ul>
<li class="chapter" data-level="10.1" data-path="nested-model.html"><a href="nested-model.html"><i class="fa fa-check"></i><b>10.1</b> Nested Model</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="nested-model.html"><a href="nested-model.html#chow-test"><i class="fa fa-check"></i><b>10.1.1</b> Chow test</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="non-nested-model.html"><a href="non-nested-model.html"><i class="fa fa-check"></i><b>10.2</b> Non-Nested Model</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="non-nested-model.html"><a href="non-nested-model.html#davidson-mackinnon-test"><i class="fa fa-check"></i><b>10.2.1</b> Davidson-Mackinnon test</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html"><i class="fa fa-check"></i><b>10.3</b> Heteroskedasticity</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#breusch-pagan-test"><i class="fa fa-check"></i><b>10.3.1</b> Breusch-Pagan test</a></li>
<li class="chapter" data-level="10.3.2" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#white-test"><i class="fa fa-check"></i><b>10.3.2</b> White test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="imputation-missing-data.html"><a href="imputation-missing-data.html"><i class="fa fa-check"></i><b>11</b> Imputation (Missing Data)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="assumptions-1.html"><a href="assumptions-1.html"><i class="fa fa-check"></i><b>11.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-completely-at-random-mcar"><i class="fa fa-check"></i><b>11.1.1</b> Missing Completely at Random (MCAR)</a></li>
<li class="chapter" data-level="11.1.2" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-at-random-mar"><i class="fa fa-check"></i><b>11.1.2</b> Missing at Random (MAR)</a></li>
<li class="chapter" data-level="11.1.3" data-path="assumptions-1.html"><a href="assumptions-1.html#ignorable"><i class="fa fa-check"></i><b>11.1.3</b> Ignorable</a></li>
<li class="chapter" data-level="11.1.4" data-path="assumptions-1.html"><a href="assumptions-1.html#nonignorable"><i class="fa fa-check"></i><b>11.1.4</b> Nonignorable</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html"><i class="fa fa-check"></i><b>11.2</b> Solutions to Missing data</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#listwise-deletion"><i class="fa fa-check"></i><b>11.2.1</b> Listwise Deletion</a></li>
<li class="chapter" data-level="11.2.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#pairwise-deletion"><i class="fa fa-check"></i><b>11.2.2</b> Pairwise Deletion</a></li>
<li class="chapter" data-level="11.2.3" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#dummy-variable-adjustment"><i class="fa fa-check"></i><b>11.2.3</b> Dummy Variable Adjustment</a></li>
<li class="chapter" data-level="11.2.4" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#imputation"><i class="fa fa-check"></i><b>11.2.4</b> Imputation</a></li>
<li class="chapter" data-level="11.2.5" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#other-methods"><i class="fa fa-check"></i><b>11.2.5</b> Other methods</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="criteria-for-choosing-an-effective-approach.html"><a href="criteria-for-choosing-an-effective-approach.html"><i class="fa fa-check"></i><b>11.3</b> Criteria for Choosing an Effective Approach</a></li>
<li class="chapter" data-level="11.4" data-path="another-perspective.html"><a href="another-perspective.html"><i class="fa fa-check"></i><b>11.4</b> Another Perspective</a></li>
<li class="chapter" data-level="11.5" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html"><i class="fa fa-check"></i><b>11.5</b> Diagnosing the Mechanism</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mar-vs.-mnar"><i class="fa fa-check"></i><b>11.5.1</b> MAR vs. MNAR</a></li>
<li class="chapter" data-level="11.5.2" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mcar-vs.-mar"><i class="fa fa-check"></i><b>11.5.2</b> MCAR vs. MAR</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="application-8.html"><a href="application-8.html"><i class="fa fa-check"></i><b>11.6</b> Application</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="application-8.html"><a href="application-8.html#imputation-with-mean-median-mode"><i class="fa fa-check"></i><b>11.6.1</b> Imputation with mean / median / mode</a></li>
<li class="chapter" data-level="11.6.2" data-path="application-8.html"><a href="application-8.html#knn"><i class="fa fa-check"></i><b>11.6.2</b> KNN</a></li>
<li class="chapter" data-level="11.6.3" data-path="application-8.html"><a href="application-8.html#rpart"><i class="fa fa-check"></i><b>11.6.3</b> rpart</a></li>
<li class="chapter" data-level="11.6.4" data-path="application-8.html"><a href="application-8.html#mice-multivariate-imputation-via-chained-equations"><i class="fa fa-check"></i><b>11.6.4</b> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li class="chapter" data-level="11.6.5" data-path="application-8.html"><a href="application-8.html#amelia"><i class="fa fa-check"></i><b>11.6.5</b> Amelia</a></li>
<li class="chapter" data-level="11.6.6" data-path="application-8.html"><a href="application-8.html#missforest"><i class="fa fa-check"></i><b>11.6.6</b> missForest</a></li>
<li class="chapter" data-level="11.6.7" data-path="application-8.html"><a href="application-8.html#hmisc"><i class="fa fa-check"></i><b>11.6.7</b> Hmisc</a></li>
<li class="chapter" data-level="11.6.8" data-path="application-8.html"><a href="application-8.html#mi"><i class="fa fa-check"></i><b>11.6.8</b> mi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>12</b> Data</a>
<ul>
<li class="chapter" data-level="12.1" data-path="cross-sectional.html"><a href="cross-sectional.html"><i class="fa fa-check"></i><b>12.1</b> Cross-Sectional</a></li>
<li class="chapter" data-level="12.2" data-path="time-series-1.html"><a href="time-series-1.html"><i class="fa fa-check"></i><b>12.2</b> Time Series</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="time-series-1.html"><a href="time-series-1.html#deterministic-time-trend"><i class="fa fa-check"></i><b>12.2.1</b> Deterministic Time trend</a></li>
<li class="chapter" data-level="12.2.2" data-path="time-series-1.html"><a href="time-series-1.html#feedback-effect"><i class="fa fa-check"></i><b>12.2.2</b> Feedback Effect</a></li>
<li class="chapter" data-level="12.2.3" data-path="time-series-1.html"><a href="time-series-1.html#dynamic-specification"><i class="fa fa-check"></i><b>12.2.3</b> Dynamic Specification</a></li>
<li class="chapter" data-level="12.2.4" data-path="time-series-1.html"><a href="time-series-1.html#dynamically-complete"><i class="fa fa-check"></i><b>12.2.4</b> Dynamically Complete</a></li>
<li class="chapter" data-level="12.2.5" data-path="time-series-1.html"><a href="time-series-1.html#highly-persistent-data"><i class="fa fa-check"></i><b>12.2.5</b> Highly Persistent Data</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html"><i class="fa fa-check"></i><b>12.3</b> Repeated Cross Sections</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html#pooled-cross-section"><i class="fa fa-check"></i><b>12.3.1</b> Pooled Cross Section</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>12.4</b> Panel Data</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="panel-data.html"><a href="panel-data.html#pooled-ols-estimator"><i class="fa fa-check"></i><b>12.4.1</b> Pooled OLS Estimator</a></li>
<li class="chapter" data-level="12.4.2" data-path="panel-data.html"><a href="panel-data.html#individual-specific-effects-model"><i class="fa fa-check"></i><b>12.4.2</b> Individual-specific effects model</a></li>
<li class="chapter" data-level="12.4.3" data-path="panel-data.html"><a href="panel-data.html#tests-for-assumptions"><i class="fa fa-check"></i><b>12.4.3</b> Tests for Assumptions</a></li>
<li class="chapter" data-level="12.4.4" data-path="panel-data.html"><a href="panel-data.html#model-selection"><i class="fa fa-check"></i><b>12.4.4</b> Model Selection</a></li>
<li class="chapter" data-level="12.4.5" data-path="panel-data.html"><a href="panel-data.html#summary-2"><i class="fa fa-check"></i><b>12.4.5</b> Summary</a></li>
<li class="chapter" data-level="12.4.6" data-path="panel-data.html"><a href="panel-data.html#application-9"><i class="fa fa-check"></i><b>12.4.6</b> Application</a></li>
<li class="chapter" data-level="12.4.7" data-path="panel-data.html"><a href="panel-data.html#other-estimators"><i class="fa fa-check"></i><b>12.4.7</b> Other Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>13</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="13.1" data-path="types-of-hypothesis-testing.html"><a href="types-of-hypothesis-testing.html"><i class="fa fa-check"></i><b>13.1</b> Types of hypothesis testing</a></li>
<li class="chapter" data-level="13.2" data-path="wald-test.html"><a href="wald-test.html"><i class="fa fa-check"></i><b>13.2</b> Wald test</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="wald-test.html"><a href="wald-test.html#multiple-hypothesis"><i class="fa fa-check"></i><b>13.2.1</b> Multiple Hypothesis</a></li>
<li class="chapter" data-level="13.2.2" data-path="wald-test.html"><a href="wald-test.html#linear-combination"><i class="fa fa-check"></i><b>13.2.2</b> Linear Combination</a></li>
<li class="chapter" data-level="13.2.3" data-path="wald-test.html"><a href="wald-test.html#application-10"><i class="fa fa-check"></i><b>13.2.3</b> Application</a></li>
<li class="chapter" data-level="13.2.4" data-path="wald-test.html"><a href="wald-test.html#nonlinear-1"><i class="fa fa-check"></i><b>13.2.4</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="the-likelihood-ratio-test.html"><a href="the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>13.3</b> The likelihood ratio test</a></li>
<li class="chapter" data-level="13.4" data-path="lagrange-multiplier-score.html"><a href="lagrange-multiplier-score.html"><i class="fa fa-check"></i><b>13.4</b> Lagrange Multiplier (Score)</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="prediction-and-estimation.html"><a href="prediction-and-estimation.html"><i class="fa fa-check"></i><b>14</b> Prediction and Estimation</a></li>
<li class="part"><span><b>IV EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="15" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>15</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="15.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html"><i class="fa fa-check"></i><b>15.1</b> Completely Randomized Design (CRD)</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model"><i class="fa fa-check"></i><b>15.1.1</b> Single Factor Fixed Effects Model</a></li>
<li class="chapter" data-level="15.1.2" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-random-effects-model"><i class="fa fa-check"></i><b>15.1.2</b> Single Factor Random Effects Model</a></li>
<li class="chapter" data-level="15.1.3" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova"><i class="fa fa-check"></i><b>15.1.3</b> Two Factor Fixed Effect ANOVA</a></li>
<li class="chapter" data-level="15.1.4" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-random-effects-anova"><i class="fa fa-check"></i><b>15.1.4</b> Two-Way Random Effects ANOVA</a></li>
<li class="chapter" data-level="15.1.5" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova"><i class="fa fa-check"></i><b>15.1.5</b> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html"><i class="fa fa-check"></i><b>15.2</b> Nonparametric ANOVA</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#kruskal-wallis"><i class="fa fa-check"></i><b>15.2.1</b> Kruskal-Wallis</a></li>
<li class="chapter" data-level="15.2.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#friedman-test"><i class="fa fa-check"></i><b>15.2.2</b> Friedman Test</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html"><i class="fa fa-check"></i><b>15.3</b> Sample Size Planning for ANOVA</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#balanced-designs"><i class="fa fa-check"></i><b>15.3.1</b> Balanced Designs</a></li>
<li class="chapter" data-level="15.3.2" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#randomized-block-experiments"><i class="fa fa-check"></i><b>15.3.2</b> Randomized Block Experiments</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html"><i class="fa fa-check"></i><b>15.4</b> Randomized Block Designs</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html#tukey-test-of-additivity"><i class="fa fa-check"></i><b>15.4.1</b> Tukey Test of Additivity</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="nested-designs.html"><a href="nested-designs.html"><i class="fa fa-check"></i><b>15.5</b> Nested Designs</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="nested-designs.html"><a href="nested-designs.html#two-factor-nested-designs"><i class="fa fa-check"></i><b>15.5.1</b> Two-Factor Nested Designs</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html"><i class="fa fa-check"></i><b>15.6</b> Single Factor Covariance Model</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="multivariate-methods.html"><a href="multivariate-methods.html"><i class="fa fa-check"></i><b>16</b> Multivariate Methods</a>
<ul>
<li class="chapter" data-level="16.0.1" data-path="multivariate-methods.html"><a href="multivariate-methods.html#properties-of-mvn"><i class="fa fa-check"></i><b>16.0.1</b> Properties of MVN</a></li>
<li class="chapter" data-level="16.0.2" data-path="multivariate-methods.html"><a href="multivariate-methods.html#mean-vector-inference"><i class="fa fa-check"></i><b>16.0.2</b> Mean Vector Inference</a></li>
<li class="chapter" data-level="16.0.3" data-path="multivariate-methods.html"><a href="multivariate-methods.html#general-hypothesis-testing"><i class="fa fa-check"></i><b>16.0.3</b> General Hypothesis Testing</a></li>
<li class="chapter" data-level="16.1" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>16.1</b> MANOVA</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="manova.html"><a href="manova.html#testing-general-hypotheses"><i class="fa fa-check"></i><b>16.1.1</b> Testing General Hypotheses</a></li>
<li class="chapter" data-level="16.1.2" data-path="manova.html"><a href="manova.html#profile-analysis"><i class="fa fa-check"></i><b>16.1.2</b> Profile Analysis</a></li>
<li class="chapter" data-level="16.1.3" data-path="manova.html"><a href="manova.html#summary-4"><i class="fa fa-check"></i><b>16.1.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="principal-components.html"><a href="principal-components.html"><i class="fa fa-check"></i><b>16.2</b> Principal Components</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="principal-components.html"><a href="principal-components.html#population-principal-components"><i class="fa fa-check"></i><b>16.2.1</b> Population Principal Components</a></li>
<li class="chapter" data-level="16.2.2" data-path="principal-components.html"><a href="principal-components.html#sample-principal-components"><i class="fa fa-check"></i><b>16.2.2</b> Sample Principal Components</a></li>
<li class="chapter" data-level="16.2.3" data-path="principal-components.html"><a href="principal-components.html#application-11"><i class="fa fa-check"></i><b>16.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>16.3</b> Factor Analysis</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="factor-analysis.html"><a href="factor-analysis.html#methods-of-estimation"><i class="fa fa-check"></i><b>16.3.1</b> Methods of Estimation</a></li>
<li class="chapter" data-level="16.3.2" data-path="factor-analysis.html"><a href="factor-analysis.html#factor-rotation"><i class="fa fa-check"></i><b>16.3.2</b> Factor Rotation</a></li>
<li class="chapter" data-level="16.3.3" data-path="factor-analysis.html"><a href="factor-analysis.html#estimation-of-factor-scores"><i class="fa fa-check"></i><b>16.3.3</b> Estimation of Factor Scores</a></li>
<li class="chapter" data-level="16.3.4" data-path="factor-analysis.html"><a href="factor-analysis.html#model-diagnostic"><i class="fa fa-check"></i><b>16.3.4</b> Model Diagnostic</a></li>
<li class="chapter" data-level="16.3.5" data-path="factor-analysis.html"><a href="factor-analysis.html#application-12"><i class="fa fa-check"></i><b>16.3.5</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html"><i class="fa fa-check"></i><b>16.4</b> Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#known-populations"><i class="fa fa-check"></i><b>16.4.1</b> Known Populations</a></li>
<li class="chapter" data-level="16.4.2" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#probabilities-of-misclassification"><i class="fa fa-check"></i><b>16.4.2</b> Probabilities of Misclassification</a></li>
<li class="chapter" data-level="16.4.3" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#unknown-populations-nonparametric-discrimination"><i class="fa fa-check"></i><b>16.4.3</b> Unknown Populations/ Nonparametric Discrimination</a></li>
<li class="chapter" data-level="16.4.4" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#application-13"><i class="fa fa-check"></i><b>16.4.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>16.5</b> Cluster Analysis</a></li>
</ul></li>
<li class="part"><span><b>V CAUSAL INFERENCE</b></span></li>
<li class="chapter" data-level="17" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>17</b> Causal Inference</a></li>
<li class="chapter" data-level="18" data-path="experimental-design.html"><a href="experimental-design.html"><i class="fa fa-check"></i><b>18</b> Experimental Design</a></li>
<li class="chapter" data-level="19" data-path="quasi-experimental.html"><a href="quasi-experimental.html"><i class="fa fa-check"></i><b>19</b> Quasi-experimental</a>
<ul>
<li class="chapter" data-level="19.1" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html"><i class="fa fa-check"></i><b>19.1</b> Regression Discontinuity</a></li>
<li class="chapter" data-level="19.2" data-path="difference-in-differences.html"><a href="difference-in-differences.html"><i class="fa fa-check"></i><b>19.2</b> Difference-In-Differences</a></li>
<li class="chapter" data-level="19.3" data-path="synthetic-control.html"><a href="synthetic-control.html"><i class="fa fa-check"></i><b>19.3</b> Synthetic Control</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="synthetic-control.html"><a href="synthetic-control.html#example-1-1"><i class="fa fa-check"></i><b>19.3.1</b> Example 1</a></li>
<li class="chapter" data-level="19.3.2" data-path="synthetic-control.html"><a href="synthetic-control.html#example-2"><i class="fa fa-check"></i><b>19.3.2</b> Example 2</a></li>
<li class="chapter" data-level="19.3.3" data-path="synthetic-control.html"><a href="synthetic-control.html#example-3"><i class="fa fa-check"></i><b>19.3.3</b> Example 3</a></li>
<li class="chapter" data-level="19.3.4" data-path="synthetic-control.html"><a href="synthetic-control.html#example-4"><i class="fa fa-check"></i><b>19.3.4</b> Example 4</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="matching-methods.html"><a href="matching-methods.html"><i class="fa fa-check"></i><b>19.4</b> Matching Methods</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="matching-methods.html"><a href="matching-methods.html#matchit"><i class="fa fa-check"></i><b>19.4.1</b> MatchIt</a></li>
<li class="chapter" data-level="19.4.2" data-path="matching-methods.html"><a href="matching-methods.html#matchingfrontier"><i class="fa fa-check"></i><b>19.4.2</b> MatchingFrontier</a></li>
<li class="chapter" data-level="19.4.3" data-path="matching-methods.html"><a href="matching-methods.html#propensity-scores"><i class="fa fa-check"></i><b>19.4.3</b> Propensity Scores</a></li>
<li class="chapter" data-level="19.4.4" data-path="matching-methods.html"><a href="matching-methods.html#mahalanobis-distance"><i class="fa fa-check"></i><b>19.4.4</b> Mahalanobis Distance</a></li>
<li class="chapter" data-level="19.4.5" data-path="matching-methods.html"><a href="matching-methods.html#coarsened-exact-matching"><i class="fa fa-check"></i><b>19.4.5</b> Coarsened Exact Matching</a></li>
<li class="chapter" data-level="19.4.6" data-path="matching-methods.html"><a href="matching-methods.html#genetic-matching"><i class="fa fa-check"></i><b>19.4.6</b> Genetic Matching</a></li>
<li class="chapter" data-level="19.4.7" data-path="matching-methods.html"><a href="matching-methods.html#matching-for-time-series-cross-section-data"><i class="fa fa-check"></i><b>19.4.7</b> Matching for time series-cross-section data</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="interrupted-time-series.html"><a href="interrupted-time-series.html"><i class="fa fa-check"></i><b>19.5</b> Interrupted Time Series</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="endogeneity.html"><a href="endogeneity.html"><i class="fa fa-check"></i><b>20</b> Endogeneity</a>
<ul>
<li class="chapter" data-level="20.1" data-path="measurement-error.html"><a href="measurement-error.html"><i class="fa fa-check"></i><b>20.1</b> Measurement Error</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="measurement-error.html"><a href="measurement-error.html#classical-measurement-errors"><i class="fa fa-check"></i><b>20.1.1</b> Classical Measurement Errors</a></li>
<li class="chapter" data-level="20.1.2" data-path="measurement-error.html"><a href="measurement-error.html#non-classical-measurement-errors"><i class="fa fa-check"></i><b>20.1.2</b> Non-classical Measurement Errors</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="simultaneity.html"><a href="simultaneity.html"><i class="fa fa-check"></i><b>20.2</b> Simultaneity</a></li>
<li class="chapter" data-level="20.3" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html"><i class="fa fa-check"></i><b>20.3</b> Endogenous Treatment</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#instrumental-variable"><i class="fa fa-check"></i><b>20.3.1</b> Instrumental Variable</a></li>
<li class="chapter" data-level="20.3.2" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#internal-instrumental-variable"><i class="fa fa-check"></i><b>20.3.2</b> Internal instrumental variable</a></li>
<li class="chapter" data-level="20.3.3" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#proxy-variables"><i class="fa fa-check"></i><b>20.3.3</b> Proxy Variables</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html"><i class="fa fa-check"></i><b>20.4</b> Endogenous Sample Selection</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-2"><i class="fa fa-check"></i><b>20.4.1</b> Tobit-2</a></li>
<li class="chapter" data-level="20.4.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-5"><i class="fa fa-check"></i><b>20.4.2</b> Tobit-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="mediation.html"><a href="mediation.html"><i class="fa fa-check"></i><b>21</b> Mediation</a>
<ul>
<li class="chapter" data-level="21.1" data-path="traditional.html"><a href="traditional.html"><i class="fa fa-check"></i><b>21.1</b> Traditional</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="traditional.html"><a href="traditional.html#example-1-mediation-traditional"><i class="fa fa-check"></i><b>21.1.1</b> Example 1</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="model-based-causal-mediation-analysis.html"><a href="model-based-causal-mediation-analysis.html"><i class="fa fa-check"></i><b>21.2</b> Model-based causal mediation analysis</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>22</b> Report</a>
<ul>
<li class="chapter" data-level="22.1" data-path="one-summary-table.html"><a href="one-summary-table.html"><i class="fa fa-check"></i><b>22.1</b> One summary table</a></li>
<li class="chapter" data-level="22.2" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>22.2</b> Model Comparison</a></li>
<li class="chapter" data-level="22.3" data-path="changes-in-an-estimate.html"><a href="changes-in-an-estimate.html"><i class="fa fa-check"></i><b>22.3</b> Changes in an estimate</a></li>
</ul></li>
<li class="appendix"><span><b>APPENDIX</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a>
<ul>
<li class="chapter" data-level="A.1" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>A.1</b> Git</a></li>
<li class="chapter" data-level="A.2" data-path="short-cut.html"><a href="short-cut.html"><i class="fa fa-check"></i><b>A.2</b> Short-cut</a></li>
<li class="chapter" data-level="A.3" data-path="function-short-cut.html"><a href="function-short-cut.html"><i class="fa fa-check"></i><b>A.3</b> Function short-cut</a></li>
<li class="chapter" data-level="A.4" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>A.4</b> Citation</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bookdown-cheat-sheet.html"><a href="bookdown-cheat-sheet.html"><i class="fa fa-check"></i><b>B</b> Bookdown cheat sheet</a>
<ul>
<li class="chapter" data-level="B.1" data-path="operation.html"><a href="operation.html"><i class="fa fa-check"></i><b>B.1</b> Operation</a></li>
<li class="chapter" data-level="B.2" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html"><i class="fa fa-check"></i><b>B.2</b> Math Expresssion/ Syntax</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html#statistics-notation"><i class="fa fa-check"></i><b>B.2.1</b> Statistics Notation</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="table.html"><a href="table.html"><i class="fa fa-check"></i><b>B.3</b> Table</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generalization" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Generalization</h2>
<p>We can see that Poisson regression looks similar to logistic regression. Hence, we can generalize to a class of modeling. Thanks to <span class="citation">(<a href="#ref-Nelder_1972" role="doc-biblioref">Nelder and Wedderburn 1972</a>)</span>, we have the <strong>generalized linear models</strong> (GLMs). Estimation is generalize in these models.</p>
<p><strong>Exponential Family</strong><br />
The theory of GLMs is developed for data with distribution given y the <strong>exponential family</strong>.<br />
The form of the data distribution that is useful for GLMs is</p>
<p><span class="math display">\[
f(y;\theta, \phi) = \exp(\frac{\theta y - b(\theta)}{a(\phi)} + c(y, \phi))
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta\)</span> is called the natural parameter</li>
<li><span class="math inline">\(\phi\)</span> is called the dispersion parameter</li>
</ul>
<p><strong>Note</strong>:</p>
<p>This family includes the <a href="probability-theory.html#gamma">Gamma</a>, <a href="probability-theory.html#normal">Normal</a>, <a href="probability-theory.html#poisson">Poisson</a>, and other. For all parameterization of the exponential family, check this <a href="https://www.stat.purdue.edu/~tlzhang/stat526/logistic.pdf">link</a></p>
<p><strong>Example</strong></p>
<p>if we have <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span></p>
<p><span class="math display">\[
\begin{aligned}
f(y; \mu, \sigma^2) &amp;= \frac{1}{(2\pi \sigma^2)^{1/2}}\exp(-\frac{1}{2\sigma^2}(y- \mu)^2) \\
&amp;= \exp(-\frac{1}{2\sigma^2}(y^2 - 2y \mu +\mu^2)- \frac{1}{2}\log(2\pi \sigma^2)) \\
&amp;= \exp(\frac{y \mu - \mu^2/2}{\sigma^2} - \frac{y^2}{2\sigma^2} - \frac{1}{2}\log(2\pi \sigma^2)) \\
&amp;= \exp(\frac{\theta y - b(\theta)}{a(\phi)} + c(y , \phi))
\end{aligned}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta = \mu\)</span></li>
<li><span class="math inline">\(b(\theta) = \frac{\mu^2}{2}\)</span></li>
<li><span class="math inline">\(a(\phi) = \sigma^2 = \phi\)</span></li>
<li><span class="math inline">\(c(y , \phi) = - \frac{1}{2}(\frac{y^2}{\phi}+\log(2\pi \sigma^2))\)</span></li>
</ul>
<p><strong>Properties of GLM exponential families</strong></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(E(Y) = b&#39; (\theta)\)</span> where <span class="math inline">\(b&#39;(\theta) = \frac{\partial b(\theta)}{\partial \theta}\)</span> (here <code>'</code> is “prime,” not transpose)</p></li>
<li><p><span class="math inline">\(var(Y) = a(\phi)b&#39;&#39;(\theta)= a(\phi)V(\mu)\)</span>.</p>
<ul>
<li><span class="math inline">\(V(\mu)\)</span> is the <em>variance function</em>; however, it is only the variance in the case that <span class="math inline">\(a(\phi) =1\)</span></li>
</ul></li>
<li><p>If <span class="math inline">\(a(), b(), c()\)</span> are identifiable, we will derive expected value and variance of Y.</p></li>
</ol>
<p>Example</p>
<p>Normal distribution</p>
<p><span class="math display">\[
b&#39;(\theta) = \frac{\partial b(\mu^2/2)}{\partial \mu} = \mu \\
V(\mu) = \frac{\partial^2 (\mu^2/2)}{\partial \mu^2} = 1 \\
\to var(Y) = a(\phi) = \sigma^2
\]</span></p>
<p>Poisson distribution</p>
<p><span class="math display">\[
\begin{aligned}
f(y, \theta, \phi) &amp;= \frac{\mu^y \exp(-\mu)}{y!} \\
&amp;= \exp(y\log(\mu) - \mu - \log(y!)) \\
&amp;= \exp(y\theta - \exp(\theta) - \log(y!))
\end{aligned}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta = \log(\mu)\)</span></li>
<li><span class="math inline">\(a(\phi) = 1\)</span></li>
<li><span class="math inline">\(b(\theta) = \exp(\theta)\)</span></li>
<li><span class="math inline">\(c(y, \phi) = \log(y!)\)</span></li>
</ul>
<p>Hence,</p>
<p><span class="math display">\[
E(Y) = \frac{\partial b(\theta)}{\partial \theta} = \exp(\theta) = \mu \\
var(Y) = \frac{\partial^2 b(\theta)}{\partial \theta^2} = \mu
\]</span></p>
<p>Since <span class="math inline">\(\mu = E(Y) = b&#39;(\theta)\)</span></p>
<p>In GLM, we take some monotone function (typically nonlinear) of <span class="math inline">\(\mu\)</span> to be linear in the set of covariates</p>
<p><span class="math display">\[
g(\mu) = g(b&#39;(\theta)) = \mathbf{x&#39;\beta}
\]</span></p>
<p>Equivalently,</p>
<p><span class="math display">\[
\mu = g^{-1}(\mathbf{x&#39;\beta})
\]</span></p>
<p>where <span class="math inline">\(g(.)\)</span> is the <strong>link function</strong> since it links mean response (<span class="math inline">\(\mu = E(Y)\)</span>) and a linear expression of the covariates</p>
<p>Some people use <span class="math inline">\(\eta = \mathbf{x&#39;\beta}\)</span> where <span class="math inline">\(\eta\)</span> = the “linear predictor”</p>
<p><strong>GLM is composed of 2 components</strong></p>
<p>The <strong>random component</strong>:</p>
<ul>
<li><p>is the distribution chosen to model the response variables <span class="math inline">\(Y_1,...,Y_n\)</span></p></li>
<li><p>is specified by the choice fo <span class="math inline">\(a(), b(), c()\)</span> in the exponential form</p></li>
<li><p>Notation:</p>
<ul>
<li>Assume that there are n <strong>independent</strong> response variables <span class="math inline">\(Y_1,...,Y_n\)</span> with densities<br />
<span class="math display">\[
f(y_i ; \theta_i, \phi) = \exp(\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi))
\]</span> notice each observation might have different densities</li>
<li>Assume that <span class="math inline">\(\phi\)</span> is constant for all <span class="math inline">\(i = 1,...,n\)</span>, but <span class="math inline">\(\theta_i\)</span> will vary. <span class="math inline">\(\mu_i = E(Y_i)\)</span> for all i.</li>
</ul></li>
</ul>
<p>The <strong>systematic component</strong></p>
<ul>
<li><p>is the portion of the model that gives the relation between <span class="math inline">\(\mu\)</span> and the covariates <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>consists of 2 parts:</p>
<ul>
<li>the <em>link</em> function, <span class="math inline">\(g(.)\)</span></li>
<li>the <em>linear predictor</em>, <span class="math inline">\(\eta = \mathbf{x&#39;\beta}\)</span></li>
</ul></li>
<li><p>Notation:</p>
<ul>
<li>assume <span class="math inline">\(g(\mu_i) = \mathbf{x&#39;\beta} = \eta_i\)</span> where <span class="math inline">\(\mathbf{\beta} = (\beta_1,..., \beta_p)&#39;\)</span></li>
<li>The parameters to be estimated are <span class="math inline">\(\beta_1,...\beta_p , \phi\)</span></li>
</ul></li>
</ul>
<p><strong>The Canonical Link</strong></p>
<p>To choose <span class="math inline">\(g(.)\)</span>, we can use <strong>canonical link function</strong> (Remember: Canonical link is just a special case of the link function)</p>
<p>If the link function <span class="math inline">\(g(.)\)</span> is such <span class="math inline">\(g(\mu_i) = \eta_i = \theta_i\)</span>, the natural parameter, then <span class="math inline">\(g(.)\)</span> is the canonical link.</p>
<pre><code>## Warning: package &#39;jpeg&#39; was built under R version 4.0.5</code></pre>
<p><img src="images/GLM.PNG" width="416" style="display: block; margin: auto;" /></p>
<ul>
<li><span class="math inline">\(b(\theta)\)</span> = cumulant moment generating function</li>
<li><span class="math inline">\(g(\mu)\)</span> is the link function, which relates the linear predictor to the mean and is required to be monotone increasing, continuously differentiable and invertible.</li>
</ul>
<p>Equivalently, we can think of canonical link function as</p>
<p><span class="math display">\[
\gamma^{-1} \circ g^{-1} = I
\]</span>
which is the identity. Hence,</p>
<p><span class="math display">\[
\theta = \eta
\]</span></p>
<p><strong>The inverse link</strong></p>
<p><span class="math inline">\(g^{-1}(.)\)</span> is also known as the mean function, take linear predictor output (ranging from <span class="math inline">\(-\infty\)</span> to <span class="math inline">\(\infty\)</span>) and transform it into a different scale.</p>
<ul>
<li><strong>Exponential</strong>: converts <span class="math inline">\(\mathbf{\beta X}\)</span> into a curve that is restricted between 0 and <span class="math inline">\(\infty\)</span> (which you can see that is useful in case you want to convert a linear predictor into a non-negative value). <span class="math inline">\(\lambda = \exp(y) = \mathbf{\beta X}\)</span></li>
<li><strong>Inverse Logit</strong> (also known as logistic): converts <span class="math inline">\(\mathbf{\beta X}\)</span> into a curve that is restricted between 0 and 1, which is useful in case you want to convert a linear predictor to a probability. <span class="math inline">\(\theta = \frac{1}{1 + \exp(-y)} = \frac{1}{1 + \exp(- \mathbf{\beta X})}\)</span>
<ul>
<li><span class="math inline">\(y\)</span> = linear predictor value</li>
<li><span class="math inline">\(\theta\)</span> = transformed value</li>
</ul></li>
</ul>
<p>The <strong>identity link</strong> is that</p>
<p><span class="math display">\[
\eta_i = g(\mu_i) = \mu_i \\
\mu_i = g^{-1}(\eta_i) = \eta_i
\]</span></p>
<p><img src="images/2-Table15.1-1.png" width="425" style="display: block; margin: auto;" /></p>
<p>Table 15.1 Generalized Linear Models 15.1 the Structure of Generalized Linear Models</p>
<p>More example on the link functions and their inverses can be found on <a href="https://www.sagepub.com/sites/default/files/upm-binaries/21121_Chapter_15.pdf">page 380</a></p>
<p>Example</p>
<p>Normal random component</p>
<ul>
<li><p>Mean Response: <span class="math inline">\(\mu_i = \theta_i\)</span></p></li>
<li><p>Canonical Link: <span class="math inline">\(g( \mu_i) = \mu_i\)</span> (the identity link)</p></li>
</ul>
<p>Binomial random component</p>
<ul>
<li><p>Mean Response: <span class="math inline">\(\mu_i = \frac{n_i \exp( \theta)}{1+\exp (\theta_i)}\)</span> and <span class="math inline">\(\theta(\mu_i) = \log(\frac{p_i }{1-p_i}) = \log (\frac{\mu_i} {n_i - \mu_i})\)</span></p></li>
<li><p>Canonical link: <span class="math inline">\(g(\mu_i) = \log(\frac{\mu_i} {n_i - \mu_i})\)</span> (logit link)</p></li>
</ul>
<p>Poisson random component</p>
<ul>
<li><p>Mean Response: <span class="math inline">\(\mu_i = \exp(\theta_i)\)</span></p></li>
<li><p>Canonical Link: <span class="math inline">\(g(\mu_i) = \log(\mu_i)\)</span></p></li>
</ul>
<p>Gamma random component:</p>
<ul>
<li><p>Mean response: <span class="math inline">\(\mu_i = -\frac{1}{\theta_i}\)</span> and <span class="math inline">\(\theta(\mu_i) = - \mu_i^{-1}\)</span></p></li>
<li><p>Canonical Link: <span class="math inline">\(g(\mu\_i) = - \frac{1}{\mu_i}\)</span></p></li>
</ul>
<p>Inverse Gaussian random</p>
<ul>
<li>Canonical Link: <span class="math inline">\(g(\mu_i) = \frac{1}{\mu_i^2}\)</span></li>
</ul>
<div id="estimation-1" class="section level3" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Estimation</h3>
<ul>
<li>MLE for parameters of the <strong>systematic component (</strong><span class="math inline">\(\beta\)</span>)<br />
</li>
<li>Unification of derivation and computation (thanks to the exponential forms)<br />
</li>
<li>No unification for estimation of the dispersion parameter (<span class="math inline">\(\phi\)</span>)</li>
</ul>
<div id="estimation-of-beta" class="section level4" number="7.7.1.1">
<h4><span class="header-section-number">7.7.1.1</span> Estimation of <span class="math inline">\(\beta\)</span></h4>
<p>We have</p>
<p><span class="math display">\[
f(y_i ; \theta_i, \phi) = \exp(\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi)) \\
E(Y_i) = \mu_i = b&#39;(\theta) \\
var(Y_i) = b&#39;&#39;(\theta)a(\phi) = V(\mu_i)a(\phi) \\
g(\mu_i) = \mathbf{x}_i&#39;\beta = \eta_i
\]</span></p>
<p>If the log-likelihood for a single observation is <span class="math inline">\(l_i (\beta,\phi)\)</span>. The log-likelihood for all n observations is</p>
<p><span class="math display">\[
\begin{aligned}
l(\beta,\phi) &amp;= \sum_{i=1}^n l_i (\beta,\phi) \\
&amp;= \sum_{i=1}^n (\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi))
\end{aligned}
\]</span></p>
<p>Using MLE to find <span class="math inline">\(\beta\)</span>, we use the chain rule to get the derivatives</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l_i (\beta,\phi)}{\partial \beta_j} &amp;=  \frac{\partial l_i (\beta, \phi)}{\partial \theta_i} \times \frac{\partial \theta_i}{\partial \mu_i} \times \frac{\partial \mu_i}{\partial \eta_i}\times \frac{\partial \eta_i}{\partial \beta_j} \\
&amp;= \sum_{i=1}^{n}(\frac{ y_i - \mu_i}{a(\phi)} \times \frac{1}{V(\mu_i)} \times \frac{\partial \mu_i}{\partial \eta_i} \times x_{ij})
\end{aligned}
\]</span></p>
<p>If we let</p>
<p><span class="math display">\[
w_i \equiv ((\frac{\partial \eta_i}{\partial \mu_i})^2 V(\mu_i))^{-1}
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\frac{\partial l_i (\beta,\phi)}{\partial \beta_j} = \sum_{i=1}^n (\frac{y_i \mu_i}{a(\phi)} \times w_i \times \frac{\partial \eta_i}{\partial \mu_i} \times x_{ij})
\]</span></p>
<p>We can also get the second derivatives using the chain rule.</p>
<p>Example:</p>
<p>For the <a href="non-linear-least-squares.html#newton-raphson">Newton-Raphson</a> algorithm, we need</p>
<p><span class="math display">\[
- E(\frac{\partial^2 l(\beta,\phi)}{\partial \beta_j \partial \beta_k})
\]</span></p>
<p>where <span class="math inline">\((j,k)\)</span>th element of the <strong>Fisher information matrix</strong> <span class="math inline">\(\mathbf{I}(\beta)\)</span></p>
<p>Hence,</p>
<p><span class="math display">\[
- E(\frac{\partial^2 l(\beta,\phi)}{\partial \beta_j \partial \beta_k}) = \sum_{i=1}^n \frac{w_i}{a(\phi)}x_{ij}x_{ik}
\]</span></p>
<p>for the (j,k)th element</p>
<p>If Bernoulli model with logit link function (which is the canonical link)</p>
<p><span class="math display">\[
b(\theta) = \log(1 + \exp(\theta)) = \log(1 + \exp(\mathbf{x&#39;\beta})) \\
a(\phi) = 1  \\
c(y_i, \phi) = 0 \\
E(Y) = b&#39;(\theta) = \frac{\exp(\theta)}{1 + \exp(\theta)} = \mu = p \\
\eta = g(\mu) = \log(\frac{\mu}{1-\mu}) = \theta = \log(\frac{p}{1-p}) = \mathbf{x&#39;\beta} 
\]</span></p>
<p>For <span class="math inline">\(Y_i\)</span>, i = 1,.., the log-likelihood is</p>
<p><span class="math display">\[
l_i (\beta, \phi) = \frac{y_i \theta_i - b(\theta_i)}{a(\phi)} + c(y_i, \phi) = y_i \mathbf{x}&#39;_i \beta - \log(1+ \exp(\mathbf{x&#39;\beta}))
\]</span></p>
<p>Additionally,</p>
<p><span class="math display">\[
V(\mu_i) = \mu_i(1-\mu_i)= p_i (1-p_i) \\
\frac{\partial \mu_i}{\partial \eta_i} = p_i(1-p_i)
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l(\beta, \phi)}{\partial \beta_j} &amp;= \sum_{i=1}^n[\frac{y_i - \mu_i}{a(\phi)} \times \frac{1}{V(\mu_i)}\times \frac{\partial \mu_i}{\partial \eta_i} \times x_{ij}] \\
&amp;= \sum_{i=1}^n (y_i - p_i) \times \frac{1}{p_i(1-p_i)} \times p_i(1-p_i) \times x_{ij} \\
&amp;= \sum_{i=1}^n (y_i - p_i) x_{ij} \\
&amp;= \sum_{i=1}^n (y_i - \frac{\exp(\mathbf{x&#39;_i\beta})}{1+ \exp(\mathbf{x&#39;_i\beta})})x_{ij}
\end{aligned}
\]</span></p>
<p>then</p>
<p><span class="math display">\[
w_i = ((\frac{\partial \eta_i}{\partial \mu_i})^2 V(\mu_i))^{-1} = p_i (1-p_i)
\]</span></p>
<p><span class="math display">\[
\mathbf{I}_{jk}(\mathbf{\beta}) = \sum_{i=1}^n \frac{w_i}{a(\phi)} x_{ij}x_{ik} = \sum_{i=1}^n p_i (1-p_i)x_{ij}x_{ik}
\]</span></p>
<p>The <strong>Fisher-scoring</strong> algorithm for the MLE of <span class="math inline">\(\mathbf{\beta}\)</span> is</p>
<p><span class="math display">\[
\left(
\begin{array}
{c}
\beta_1 \\
\beta_2 \\
. \\
. \\
. \\
\beta_p \\
\end{array}
\right)^{(m+1)}
=
\left(
\begin{array}
{c}
\beta_1 \\
\beta_2 \\
. \\
. \\
. \\
\beta_p \\
\end{array}
\right)^{(m)} +
\mathbf{I}^{-1}(\mathbf{\beta})
\left(
\begin{array}
{c}
\frac{\partial l (\beta, \phi)}{\partial \beta_1} \\
\frac{\partial l (\beta, \phi)}{\partial \beta_2} \\
. \\
. \\
. \\
\frac{\partial l (\beta, \phi)}{\partial \beta_p} \\
\end{array}
\right)|_{\beta = \beta^{(m)}}
\]</span></p>
<p>Similar to <a href="non-linear-least-squares.html#newton-raphson">Newton-Raphson</a> expect the matrix of second derivatives by the expected value of the second derivative matrix.</p>
<p>In matrix notation,</p>
<p><span class="math display">\[
\begin{aligned}
\frac{\partial l }{\partial \beta} &amp;= \frac{1}{a(\phi)}\mathbf{X&#39;W\Delta(y - \mu)} \\
&amp;= \frac{1}{a(\phi)}\mathbf{F&#39;V^{-1}(y - \mu)} \\
\end{aligned}
\]</span></p>
<p><span class="math display">\[
\mathbf{I}(\beta) = \frac{1}{a(\phi)}\mathbf{X&#39;WX} = \frac{1}{a(\phi)}\mathbf{F&#39;V^{-1}F} \\
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{X}\)</span> is an n x p matrix of covariates</li>
<li><span class="math inline">\(\mathbf{W}\)</span> is an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(w_i\)</span></li>
<li><span class="math inline">\(\mathbf{\Delta}\)</span> an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(\frac{\partial \eta_i}{\partial \mu_i}\)</span></li>
<li><span class="math inline">\(\mathbf{F} = \mathbf{\frac{\partial \mu}{\partial \beta}}\)</span> an n x p matrix with ith row <span class="math inline">\(\frac{\partial \mu_i}{\partial \beta} = (\frac{\partial \mu_i}{\partial \eta_i})\mathbf{x}&#39;_i\)</span></li>
<li><span class="math inline">\(\mathbf{V}\)</span> an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(V(\mu_i)\)</span></li>
</ul>
<p>Setting the derivative of the log-likelihood equal to 0, ML estimating equations are</p>
<p><span class="math display">\[
\mathbf{F&#39;V^{-1}y= F&#39;V^{-1}\mu}
\]</span></p>
<p>where all components of this equation expect y depends on the parameters <span class="math inline">\(\beta\)</span></p>
<p><strong>Special Cases</strong></p>
<p>If one has a canonical link, the estimating equations reduce to</p>
<p><span class="math display">\[
\mathbf{X&#39;y= X&#39;\mu}
\]</span></p>
<p>If one has an identity link, then</p>
<p><span class="math display">\[
\mathbf{X&#39;V^{-1}y = X&#39;V^{-1}X\hat{\beta}}
\]</span></p>
<p>which gives the generalized least squares estimator</p>
<p>Generally, we can rewrite the Fisher-scoring algorithm as</p>
<p><span class="math display">\[
\beta^{(m+1)} = \beta^{(m)} + \mathbf{(\hat{F}&#39;\hat{V}^{-1}\hat{F})^{-1}\hat{F}&#39;\hat{V}^{-1}(y- \hat{\mu})}
\]</span></p>
<p>Since <span class="math inline">\(\hat{F},\hat{V}, \hat{\mu}\)</span> depend on <span class="math inline">\(\beta\)</span>, we evaluate at <span class="math inline">\(\beta^{(m)}\)</span></p>
<p>From starting values <span class="math inline">\(\beta^{(0)}\)</span>, we can iterate until convergence.</p>
<p>Notes:</p>
<ul>
<li>if <span class="math inline">\(a(\phi)\)</span> is a constant or of the form <span class="math inline">\(m_i \phi\)</span> with known <span class="math inline">\(m_i\)</span>, then <span class="math inline">\(\phi\)</span> cancels.</li>
</ul>
</div>
<div id="estimation-of-phi" class="section level4" number="7.7.1.2">
<h4><span class="header-section-number">7.7.1.2</span> Estimation of <span class="math inline">\(\phi\)</span></h4>
<p>2 approaches:</p>
<ol style="list-style-type: decimal">
<li>MLE</li>
</ol>
<p><span class="math display">\[
\frac{\partial l_i}{\partial \phi} = \frac{(\theta_i y_i - b(\theta_i)a&#39;(\phi))}{a^2(\phi)} + \frac{\partial c(y_i,\phi)}{\partial \phi}
\]</span></p>
<p>the MLE of <span class="math inline">\(\phi\)</span> solves</p>
<p><span class="math display">\[
\frac{a^2(\phi)}{a&#39;(\phi)}\sum_{i=1}^n \frac{\partial c(y_i, \phi)}{\partial \phi} = \sum_{i=1}^n(\theta_i y_i - b(\theta_i))
\]</span></p>
<ul>
<li><p>Situation others than normal error case, expression for <span class="math inline">\(\frac{\partial c(y,\phi)}{\partial \phi}\)</span> are not simple</p></li>
<li><p>Even for the canonical link and <span class="math inline">\(a(\phi)\)</span> constant, there is no nice general expression for <span class="math inline">\(-E(\frac{\partial^2 l}{\partial \phi^2})\)</span>, so the unification GLMs provide for estimation of <span class="math inline">\(\beta\)</span> breaks down for <span class="math inline">\(\phi\)</span></p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><p>Moment Estimation (“Bias Corrected <span class="math inline">\(\chi^2\)</span>”)</p>
<ul>
<li>The MLE is not conventional approach to estimation of <span class="math inline">\(\phi\)</span> in GLMS.</li>
<li>For the exponential family <span class="math inline">\(var(Y) =V(\mu)a(\phi)\)</span>. This implies<br />
<span class="math display">\[
a(\phi) = \frac{var(Y)}{V(\mu)} = \frac{E(Y- \mu)^2}{V(\mu)} \\
a(\hat{\phi})  = \frac{1}{n-p} \sum_{i=1}^n \frac{(y_i -\hat{\mu}_i)^2}{V(\hat{\mu})}
\]</span> where p is the dimension of <span class="math inline">\(\beta\)</span></li>
<li>GLM with canonical link function <span class="math inline">\(g(.)= (b&#39;(.))^{-1}\)</span><br />
<span class="math display">\[
g(\mu) = \theta = \eta = \mathbf{x&#39;\beta} \\
\mu = g^{-1}(\eta)= b&#39;(\eta)
\]</span></li>
<li>so the method estimator for <span class="math inline">\(a(\phi)=\phi\)</span> is</li>
</ul></li>
</ol>
<p><span class="math display">\[
\hat{\phi} = \frac{1}{n-p} \sum_{i=1}^n \frac{(y_i - g^{-1}(\hat{\eta}_i))^2}{V(g^{-1}(\hat{\eta}_i))}
\]</span></p>
</div>
</div>
<div id="inference-2" class="section level3" number="7.7.2">
<h3><span class="header-section-number">7.7.2</span> Inference</h3>
<p>We have</p>
<p><span class="math display">\[
\hat{var}(\beta) = a(\phi)(\mathbf{\hat{F}&#39;\hat{V}\hat{F}})^{-1}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{V}\)</span> is an n x n diagonal matrix with diagonal elements given by <span class="math inline">\(V(\mu_i)\)</span></li>
<li><span class="math inline">\(\mathbf{F}\)</span> is an n x p matrix given by <span class="math inline">\(\mathbf{F} = \frac{\partial \mu}{\partial \beta}\)</span></li>
<li>Both <span class="math inline">\(\mathbf{V,F}\)</span> are dependent on the mean <span class="math inline">\(\mu\)</span>, and thus <span class="math inline">\(\beta\)</span>. Hence, their estimates (<span class="math inline">\(\mathbf{\hat{V},\hat{F}}\)</span>) depend on <span class="math inline">\(\hat{\beta}\)</span>.</li>
</ul>
<p><span class="math display">\[
H_0: \mathbf{L\beta = d}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{L}\)</span> is a q x p matrix with a <strong>Wald</strong> test</p>
<p><span class="math display">\[
W = \mathbf{(L \hat{\beta}-d)&#39;(a(\phi)L(\hat{F}&#39;\hat{V}^{-1}\hat{F})L&#39;)^{-1}(L \hat{\beta}-d)}
\]</span></p>
<p>which follows <span class="math inline">\(\chi_q^2\)</span> distribution (asymptotically), where q is the rank of <span class="math inline">\(\mathbf{L}\)</span></p>
<p>In the simple case <span class="math inline">\(H_0: \beta_j = 0\)</span> gives <span class="math inline">\(W = \frac{\hat{\beta}^2_j}{\hat{var}(\hat{\beta}_j)} \sim \chi^2_1\)</span> asymptotically</p>
<p>Likelihood ratio test</p>
<p><span class="math display">\[
\Lambda = 2 (l(\hat{\beta}_f)-l(\hat{\beta}_r)) \sim \chi^2_q
\]</span></p>
<p>where</p>
<ul>
<li>q is the number of constraints used to fit the reduced model <span class="math inline">\(\hat{\beta}_r\)</span>, and <span class="math inline">\(\hat{\beta}_r\)</span> is the fit under the full model.</li>
</ul>
<p>Wald test is easier to implement, but likelihood ratio test is better (especially for small samples).</p>
</div>
<div id="deviance" class="section level3" number="7.7.3">
<h3><span class="header-section-number">7.7.3</span> Deviance</h3>
<p><a href="generalization.html#deviance">Deviance</a> is necessary for goodness of fit, inference and for alternative estimation of the dispersion parameter. We define and consider <a href="generalization.html#deviance">Deviance</a> from a likelihood ratio perspective.</p>
<ul>
<li><p>Assume that <span class="math inline">\(\phi\)</span> is known. Let <span class="math inline">\(\tilde{\theta}\)</span> denote the full and <span class="math inline">\(\hat{\theta}\)</span> denote the reduced model MLEs. Then, the likelihood ratio (2 times the difference in log-likelihoods) is <span class="math display">\[
2\sum_{i=1}^{n} \frac{y_i (\tilde{\theta}_i- \hat{\theta}_i)-b(\tilde{\theta}_i) + b(\hat{\theta}_i)}{a_i(\phi)}
\]</span></p></li>
<li><p>For exponential families, <span class="math inline">\(\mu = E(y) = b&#39;(\theta)\)</span>, so the natural parameter is a function of <span class="math inline">\(\mu: \theta = \theta(\mu) = b&#39;^{-1}(\mu)\)</span>, and the likelihood ratio turns into<br />
<span class="math display">\[
2 \sum_{i=1}^m \frac{y_i\{\theta(\tilde{\mu}_i - \theta(\hat{\mu}_i)\} - b(\theta(\tilde{\mu}_i)) + b(\theta(\hat{\mu}_i))}{a_i(\phi)}
\]</span></p></li>
<li><p>Comparing a fitted model to “the fullest possible model,” which is the <strong>saturated model</strong>: <span class="math inline">\(\tilde{\mu}_i = y_i\)</span>, i = 1,..,n. If <span class="math inline">\(\tilde{\theta}_i^* = \theta(y_i), \hat{\theta}_i^* = \theta (\hat{\mu})\)</span>, the likelihood ratio is<br />
<span class="math display">\[
2 \sum_{i=1}^{n} \frac{y_i (\tilde{\theta}_i^* - \hat{\theta}_i^* + b(\hat{\theta}_i^*))}{a_i(\phi)}
\]</span></p></li>
<li><p><span class="citation">(<a href="#ref-McCullagh_2019" role="doc-biblioref">McCullagh and Nelder 2019</a>)</span> specify <span class="math inline">\(a(\phi) = \phi\)</span>, then the likelihood ratio can be written as<br />
<span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) = \frac{2}{\phi}\sum_{i=1}^n\{y_i (\tilde{\theta}_i^*- \hat{\theta}_i^*)- b(\tilde{\theta}_i^*) +b(\hat{\theta}_i^*)  \}  
\]</span> where</p></li>
<li><p><span class="math inline">\(D^*(\mathbf{y, \hat{\mu}})\)</span> = <strong>scaled deviance</strong></p></li>
<li><p><span class="math inline">\(D(\mathbf{y, \hat{\mu}}) = \phi D^*(\mathbf{y, \hat{\mu}})\)</span> = <strong>deviance</strong></p></li>
</ul>
<p><br></p>
<p><strong>Note</strong>:</p>
<ul>
<li><p>in some random component distributions, we can write <span class="math inline">\(a_i(\phi) = \phi m_i\)</span>, where</p>
<ul>
<li><span class="math inline">\(m_i\)</span> is some known scalar that may change with the observations. THen, the scaled deviance components are divided by <span class="math inline">\(m_i\)</span>:<br />
<span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) \equiv 2\sum_{i=1}^n\{y_i (\tilde{\theta}_i^*- \hat{\theta}_i^*)- b(\tilde{\theta}_i^*) +b(\hat{\theta}_i^*)\} / (\phi m_i)  
\]</span></li>
</ul></li>
<li><p><span class="math inline">\(D^*(\mathbf{y, \hat{\mu}}) = \sum_{i=1}^n d_i\)</span>m where <span class="math inline">\(d_i\)</span> is the deviance contribution from the ith observation.</p></li>
<li><p>D is used in model selection</p></li>
<li><p><span class="math inline">\(D^*\)</span> is used in goodness of fit tests (as it is a likelihood ratio statistic). <span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) = 2\{l(\mathbf{y,\tilde{\mu}})-l(\mathbf{y,\hat{\mu}})\}
\]</span></p></li>
<li><p><span class="math inline">\(d_i\)</span> are used to form <strong>deviance residuals</strong></p></li>
</ul>
<p><br></p>
<p><strong>Example</strong>:</p>
<p><br></p>
<p><strong>Normal</strong></p>
<p>We have</p>
<p><span class="math display">\[
\theta = \mu \\
\phi = \sigma^2 \\
b(\theta) = \frac{1}{2} \theta^2 \\
a(\phi) = \phi
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\tilde{\theta}_i = y_i \\
\hat{\theta}_i = \hat{\mu}_i = g^{-1}(\hat{\eta}_i) 
\]</span></p>
<p>And</p>
<p><span class="math display">\[
\begin{aligned}
D &amp;= 2 \sum_{1=1}^n Y^2_i - y_i \hat{\mu}_i - \frac{1}{2}y^2_i + \frac{1}{2} \hat{\mu}_i^2 \\
&amp;= \sum_{i=1}^n y_i^2 - 2y_i \hat{\mu}_i + \hat{\mu}_i^2 \\
&amp;= \sum_{i=1}^n (y_i - \hat{\mu}_i)^2
\end{aligned}
\]</span></p>
<p>which is the <strong>residual sum of squares</strong></p>
<p><br></p>
<p><strong>Poisson</strong></p>
<p><span class="math display">\[
f(y) = \exp\{y\log(\mu) - \mu - \log(y!)\} \\
\theta = \log(\mu) \\
b(\theta) = \exp(\theta) \\
a(\phi) = 1 \\
\tilde{\theta}_i = \log(y_i) \\
\hat{\theta}_i = \log(\hat{\mu}_i) \\
\hat{\mu}_i = g^{-1}(\hat{\eta}_i)
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\begin{aligned}
D &amp;= 2 \sum_{i = 1}^n y_i \log(y_i) - y_i \log(\hat{\mu}_i) - y_i + \hat{\mu}_i \\
&amp;= 2 \sum_{i = 1}^n y_i \log(\frac{y_i}{\hat{\mu}_i}) - (y_i - \hat{\mu}_i)
\end{aligned}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
d_i = 2\{y_i \log(\frac{y_i}{\hat{\mu}})- (y_i - \hat{\mu}_i)\}
\]</span></p>
<p><br></p>
<div id="analysis-of-deviance" class="section level4" number="7.7.3.1">
<h4><span class="header-section-number">7.7.3.1</span> Analysis of Deviance</h4>
<p>The difference in deviance between a reduced and full model, where q is the difference in the number of free parameters, has an asymptotic <span class="math inline">\(\chi^2_q\)</span>. The likelihood ratio test</p>
<p><span class="math display">\[
D^*(\mathbf{y;\hat{\mu}_r}) - D^*(\mathbf{y;\hat{\mu}_f}) = 2\{l(\mathbf{y;\hat{\mu}_f})-l(\mathbf{y;\hat{\mu}_r})\}
\]</span></p>
<p>this comparison of models is <strong>Analysis of Deviance</strong>. <a href="generalized-linear-models.html#generalized-linear-models">GLM</a> uses this analysis for model selection.</p>
<p>An estimation of <span class="math inline">\(\phi\)</span> is</p>
<p><span class="math display">\[
\hat{\phi} = \frac{D(\mathbf{y, \hat{\mu}})}{n - p}
\]</span></p>
<p>where p = number of parameters fit.</p>
<p>Excessive use of <span class="math inline">\(\chi^2\)</span> test could be problematic since it is asymptotic <span class="citation">(<a href="#ref-McCullagh_2019" role="doc-biblioref">McCullagh and Nelder 2019</a>)</span></p>
<p><br></p>
</div>
<div id="deviance-residuals" class="section level4" number="7.7.3.2">
<h4><span class="header-section-number">7.7.3.2</span> Deviance Residuals</h4>
<p>We have <span class="math inline">\(D = \sum_{i=1}^{n}d_i\)</span>. Then, we define <strong>deviance residuals</strong></p>
<p><span class="math display">\[
r_{D_i} = \text{sign}(y_i -\hat{\mu}_i)\sqrt{d_i}
\]</span></p>
<p>Standardized version of deviance residuals is</p>
<p><span class="math display">\[
r_{s,i} = \frac{y_i -\hat{\mu}}{\hat{\sigma}(1-h_{ii})^{1/2}}
\]</span></p>
<p>Let <span class="math inline">\(\mathbf{H^{GLM} = W^{1/2}X(X&#39;WX)^{-1}X&#39;W^{-1/2}}\)</span>, where <span class="math inline">\(\mathbf{W}\)</span> is an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(w_i\)</span> (see <a href="generalization.html#estimation-of-beta">Estimation of <span class="math inline">\(\beta\)</span></a>). Then Standardized deviance residuals is equivalently</p>
<p><span class="math display">\[
r_{s, D_i} = \frac{r_{D_i}}{\{\hat{\phi}(1-h_{ii}^{glm}\}^{1/2}}
\]</span></p>
<p>where <span class="math inline">\(h_{ii}^{glm}\)</span> is the ith diagonal of <span class="math inline">\(\mathbf{H}^{GLM}\)</span></p>
<p><br></p>
</div>
<div id="pearson-chi-square-residuals" class="section level4" number="7.7.3.3">
<h4><span class="header-section-number">7.7.3.3</span> Pearson Chi-square Residuals</h4>
<p>Another <span class="math inline">\(\chi^2\)</span> statistic is <strong>Pearson</strong> <span class="math inline">\(\chi^2\)</span> statistics: (assume <span class="math inline">\(m_i = 1\)</span>)</p>
<p><span class="math display">\[
X^2 = \sum_{i=1}^{n} \frac{(y_i - \hat{\mu}_i)^2}{V(\hat{\mu}_i)}
\]</span></p>
<p>where <span class="math inline">\(\hat{\mu}_i\)</span> is the fitted mean response fo the model of interest.</p>
<p>The <strong>Scaled Pearson</strong> <span class="math inline">\(\chi^2\)</span> statistic is given by <span class="math inline">\(\frac{X^2}{\phi} \sim \chi^2_{n-p}\)</span> where p is the number of parameters estimated. Hence, the <strong>Pearson</strong> <span class="math inline">\(\chi^2\)</span> residuals are</p>
<p><span class="math display">\[
X^2_i = \frac{(y_i - \hat{\mu}_i)^2}{V(\hat{\mu}_i)}
\]</span></p>
<p>If we have the following assumptions:</p>
<ul>
<li>Independent samples<br />
</li>
<li>No over-dispersion: If <span class="math inline">\(\phi = 1\)</span>, <span class="math inline">\(\frac{D(\mathbf{y;\hat{\mu}})}{n-p}\)</span> and <span class="math inline">\(\frac{X^2}{n-p}\)</span> have a value substantially larger 1 indicates <strong>improperly specified model</strong> or <strong>overdispersion</strong><br />
</li>
<li>Multiple groups</li>
</ul>
<p>then <span class="math inline">\(\frac{X^2}{\phi}\)</span> and <span class="math inline">\(D^*(\mathbf{y; \hat{\mu}})\)</span> both follow <span class="math inline">\(\chi^2_{n-p}\)</span></p>
<p><br></p>
</div>
</div>
<div id="diagnostic-plots" class="section level3" number="7.7.4">
<h3><span class="header-section-number">7.7.4</span> Diagnostic Plots</h3>
<ul>
<li><p>Standardized residual Plots:</p>
<ul>
<li>plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(\hat{\mu}_i\)</span>) or plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(T(\hat{\mu}_i)\)</span>) where <span class="math inline">\(T(\hat{\mu}_i)\)</span> is transformation(<span class="math inline">\(\hat{\mu}_i\)</span>) called <strong>constant information scale</strong>:<br />
</li>
<li>plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(\hat{\eta}_i\)</span>)</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center">Random Component</th>
<th align="center"><span class="math inline">\(T(\hat{\mu}_i)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Normal</td>
<td align="center"><span class="math inline">\(\hat{\mu}\)</span></td>
</tr>
<tr class="even">
<td align="center">Poisson</td>
<td align="center"><span class="math inline">\(2\sqrt{\mu}\)</span></td>
</tr>
<tr class="odd">
<td align="center">Binomial</td>
<td align="center"><span class="math inline">\(2 \sin^{-1}(\sqrt{\hat{\mu}})\)</span></td>
</tr>
<tr class="even">
<td align="center">Gamma</td>
<td align="center"><span class="math inline">\(2 \log(\hat{\mu})\)</span></td>
</tr>
<tr class="odd">
<td align="center">Inverse Gaussian</td>
<td align="center"><span class="math inline">\(-2\hat{\mu}^{-1/2}\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li><p>If we see:</p>
<ul>
<li>Trend, it means we might have a wrong link function, or choice of scale<br />
</li>
<li>Systematic change in range of residuals with a change in <span class="math inline">\(T(\hat{\mu})\)</span> (incorrect random component) (systematic <span class="math inline">\(\neq\)</span> random)<br />
</li>
</ul></li>
<li><p>plot(<span class="math inline">\(|r_{D_i}|,\hat{\mu}_i\)</span>) to check <strong>Variance Function</strong>.</p></li>
</ul>
</div>
<div id="goodness-of-fit" class="section level3" number="7.7.5">
<h3><span class="header-section-number">7.7.5</span> Goodness of Fit</h3>
<p>To assess goodness of fit, we can use</p>
<ul>
<li><a href="generalization.html#deviance">Deviance</a><br />
</li>
<li><a href="generalization.html#pearson-chi-square-residuals">Pearson Chi-square Residuals</a></li>
</ul>
<p>In nested model, we could use likelihood-based information measures:</p>
<p><span class="math display">\[
AIC = -2l(\mathbf{\hat{\mu}}) + 2p \\
AICC = -2l(\mathbf{\hat{\mu}}) + 2p(\frac{n}{n-p-1}) \\
BIC = 2l(\hat{\mu}) + p \log(n)
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(l(\hat{\mu})\)</span> is the log-likelihood evaluated at the parameter estimates</li>
<li>p is the number of parameters</li>
<li>n is the number of observations.</li>
</ul>
<p>Note: you have to use the same data with the same model (i.e., same link function, same random underlying random distribution). but you can have different number of parameters.</p>
<p>Even though statisticians try to come up with measures that are similar to <span class="math inline">\(R^2\)</span>, in practice, it is not so appropriate. For example, they comapre the log-likelihood of the fitted model against the that of a model with jsut the intercept:</p>
<p><span class="math display">\[
R^2_p = 1 - \frac{l(\hat{\mu})}{l(\hat{\mu}_0)}
\]</span></p>
<p>For certain specific random components such as binary response model, we have **rescaled generalized <span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
\bar{R}^2 = \frac{R^2_*}{\max(R^2_*)} = \frac{1-\exp\{-\frac{2}{n}(l(\hat{\mu}) - l(\hat{\mu}_0) \}}{1 - \exp\{\frac{2}{n}l(\hat{\mu}_0)\}}
\]</span></p>
</div>
<div id="over-dispersion" class="section level3" number="7.7.6">
<h3><span class="header-section-number">7.7.6</span> Over-Dispersion</h3>
<table>
<thead>
<tr class="header">
<th>Random Components</th>
<th><span class="math inline">\(var(Y)\)</span></th>
<th><span class="math inline">\(V(\mu)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomial</td>
<td><span class="math inline">\(var(Y) = n \mu (1- \mu)\)</span></td>
<td><span class="math inline">\(V(\mu) = \phi n \mu(1- \mu)\)</span> where <span class="math inline">\(m_i =n\)</span></td>
</tr>
<tr class="even">
<td>Poisson</td>
<td><span class="math inline">\(var(Y) = \mu\)</span></td>
<td><span class="math inline">\(V(\mu) = \phi \mu\)</span></td>
</tr>
</tbody>
</table>
<p>In both cases <span class="math inline">\(\phi = 1\)</span>. Recall <span class="math inline">\(b&#39;&#39;(\theta)= V(\mu)\)</span> check <a href="generalization.html#estimation-of-phi">Estimation of <span class="math inline">\(\phi\)</span></a>.</p>
<p>If we find</p>
<ul>
<li><span class="math inline">\(\phi &gt;1\)</span>: over-dispersion (i.e., too much variation for an independent binomial or Poisson distribution).</li>
<li><span class="math inline">\(\phi&lt;1\)</span>: under-dispersion (i.e., too little variation for an independent binomial or Poisson distribution).</li>
</ul>
<p>If we have either over or under-dispersion, it means we might have unspecified random component, we could</p>
<ul>
<li>Select a different random component distribution that can accommodate over or under-dispersion (e.g., negative binomial, Conway-Maxwell Poisson)</li>
<li>use <a href="nonlinear-and-generalized-linear-mixed-models.html#nonlinear-and-generalized-linear-mixed-models">Generalized Linear Mixed Models</a> to handle random effects in generalized linear models.</li>
</ul>
</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-McCullagh_2019" class="csl-entry">
McCullagh, P., and J. A. Nelder. 2019. <span>“An Outline of Generalized Linear Models.”</span> In <em>Generalized Linear Models</em>, 21–47. Routledge. <a href="https://doi.org/10.1201/9780203753736-2">https://doi.org/10.1201/9780203753736-2</a>.
</div>
<div id="ref-Nelder_1972" class="csl-entry">
Nelder, J. A., and R. W. M. Wedderburn. 1972. <span>“Generalized Linear Models.”</span> <em>Journal of the Royal Statistical Society. Series A (General)</em> 135 (3): 370. <a href="https://doi.org/10.2307/2344614">https://doi.org/10.2307/2344614</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multinomial.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-mixed-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/06-nonlinear_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Data Analysis.pdf", "Data Analysis.epub", "Data Analysis.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
