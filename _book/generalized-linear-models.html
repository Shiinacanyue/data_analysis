<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.3 Generalized Linear Models | Appendix</title>
  <meta name="description" content="This is a guide on how to conduct data analysis" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="6.3 Generalized Linear Models | Appendix" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a guide on how to conduct data analysis" />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.3 Generalized Linear Models | Appendix" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis" />
  

<meta name="author" content="Mike" />


<meta name="date" content="2021-02-25" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="non-linear-least-squares.html"/>
<link rel="next" href="generalized-linear-mixed-models.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-3.5.0/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-8.1.2/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-8.1.2/highcharts.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-3d.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-more.js"></script>
<script src="libs/highcharts-8.1.2/modules/stock.js"></script>
<script src="libs/highcharts-8.1.2/modules/map.js"></script>
<script src="libs/highcharts-8.1.2/modules/annotations.js"></script>
<script src="libs/highcharts-8.1.2/modules/data.js"></script>
<script src="libs/highcharts-8.1.2/modules/drilldown.js"></script>
<script src="libs/highcharts-8.1.2/modules/item-series.js"></script>
<script src="libs/highcharts-8.1.2/modules/offline-exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-8.1.2/modules/exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/export-data.js"></script>
<script src="libs/highcharts-8.1.2/modules/funnel.js"></script>
<script src="libs/highcharts-8.1.2/modules/heatmap.js"></script>
<script src="libs/highcharts-8.1.2/modules/treemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/sankey.js"></script>
<script src="libs/highcharts-8.1.2/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-8.1.2/modules/organization.js"></script>
<script src="libs/highcharts-8.1.2/modules/solid-gauge.js"></script>
<script src="libs/highcharts-8.1.2/modules/streamgraph.js"></script>
<script src="libs/highcharts-8.1.2/modules/sunburst.js"></script>
<script src="libs/highcharts-8.1.2/modules/vector.js"></script>
<script src="libs/highcharts-8.1.2/modules/wordcloud.js"></script>
<script src="libs/highcharts-8.1.2/modules/xrange.js"></script>
<script src="libs/highcharts-8.1.2/modules/tilemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/venn.js"></script>
<script src="libs/highcharts-8.1.2/modules/gantt.js"></script>
<script src="libs/highcharts-8.1.2/modules/timeline.js"></script>
<script src="libs/highcharts-8.1.2/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-8.1.2/modules/bullet.js"></script>
<script src="libs/highcharts-8.1.2/modules/coloraxis.js"></script>
<script src="libs/highcharts-8.1.2/modules/dumbbell.js"></script>
<script src="libs/highcharts-8.1.2/modules/lollipop.js"></script>
<script src="libs/highcharts-8.1.2/modules/series-label.js"></script>
<script src="libs/highcharts-8.1.2/plugins/motion.js"></script>
<script src="libs/highcharts-8.1.2/custom/reset.js"></script>
<script src="libs/highcharts-8.1.2/modules/boost.js"></script>
<script src="libs/highchart-binding-0.8.2/highchart.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="2.1" data-path="matrix-theory.html"><a href="matrix-theory.html"><i class="fa fa-check"></i><b>2.1</b> Matrix Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="matrix-theory.html"><a href="matrix-theory.html#rank"><i class="fa fa-check"></i><b>2.1.1</b> Rank</a></li>
<li class="chapter" data-level="2.1.2" data-path="matrix-theory.html"><a href="matrix-theory.html#inverse"><i class="fa fa-check"></i><b>2.1.2</b> Inverse</a></li>
<li class="chapter" data-level="2.1.3" data-path="matrix-theory.html"><a href="matrix-theory.html#definiteness"><i class="fa fa-check"></i><b>2.1.3</b> Definiteness</a></li>
<li class="chapter" data-level="2.1.4" data-path="matrix-theory.html"><a href="matrix-theory.html#matrix-calculus"><i class="fa fa-check"></i><b>2.1.4</b> Matrix Calculus</a></li>
<li class="chapter" data-level="2.1.5" data-path="matrix-theory.html"><a href="matrix-theory.html#optimization"><i class="fa fa-check"></i><b>2.1.5</b> Optimization</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2.2</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="probability-theory.html"><a href="probability-theory.html#axiom-and-theorems-of-probability"><i class="fa fa-check"></i><b>2.2.1</b> Axiom and Theorems of Probability</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-theory.html"><a href="probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.3" data-path="probability-theory.html"><a href="probability-theory.html#random-variable"><i class="fa fa-check"></i><b>2.2.3</b> Random variable</a></li>
<li class="chapter" data-level="2.2.4" data-path="probability-theory.html"><a href="probability-theory.html#moment-generating-function"><i class="fa fa-check"></i><b>2.2.4</b> Moment generating function</a></li>
<li class="chapter" data-level="2.2.5" data-path="probability-theory.html"><a href="probability-theory.html#moment"><i class="fa fa-check"></i><b>2.2.5</b> Moment</a></li>
<li class="chapter" data-level="2.2.6" data-path="probability-theory.html"><a href="probability-theory.html#distributions"><i class="fa fa-check"></i><b>2.2.6</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="general-math.html"><a href="general-math.html"><i class="fa fa-check"></i><b>2.3</b> General Math</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="general-math.html"><a href="general-math.html#law-of-large-numbers"><i class="fa fa-check"></i><b>2.3.1</b> Law of large numbers</a></li>
<li class="chapter" data-level="2.3.2" data-path="general-math.html"><a href="general-math.html#law-of-iterated-expectation"><i class="fa fa-check"></i><b>2.3.2</b> Law of Iterated Expectation</a></li>
<li class="chapter" data-level="2.3.3" data-path="general-math.html"><a href="general-math.html#convergence"><i class="fa fa-check"></i><b>2.3.3</b> Convergence</a></li>
<li class="chapter" data-level="2.3.4" data-path="general-math.html"><a href="general-math.html#sufficient-statistics"><i class="fa fa-check"></i><b>2.3.4</b> Sufficient Statistics</a></li>
<li class="chapter" data-level="2.3.5" data-path="general-math.html"><a href="general-math.html#parameter-transformations"><i class="fa fa-check"></i><b>2.3.5</b> Parameter transformations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>2.4</b> Methods</a></li>
<li class="chapter" data-level="2.5" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>2.5</b> Data Manipulation</a></li>
</ul></li>
<li class="part"><span><b>I BASIC</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-stat.html"><a href="descriptive-stat.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="numerical-measures.html"><a href="numerical-measures.html"><i class="fa fa-check"></i><b>3.1</b> Numerical Measures</a></li>
<li class="chapter" data-level="3.2" data-path="graphical-measures.html"><a href="graphical-measures.html"><i class="fa fa-check"></i><b>3.2</b> Graphical Measures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="graphical-measures.html"><a href="graphical-measures.html#shape"><i class="fa fa-check"></i><b>3.2.1</b> Shape</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="normality-assessment.html"><a href="normality-assessment.html"><i class="fa fa-check"></i><b>3.3</b> Normality Assessment</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="normality-assessment.html"><a href="normality-assessment.html#graphical-assessment"><i class="fa fa-check"></i><b>3.3.1</b> Graphical Assessment</a></li>
<li class="chapter" data-level="3.3.2" data-path="normality-assessment.html"><a href="normality-assessment.html#summary-statistics"><i class="fa fa-check"></i><b>3.3.2</b> Summary Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-statistical-inference.html"><a href="basic-statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>4.1</b> One Sample Inference</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#the-mean"><i class="fa fa-check"></i><b>4.1.1</b> The Mean</a></li>
<li class="chapter" data-level="4.1.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-variance"><i class="fa fa-check"></i><b>4.1.2</b> Single Variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-proportion-p"><i class="fa fa-check"></i><b>4.1.3</b> Single Proportion (p)</a></li>
<li class="chapter" data-level="4.1.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#power"><i class="fa fa-check"></i><b>4.1.4</b> Power</a></li>
<li class="chapter" data-level="4.1.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#sample-size"><i class="fa fa-check"></i><b>4.1.5</b> Sample Size</a></li>
<li class="chapter" data-level="4.1.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#note"><i class="fa fa-check"></i><b>4.1.6</b> Note</a></li>
<li class="chapter" data-level="4.1.7" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-non-parametric-methods"><i class="fa fa-check"></i><b>4.1.7</b> One-sample Non-parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>4.2</b> Two Sample Inference</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#means"><i class="fa fa-check"></i><b>4.2.1</b> Means</a></li>
<li class="chapter" data-level="4.2.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#variances"><i class="fa fa-check"></i><b>4.2.2</b> Variances</a></li>
<li class="chapter" data-level="4.2.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#power-1"><i class="fa fa-check"></i><b>4.2.3</b> Power</a></li>
<li class="chapter" data-level="4.2.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#sample-size-1"><i class="fa fa-check"></i><b>4.2.4</b> Sample Size</a></li>
<li class="chapter" data-level="4.2.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#matched-pair-designs"><i class="fa fa-check"></i><b>4.2.5</b> Matched Pair Designs</a></li>
<li class="chapter" data-level="4.2.6" data-path="two-sample-inference.html"><a href="two-sample-inference.html#nonparametric-tests-for-two-samples"><i class="fa fa-check"></i><b>4.2.6</b> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html"><i class="fa fa-check"></i><b>4.3</b> Categorical Data Analysis</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#inferences-for-small-samples"><i class="fa fa-check"></i><b>4.3.1</b> Inferences for Small Samples</a></li>
<li class="chapter" data-level="4.3.2" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#test-of-association"><i class="fa fa-check"></i><b>4.3.2</b> Test of Association</a></li>
<li class="chapter" data-level="4.3.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-association"><i class="fa fa-check"></i><b>4.3.3</b> Ordinal Association</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II REGRESSION</b></span></li>
<li class="chapter" data-level="5" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>5</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5.1</b> Ordinary Least Squares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#simple-regression-basic-model"><i class="fa fa-check"></i><b>5.1.1</b> Simple Regression (Basic Model)</a></li>
<li class="chapter" data-level="5.1.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="5.1.3" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#ols-assumptions"><i class="fa fa-check"></i><b>5.1.3</b> OLS Assumptions</a></li>
<li class="chapter" data-level="5.1.4" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#theorems"><i class="fa fa-check"></i><b>5.1.4</b> Theorems</a></li>
<li class="chapter" data-level="5.1.5" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#variable-selection"><i class="fa fa-check"></i><b>5.1.5</b> Variable Selection</a></li>
<li class="chapter" data-level="5.1.6" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#diagnostics-1"><i class="fa fa-check"></i><b>5.1.6</b> Diagnostics</a></li>
<li class="chapter" data-level="5.1.7" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#model-validation"><i class="fa fa-check"></i><b>5.1.7</b> Model Validation</a></li>
<li class="chapter" data-level="5.1.8" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#finite-sample-properties"><i class="fa fa-check"></i><b>5.1.8</b> Finite Sample Properties</a></li>
<li class="chapter" data-level="5.1.9" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#large-sample-properties"><i class="fa fa-check"></i><b>5.1.9</b> Large Sample Properties</a></li>
<li class="chapter" data-level="5.1.10" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#application"><i class="fa fa-check"></i><b>5.1.10</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html"><i class="fa fa-check"></i><b>5.2</b> Feasible Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#heteroskedasticity"><i class="fa fa-check"></i><b>5.2.1</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="5.2.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#serial-correlation"><i class="fa fa-check"></i><b>5.2.2</b> Serial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="weighted-least-squares.html"><a href="weighted-least-squares.html"><i class="fa fa-check"></i><b>5.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.4" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5.4</b> Generalized Least Squares</a></li>
<li class="chapter" data-level="5.5" data-path="feasiable-prais-winsten.html"><a href="feasiable-prais-winsten.html"><i class="fa fa-check"></i><b>5.5</b> Feasiable Prais Winsten</a></li>
<li class="chapter" data-level="5.6" data-path="feasible-group-level-random-effects.html"><a href="feasible-group-level-random-effects.html"><i class="fa fa-check"></i><b>5.6</b> Feasible group level Random Effects</a></li>
<li class="chapter" data-level="5.7" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>5.7</b> Ridge Regression</a></li>
<li class="chapter" data-level="5.8" data-path="principal-component-regression.html"><a href="principal-component-regression.html"><i class="fa fa-check"></i><b>5.8</b> Principal Component Regression</a></li>
<li class="chapter" data-level="5.9" data-path="robust-regression.html"><a href="robust-regression.html"><i class="fa fa-check"></i><b>5.9</b> Robust Regression</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="robust-regression.html"><a href="robust-regression.html#least-absolute-residuals-lar-regression"><i class="fa fa-check"></i><b>5.9.1</b> Least Absolute Residuals (LAR) Regression</a></li>
<li class="chapter" data-level="5.9.2" data-path="robust-regression.html"><a href="robust-regression.html#least-median-of-squares-lms-regression"><i class="fa fa-check"></i><b>5.9.2</b> Least Median of Squares (LMS) Regression</a></li>
<li class="chapter" data-level="5.9.3" data-path="robust-regression.html"><a href="robust-regression.html#iteratively-reweighted-least-squares-irls-robust-regression"><i class="fa fa-check"></i><b>5.9.3</b> Iteratively Reweighted Least Squares (IRLS) Robust Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>5.10</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#motivation-for-mle"><i class="fa fa-check"></i><b>5.10.1</b> Motivation for MLE</a></li>
<li class="chapter" data-level="5.10.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#assumption"><i class="fa fa-check"></i><b>5.10.2</b> Assumption</a></li>
<li class="chapter" data-level="5.10.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>5.10.3</b> Properties</a></li>
<li class="chapter" data-level="5.10.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#compare-to-ols"><i class="fa fa-check"></i><b>5.10.4</b> Compare to OLS</a></li>
<li class="chapter" data-level="5.10.5" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#application-1"><i class="fa fa-check"></i><b>5.10.5</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Non-linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference-1.html"><a href="inference-1.html"><i class="fa fa-check"></i><b>6.1</b> Inference</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="inference-1.html"><a href="inference-1.html#linear-function-of-the-parameters"><i class="fa fa-check"></i><b>6.1.1</b> Linear Function of the Parameters</a></li>
<li class="chapter" data-level="6.1.2" data-path="inference-1.html"><a href="inference-1.html#nonlinear"><i class="fa fa-check"></i><b>6.1.2</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html"><i class="fa fa-check"></i><b>6.2</b> Non-linear Least Squares</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#alternative-of-gauss-newton-algorithm"><i class="fa fa-check"></i><b>6.2.1</b> Alternative of Gauss-Newton Algorithm</a></li>
<li class="chapter" data-level="6.2.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#practical-considerations"><i class="fa fa-check"></i><b>6.2.2</b> Practical Considerations</a></li>
<li class="chapter" data-level="6.2.3" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#modelestiamtion-adequcy"><i class="fa fa-check"></i><b>6.2.3</b> Model/Estiamtion Adequcy</a></li>
<li class="chapter" data-level="6.2.4" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#application-2"><i class="fa fa-check"></i><b>6.2.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>6.3</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#logistic-regression"><i class="fa fa-check"></i><b>6.3.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="6.3.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#probit-regression"><i class="fa fa-check"></i><b>6.3.2</b> Probit Regression</a></li>
<li class="chapter" data-level="6.3.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#binomial-regression"><i class="fa fa-check"></i><b>6.3.3</b> Binomial Regression</a></li>
<li class="chapter" data-level="6.3.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>6.3.4</b> Poisson Regression</a></li>
<li class="chapter" data-level="6.3.5" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#negative-binomial-regression"><i class="fa fa-check"></i><b>6.3.5</b> Negative Binomial Regression</a></li>
<li class="chapter" data-level="6.3.6" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#multinomial"><i class="fa fa-check"></i><b>6.3.6</b> Multinomial</a></li>
<li class="chapter" data-level="6.3.7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalization"><i class="fa fa-check"></i><b>6.3.7</b> Generalization</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>6.4</b> Generalized Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="generalized-linear-mixed-models.html"><a href="generalized-linear-mixed-models.html#dependent-data"><i class="fa fa-check"></i><b>6.4.1</b> Dependent Data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="generalized-method-of-moments.html"><a href="generalized-method-of-moments.html"><i class="fa fa-check"></i><b>6.5</b> Generalized Method of Moments</a></li>
<li class="chapter" data-level="6.6" data-path="minimum-distance.html"><a href="minimum-distance.html"><i class="fa fa-check"></i><b>6.6</b> Minimum Distance</a></li>
<li class="chapter" data-level="6.7" data-path="spline-regression.html"><a href="spline-regression.html"><i class="fa fa-check"></i><b>6.7</b> Spline Regression</a>
<ul>
<li class="chapter" data-level="6.7.1" data-path="spline-regression.html"><a href="spline-regression.html#regression-splines"><i class="fa fa-check"></i><b>6.7.1</b> Regression Splines</a></li>
<li class="chapter" data-level="6.7.2" data-path="spline-regression.html"><a href="spline-regression.html#natural-splines"><i class="fa fa-check"></i><b>6.7.2</b> Natural splines</a></li>
<li class="chapter" data-level="6.7.3" data-path="spline-regression.html"><a href="spline-regression.html#smoothing-splines"><i class="fa fa-check"></i><b>6.7.3</b> Smoothing splines</a></li>
<li class="chapter" data-level="6.7.4" data-path="spline-regression.html"><a href="spline-regression.html#application-5"><i class="fa fa-check"></i><b>6.7.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="6.8" data-path="generalized-additive-models.html"><a href="generalized-additive-models.html"><i class="fa fa-check"></i><b>6.8</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="6.9" data-path="quantile-regression.html"><a href="quantile-regression.html"><i class="fa fa-check"></i><b>6.9</b> Quantile Regression</a>
<ul>
<li class="chapter" data-level="6.9.1" data-path="quantile-regression.html"><a href="quantile-regression.html#application-6"><i class="fa fa-check"></i><b>6.9.1</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="model-specification.html"><a href="model-specification.html"><i class="fa fa-check"></i><b>7</b> Model Specification</a>
<ul>
<li class="chapter" data-level="7.1" data-path="nested-model.html"><a href="nested-model.html"><i class="fa fa-check"></i><b>7.1</b> Nested Model</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="nested-model.html"><a href="nested-model.html#chow-test"><i class="fa fa-check"></i><b>7.1.1</b> Chow test</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="non-nested-model.html"><a href="non-nested-model.html"><i class="fa fa-check"></i><b>7.2</b> Non-Nested Model</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="non-nested-model.html"><a href="non-nested-model.html#davidson-mackinnon-test"><i class="fa fa-check"></i><b>7.2.1</b> Davidson-Mackinnon test</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html"><i class="fa fa-check"></i><b>7.3</b> Heteroskedasticity</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#breusch-pagan-test"><i class="fa fa-check"></i><b>7.3.1</b> Breusch-Pagan test</a></li>
<li class="chapter" data-level="7.3.2" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#white-test"><i class="fa fa-check"></i><b>7.3.2</b> White test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="endogeneity.html"><a href="endogeneity.html"><i class="fa fa-check"></i><b>8</b> Endogeneity</a>
<ul>
<li class="chapter" data-level="8.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html"><i class="fa fa-check"></i><b>8.1</b> Endogenous Treatment</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#instrumental-variable"><i class="fa fa-check"></i><b>8.1.1</b> Instrumental Variable</a></li>
<li class="chapter" data-level="8.1.2" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#internal-instrumental-variable"><i class="fa fa-check"></i><b>8.1.2</b> Internal instrumental variable</a></li>
<li class="chapter" data-level="8.1.3" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#proxy-variables"><i class="fa fa-check"></i><b>8.1.3</b> Proxy Variables</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html"><i class="fa fa-check"></i><b>8.2</b> Endogenous Sample Selection</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-2"><i class="fa fa-check"></i><b>8.2.1</b> Tobit-2</a></li>
<li class="chapter" data-level="8.2.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-5"><i class="fa fa-check"></i><b>8.2.2</b> Tobit-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="imputation-missing-data.html"><a href="imputation-missing-data.html"><i class="fa fa-check"></i><b>9</b> Imputation (Missing Data)</a>
<ul>
<li class="chapter" data-level="9.1" data-path="assumptions-1.html"><a href="assumptions-1.html"><i class="fa fa-check"></i><b>9.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-completely-at-random-mcar"><i class="fa fa-check"></i><b>9.1.1</b> Missing Completely at Random (MCAR)</a></li>
<li class="chapter" data-level="9.1.2" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-at-random-mar"><i class="fa fa-check"></i><b>9.1.2</b> Missing at Random (MAR)</a></li>
<li class="chapter" data-level="9.1.3" data-path="assumptions-1.html"><a href="assumptions-1.html#ignorable"><i class="fa fa-check"></i><b>9.1.3</b> Ignorable</a></li>
<li class="chapter" data-level="9.1.4" data-path="assumptions-1.html"><a href="assumptions-1.html#nonignorable"><i class="fa fa-check"></i><b>9.1.4</b> Nonignorable</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html"><i class="fa fa-check"></i><b>9.2</b> Solutions to Missing data</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#listwise-deletion"><i class="fa fa-check"></i><b>9.2.1</b> Listwise Deletion</a></li>
<li class="chapter" data-level="9.2.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#pairwise-deletion"><i class="fa fa-check"></i><b>9.2.2</b> Pairwise Deletion</a></li>
<li class="chapter" data-level="9.2.3" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#dummy-variable-adjustment"><i class="fa fa-check"></i><b>9.2.3</b> Dummy Variable Adjustment</a></li>
<li class="chapter" data-level="9.2.4" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#imputation"><i class="fa fa-check"></i><b>9.2.4</b> Imputation</a></li>
<li class="chapter" data-level="9.2.5" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#heckmans-sample-selection-model"><i class="fa fa-check"></i><b>9.2.5</b> Heckman’s Sample Selection Model</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="criteria-for-choosing-an-effective-approach.html"><a href="criteria-for-choosing-an-effective-approach.html"><i class="fa fa-check"></i><b>9.3</b> Criteria for Choosing an Effective Approach</a></li>
<li class="chapter" data-level="9.4" data-path="another-perspective.html"><a href="another-perspective.html"><i class="fa fa-check"></i><b>9.4</b> Another Perspective</a></li>
<li class="chapter" data-level="9.5" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html"><i class="fa fa-check"></i><b>9.5</b> Diagnosing the Mechanism</a>
<ul>
<li class="chapter" data-level="9.5.1" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mar-vs.-mnar"><i class="fa fa-check"></i><b>9.5.1</b> MAR vs. MNAR</a></li>
<li class="chapter" data-level="9.5.2" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mcar-vs.-mar"><i class="fa fa-check"></i><b>9.5.2</b> MCAR vs. MAR</a></li>
</ul></li>
<li class="chapter" data-level="9.6" data-path="application-7.html"><a href="application-7.html"><i class="fa fa-check"></i><b>9.6</b> Application</a>
<ul>
<li class="chapter" data-level="9.6.1" data-path="application-7.html"><a href="application-7.html#imputation-with-mean-median-mode"><i class="fa fa-check"></i><b>9.6.1</b> Imputation with mean / median / mode</a></li>
<li class="chapter" data-level="9.6.2" data-path="application-7.html"><a href="application-7.html#knn"><i class="fa fa-check"></i><b>9.6.2</b> KNN</a></li>
<li class="chapter" data-level="9.6.3" data-path="application-7.html"><a href="application-7.html#rpart"><i class="fa fa-check"></i><b>9.6.3</b> rpart</a></li>
<li class="chapter" data-level="9.6.4" data-path="application-7.html"><a href="application-7.html#mice-multivariate-imputation-via-chained-equations"><i class="fa fa-check"></i><b>9.6.4</b> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li class="chapter" data-level="9.6.5" data-path="application-7.html"><a href="application-7.html#amelia"><i class="fa fa-check"></i><b>9.6.5</b> Amelia</a></li>
<li class="chapter" data-level="9.6.6" data-path="application-7.html"><a href="application-7.html#missforest"><i class="fa fa-check"></i><b>9.6.6</b> missForest</a></li>
<li class="chapter" data-level="9.6.7" data-path="application-7.html"><a href="application-7.html#hmisc"><i class="fa fa-check"></i><b>9.6.7</b> Hmisc</a></li>
<li class="chapter" data-level="9.6.8" data-path="application-7.html"><a href="application-7.html#mi"><i class="fa fa-check"></i><b>9.6.8</b> mi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>10</b> Data</a>
<ul>
<li class="chapter" data-level="10.1" data-path="cross-sectional.html"><a href="cross-sectional.html"><i class="fa fa-check"></i><b>10.1</b> Cross-Sectional</a></li>
<li class="chapter" data-level="10.2" data-path="time-series-1.html"><a href="time-series-1.html"><i class="fa fa-check"></i><b>10.2</b> Time Series</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="time-series-1.html"><a href="time-series-1.html#deterministic-time-trend"><i class="fa fa-check"></i><b>10.2.1</b> Deterministic Time trend</a></li>
<li class="chapter" data-level="10.2.2" data-path="time-series-1.html"><a href="time-series-1.html#feedback-effect"><i class="fa fa-check"></i><b>10.2.2</b> Feedback Effect</a></li>
<li class="chapter" data-level="10.2.3" data-path="time-series-1.html"><a href="time-series-1.html#dynamic-specification"><i class="fa fa-check"></i><b>10.2.3</b> Dynamic Specification</a></li>
<li class="chapter" data-level="10.2.4" data-path="time-series-1.html"><a href="time-series-1.html#dynamically-complete"><i class="fa fa-check"></i><b>10.2.4</b> Dynamically Complete</a></li>
<li class="chapter" data-level="10.2.5" data-path="time-series-1.html"><a href="time-series-1.html#highly-persistent-data"><i class="fa fa-check"></i><b>10.2.5</b> Highly Persistent Data</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html"><i class="fa fa-check"></i><b>10.3</b> Repeated Cross Sections</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html#pooled-cross-section"><i class="fa fa-check"></i><b>10.3.1</b> Pooled Cross Section</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>10.4</b> Panel Data</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="panel-data.html"><a href="panel-data.html#pooled-ols-esimator"><i class="fa fa-check"></i><b>10.4.1</b> Pooled OLS Esimator</a></li>
<li class="chapter" data-level="10.4.2" data-path="panel-data.html"><a href="panel-data.html#individual-specific-effects-model"><i class="fa fa-check"></i><b>10.4.2</b> Individual-specific effects model</a></li>
<li class="chapter" data-level="10.4.3" data-path="panel-data.html"><a href="panel-data.html#tests-for-assumptions"><i class="fa fa-check"></i><b>10.4.3</b> Tests for Assumptions</a></li>
<li class="chapter" data-level="10.4.4" data-path="panel-data.html"><a href="panel-data.html#model-selection"><i class="fa fa-check"></i><b>10.4.4</b> Model Selection</a></li>
<li class="chapter" data-level="10.4.5" data-path="panel-data.html"><a href="panel-data.html#summary-1"><i class="fa fa-check"></i><b>10.4.5</b> Summary</a></li>
<li class="chapter" data-level="10.4.6" data-path="panel-data.html"><a href="panel-data.html#application-8"><i class="fa fa-check"></i><b>10.4.6</b> Application</a></li>
<li class="chapter" data-level="10.4.7" data-path="panel-data.html"><a href="panel-data.html#other-estimators"><i class="fa fa-check"></i><b>10.4.7</b> Other Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>11</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="11.1" data-path="types-of-hypothesis-testing.html"><a href="types-of-hypothesis-testing.html"><i class="fa fa-check"></i><b>11.1</b> Types of hypothesis testing</a></li>
<li class="chapter" data-level="11.2" data-path="wald-test.html"><a href="wald-test.html"><i class="fa fa-check"></i><b>11.2</b> Wald test</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="wald-test.html"><a href="wald-test.html#multiple-hypothesis"><i class="fa fa-check"></i><b>11.2.1</b> Multiple Hypothesis</a></li>
<li class="chapter" data-level="11.2.2" data-path="wald-test.html"><a href="wald-test.html#linear-combination"><i class="fa fa-check"></i><b>11.2.2</b> Linear Combination</a></li>
<li class="chapter" data-level="11.2.3" data-path="wald-test.html"><a href="wald-test.html#application-9"><i class="fa fa-check"></i><b>11.2.3</b> Application</a></li>
<li class="chapter" data-level="11.2.4" data-path="wald-test.html"><a href="wald-test.html#nonlinear-1"><i class="fa fa-check"></i><b>11.2.4</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="the-likelihood-ratio-test.html"><a href="the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>11.3</b> The likelihood ratio test</a></li>
<li class="chapter" data-level="11.4" data-path="lagrange-multiplier-score.html"><a href="lagrange-multiplier-score.html"><i class="fa fa-check"></i><b>11.4</b> Lagrange Multiplier (Score)</a></li>
</ul></li>
<li class="part"><span><b>III EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="12" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>12</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="12.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html"><i class="fa fa-check"></i><b>12.1</b> Completely Randomized Design (CRD)</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model"><i class="fa fa-check"></i><b>12.1.1</b> Single Factor Fixed Effects Model</a></li>
<li class="chapter" data-level="12.1.2" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-random-effects-model"><i class="fa fa-check"></i><b>12.1.2</b> Single Factor Random Effects Model</a></li>
<li class="chapter" data-level="12.1.3" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova"><i class="fa fa-check"></i><b>12.1.3</b> Two Factor Fixed Effect ANOVA</a></li>
<li class="chapter" data-level="12.1.4" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-random-effects-anova"><i class="fa fa-check"></i><b>12.1.4</b> Two-Way Random Effects ANOVA</a></li>
<li class="chapter" data-level="12.1.5" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova"><i class="fa fa-check"></i><b>12.1.5</b> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html"><i class="fa fa-check"></i><b>12.2</b> Nonparametric ANOVA</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#kruskal-wallis"><i class="fa fa-check"></i><b>12.2.1</b> Kruskal-Wallis</a></li>
<li class="chapter" data-level="12.2.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#friedman-test"><i class="fa fa-check"></i><b>12.2.2</b> Friedman Test</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html"><i class="fa fa-check"></i><b>12.3</b> Sample Size Planning for ANOVA</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#balanced-designs"><i class="fa fa-check"></i><b>12.3.1</b> Balanced Designs</a></li>
<li class="chapter" data-level="12.3.2" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#randomized-block-experiments"><i class="fa fa-check"></i><b>12.3.2</b> Randomized Block Experiments</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html"><i class="fa fa-check"></i><b>12.4</b> Randomized Block Designs</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html#tukey-test-of-additivity"><i class="fa fa-check"></i><b>12.4.1</b> Tukey Test of Additivity</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="nested-designs.html"><a href="nested-designs.html"><i class="fa fa-check"></i><b>12.5</b> Nested Designs</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="nested-designs.html"><a href="nested-designs.html#two-factor-nested-designs"><i class="fa fa-check"></i><b>12.5.1</b> Two-Factor Nested Designs</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html"><i class="fa fa-check"></i><b>12.6</b> Single Factor Covariance Model</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>13</b> Causality</a></li>
<li class="chapter" data-level="14" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>14</b> Report</a>
<ul>
<li class="chapter" data-level="14.1" data-path="one-summary-table.html"><a href="one-summary-table.html"><i class="fa fa-check"></i><b>14.1</b> One summary table</a></li>
<li class="chapter" data-level="14.2" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>14.2</b> Model Comparison</a></li>
<li class="chapter" data-level="14.3" data-path="changes-in-an-estimate.html"><a href="changes-in-an-estimate.html"><i class="fa fa-check"></i><b>14.3</b> Changes in an estimate</a></li>
</ul></li>
<li class="appendix"><span><b>APPENDIX</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a>
<ul>
<li class="chapter" data-level="A.1" data-path="short-cut.html"><a href="short-cut.html"><i class="fa fa-check"></i><b>A.1</b> Short-cut</a></li>
<li class="chapter" data-level="A.2" data-path="function-short-cut.html"><a href="function-short-cut.html"><i class="fa fa-check"></i><b>A.2</b> Function short-cut</a></li>
<li class="chapter" data-level="A.3" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>A.3</b> Citation</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bookdown-cheat-sheet.html"><a href="bookdown-cheat-sheet.html"><i class="fa fa-check"></i><b>B</b> Bookdown cheat sheet</a>
<ul>
<li class="chapter" data-level="B.1" data-path="operation.html"><a href="operation.html"><i class="fa fa-check"></i><b>B.1</b> Operation</a></li>
<li class="chapter" data-level="B.2" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html"><i class="fa fa-check"></i><b>B.2</b> Math Expresssion/ Syntax</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html#statistics-notation"><i class="fa fa-check"></i><b>B.2.1</b> Statistics Notation</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="table.html"><a href="table.html"><i class="fa fa-check"></i><b>B.3</b> Table</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Appendix</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generalized-linear-models" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Generalized Linear Models</h2>
<p>Even though we call it generalized linear model, it is still under the paradigm of non-linear regression, because the form of the regression model is non-linear. The name generalized linear model derived from the fact that we have <span class="math inline">\(\mathbf{x&#39;_i \beta}\)</span> (which is linear form) in the model.</p>
<div id="logistic-regression" class="section level3" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Logistic Regression</h3>
<p><span class="math display">\[
p_i = f(\mathbf{x}_i ; \beta) = \frac{exp(\mathbf{x_i&#39;\beta})}{1 + exp(\mathbf{x_i&#39;\beta})}
\]</span> Equivalently,</p>
<p><span class="math display">\[
logit(p_i) = log(\frac{p_i}{1+p_i}) = \mathbf{x_i&#39;\beta}
\]</span> where <span class="math inline">\(\frac{p_i}{1+p_i}\)</span>is the <strong>odds</strong>.</p>
<p>In this form, the model is specified such that <strong>a function of the mean response is linear</strong>. Hence, <strong>Generalized Linear Models</strong></p>
<p>The likelihood function</p>
<p><span class="math display">\[
L(p_i) = \prod_{i=1}^{n} p_i^{Y_i}(1-p_i)^{1-Y_i}
\]</span> where <span class="math inline">\(p_i = \frac{\mathbf{x&#39;_i \beta}}{1+\mathbf{x&#39;_i \beta}}\)</span> and <span class="math inline">\(1-p_i = (1+ exp(\mathbf{x&#39;_i \beta}))^{-1}\)</span></p>
<p>Hence, our objective function is</p>
<p><span class="math display">\[
Q(\beta) = log(L(\beta)) = \sum_{i=1}^n Y_i \mathbf{x&#39;_i \beta} - \sum_{i=1}^n  log(1+ exp(\mathbf{x&#39;_i \beta}))
\]</span></p>
<p>we could maximize this function numerically using the optimization method above, which allows us to find numerical MLE for <span class="math inline">\(\hat{\beta}\)</span>. Then we can use the standard asymptotic properties of MLEs to make inference.</p>
<p>Property of MLEs is that parameters are asymptotically unbiased with sample variance-covariance matrix given by the <strong>inverse Fisher information matrix</strong></p>
<p><span class="math display">\[
\hat{\beta} \dot{\sim} AN(\beta,[\mathbf{I}(\beta)]^{-1})
\]</span> where the <strong>Fisher Information matrix</strong>, <span class="math inline">\(\mathbf{I}(\beta)\)</span> is</p>
<p><span class="math display">\[
\begin{align}
\mathbf{I}(\beta) &amp;= E[\frac{\partial \log(L(\beta))}{\partial (\beta)}\frac{\partial \log(L(\beta))}{\partial \beta&#39;}] \\
&amp;= E[(\frac{\partial \log(L(\beta))}{\partial \beta_i} \frac{\partial \log(L(\beta))}{\partial \beta_j})_{ij}]
\end{align}
\]</span> Under <strong>regularity conditions</strong>, this is equivalent to the negative of the expected value of the Hessian Matrix</p>
<p><span class="math display">\[
\begin{align}
\mathbf{I}(\beta) &amp;= -E[\frac{\partial^2 \log(L(\beta))}{\partial \beta \partial \beta&#39;}] \\
&amp;= -E[(\frac{\partial^2 \log(L(\beta))}{\partial \beta_i \partial \beta_j})_{ij}]
\end{align}
\]</span></p>
<p>Example:</p>
<p><span class="math display">\[
x_i&#39; \beta = \beta_0 + \beta_1 x_i
\]</span></p>
<p><span class="math display">\[
- \frac{\partial^2 \ln(L(\beta))}{\partial \beta^2_0} = \sum_{i=1}^n \frac{\exp(x&#39;_i \beta)}{1 + \exp(x&#39;_i \beta)} - [\frac{\exp(x_i&#39; \beta)}{1+ \exp(x&#39;_i \beta)}]^2 = \sum_{i=1}^n p_i (1-p_i) \\
- \frac{\partial^2 \ln(L(\beta))}{\partial \beta^2_1} = \sum_{i=1}^n \frac{x_i^2\exp(x&#39;_i \beta)}{1 + \exp(x&#39;_i \beta)} - [\frac{x_i\exp(x_i&#39; \beta)}{1+ \exp(x&#39;_i \beta)}]^2 = \sum_{i=1}^n x_i^2p_i (1-p_i) \\
- \frac{\partial^2 \ln(L(\beta))}{\partial \beta_0 \partial \beta_1} = \sum_{i=1}^n \frac{x_i\exp(x&#39;_i \beta)}{1 + \exp(x&#39;_i \beta)} - x_i[\frac{\exp(x_i&#39; \beta)}{1+ \exp(x&#39;_i \beta)}]^2 = \sum_{i=1}^n x_ip_i (1-p_i) \\
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\mathbf{I} (\beta) = 
\left[
\begin{array}
{cc}
\sum_i p_i(1-p_i) &amp;&amp; \sum_i x_i p_i(1-p_i) \\
\sum_i x_i p_i(1-p_i) &amp;&amp; \sum_i x_i^2 p_i(1-p_i)
\end{array}
\right]
\]</span></p>
<p><strong>Inference</strong></p>
<p><strong>Likelihood Ratio Tests</strong></p>
<p>To formulate the test, let <span class="math inline">\(\beta = [\beta_1&#39;, \beta_2&#39;]&#39;\)</span>. If you are interested in testing a hypothesis about <span class="math inline">\(\beta_1\)</span>, then we leave <span class="math inline">\(\beta_2\)</span> unspecified (called <strong>nuisance parameters</strong>). <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> can either a <strong>vector</strong> or <strong>scalar</strong>, or <span class="math inline">\(\beta_2\)</span> can be null.</p>
<p>Example: <span class="math inline">\(H_0: \beta_1 = \beta_{1,0}\)</span> (where <span class="math inline">\(\beta_{1,0}\)</span> is specified) and <span class="math inline">\(\hat{\beta}_{2,0}\)</span> be the MLE of <span class="math inline">\(\beta_2\)</span> under the restriction that <span class="math inline">\(\beta_1 = \beta_{1,0}\)</span>. The likelihood ratio test statistic is</p>
<p><span class="math display">\[
-2\log\Lambda = -2[\log(L(\beta_{1,0},\hat{\beta}_{2,0})) - \log(L(\hat{\beta}_1,\hat{\beta}_2))]
\]</span> where</p>
<ul>
<li>the first term is the value fo the likelihood for the fitted restricted model<br />
</li>
<li>the second term is the likelihood value of the fitted unrestricted model</li>
</ul>
<p>Under the null,</p>
<p><span class="math display">\[
-2 \log \Lambda \sim \chi^2_{\upsilon}
\]</span> where <span class="math inline">\(\upsilon\)</span> is the dimension of <span class="math inline">\(\beta_1\)</span></p>
<p>We reject the null when <span class="math inline">\(-2\log \Lambda &gt; \chi_{\upsilon,1-\alpha}^2\)</span></p>
<p><strong>Wald Statistics</strong></p>
<p>Based on</p>
<p><span class="math display">\[
\hat{\beta} \sim AN (\beta, [\mathbf{I}(\beta)^{-1}])
\]</span> <span class="math display">\[
H_0: \mathbf{L}\hat{\beta} = 0 
\]</span> where <span class="math inline">\(\mathbf{L}\)</span> is a q x p matrix with q linearly independent rows. Then</p>
<p><span class="math display">\[
W = (\mathbf{L\hat{\beta}})&#39;(\mathbf{L[I(\hat{\beta})]^{-1}L&#39;})^{-1}(\mathbf{L\hat{\beta}})
\]</span> under the null hypothesis</p>
<p>Confidence interval</p>
<p><span class="math display">\[
\hat{\beta}_i \pm 1.96 \hat{s}_{ii}^2
\]</span> where <span class="math inline">\(\hat{s}_{ii}^2\)</span> is the i-th diagonal of <span class="math inline">\(\mathbf{[I(\hat{\beta})]}^{-1}\)</span></p>
<p>If you have</p>
<ul>
<li>large sample size, the likelihood ratio and Wald tests have similar results.<br />
</li>
<li>small sample size, the likelihood ratio test is better.</li>
</ul>
<p><strong>Logistic Regression: Interpretation of</strong> <span class="math inline">\(\beta\)</span></p>
<p>For single regressor, the model is</p>
<p><span class="math display">\[
logit\{\hat{p}_{x_i}\} \equiv logit (\hat{p}_i) = \log(\frac{\hat{p}_i}{1 - \hat{p}_i}) = \hat{\beta}_0 + \hat{\beta}_1 x_i
\]</span></p>
<p>When <span class="math inline">\(x= x_i + 1\)</span></p>
<p><span class="math display">\[
logit\{\hat{p}_{x_i +1}\} = \hat{\beta}_0 + \hat{\beta}(x_i + 1) = logit\{\hat{p}_{x_i}\} + \hat{\beta}_1
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
logit\{\hat{p}_{x_i +1}\} - logit\{\hat{p}_{x_i}\} = log\{odds[\hat{p}_{x_i +1}]\} - log\{odds[\hat{p}_{x_i}]\} \\
= log(\frac{odds[\hat{p}_{x_i + 1}]}{odds[\hat{p}_{x_i}]}) = \hat{\beta}_1
\]</span></p>
<p>and</p>
<p><span class="math display">\[
exp(\hat{\beta}_1) = \frac{odds[\hat{p}_{x_i + 1}]}{odds[\hat{p}_{x_i}]}
\]</span> the estimated <strong>odds ratio</strong></p>
<p>the estimated odds ratio, when there is a difference of c units in the regressor x, is <span class="math inline">\(exp(c\hat{\beta}_1)\)</span>. When there are multiple covariates, <span class="math inline">\(exp(\hat{\beta}_k)\)</span> is the estimated odds ratio for the variable <span class="math inline">\(x_k\)</span>, assuming that all of the other variables are held constant.</p>
<p><strong>Inference on the Mean Response</strong></p>
<p>Let <span class="math inline">\(x_h = (1, x_{h1}, ...,x_{h,p-1})&#39;\)</span>. Then</p>
<p><span class="math display">\[
\hat{p}_h = \frac{exp(\mathbf{x&#39;_h \hat{\beta}})}{1 + exp(\mathbf{x&#39;_h \hat{\beta}})}
\]</span></p>
<p>and <span class="math inline">\(s^2(\hat{p}_h) = \mathbf{x&#39;_h[I(\hat{\beta})]^{-1}x_h}\)</span></p>
<p>For new observation, we can have a cutoff point to decide whether y = 0 or 1.</p>
<div id="application-3" class="section level4" number="6.3.1.1">
<h4><span class="header-section-number">6.3.1.1</span> Application</h4>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="generalized-linear-models.html#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(kableExtra)</span>
<span id="cb222-2"><a href="generalized-linear-models.html#cb222-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb222-3"><a href="generalized-linear-models.html#cb222-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pscl)</span>
<span id="cb222-4"><a href="generalized-linear-models.html#cb222-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb222-5"><a href="generalized-linear-models.html#cb222-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(faraway)</span>
<span id="cb222-6"><a href="generalized-linear-models.html#cb222-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb222-7"><a href="generalized-linear-models.html#cb222-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(agridat)</span>
<span id="cb222-8"><a href="generalized-linear-models.html#cb222-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nlstools)</span></code></pre></div>
<p>Logistic Regression</p>
<p><span class="math inline">\(x \sim Unif(-0.5,2.5)\)</span>. Then <span class="math inline">\(\eta = 0.5 + 0.75 x\)</span></p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="generalized-linear-models.html#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">23</span>) <span class="co">#set seed for reproducibility</span></span>
<span id="cb223-2"><a href="generalized-linear-models.html#cb223-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">1000</span>,<span class="at">min =</span> <span class="sc">-</span><span class="fl">0.5</span>,<span class="at">max =</span> <span class="fl">2.5</span>)</span>
<span id="cb223-3"><a href="generalized-linear-models.html#cb223-3" aria-hidden="true" tabindex="-1"></a>eta1 <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.75</span><span class="sc">*</span>x</span></code></pre></div>
<p>Passing <span class="math inline">\(\eta\)</span>’s into the inverse-logit function, we get</p>
<p><span class="math display">\[
p = \frac{\exp(\eta)}{1+ \exp(\eta)}
\]</span></p>
<p>where <span class="math inline">\(p \in [0,1]\)</span></p>
<p>Then, we generate <span class="math inline">\(y \sim Bernoulli(p)\)</span></p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="generalized-linear-models.html#cb224-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">exp</span>(eta1)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span><span class="fu">exp</span>(eta1))</span>
<span id="cb224-2"><a href="generalized-linear-models.html#cb224-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(<span class="dv">1000</span>,<span class="dv">1</span>,p)</span>
<span id="cb224-3"><a href="generalized-linear-models.html#cb224-3" aria-hidden="true" tabindex="-1"></a>BinData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">X =</span> x, <span class="at">Y =</span> y)</span></code></pre></div>
<p><strong>Model Fit</strong></p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="generalized-linear-models.html#cb225-1" aria-hidden="true" tabindex="-1"></a>Logistic_Model <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="at">formula =</span> Y <span class="sc">~</span> X,</span>
<span id="cb225-2"><a href="generalized-linear-models.html#cb225-2" aria-hidden="true" tabindex="-1"></a>                      <span class="at">family =</span> binomial, <span class="co"># family = specifies the response distribution</span></span>
<span id="cb225-3"><a href="generalized-linear-models.html#cb225-3" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> BinData)</span>
<span id="cb225-4"><a href="generalized-linear-models.html#cb225-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Logistic_Model)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Y ~ X, family = binomial, data = BinData)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.2317   0.4153   0.5574   0.7922   1.1469  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  0.46205    0.10201   4.530 5.91e-06 ***
## X            0.78527    0.09296   8.447  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1106.7  on 999  degrees of freedom
## Residual deviance: 1027.4  on 998  degrees of freedom
## AIC: 1031.4
## 
## Number of Fisher Scoring iterations: 4</code></pre>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="generalized-linear-models.html#cb227-1" aria-hidden="true" tabindex="-1"></a>nlstools<span class="sc">::</span><span class="fu">confint2</span>(Logistic_Model)</span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 0.2618709 0.6622204
## X           0.6028433 0.9676934</code></pre>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="generalized-linear-models.html#cb229-1" aria-hidden="true" tabindex="-1"></a>OddsRatio <span class="ot">&lt;-</span> <span class="fu">coef</span>(Logistic_Model) <span class="sc">%&gt;%</span> exp</span></code></pre></div>
<p>Based on the odds ratio, when</p>
<ul>
<li><span class="math inline">\(x = 0\)</span> , the odds of success of 1/59</li>
<li><span class="math inline">\(x = 1\)</span>, the odds of success increase by a factor of 2.19 (i.e., 119.29% increase).</li>
</ul>
<p>Deviance Tests</p>
<p><span class="math display">\[
H_0: \text{No variables are related to the response (i.e., model with just the intercept)} \\
H_1: \text{at least one variable is related to the response}
\]</span></p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="generalized-linear-models.html#cb230-1" aria-hidden="true" tabindex="-1"></a>Test_Dev <span class="ot">=</span> Logistic_Model<span class="sc">$</span>null.deviance <span class="sc">-</span> Logistic_Model<span class="sc">$</span>deviance</span>
<span id="cb230-2"><a href="generalized-linear-models.html#cb230-2" aria-hidden="true" tabindex="-1"></a>p_val_dev <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">-</span><span class="fu">pchisq</span>(<span class="at">q =</span> Test_Dev, <span class="at">df =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>Since we see the p-value of 0, we reject the null that no variables are related to the response</p>
<p><strong>Deviance residuals</strong></p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="generalized-linear-models.html#cb231-1" aria-hidden="true" tabindex="-1"></a>Logistic_Resids <span class="ot">&lt;-</span> <span class="fu">residuals</span>(Logistic_Model,<span class="at">type=</span><span class="st">&quot;deviance&quot;</span>)</span>
<span id="cb231-2"><a href="generalized-linear-models.html#cb231-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="at">y =</span> Logistic_Resids, <span class="at">x =</span> BinData<span class="sc">$</span>X,<span class="at">xlab =</span> <span class="st">&#39;X&#39;</span>,<span class="at">ylab =</span> <span class="st">&#39;Deviance Resids&#39;</span>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>However, this plot is not informative. Hence, we can can see the residudals plots that are grouped into bins based on prediction values.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="generalized-linear-models.html#cb232-1" aria-hidden="true" tabindex="-1"></a>plot_bin <span class="ot">&lt;-</span> <span class="cf">function</span>(Y,</span>
<span id="cb232-2"><a href="generalized-linear-models.html#cb232-2" aria-hidden="true" tabindex="-1"></a>                     X,</span>
<span id="cb232-3"><a href="generalized-linear-models.html#cb232-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">bins =</span> <span class="dv">100</span>,</span>
<span id="cb232-4"><a href="generalized-linear-models.html#cb232-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">return.DF =</span> <span class="cn">FALSE</span>) {</span>
<span id="cb232-5"><a href="generalized-linear-models.html#cb232-5" aria-hidden="true" tabindex="-1"></a>    Y_Name <span class="ot">&lt;-</span> <span class="fu">deparse</span>(<span class="fu">substitute</span>(Y))</span>
<span id="cb232-6"><a href="generalized-linear-models.html#cb232-6" aria-hidden="true" tabindex="-1"></a>    X_Name <span class="ot">&lt;-</span> <span class="fu">deparse</span>(<span class="fu">substitute</span>(X))</span>
<span id="cb232-7"><a href="generalized-linear-models.html#cb232-7" aria-hidden="true" tabindex="-1"></a>    Binned_Plot <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">Plot_Y =</span> Y, <span class="at">Plot_X =</span> X)</span>
<span id="cb232-8"><a href="generalized-linear-models.html#cb232-8" aria-hidden="true" tabindex="-1"></a>    Binned_Plot<span class="sc">$</span>bin <span class="ot">&lt;-</span></span>
<span id="cb232-9"><a href="generalized-linear-models.html#cb232-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">cut</span>(Binned_Plot<span class="sc">$</span>Plot_X, <span class="at">breaks =</span> bins) <span class="sc">%&gt;%</span> as.numeric</span>
<span id="cb232-10"><a href="generalized-linear-models.html#cb232-10" aria-hidden="true" tabindex="-1"></a>    Binned_Plot_summary <span class="ot">&lt;-</span> Binned_Plot <span class="sc">%&gt;%</span></span>
<span id="cb232-11"><a href="generalized-linear-models.html#cb232-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">group_by</span>(bin) <span class="sc">%&gt;%</span></span>
<span id="cb232-12"><a href="generalized-linear-models.html#cb232-12" aria-hidden="true" tabindex="-1"></a>        <span class="fu">summarise</span>(</span>
<span id="cb232-13"><a href="generalized-linear-models.html#cb232-13" aria-hidden="true" tabindex="-1"></a>            <span class="at">Y_ave =</span> <span class="fu">mean</span>(Plot_Y),</span>
<span id="cb232-14"><a href="generalized-linear-models.html#cb232-14" aria-hidden="true" tabindex="-1"></a>            <span class="at">X_ave =</span> <span class="fu">mean</span>(Plot_X),</span>
<span id="cb232-15"><a href="generalized-linear-models.html#cb232-15" aria-hidden="true" tabindex="-1"></a>            <span class="at">Count =</span> <span class="fu">n</span>()</span>
<span id="cb232-16"><a href="generalized-linear-models.html#cb232-16" aria-hidden="true" tabindex="-1"></a>        ) <span class="sc">%&gt;%</span> as.data.frame</span>
<span id="cb232-17"><a href="generalized-linear-models.html#cb232-17" aria-hidden="true" tabindex="-1"></a>    <span class="fu">plot</span>(</span>
<span id="cb232-18"><a href="generalized-linear-models.html#cb232-18" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> Binned_Plot_summary<span class="sc">$</span>Y_ave,</span>
<span id="cb232-19"><a href="generalized-linear-models.html#cb232-19" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> Binned_Plot_summary<span class="sc">$</span>X_ave,</span>
<span id="cb232-20"><a href="generalized-linear-models.html#cb232-20" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> Y_Name,</span>
<span id="cb232-21"><a href="generalized-linear-models.html#cb232-21" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab =</span> X_Name</span>
<span id="cb232-22"><a href="generalized-linear-models.html#cb232-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb232-23"><a href="generalized-linear-models.html#cb232-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (return.DF)</span>
<span id="cb232-24"><a href="generalized-linear-models.html#cb232-24" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(Binned_Plot_summary)</span>
<span id="cb232-25"><a href="generalized-linear-models.html#cb232-25" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb232-26"><a href="generalized-linear-models.html#cb232-26" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_bin</span>(<span class="at">Y =</span> Logistic_Resids,</span>
<span id="cb232-27"><a href="generalized-linear-models.html#cb232-27" aria-hidden="true" tabindex="-1"></a>         <span class="at">X =</span> BinData<span class="sc">$</span>X,</span>
<span id="cb232-28"><a href="generalized-linear-models.html#cb232-28" aria-hidden="true" tabindex="-1"></a>         <span class="at">bins =</span> <span class="dv">100</span>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<p>We can also see the predicted value against the residuals.</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="generalized-linear-models.html#cb233-1" aria-hidden="true" tabindex="-1"></a>Logistic_Predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(Logistic_Model,<span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb233-2"><a href="generalized-linear-models.html#cb233-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_bin</span>(<span class="at">Y =</span> Logistic_Resids, <span class="at">X =</span> Logistic_Predictions,<span class="at">bins =</span> <span class="dv">100</span>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>We can also look at a binned plot of the logistic prediction versus the true category</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="generalized-linear-models.html#cb234-1" aria-hidden="true" tabindex="-1"></a>NumBins <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb234-2"><a href="generalized-linear-models.html#cb234-2" aria-hidden="true" tabindex="-1"></a>Binned_Data <span class="ot">&lt;-</span><span class="fu">plot_bin</span>(<span class="at">Y =</span> BinData<span class="sc">$</span>Y,</span>
<span id="cb234-3"><a href="generalized-linear-models.html#cb234-3" aria-hidden="true" tabindex="-1"></a><span class="at">X =</span> Logistic_Predictions,</span>
<span id="cb234-4"><a href="generalized-linear-models.html#cb234-4" aria-hidden="true" tabindex="-1"></a><span class="at">bins =</span> NumBins,</span>
<span id="cb234-5"><a href="generalized-linear-models.html#cb234-5" aria-hidden="true" tabindex="-1"></a><span class="at">return.DF =</span> <span class="cn">TRUE</span>)</span>
<span id="cb234-6"><a href="generalized-linear-models.html#cb234-6" aria-hidden="true" tabindex="-1"></a>Binned_Data</span></code></pre></div>
<pre><code>##    bin     Y_ave     X_ave Count
## 1    1 0.5714286 0.1845581    98
## 2    2 0.5909091 0.4117980   110
## 3    3 0.6823529 0.6620605    85
## 4    4 0.6936937 0.8883213   111
## 5    5 0.6875000 1.1406997    80
## 6    6 0.7938144 1.3599227    97
## 7    7 0.8611111 1.5962995   108
## 8    8 0.8854167 1.8359575    96
## 9    9 0.8811881 2.0779920   101
## 10  10 0.9035088 2.2981478   114</code></pre>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="generalized-linear-models.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="at">lty=</span><span class="dv">2</span>,<span class="at">col=</span><span class="st">&#39;blue&#39;</span>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
<p><strong>Formal deviance test</strong></p>
<p><strong>Hosmer-Lemeshow test</strong></p>
<p>Null hypothesis: the observed events match the expected evens</p>
<p><span class="math display">\[
X^2_{HL} = \sum_{j=1}^{J} \frac{(y_j - m_j \hat{p}_j)^2}{m_j \hat{p}_j(1-\hat{p}_j)}
\]</span></p>
<p>where</p>
<ul>
<li>within the j-th bin, <span class="math inline">\(y_j\)</span> is the number of successes</li>
<li><span class="math inline">\(m_j\)</span> = number of observations</li>
<li><span class="math inline">\(\hat{p}_j\)</span> = predicted probability</li>
</ul>
<p>Under the null hypothesis, <span class="math inline">\(X^2_{HLL} \sim \chi^2_{J-1}\)</span></p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="generalized-linear-models.html#cb237-1" aria-hidden="true" tabindex="-1"></a>HL_BinVals <span class="ot">&lt;-</span></span>
<span id="cb237-2"><a href="generalized-linear-models.html#cb237-2" aria-hidden="true" tabindex="-1"></a>(Binned_Data<span class="sc">$</span>Count<span class="sc">*</span>Binned_Data<span class="sc">$</span>Y_ave <span class="sc">-</span> Binned_Data<span class="sc">$</span>Count<span class="sc">*</span>Binned_Data<span class="sc">$</span>X_ave)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span></span>
<span id="cb237-3"><a href="generalized-linear-models.html#cb237-3" aria-hidden="true" tabindex="-1"></a>Binned_Data<span class="sc">$</span>Count<span class="sc">*</span>Binned_Data<span class="sc">$</span>X_ave<span class="sc">*</span>(<span class="dv">1</span><span class="sc">-</span>Binned_Data<span class="sc">$</span>X_ave)</span>
<span id="cb237-4"><a href="generalized-linear-models.html#cb237-4" aria-hidden="true" tabindex="-1"></a>HLpval <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fu">sum</span>(HL_BinVals),<span class="at">df =</span> NumBins,<span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb237-5"><a href="generalized-linear-models.html#cb237-5" aria-hidden="true" tabindex="-1"></a>HLpval</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>Since p-value = 0.99, we do not reject the null hypothesis (i.e., the model is fitting well).</p>
<p><br></p>
</div>
</div>
<div id="probit-regression" class="section level3" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Probit Regression</h3>
<p><span class="math display">\[
E(Y_i) = p_i = \Phi(\mathbf{x_i&#39;\theta})
\]</span></p>
<p>where <span class="math inline">\(\Phi()\)</span> is the CDF of a N(0,1) random variable.</p>
<p>Other models (e..g, t–distribution; log-log; I complimentary log-log)</p>
<p>We let <span class="math inline">\(Y_i = 1\)</span> success, <span class="math inline">\(Y_i =0\)</span> no success. We assume <span class="math inline">\(Y \sim Ber\)</span> and <span class="math inline">\(p_i = P(Y_i =1)\)</span>, the success probability. We cosnider a logistic regression with the response function <span class="math inline">\(logit(p_i) = x&#39;_i \beta\)</span></p>
<p><strong>Confusion matrix</strong></p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Predicted</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Truth</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>1</td>
<td>True Positive (TP)</td>
<td>False Negative (FN)</td>
</tr>
<tr class="odd">
<td>0</td>
<td>False Positive (FP)</td>
<td>True Negative (TN)</td>
</tr>
</tbody>
</table>
<p>Sensitivity: ability to identify positive results</p>
<p><span class="math display">\[
\text{Sensitivity} = \frac{TP}{TP + FN}
\]</span></p>
<p>Specificity: ability to identify negative results</p>
<p><span class="math display">\[
\text{Specificity} = \frac{TN}{TN + FP}
\]</span></p>
<p>False positive rate: Type I error (1- specificity)</p>
<p><span class="math display">\[
\text{ False Positive Rate} = \frac{FP}{TN+ FP}
\]</span></p>
<p>False Negative Rate: Type II error (1-sensitivity)</p>
<p><span class="math display">\[
\text{False Negative Rate} = \frac{FN}{TP + FN}
\]</span></p>
<table>
<thead>
<tr class="header">
<th></th>
<th>Predicted</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Truth</td>
<td>1</td>
<td>0</td>
</tr>
<tr class="even">
<td>1</td>
<td>Sensitivity</td>
<td>False Negative Rate</td>
</tr>
<tr class="odd">
<td>0</td>
<td>False Positive Rate</td>
<td>Specificity</td>
</tr>
</tbody>
</table>
</div>
<div id="binomial-regression" class="section level3" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Binomial Regression</h3>
<p><strong>Binomial</strong></p>
<p>Here, cancer case = successes, and control case = failures.</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="generalized-linear-models.html#cb239-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;esoph&quot;</span>)</span>
<span id="cb239-2"><a href="generalized-linear-models.html#cb239-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(esoph, <span class="at">n =</span> <span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   agegp     alcgp    tobgp ncases ncontrols
## 1 25-34 0-39g/day 0-9g/day      0        40
## 2 25-34 0-39g/day    10-19      0        10
## 3 25-34 0-39g/day    20-29      0         6</code></pre>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="generalized-linear-models.html#cb241-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb241-2"><a href="generalized-linear-models.html#cb241-2" aria-hidden="true" tabindex="-1"></a>    esoph<span class="sc">$</span>ncases <span class="sc">/</span> (esoph<span class="sc">$</span>ncases <span class="sc">+</span> esoph<span class="sc">$</span>ncontrols) <span class="sc">~</span> esoph<span class="sc">$</span>alcgp,</span>
<span id="cb241-3"><a href="generalized-linear-models.html#cb241-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Proportion&quot;</span>,</span>
<span id="cb241-4"><a href="generalized-linear-models.html#cb241-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&#39;Alcohol consumption&#39;</span>,</span>
<span id="cb241-5"><a href="generalized-linear-models.html#cb241-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">main =</span> <span class="st">&#39;Esophageal Cancer data&#39;</span></span>
<span id="cb241-6"><a href="generalized-linear-models.html#cb241-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="generalized-linear-models.html#cb242-1" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(esoph<span class="sc">$</span>agegp) <span class="ot">&lt;-</span> <span class="st">&quot;factor&quot;</span></span>
<span id="cb242-2"><a href="generalized-linear-models.html#cb242-2" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(esoph<span class="sc">$</span>alcgp) <span class="ot">&lt;-</span> <span class="st">&quot;factor&quot;</span></span>
<span id="cb242-3"><a href="generalized-linear-models.html#cb242-3" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(esoph<span class="sc">$</span>tobgp) <span class="ot">&lt;-</span> <span class="st">&quot;factor&quot;</span></span></code></pre></div>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="generalized-linear-models.html#cb243-1" aria-hidden="true" tabindex="-1"></a><span class="co">#  only the alcohol consumption as a predictor</span></span>
<span id="cb243-2"><a href="generalized-linear-models.html#cb243-2" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">cbind</span>(ncases, ncontrols) <span class="sc">~</span> alcgp, <span class="at">data =</span> esoph, <span class="at">family =</span> binomial)</span>
<span id="cb243-3"><a href="generalized-linear-models.html#cb243-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(ncases, ncontrols) ~ alcgp, family = binomial, 
##     data = esoph)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.6629  -1.0478  -0.0081   0.6307   3.0296  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -2.6610     0.1921 -13.854  &lt; 2e-16 ***
## alcgp40-79    1.1064     0.2303   4.804 1.56e-06 ***
## alcgp80-119   1.6656     0.2525   6.597 4.20e-11 ***
## alcgp120+     2.2630     0.2721   8.317  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 227.24  on 87  degrees of freedom
## Residual deviance: 138.79  on 84  degrees of freedom
## AIC: 294.27
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="generalized-linear-models.html#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Coefficient Odds</span></span>
<span id="cb245-2"><a href="generalized-linear-models.html#cb245-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coefficients</span>(model) <span class="sc">%&gt;%</span> exp</span></code></pre></div>
<pre><code>## (Intercept)  alcgp40-79 alcgp80-119   alcgp120+ 
##  0.06987952  3.02331229  5.28860570  9.61142563</code></pre>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="generalized-linear-models.html#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="fu">deviance</span>(model)<span class="sc">/</span><span class="fu">df.residual</span>(model)</span></code></pre></div>
<pre><code>## [1] 1.652253</code></pre>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="generalized-linear-models.html#cb249-1" aria-hidden="true" tabindex="-1"></a>model<span class="sc">$</span>aic</span></code></pre></div>
<pre><code>## [1] 294.27</code></pre>
<div class="sourceCode" id="cb251"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb251-1"><a href="generalized-linear-models.html#cb251-1" aria-hidden="true" tabindex="-1"></a><span class="co"># alcohol consumption and age as predictors</span></span>
<span id="cb251-2"><a href="generalized-linear-models.html#cb251-2" aria-hidden="true" tabindex="-1"></a>better_model <span class="ot">&lt;-</span> <span class="fu">glm</span>(<span class="fu">cbind</span>(ncases, ncontrols) <span class="sc">~</span> agegp <span class="sc">+</span> alcgp, <span class="at">data =</span> esoph, <span class="at">family =</span> binomial)</span>
<span id="cb251-3"><a href="generalized-linear-models.html#cb251-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(better_model)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(ncases, ncontrols) ~ agegp + alcgp, family = binomial, 
##     data = esoph)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8979  -0.5592  -0.1995   0.5029   2.6250  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -5.6180     1.0217  -5.499 3.82e-08 ***
## agegp35-44    1.5376     1.0646   1.444 0.148669    
## agegp45-54    2.9470     1.0217   2.884 0.003922 ** 
## agegp55-64    3.3116     1.0172   3.255 0.001132 ** 
## agegp65-74    3.5774     1.0209   3.504 0.000458 ***
## agegp75+      3.5858     1.0620   3.377 0.000734 ***
## alcgp40-79    1.1392     0.2367   4.814 1.48e-06 ***
## alcgp80-119   1.4951     0.2600   5.749 8.97e-09 ***
## alcgp120+     2.2228     0.2843   7.820 5.29e-15 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 227.241  on 87  degrees of freedom
## Residual deviance:  64.572  on 79  degrees of freedom
## AIC: 230.05
## 
## Number of Fisher Scoring iterations: 6</code></pre>
<div class="sourceCode" id="cb253"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb253-1"><a href="generalized-linear-models.html#cb253-1" aria-hidden="true" tabindex="-1"></a>better_model<span class="sc">$</span>aic <span class="co">#smaller AIC is better</span></span></code></pre></div>
<pre><code>## [1] 230.0526</code></pre>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="generalized-linear-models.html#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coefficients</span>(better_model) <span class="sc">%&gt;%</span> exp</span></code></pre></div>
<pre><code>##  (Intercept)   agegp35-44   agegp45-54   agegp55-64   agegp65-74     agegp75+ 
##  0.003631855  4.653273722 19.047899816 27.428640745 35.780787582 36.082010052 
##   alcgp40-79  alcgp80-119    alcgp120+ 
##  3.124334222  4.459579378  9.233256747</code></pre>
<div class="sourceCode" id="cb257"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb257-1"><a href="generalized-linear-models.html#cb257-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(</span>
<span id="cb257-2"><a href="generalized-linear-models.html#cb257-2" aria-hidden="true" tabindex="-1"></a>    <span class="at">q =</span> model<span class="sc">$</span>deviance <span class="sc">-</span> better_model<span class="sc">$</span>deviance,</span>
<span id="cb257-3"><a href="generalized-linear-models.html#cb257-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">df =</span> model<span class="sc">$</span>df.residual <span class="sc">-</span> better_model<span class="sc">$</span>df.residual,</span>
<span id="cb257-4"><a href="generalized-linear-models.html#cb257-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">lower =</span> <span class="cn">FALSE</span></span>
<span id="cb257-5"><a href="generalized-linear-models.html#cb257-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## [1] 1.354906e-14</code></pre>
<div class="sourceCode" id="cb259"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb259-1"><a href="generalized-linear-models.html#cb259-1" aria-hidden="true" tabindex="-1"></a><span class="co"># specify link function as probit</span></span>
<span id="cb259-2"><a href="generalized-linear-models.html#cb259-2" aria-hidden="true" tabindex="-1"></a>Prob_better_model <span class="ot">&lt;-</span> <span class="fu">glm</span>(</span>
<span id="cb259-3"><a href="generalized-linear-models.html#cb259-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">cbind</span>(ncases, ncontrols) <span class="sc">~</span> agegp <span class="sc">+</span> alcgp,</span>
<span id="cb259-4"><a href="generalized-linear-models.html#cb259-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> esoph,</span>
<span id="cb259-5"><a href="generalized-linear-models.html#cb259-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">family =</span> <span class="fu">binomial</span>(<span class="at">link =</span> probit)</span>
<span id="cb259-6"><a href="generalized-linear-models.html#cb259-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb259-7"><a href="generalized-linear-models.html#cb259-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Prob_better_model)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = cbind(ncases, ncontrols) ~ agegp + alcgp, family = binomial(link = probit), 
##     data = esoph)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.8676  -0.5938  -0.1802   0.4852   2.6056  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  -2.9800     0.4291  -6.945 3.79e-12 ***
## agegp35-44    0.6991     0.4491   1.557 0.119520    
## agegp45-54    1.4212     0.4292   3.311 0.000929 ***
## agegp55-64    1.6512     0.4262   3.874 0.000107 ***
## agegp65-74    1.8039     0.4297   4.198 2.69e-05 ***
## agegp75+      1.8025     0.4613   3.908 9.32e-05 ***
## alcgp40-79    0.6224     0.1247   4.990 6.03e-07 ***
## alcgp80-119   0.8256     0.1418   5.823 5.80e-09 ***
## alcgp120+     1.2839     0.1596   8.043 8.77e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 227.241  on 87  degrees of freedom
## Residual deviance:  61.938  on 79  degrees of freedom
## AIC: 227.42
## 
## Number of Fisher Scoring iterations: 6</code></pre>
</div>
<div id="poisson-regression" class="section level3" number="6.3.4">
<h3><span class="header-section-number">6.3.4</span> Poisson Regression</h3>
<p>From the Poisson distribution</p>
<p><span class="math display">\[
f(Y_i) = \frac{\mu_i^{Y_i}exp(-\mu_i)}{Y_i!}, Y_i = 0,1,.. \\
E(Y_i) = \mu_i  \\
var(Y_i) = \mu_i
\]</span></p>
<p>which is a natural distribution for counts. We can see that the variance is a function of the mean. If we let <span class="math inline">\(\mu_i = f(\mathbf{x_i; \theta})\)</span>, it would be similar to <a href="generalized-linear-models.html#logistic-regression">Logistic Regression</a> since we can choose <span class="math inline">\(f()\)</span> as <span class="math inline">\(\mu_i = \mathbf{x_i&#39;\theta}, \mu_i = \exp(\mathbf{x_i&#39;\theta}), \mu_i = \log(\mathbf{x_i&#39;\theta})\)</span></p>
<div id="application-4" class="section level4" number="6.3.4.1">
<h4><span class="header-section-number">6.3.4.1</span> Application</h4>
<p>Count Data and Poisson regression</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="generalized-linear-models.html#cb261-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(bioChemists, <span class="at">package =</span> <span class="st">&quot;pscl&quot;</span>)</span>
<span id="cb261-2"><a href="generalized-linear-models.html#cb261-2" aria-hidden="true" tabindex="-1"></a>bioChemists <span class="ot">&lt;-</span> bioChemists <span class="sc">%&gt;%</span></span>
<span id="cb261-3"><a href="generalized-linear-models.html#cb261-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">rename</span>(</span>
<span id="cb261-4"><a href="generalized-linear-models.html#cb261-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">Num_Article =</span> art, <span class="co">#articles in last 3 years of PhD</span></span>
<span id="cb261-5"><a href="generalized-linear-models.html#cb261-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">Sex =</span> fem, <span class="co">#coded 1 if female</span></span>
<span id="cb261-6"><a href="generalized-linear-models.html#cb261-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">Married =</span> mar, <span class="co">#coded 1 if married</span></span>
<span id="cb261-7"><a href="generalized-linear-models.html#cb261-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">Num_Kid5 =</span> kid5, <span class="co">#number of childeren under age 6</span></span>
<span id="cb261-8"><a href="generalized-linear-models.html#cb261-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">PhD_Quality =</span> phd, <span class="co">#prestige of PhD program</span></span>
<span id="cb261-9"><a href="generalized-linear-models.html#cb261-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">Num_MentArticle =</span> ment <span class="co">#articles by mentor in last 3 years</span></span>
<span id="cb261-10"><a href="generalized-linear-models.html#cb261-10" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb261-11"><a href="generalized-linear-models.html#cb261-11" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(bioChemists<span class="sc">$</span>Num_Article, <span class="at">breaks =</span> <span class="dv">25</span>, <span class="at">main =</span> <span class="st">&#39;Number of Articles&#39;</span>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-89-1.png" width="672" /></p>
<div class="sourceCode" id="cb262"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb262-1"><a href="generalized-linear-models.html#cb262-1" aria-hidden="true" tabindex="-1"></a>Poisson_Mod <span class="ot">&lt;-</span> <span class="fu">glm</span>(Num_Article <span class="sc">~</span> ., <span class="at">family=</span>poisson, bioChemists)</span>
<span id="cb262-2"><a href="generalized-linear-models.html#cb262-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Poisson_Mod)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Num_Article ~ ., family = poisson, data = bioChemists)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.5672  -1.5398  -0.3660   0.5722   5.4467  
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      0.304617   0.102981   2.958   0.0031 ** 
## SexWomen        -0.224594   0.054613  -4.112 3.92e-05 ***
## MarriedMarried   0.155243   0.061374   2.529   0.0114 *  
## Num_Kid5        -0.184883   0.040127  -4.607 4.08e-06 ***
## PhD_Quality      0.012823   0.026397   0.486   0.6271    
## Num_MentArticle  0.025543   0.002006  12.733  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1817.4  on 914  degrees of freedom
## Residual deviance: 1634.4  on 909  degrees of freedom
## AIC: 3314.1
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Residual of 1634 with 909 df isn’t great.</p>
<p>We see Pearson <span class="math inline">\(\chi^2\)</span></p>
<div class="sourceCode" id="cb264"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb264-1"><a href="generalized-linear-models.html#cb264-1" aria-hidden="true" tabindex="-1"></a>Predicted_Means <span class="ot">&lt;-</span> <span class="fu">predict</span>(Poisson_Mod,<span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb264-2"><a href="generalized-linear-models.html#cb264-2" aria-hidden="true" tabindex="-1"></a>X2 <span class="ot">&lt;-</span> <span class="fu">sum</span>((bioChemists<span class="sc">$</span>Num_Article <span class="sc">-</span> Predicted_Means)<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span>Predicted_Means)</span>
<span id="cb264-3"><a href="generalized-linear-models.html#cb264-3" aria-hidden="true" tabindex="-1"></a>X2</span></code></pre></div>
<pre><code>## [1] 9765.751</code></pre>
<div class="sourceCode" id="cb266"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb266-1"><a href="generalized-linear-models.html#cb266-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(X2,Poisson_Mod<span class="sc">$</span>df.residual, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0</code></pre>
<p>With interaction terms, there are some improvements</p>
<div class="sourceCode" id="cb268"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb268-1"><a href="generalized-linear-models.html#cb268-1" aria-hidden="true" tabindex="-1"></a>Poisson_Mod_All2way <span class="ot">&lt;-</span> <span class="fu">glm</span>(Num_Article <span class="sc">~</span> .<span class="sc">^</span><span class="dv">2</span>, <span class="at">family=</span>poisson, bioChemists)</span>
<span id="cb268-2"><a href="generalized-linear-models.html#cb268-2" aria-hidden="true" tabindex="-1"></a>Poisson_Mod_All3way <span class="ot">&lt;-</span> <span class="fu">glm</span>(Num_Article <span class="sc">~</span> .<span class="sc">^</span><span class="dv">3</span>, <span class="at">family=</span>poisson, bioChemists)</span></code></pre></div>
<p>Consider the <span class="math inline">\(\hat{\phi} = \frac{\text{deviance}}{df}\)</span></p>
<div class="sourceCode" id="cb269"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb269-1"><a href="generalized-linear-models.html#cb269-1" aria-hidden="true" tabindex="-1"></a>Poisson_Mod<span class="sc">$</span>deviance <span class="sc">/</span> Poisson_Mod<span class="sc">$</span>df.residual</span></code></pre></div>
<pre><code>## [1] 1.797988</code></pre>
<p>This is evidence for over-dispersion. Likely cause is missing variables. And remedies could either be to include more variables or consider random effects.</p>
<p>A quick fix is to force the Poisson Regression to include this value of <span class="math inline">\(\phi\)</span>, and this model is called “Quasi-Poisson.”</p>
<div class="sourceCode" id="cb271"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb271-1"><a href="generalized-linear-models.html#cb271-1" aria-hidden="true" tabindex="-1"></a>phi_hat <span class="ot">=</span> Poisson_Mod<span class="sc">$</span>deviance<span class="sc">/</span>Poisson_Mod<span class="sc">$</span>df.residual</span>
<span id="cb271-2"><a href="generalized-linear-models.html#cb271-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Poisson_Mod,<span class="at">dispersion =</span> phi_hat)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Num_Article ~ ., family = poisson, data = bioChemists)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.5672  -1.5398  -0.3660   0.5722   5.4467  
## 
## Coefficients:
##                 Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      0.30462    0.13809   2.206  0.02739 *  
## SexWomen        -0.22459    0.07323  -3.067  0.00216 ** 
## MarriedMarried   0.15524    0.08230   1.886  0.05924 .  
## Num_Kid5        -0.18488    0.05381  -3.436  0.00059 ***
## PhD_Quality      0.01282    0.03540   0.362  0.71715    
## Num_MentArticle  0.02554    0.00269   9.496  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1.797988)
## 
##     Null deviance: 1817.4  on 914  degrees of freedom
## Residual deviance: 1634.4  on 909  degrees of freedom
## AIC: 3314.1
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>Or directly rerun the model as</p>
<div class="sourceCode" id="cb273"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb273-1"><a href="generalized-linear-models.html#cb273-1" aria-hidden="true" tabindex="-1"></a>quasiPoisson_Mod <span class="ot">&lt;-</span> <span class="fu">glm</span>(Num_Article <span class="sc">~</span> ., <span class="at">family=</span>quasipoisson, bioChemists)</span></code></pre></div>
<p>Quasi-Poisson is not recommended, but <a href="generalized-linear-models.html#negative-binomial-regression">Negative Binomial Regression</a> that has an extra parameter to account for over-dispersion is.</p>
</div>
</div>
<div id="negative-binomial-regression" class="section level3" number="6.3.5">
<h3><span class="header-section-number">6.3.5</span> Negative Binomial Regression</h3>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="generalized-linear-models.html#cb274-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MASS)</span>
<span id="cb274-2"><a href="generalized-linear-models.html#cb274-2" aria-hidden="true" tabindex="-1"></a>NegBinom_Mod <span class="ot">&lt;-</span> MASS<span class="sc">::</span><span class="fu">glm.nb</span>(Num_Article <span class="sc">~</span> .,bioChemists)</span>
<span id="cb274-3"><a href="generalized-linear-models.html#cb274-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(NegBinom_Mod)</span></code></pre></div>
<pre><code>## 
## Call:
## MASS::glm.nb(formula = Num_Article ~ ., data = bioChemists, init.theta = 2.264387695, 
##     link = log)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1678  -1.3617  -0.2806   0.4476   3.4524  
## 
## Coefficients:
##                  Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      0.256144   0.137348   1.865 0.062191 .  
## SexWomen        -0.216418   0.072636  -2.979 0.002887 ** 
## MarriedMarried   0.150489   0.082097   1.833 0.066791 .  
## Num_Kid5        -0.176415   0.052813  -3.340 0.000837 ***
## PhD_Quality      0.015271   0.035873   0.426 0.670326    
## Num_MentArticle  0.029082   0.003214   9.048  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(2.2644) family taken to be 1)
## 
##     Null deviance: 1109.0  on 914  degrees of freedom
## Residual deviance: 1004.3  on 909  degrees of freedom
## AIC: 3135.9
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  2.264 
##           Std. Err.:  0.271 
## 
##  2 x log-likelihood:  -3121.917</code></pre>
<p>We can see the dispersion is 2.264 with SE = 0.271, which is significantly different from 1, indicating overdispersion. Check <a href="generalized-linear-models.html#over-dispersion">Over-Dispersion</a> for more detail</p>
</div>
<div id="multinomial" class="section level3" number="6.3.6">
<h3><span class="header-section-number">6.3.6</span> Multinomial</h3>
<p>If we have more than two categories or groups that we want to model relative to covariates (e.g., we have observations <span class="math inline">\(i = 1,…,n\)</span> and groups/ covariates <span class="math inline">\(j = 1,2,…,J\)</span>), multinomial is our candidate model</p>
<p>Let</p>
<ul>
<li><span class="math inline">\(p_{ij}\)</span> be the probability that the i-th observation belongs to the j-th group</li>
<li><span class="math inline">\(Y_{ij}\)</span> be the number of observations for individual i in group j; An individual will have observations <span class="math inline">\(Y_{i1},Y_{i2},…Y_{iJ}\)</span></li>
<li>assume the probability of observing this response is given by a multinomial distribution in terms of probabilities <span class="math inline">\(p_{ij}\)</span>, where <span class="math inline">\(\sum_{j = 1}^J p_{ij} = 1\)</span> . For interpretation, we have a baseline category <span class="math inline">\(p_{i1} = 1 - \sum_{j = 2}^J p_{ij}\)</span></li>
</ul>
<p>The link between the mean response (probability) <span class="math inline">\(p_{ij}\)</span> and a linear function of the covariates</p>
<p><span class="math display">\[
\eta_{ij} = \mathbf{x&#39;_i \beta_j} = \log \frac{p_{ij}}{p_{i1}}, j = 2,..,J
\]</span></p>
<p>We compare <span class="math inline">\(p_{ij}\)</span> to the baseline <span class="math inline">\(p_{i1}\)</span>, suggesting</p>
<p><span class="math display">\[
p_{ij} = \frac{\exp(\eta_{ij})}{1 + \sum_{i=2}^J \exp(\eta_{ij})}
\]</span></p>
<p>which is known as <strong>multinomial logistic</strong> model.</p>
<div class="sourceCode" id="cb276"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb276-1"><a href="generalized-linear-models.html#cb276-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(faraway)</span>
<span id="cb276-2"><a href="generalized-linear-models.html#cb276-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb276-3"><a href="generalized-linear-models.html#cb276-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(nes96, <span class="at">package=</span><span class="st">&quot;faraway&quot;</span>)</span>
<span id="cb276-4"><a href="generalized-linear-models.html#cb276-4" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(nes96,<span class="dv">3</span>)</span></code></pre></div>
<pre><code>##   popul TVnews selfLR ClinLR DoleLR     PID age  educ   income    vote
## 1     0      7 extCon extLib    Con  strRep  36    HS $3Kminus    Dole
## 2   190      1 sliLib sliLib sliCon weakDem  20  Coll $3Kminus Clinton
## 3    31      7    Lib    Lib    Con weakDem  24 BAdeg $3Kminus Clinton</code></pre>
<p>We try to understand their political strength</p>
<div class="sourceCode" id="cb278"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb278-1"><a href="generalized-linear-models.html#cb278-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(nes96<span class="sc">$</span>PID)</span></code></pre></div>
<pre><code>## 
##  strDem weakDem  indDem  indind  indRep weakRep  strRep 
##     200     180     108      37      94     150     175</code></pre>
<div class="sourceCode" id="cb280"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb280-1"><a href="generalized-linear-models.html#cb280-1" aria-hidden="true" tabindex="-1"></a>nes96<span class="sc">$</span>Political_Strength <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb280-2"><a href="generalized-linear-models.html#cb280-2" aria-hidden="true" tabindex="-1"></a>nes96<span class="sc">$</span>Political_Strength[nes96<span class="sc">$</span>PID <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;strDem&quot;</span>, <span class="st">&quot;strRep&quot;</span>)] <span class="ot">&lt;-</span></span>
<span id="cb280-3"><a href="generalized-linear-models.html#cb280-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Strong&quot;</span></span>
<span id="cb280-4"><a href="generalized-linear-models.html#cb280-4" aria-hidden="true" tabindex="-1"></a>nes96<span class="sc">$</span>Political_Strength[nes96<span class="sc">$</span>PID <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;weakDem&quot;</span>, <span class="st">&quot;weakRep&quot;</span>)] <span class="ot">&lt;-</span></span>
<span id="cb280-5"><a href="generalized-linear-models.html#cb280-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Weak&quot;</span></span>
<span id="cb280-6"><a href="generalized-linear-models.html#cb280-6" aria-hidden="true" tabindex="-1"></a>nes96<span class="sc">$</span>Political_Strength[nes96<span class="sc">$</span>PID <span class="sc">%in%</span> <span class="fu">c</span>(<span class="st">&quot;indDem&quot;</span>, <span class="st">&quot;indind&quot;</span>, <span class="st">&quot;indRep&quot;</span>)] <span class="ot">&lt;-</span></span>
<span id="cb280-7"><a href="generalized-linear-models.html#cb280-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Neutral&quot;</span></span>
<span id="cb280-8"><a href="generalized-linear-models.html#cb280-8" aria-hidden="true" tabindex="-1"></a>nes96 <span class="sc">%&gt;%</span> <span class="fu">group_by</span>(Political_Strength) <span class="sc">%&gt;%</span> <span class="fu">summarise</span>(<span class="at">Count=</span><span class="fu">n</span>())</span></code></pre></div>
<pre><code>## # A tibble: 3 x 2
##   Political_Strength Count
## * &lt;chr&gt;              &lt;int&gt;
## 1 Neutral              239
## 2 Strong               375
## 3 Weak                 330</code></pre>
<p>visualize the political strength variable</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="generalized-linear-models.html#cb282-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb282-2"><a href="generalized-linear-models.html#cb282-2" aria-hidden="true" tabindex="-1"></a>Plot_DF <span class="ot">&lt;-</span> nes96 <span class="sc">%&gt;%</span></span>
<span id="cb282-3"><a href="generalized-linear-models.html#cb282-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">Age_Grp =</span> <span class="fu">cut_number</span>(age, <span class="dv">4</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb282-4"><a href="generalized-linear-models.html#cb282-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(Age_Grp, Political_Strength) <span class="sc">%&gt;%</span></span>
<span id="cb282-5"><a href="generalized-linear-models.html#cb282-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">summarise</span>(<span class="at">count =</span> <span class="fu">n</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb282-6"><a href="generalized-linear-models.html#cb282-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">group_by</span>(Age_Grp) <span class="sc">%&gt;%</span></span>
<span id="cb282-7"><a href="generalized-linear-models.html#cb282-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mutate</span>(<span class="at">etotal =</span> <span class="fu">sum</span>(count), <span class="at">proportion =</span> count <span class="sc">/</span> etotal)</span>
<span id="cb282-8"><a href="generalized-linear-models.html#cb282-8" aria-hidden="true" tabindex="-1"></a>Age_Plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(</span>
<span id="cb282-9"><a href="generalized-linear-models.html#cb282-9" aria-hidden="true" tabindex="-1"></a>    Plot_DF,</span>
<span id="cb282-10"><a href="generalized-linear-models.html#cb282-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">aes</span>(</span>
<span id="cb282-11"><a href="generalized-linear-models.html#cb282-11" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> Age_Grp,</span>
<span id="cb282-12"><a href="generalized-linear-models.html#cb282-12" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> proportion,</span>
<span id="cb282-13"><a href="generalized-linear-models.html#cb282-13" aria-hidden="true" tabindex="-1"></a>        <span class="at">group =</span> Political_Strength,</span>
<span id="cb282-14"><a href="generalized-linear-models.html#cb282-14" aria-hidden="true" tabindex="-1"></a>        <span class="at">linetype =</span> Political_Strength,</span>
<span id="cb282-15"><a href="generalized-linear-models.html#cb282-15" aria-hidden="true" tabindex="-1"></a>        <span class="at">color =</span> Political_Strength</span>
<span id="cb282-16"><a href="generalized-linear-models.html#cb282-16" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb282-17"><a href="generalized-linear-models.html#cb282-17" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb282-18"><a href="generalized-linear-models.html#cb282-18" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="dv">2</span>)</span>
<span id="cb282-19"><a href="generalized-linear-models.html#cb282-19" aria-hidden="true" tabindex="-1"></a>Age_Plot</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-99-1.png" width="672" /></p>
<p>Fit the multinomial logistic model:</p>
<p>model political strength as a function of age and education</p>
<div class="sourceCode" id="cb283"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb283-1"><a href="generalized-linear-models.html#cb283-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb283-2"><a href="generalized-linear-models.html#cb283-2" aria-hidden="true" tabindex="-1"></a>Multinomial_Model <span class="ot">&lt;-</span></span>
<span id="cb283-3"><a href="generalized-linear-models.html#cb283-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">multinom</span>(Political_Strength <span class="sc">~</span> age <span class="sc">+</span> educ, nes96, <span class="at">trace =</span> F)</span>
<span id="cb283-4"><a href="generalized-linear-models.html#cb283-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Multinomial_Model)</span></code></pre></div>
<pre><code>## Call:
## multinom(formula = Political_Strength ~ age + educ, data = nes96, 
##     trace = F)
## 
## Coefficients:
##        (Intercept)          age     educ.L     educ.Q     educ.C      educ^4
## Strong -0.08788729  0.010700364 -0.1098951 -0.2016197 -0.1757739 -0.02116307
## Weak    0.51976285 -0.004868771 -0.1431104 -0.2405395 -0.2411795  0.18353634
##            educ^5     educ^6
## Strong -0.1664377 -0.1359449
## Weak   -0.1489030 -0.2173144
## 
## Std. Errors:
##        (Intercept)         age    educ.L    educ.Q    educ.C    educ^4
## Strong   0.3017034 0.005280743 0.4586041 0.4318830 0.3628837 0.2964776
## Weak     0.3097923 0.005537561 0.4920736 0.4616446 0.3881003 0.3169149
##           educ^5    educ^6
## Strong 0.2515012 0.2166774
## Weak   0.2643747 0.2199186
## 
## Residual Deviance: 2024.596 
## AIC: 2056.596</code></pre>
<p>Alternatively, stepwise model selection based AIC</p>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="generalized-linear-models.html#cb285-1" aria-hidden="true" tabindex="-1"></a>Multinomial_Step <span class="ot">&lt;-</span> <span class="fu">step</span>(Multinomial_Model,<span class="at">trace =</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>## trying - age 
## trying - educ 
## trying - age</code></pre>
<div class="sourceCode" id="cb287"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb287-1"><a href="generalized-linear-models.html#cb287-1" aria-hidden="true" tabindex="-1"></a>Multinomial_Step</span></code></pre></div>
<pre><code>## Call:
## multinom(formula = Political_Strength ~ age, data = nes96, trace = F)
## 
## Coefficients:
##        (Intercept)          age
## Strong -0.01988977  0.009832916
## Weak    0.59497046 -0.005954348
## 
## Residual Deviance: 2030.756 
## AIC: 2038.756</code></pre>
<p>compare the best model to the full model based on deviance</p>
<div class="sourceCode" id="cb289"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb289-1"><a href="generalized-linear-models.html#cb289-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fu">deviance</span>(Multinomial_Step) <span class="sc">-</span> <span class="fu">deviance</span>(Multinomial_Model),</span>
<span id="cb289-2"><a href="generalized-linear-models.html#cb289-2" aria-hidden="true" tabindex="-1"></a><span class="at">df =</span> Multinomial_Model<span class="sc">$</span>edf<span class="sc">-</span>Multinomial_Step<span class="sc">$</span>edf,<span class="at">lower=</span>F)</span></code></pre></div>
<pre><code>## [1] 0.9078172</code></pre>
<p>We see no significant difference</p>
<p>Plot of the fitted model</p>
<div class="sourceCode" id="cb291"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb291-1"><a href="generalized-linear-models.html#cb291-1" aria-hidden="true" tabindex="-1"></a>PlotData <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">age =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="dv">19</span>, <span class="at">to =</span> <span class="dv">91</span>))</span>
<span id="cb291-2"><a href="generalized-linear-models.html#cb291-2" aria-hidden="true" tabindex="-1"></a>Preds <span class="ot">&lt;-</span></span>
<span id="cb291-3"><a href="generalized-linear-models.html#cb291-3" aria-hidden="true" tabindex="-1"></a>    PlotData <span class="sc">%&gt;%</span> <span class="fu">bind_cols</span>(<span class="fu">data.frame</span>(<span class="fu">predict</span>(</span>
<span id="cb291-4"><a href="generalized-linear-models.html#cb291-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">object =</span> Multinomial_Step,</span>
<span id="cb291-5"><a href="generalized-linear-models.html#cb291-5" aria-hidden="true" tabindex="-1"></a>        PlotData, <span class="at">type =</span> <span class="st">&quot;probs&quot;</span></span>
<span id="cb291-6"><a href="generalized-linear-models.html#cb291-6" aria-hidden="true" tabindex="-1"></a>    )))</span>
<span id="cb291-7"><a href="generalized-linear-models.html#cb291-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(</span>
<span id="cb291-8"><a href="generalized-linear-models.html#cb291-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> Preds<span class="sc">$</span>age,</span>
<span id="cb291-9"><a href="generalized-linear-models.html#cb291-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> Preds<span class="sc">$</span>Neutral,</span>
<span id="cb291-10"><a href="generalized-linear-models.html#cb291-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">type =</span> <span class="st">&quot;l&quot;</span>,</span>
<span id="cb291-11"><a href="generalized-linear-models.html#cb291-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylim =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="fl">0.6</span>),</span>
<span id="cb291-12"><a href="generalized-linear-models.html#cb291-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="st">&quot;black&quot;</span>,</span>
<span id="cb291-13"><a href="generalized-linear-models.html#cb291-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">ylab =</span> <span class="st">&quot;Proportion&quot;</span>,</span>
<span id="cb291-14"><a href="generalized-linear-models.html#cb291-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">xlab =</span> <span class="st">&quot;Age&quot;</span></span>
<span id="cb291-15"><a href="generalized-linear-models.html#cb291-15" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb291-16"><a href="generalized-linear-models.html#cb291-16" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> Preds<span class="sc">$</span>age,</span>
<span id="cb291-17"><a href="generalized-linear-models.html#cb291-17" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> Preds<span class="sc">$</span>Weak,</span>
<span id="cb291-18"><a href="generalized-linear-models.html#cb291-18" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb291-19"><a href="generalized-linear-models.html#cb291-19" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="at">x =</span> Preds<span class="sc">$</span>age,</span>
<span id="cb291-20"><a href="generalized-linear-models.html#cb291-20" aria-hidden="true" tabindex="-1"></a>      <span class="at">y =</span> Preds<span class="sc">$</span>Strong,</span>
<span id="cb291-21"><a href="generalized-linear-models.html#cb291-21" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb291-22"><a href="generalized-linear-models.html#cb291-22" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(</span>
<span id="cb291-23"><a href="generalized-linear-models.html#cb291-23" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;topleft&#39;</span>,</span>
<span id="cb291-24"><a href="generalized-linear-models.html#cb291-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend =</span> <span class="fu">c</span>(<span class="st">&#39;Neutral&#39;</span>, <span class="st">&#39;Weak&#39;</span>, <span class="st">&#39;Strong&#39;</span>),</span>
<span id="cb291-25"><a href="generalized-linear-models.html#cb291-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&#39;black&#39;</span>, <span class="st">&#39;blue&#39;</span>, <span class="st">&#39;red&#39;</span>),</span>
<span id="cb291-26"><a href="generalized-linear-models.html#cb291-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">lty =</span> <span class="dv">1</span></span>
<span id="cb291-27"><a href="generalized-linear-models.html#cb291-27" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<div class="sourceCode" id="cb292"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb292-1"><a href="generalized-linear-models.html#cb292-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Multinomial_Step,<span class="fu">data.frame</span>(<span class="at">age =</span> <span class="dv">34</span>)) <span class="co"># predicted result (categoriy of political strength) of 34 year old</span></span></code></pre></div>
<pre><code>## [1] Weak
## Levels: Neutral Strong Weak</code></pre>
<div class="sourceCode" id="cb294"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb294-1"><a href="generalized-linear-models.html#cb294-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(Multinomial_Step,<span class="fu">data.frame</span>(<span class="at">age =</span> <span class="fu">c</span>(<span class="dv">34</span>,<span class="dv">35</span>)),<span class="at">type=</span><span class="st">&quot;probs&quot;</span>) <span class="co"># predicted result of the probabilities of each level of political strength for a 34 and 35</span></span></code></pre></div>
<pre><code>##     Neutral    Strong      Weak
## 1 0.2597275 0.3556910 0.3845815
## 2 0.2594080 0.3587639 0.3818281</code></pre>
<p>If categories are ordered (i.e., ordinal data), we must use another approach (still multinomial, but use cumulative probabilities).</p>
<p>Another example</p>
<div class="sourceCode" id="cb296"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb296-1"><a href="generalized-linear-models.html#cb296-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(agridat)</span>
<span id="cb296-2"><a href="generalized-linear-models.html#cb296-2" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> agridat<span class="sc">::</span>streibig.competition</span>
<span id="cb296-3"><a href="generalized-linear-models.html#cb296-3" aria-hidden="true" tabindex="-1"></a><span class="co"># See Schaberger and Pierce, pages 370+</span></span>
<span id="cb296-4"><a href="generalized-linear-models.html#cb296-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Consider only the mono-species barley data (no competition from Sinapis)</span></span>
<span id="cb296-5"><a href="generalized-linear-models.html#cb296-5" aria-hidden="true" tabindex="-1"></a>gammaDat <span class="ot">&lt;-</span> <span class="fu">subset</span>(dat, sseeds<span class="sc">&lt;</span><span class="dv">1</span>)</span>
<span id="cb296-6"><a href="generalized-linear-models.html#cb296-6" aria-hidden="true" tabindex="-1"></a>gammaDat <span class="ot">&lt;-</span> <span class="fu">transform</span>(gammaDat, <span class="at">x=</span>bseeds, <span class="at">y=</span>bdwt, <span class="at">block=</span><span class="fu">factor</span>(block))</span>
<span id="cb296-7"><a href="generalized-linear-models.html#cb296-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Inverse yield looks like it will be a good fit for Gamma&#39;s inverse link</span></span>
<span id="cb296-8"><a href="generalized-linear-models.html#cb296-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(gammaDat,<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span><span class="dv">1</span><span class="sc">/</span>y))<span class="sc">+</span><span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color=</span>block,<span class="at">shape=</span>block))<span class="sc">+</span></span>
<span id="cb296-9"><a href="generalized-linear-models.html#cb296-9" aria-hidden="true" tabindex="-1"></a><span class="fu">xlab</span>(<span class="st">&#39;Seeding Rate&#39;</span>)<span class="sc">+</span><span class="fu">ylab</span>(<span class="st">&#39;Inverse yield&#39;</span>)<span class="sc">+</span><span class="fu">ggtitle</span>(<span class="st">&#39;Streibig Competion - Barley only&#39;</span>)</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
<p><span class="math display">\[
Y \sim Gamma
\]</span></p>
<p>because Gamma is non-negative as opposed to Normal. The canonical Gamma link function is the inverse (or reciprocal) link</p>
<p><span class="math display">\[
\eta_{ij} = \beta_{0j} + \beta_{1j}x_{ij} + \beta_2x_{ij}^2 \\
Y_{ij} = \eta_{ij}^{-1}
\]</span></p>
<p>The linear predictor is a quadratic model fit to each of the j-th blocks. A different model (not fitted) could be one with common slopes: glm(y <span class="math inline">\(\sim\)</span> x + I(x^2),…)</p>
<div class="sourceCode" id="cb297"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb297-1"><a href="generalized-linear-models.html#cb297-1" aria-hidden="true" tabindex="-1"></a><span class="co"># linear predictor is quadratic, with separate intercept and slope per block</span></span>
<span id="cb297-2"><a href="generalized-linear-models.html#cb297-2" aria-hidden="true" tabindex="-1"></a>m1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(y <span class="sc">~</span> block <span class="sc">+</span> block<span class="sc">*</span>x <span class="sc">+</span> block<span class="sc">*</span><span class="fu">I</span>(x<span class="sc">^</span><span class="dv">2</span>), <span class="at">data=</span>gammaDat,<span class="at">family=</span><span class="fu">Gamma</span>(<span class="at">link=</span><span class="st">&quot;inverse&quot;</span>))</span>
<span id="cb297-3"><a href="generalized-linear-models.html#cb297-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(m1)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = y ~ block + block * x + block * I(x^2), family = Gamma(link = &quot;inverse&quot;), 
##     data = gammaDat)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -1.21708  -0.44148   0.02479   0.17999   0.80745  
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)     1.115e-01  2.870e-02   3.886 0.000854 ***
## blockB2        -1.208e-02  3.880e-02  -0.311 0.758630    
## blockB3        -2.386e-02  3.683e-02  -0.648 0.524029    
## x              -2.075e-03  1.099e-03  -1.888 0.072884 .  
## I(x^2)          1.372e-05  9.109e-06   1.506 0.146849    
## blockB2:x       5.198e-04  1.468e-03   0.354 0.726814    
## blockB3:x       7.475e-04  1.393e-03   0.537 0.597103    
## blockB2:I(x^2) -5.076e-06  1.184e-05  -0.429 0.672475    
## blockB3:I(x^2) -6.651e-06  1.123e-05  -0.592 0.560012    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Gamma family taken to be 0.3232083)
## 
##     Null deviance: 13.1677  on 29  degrees of freedom
## Residual deviance:  7.8605  on 21  degrees of freedom
## AIC: 225.32
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>For predict new value of x</p>
<div class="sourceCode" id="cb299"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb299-1"><a href="generalized-linear-models.html#cb299-1" aria-hidden="true" tabindex="-1"></a>newdf <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">x=</span><span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">120</span>,<span class="at">length=</span><span class="dv">50</span>), <span class="at">block=</span><span class="fu">factor</span>(<span class="fu">c</span>(<span class="st">&#39;B1&#39;</span>,<span class="st">&#39;B2&#39;</span>,<span class="st">&#39;B3&#39;</span>)) )</span>
<span id="cb299-2"><a href="generalized-linear-models.html#cb299-2" aria-hidden="true" tabindex="-1"></a>newdf<span class="sc">$</span>pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(m1, <span class="at">new=</span>newdf, <span class="at">type=</span><span class="st">&#39;response&#39;</span>)</span>
<span id="cb299-3"><a href="generalized-linear-models.html#cb299-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(gammaDat,<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>y))<span class="sc">+</span><span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color=</span>block,<span class="at">shape=</span>block))<span class="sc">+</span></span>
<span id="cb299-4"><a href="generalized-linear-models.html#cb299-4" aria-hidden="true" tabindex="-1"></a><span class="fu">xlab</span>(<span class="st">&#39;Seeding Rate&#39;</span>)<span class="sc">+</span><span class="fu">ylab</span>(<span class="st">&#39;Inverse yield&#39;</span>)<span class="sc">+</span><span class="fu">ggtitle</span>(<span class="st">&#39;Streibig Competion - Barley only Predictions&#39;</span>) <span class="sc">+</span></span>
<span id="cb299-5"><a href="generalized-linear-models.html#cb299-5" aria-hidden="true" tabindex="-1"></a><span class="fu">geom_line</span>(<span class="at">data=</span>newdf,<span class="fu">aes</span>(<span class="at">x=</span>x,<span class="at">y=</span>pred,<span class="at">color=</span>block,<span class="at">linetype=</span>block))</span></code></pre></div>
<p><img src="Data-Analysis_files/figure-html/unnamed-chunk-107-1.png" width="672" /></p>
</div>
<div id="generalization" class="section level3" number="6.3.7">
<h3><span class="header-section-number">6.3.7</span> Generalization</h3>
<p>We can see that Poisson regression looks similar to logistic regression. Hence, we can generalize to a class of modeling. Thanks to <span class="citation">(<a href="references.html#ref-Nelder_1972" role="doc-biblioref">Nelder and Wedderburn 1972</a>)</span>, we have the <strong>generalized linear models</strong> (GLMs). Estimation is generalize in these models.</p>
<p><strong>Exponential Family</strong><br />
The theory of GLMs is developed for data with distribution given y the <strong>exponential family</strong>.<br />
The form of the data distribution that is useful for GLMs is</p>
<p><span class="math display">\[
f(y;\theta, \phi) = \exp(\frac{\theta y - b(\theta)}{a(\phi)} + c(y, \phi))
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta\)</span> is called the natural parameter</li>
<li><span class="math inline">\(\phi\)</span> is called the dispersion parameter</li>
</ul>
<p><strong>Note</strong>:</p>
<p>This family includes the <a href="probability-theory.html#gamma">Gamma</a>, <a href="probability-theory.html#normal">Normal</a>, <a href="probability-theory.html#poisson">Poisson</a>, and other. For all parameterization of the exponential family, check this <a href="https://www.stat.purdue.edu/~tlzhang/stat526/logistic.pdf">link</a></p>
<p><strong>Example</strong></p>
<p>if we have <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span></p>
<p><span class="math display">\[
\begin{align}
f(y; \mu, \sigma^2) &amp;= \frac{1}{(2\pi \sigma^2)^{1/2}}\exp(-\frac{1}{2\sigma^2}(y- \mu)^2) \\
&amp;= \exp(-\frac{1}{2\sigma^2}(y^2 - 2y \mu +\mu^2)- \frac{1}{2}\log(2\pi \sigma^2)) \\
&amp;= \exp(\frac{y \mu - \mu^2/2}{\sigma^2} - \frac{y^2}{2\sigma^2} - \frac{1}{2}\log(2\pi \sigma^2)) \\
&amp;= \exp(\frac{\theta y - b(\theta)}{a(\phi)} + c(y , \phi))
\end{align}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta = \mu\)</span></li>
<li><span class="math inline">\(b(\theta) = \frac{\mu^2}{2}\)</span></li>
<li><span class="math inline">\(a(\phi) = \sigma^2 = \phi\)</span></li>
<li><span class="math inline">\(c(y , \phi) = - \frac{1}{2}(\frac{y^2}{\phi}+\log(2\pi \sigma^2))\)</span></li>
</ul>
<p><strong>Properties of GLM exponential families</strong></p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(E(Y) = b&#39; (\theta)\)</span> where <span class="math inline">\(b&#39;(\theta) = \frac{\partial b(\theta)}{\partial \theta}\)</span> (here <code>'</code> is “prime,” not transpose)<br />
</p></li>
<li><p><span class="math inline">\(var(Y) = a(\phi)b&#39;&#39;(\theta)= a(\phi)V(\mu)\)</span>.</p>
<ul>
<li><span class="math inline">\(V(\mu)\)</span> is the <em>variance function</em>; however, it is only the variance in the case that <span class="math inline">\(a(\phi) =1\)</span><br />
</li>
</ul></li>
<li><p>If <span class="math inline">\(a(), b(), c()\)</span> are identifiable, we will derive expected value and variance of Y.</p></li>
</ol>
<p>Example</p>
<p>Normal distribution</p>
<p><span class="math display">\[
b&#39;(\theta) = \frac{\partial b(\mu^2/2)}{\partial \mu} = \mu \\
V(\mu) = \frac{\partial^2 (\mu^2/2)}{\partial \mu^2} = 1 \\
\to var(Y) = a(\phi) = \sigma^2
\]</span></p>
<p>Poisson distribution</p>
<p><span class="math display">\[
\begin{align}
f(y, \theta, \phi) &amp;= \frac{\mu^y \exp(-\mu)}{y!} \\
&amp;= \exp(y\log(\mu) - \mu - \log(y!)) \\
&amp;= \exp(y\theta - \exp(\theta) - \log(y!))
\end{align}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\theta = \log(\mu)\)</span></li>
<li><span class="math inline">\(a(\phi) = 1\)</span></li>
<li><span class="math inline">\(b(\theta) = \exp(\theta)\)</span></li>
<li><span class="math inline">\(c(y, \phi) = \log(y!)\)</span></li>
</ul>
<p>Hence,</p>
<p><span class="math display">\[
E(Y) = \frac{\partial b(\theta)}{\partial \theta} = \exp(\theta) = \mu \\
var(Y) = \frac{\partial^2 b(\theta)}{\partial \theta^2} = \mu
\]</span></p>
<p>Since <span class="math inline">\(\mu = E(Y) = b&#39;(\theta)\)</span></p>
<p>In GLM, we take some monotone function (typically nonlinear) of <span class="math inline">\(\mu\)</span> to be linear in the set of covariates</p>
<p><span class="math display">\[
g(\mu) = g(b&#39;(\theta)) = \mathbf{x&#39;\beta}
\]</span></p>
<p>Equivalently,</p>
<p><span class="math display">\[
\mu = g^{-1}(\mathbf{x&#39;\beta})
\]</span></p>
<p>where <span class="math inline">\(g(.)\)</span> is the <strong>link function</strong> since it links mean response (<span class="math inline">\(\mu = E(Y)\)</span>) and a linear expression of the covariates</p>
<p>Some people use <span class="math inline">\(\eta = \mathbf{x&#39;\beta}\)</span> where <span class="math inline">\(\eta\)</span> = the “linear predictor”</p>
<p><strong>GLM is composed of 2 components</strong></p>
<p>The <strong>random component</strong>:</p>
<ul>
<li><p>is the distribution chosen to model the response variables <span class="math inline">\(Y_1,...,Y_n\)</span></p></li>
<li><p>is specified by the choice fo <span class="math inline">\(a(), b(), c()\)</span> in the exponential form</p></li>
<li><p>Notation:</p>
<ul>
<li>Assume that there are n <strong>independent</strong> response variables <span class="math inline">\(Y_1,...,Y_n\)</span> with densities<br />
<span class="math display">\[
f(y_i ; \theta_i, \phi) = \exp(\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi))
\]</span> notice each observation might have different densities</li>
<li>Assume that <span class="math inline">\(\phi\)</span> is constant for all <span class="math inline">\(i = 1,...,n\)</span>, but <span class="math inline">\(\theta_i\)</span> will vary. <span class="math inline">\(\mu_i = E(Y_i)\)</span> for all i.</li>
</ul></li>
</ul>
<p>The <strong>systematic component</strong></p>
<ul>
<li><p>is the portion of the model that gives the relation between <span class="math inline">\(\mu\)</span> and the covariates <span class="math inline">\(\mathbf{x}\)</span></p></li>
<li><p>consists of 2 parts:</p>
<ul>
<li>the <em>link</em> function, <span class="math inline">\(g(.)\)</span></li>
<li>the <em>linear predictor</em>, <span class="math inline">\(\eta = \mathbf{x&#39;\beta}\)</span></li>
</ul></li>
<li><p>Notation:</p>
<ul>
<li>assume <span class="math inline">\(g(\mu_i) = \mathbf{x&#39;\beta} = \eta_i\)</span> where <span class="math inline">\(\mathbf{\beta} = (\beta_1,..., \beta_p)&#39;\)</span></li>
<li>The parameters to be estimated are <span class="math inline">\(\beta_1,...\beta_p , \phi\)</span></li>
</ul></li>
</ul>
<p><strong>The Canonical Link</strong></p>
<p>To choose <span class="math inline">\(g(.)\)</span>, we can use <strong>canonical link function</strong></p>
<p>If the link function <span class="math inline">\(g(.)\)</span> is such <span class="math inline">\(g(\mu_i) = \theta_i\)</span>, the natural parameter, then <span class="math inline">\(g(.)\)</span> is the canonical link.</p>
<p>Example</p>
<table>
<colgroup>
<col width="12%" />
<col width="58%" />
<col width="20%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th>Distribution</th>
<th>Mean Response</th>
<th>Canonical link</th>
<th>name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Normal random component</td>
<td><span class="math inline">\(\mu_i = \theta_i\)</span></td>
<td><span class="math inline">\(g( \mu_i) = \mu_i\)</span></td>
<td>the identity link</td>
</tr>
<tr class="even">
<td>Binomial random component</td>
<td><span class="math inline">\(\mu_i = \frac{n_i \exp( \theta)}{1+\exp (\theta_i)} \\ \theta(\mu_i) = \log(\frac{p_i }{1-p_i}) = \log (\frac{\mu_i} {n_i - \mu_i})\)</span></td>
<td><span class="math inline">\(g(\mu_i) = \log(\frac{\mu_i} {n_i - \mu_i})\)</span></td>
<td>the logit link</td>
</tr>
<tr class="odd">
<td>Poisson random component</td>
<td><span class="math inline">\(\mu_i = \exp(\theta_i)\)</span></td>
<td><span class="math inline">\(g(\mu_i) = \log(\mu_i)\)</span></td>
<td></td>
</tr>
<tr class="even">
<td>Gamma random component</td>
<td><p><span class="math inline">\(\mu_i = -\frac{1}{\theta_i}\)</span></p>
<p><span class="math inline">\(\theta(\mu_i) = - \mu_i^{-1}\)</span></p></td>
<td><span class="math inline">\(g(\mu\_i) = - \frac{1}{\mu_i}\)</span></td>
<td></td>
</tr>
<tr class="odd">
<td>Inverse Gaussian random</td>
<td></td>
<td><span class="math inline">\(g(\mu_i) = \frac{1}{\mu_i^2}\)</span></td>
<td></td>
</tr>
</tbody>
</table>
<div id="estimation-1" class="section level4" number="6.3.7.1">
<h4><span class="header-section-number">6.3.7.1</span> Estimation</h4>
<ul>
<li>MLE for parameters of the <strong>systematic component (</strong><span class="math inline">\(\beta\)</span>)<br />
</li>
<li>Unification of derivation and computation (thanks to the exponential forms)<br />
</li>
<li>No unification for estimation of the dispersion parameter (<span class="math inline">\(\phi\)</span>)</li>
</ul>
<div id="estimation-of-beta" class="section level5" number="6.3.7.1.1">
<h5><span class="header-section-number">6.3.7.1.1</span> Estimation of <span class="math inline">\(\beta\)</span></h5>
<p>We have</p>
<p><span class="math display">\[
f(y_i ; \theta_i, \phi) = \exp(\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi)) \\
E(Y_i) = \mu_i = b&#39;(\theta) \\
var(Y_i) = b&#39;&#39;(\theta)a(\phi) = V(\mu_i)a(\phi) \\
g(\mu_i) = \mathbf{x}_i&#39;\beta = \eta_i
\]</span></p>
<p>If the log-likelihood for a single observation is <span class="math inline">\(l_i (\beta,\phi)\)</span>. The log-likelihood for all n observations is</p>
<p><span class="math display">\[
\begin{align}
l(\beta,\phi) &amp;= \sum_{i=1}^n l_i (\beta,\phi) \\
&amp;= \sum_{i=1}^n (\frac{\theta_i y_i - b(\theta_i)}{a(\phi)}+ c(y_i, \phi))
\end{align}
\]</span></p>
<p>Using MLE to find <span class="math inline">\(\beta\)</span>, we use the chain rule to get the derivatives</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial l_i (\beta,\phi)}{\partial \beta_j} &amp;=  \frac{\partial l_i (\beta, \phi)}{\partial \theta_i} \times \frac{\partial \theta_i}{\partial \mu_i} \times \frac{\partial \mu_i}{\partial \eta_i}\times \frac{\partial \eta_i}{\partial \beta_j} \\
&amp;= \sum_{i=1}^{n}(\frac{ y_i - \mu_i}{a(\phi)} \times \frac{1}{V(\mu_i)} \times \frac{\partial \mu_i}{\partial \eta_i} \times x_{ij})
\end{align}
\]</span></p>
<p>If we let</p>
<p><span class="math display">\[
w_i \equiv ((\frac{\partial \eta_i}{\partial \mu_i})^2 V(\mu_i))^{-1}
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\frac{\partial l_i (\beta,\phi)}{\partial \beta_j} = \sum_{i=1}^n (\frac{y_i \mu_i}{a(\phi)} \times w_i \times \frac{\partial \eta_i}{\partial \mu_i} \times x_{ij})
\]</span></p>
<p>We can also get the second derivatives using the chain rule.</p>
<p>Example:</p>
<p>For the <a href="non-linear-least-squares.html#newton-raphson">Newton-Raphson</a> algorithm, we need</p>
<p><span class="math display">\[
- E(\frac{\partial^2 l(\beta,\phi)}{\partial \beta_j \partial \beta_k})
\]</span> where <span class="math inline">\((j,k)\)</span>th element of the <strong>Fisher information matrix</strong> <span class="math inline">\(\mathbf{I}(\beta)\)</span></p>
<p>Hence,</p>
<p><span class="math display">\[
- E(\frac{\partial^2 l(\beta,\phi)}{\partial \beta_j \partial \beta_k}) = \sum_{i=1}^n \frac{w_i}{a(\phi)}x_{ij}x_{ik}
\]</span> for the (j,k)th element</p>
<p>If Bernoulli model with logit link function (which is the canonical link)</p>
<p><span class="math display">\[
b(\theta) = \log(1 + \exp(\theta)) = \log(1 + \exp(\mathbf{x&#39;\beta})) \\
a(\phi) = 1  \\
c(y_i, \phi) = 0 \\
E(Y) = b&#39;(\theta) = \frac{\exp(\theta)}{1 + \exp(\theta)} = \mu = p \\
\eta = g(\mu) = \log(\frac{\mu}{1-\mu}) = \theta = \log(\frac{p}{1-p}) = \mathbf{x&#39;\beta} 
\]</span></p>
<p>For <span class="math inline">\(Y_i\)</span>, i = 1,.., the log-likelihood is</p>
<p><span class="math display">\[
l_i (\beta, \phi) = \frac{y_i \theta_i - b(\theta_i)}{a(\phi)} + c(y_i, \phi) = y_i \mathbf{x}&#39;_i \beta - \log(1+ \exp(\mathbf{x&#39;\beta}))
\]</span></p>
<p>Additionally,</p>
<p><span class="math display">\[
V(\mu_i) = \mu_i(1-\mu_i)= p_i (1-p_i) \\
\frac{\partial \mu_i}{\partial \eta_i} = p_i(1-p_i)
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial l(\beta, \phi)}{\partial \beta_j} &amp;= \sum_{i=1}^n[\frac{y_i - \mu_i}{a(\phi)} \times \frac{1}{V(\mu_i)}\times \frac{\partial \mu_i}{\partial \eta_i} \times x_{ij}] \\
&amp;= \sum_{i=1}^n (y_i - p_i) \times \frac{1}{p_i(1-p_i)} \times p_i(1-p_i) \times x_{ij} \\
&amp;= \sum_{i=1}^n (y_i - p_i) x_{ij} \\
&amp;= \sum_{i=1}^n (y_i - \frac{\exp(\mathbf{x&#39;_i\beta})}{1+ \exp(\mathbf{x&#39;_i\beta})})x_{ij}
\end{align}
\]</span></p>
<p>then</p>
<p><span class="math display">\[
w_i = ((\frac{\partial \eta_i}{\partial \mu_i})^2 V(\mu_i))^{-1} = p_i (1-p_i)
\]</span></p>
<p><span class="math display">\[
\mathbf{I}_{jk}(\mathbf{\beta}) = \sum_{i=1}^n \frac{w_i}{a(\phi)} x_{ij}x_{ik} = \sum_{i=1}^n p_i (1-p_i)x_{ij}x_{ik}
\]</span></p>
<p>The <strong>Fisher-scoring</strong> algorithm for the MLE of <span class="math inline">\(\mathbf{\beta}\)</span> is</p>
<p><span class="math display">\[
\left(
\begin{array}
{c}
\beta_1 \\
\beta_2 \\
. \\
. \\
. \\
\beta_p \\
\end{array}
\right)^{(m+1)}
=
\left(
\begin{array}
{c}
\beta_1 \\
\beta_2 \\
. \\
. \\
. \\
\beta_p \\
\end{array}
\right)^{(m)} +
\mathbf{I}^{-1}(\mathbf{\beta})
\left(
\begin{array}
{c}
\frac{\partial l (\beta, \phi)}{\partial \beta_1} \\
\frac{\partial l (\beta, \phi)}{\partial \beta_2} \\
. \\
. \\
. \\
\frac{\partial l (\beta, \phi)}{\partial \beta_p} \\
\end{array}
\right)|_{\beta = \beta^{(m)}}
\]</span></p>
<p>Similar to <a href="non-linear-least-squares.html#newton-raphson">Newton-Raphson</a> expect the matrix of second derivatives by the expected value of the second derivative matrix.</p>
<p>In matrix notation,</p>
<p><span class="math display">\[
\begin{align}
\frac{\partial l }{\partial \beta} &amp;= \frac{1}{a(\phi)}\mathbf{X&#39;W\Delta(y - \mu)} \\
&amp;= \frac{1}{a(\phi)}\mathbf{F&#39;V^{-1}(y - \mu)} \\
\end{align}
\]</span></p>
<p><span class="math display">\[
\mathbf{I}(\beta) = \frac{1}{a(\phi)}\mathbf{X&#39;WX} = \frac{1}{a(\phi)}\mathbf{F&#39;V^{-1}F} \\
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{X}\)</span> is an n x p matrix of covariates</li>
<li><span class="math inline">\(\mathbf{W}\)</span> is an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(w_i\)</span></li>
<li><span class="math inline">\(\mathbf{\Delta}\)</span> an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(\frac{\partial \eta_i}{\partial \mu_i}\)</span></li>
<li><span class="math inline">\(\mathbf{F} = \mathbf{\frac{\partial \mu}{\partial \beta}}\)</span> an n x p matrix with ith row <span class="math inline">\(\frac{\partial \mu_i}{\partial \beta} = (\frac{\partial \mu_i}{\partial \eta_i})\mathbf{x}&#39;_i\)</span></li>
<li><span class="math inline">\(\mathbf{V}\)</span> an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(V(\mu_i)\)</span></li>
</ul>
<p>Setting the derivative of the log-likelihood equal to 0, ML estimating equations are</p>
<p><span class="math display">\[
\mathbf{F&#39;V^{-1}y= F&#39;V^{-1}\mu}
\]</span></p>
<p>where all components of this equation expect y depends on the parameters <span class="math inline">\(\beta\)</span></p>
<p><strong>Special Cases</strong></p>
<p>If one has a canonical link, the estimating equations reduce to</p>
<p><span class="math display">\[
\mathbf{X&#39;y= X&#39;\mu}
\]</span></p>
<p>If one has an identity link, then</p>
<p><span class="math display">\[
\mathbf{X&#39;V^{-1}y = X&#39;V^{-1}X\hat{\beta}}
\]</span></p>
<p>which gives the generalized least squares estimator</p>
<p>Generally, we can rewrite the Fisher-scoring algorithm as</p>
<p><span class="math display">\[
\beta^{(m+1)} = \beta^{(m)} + \mathbf{(\hat{F}&#39;\hat{V}^{-1}\hat{F})^{-1}\hat{F}&#39;\hat{V}^{-1}(y- \hat{\mu})}
\]</span></p>
<p>Since <span class="math inline">\(\hat{F},\hat{V}, \hat{\mu}\)</span> depend on <span class="math inline">\(\beta\)</span>, we evaluate at <span class="math inline">\(\beta^{(m)}\)</span></p>
<p>From starting values <span class="math inline">\(\beta^{(0)}\)</span>, we can iterate until convergence.</p>
<p>Notes:</p>
<ul>
<li>if <span class="math inline">\(a(\phi)\)</span> is a constant or of the form <span class="math inline">\(m_i \phi\)</span> with known <span class="math inline">\(m_i\)</span>, then <span class="math inline">\(\phi\)</span> cancels.</li>
</ul>
</div>
<div id="estimation-of-phi" class="section level5" number="6.3.7.1.2">
<h5><span class="header-section-number">6.3.7.1.2</span> Estimation of <span class="math inline">\(\phi\)</span></h5>
<p>2 approaches:</p>
<ol style="list-style-type: decimal">
<li>MLE</li>
</ol>
<p><span class="math display">\[
\frac{\partial l_i}{\partial \phi} = \frac{(\theta_i y_i - b(\theta_i)a&#39;(\phi))}{a^2(\phi)} + \frac{\partial c(y_i,\phi)}{\partial \phi}
\]</span></p>
<p>the MLE of <span class="math inline">\(\phi\)</span> solves</p>
<p><span class="math display">\[
\frac{a^2(\phi)}{a&#39;(\phi)}\sum_{i=1}^n \frac{\partial c(y_i, \phi)}{\partial \phi} = \sum_{i=1}^n(\theta_i y_i - b(\theta_i))
\]</span></p>
<p>* Situation others than normal error case, expression for <span class="math inline">\(\frac{\partial c(y,\phi)}{\partial \phi}\)</span> are not simple<br />
* Even for the canonical link and <span class="math inline">\(a(\phi)\)</span> constant, there is no nice general expression for <span class="math inline">\(-E(\frac{\partial^2 l}{\partial \phi^2})\)</span>, so the unification GLMs provide for estimation of <span class="math inline">\(\beta\)</span> breaks down for <span class="math inline">\(\phi\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p>Moment Estimation (“Bias Corrected <span class="math inline">\(\chi^2\)</span>”)</p>
<ul>
<li>The MLE is not conventional approach to estimation of <span class="math inline">\(\phi\)</span> in GLMS.<br />
</li>
<li>For the exponential family <span class="math inline">\(var(Y) =V(\mu)a(\phi)\)</span>. This implies<br />
<span class="math display">\[
a(\phi) = \frac{var(Y)}{V(\mu)} = \frac{E(Y- \mu)^2}{V(\mu)} \\
a(\hat{\phi})  = \frac{1}{n-p} \sum_{i=1}^n \frac{(y_i -\hat{\mu}_i)^2}{V(\hat{\mu})}
\]</span> where p is the dimension of <span class="math inline">\(\beta\)</span><br />
</li>
<li>GLM with canonical link function <span class="math inline">\(g(.)= (b&#39;(.))^{-1}\)</span><br />
<span class="math display">\[
g(\mu) = \theta = \eta = \mathbf{x&#39;\beta} \\
\mu = g^{-1}(\eta)= b&#39;(\eta)
\]</span></li>
<li>so the method estimator for <span class="math inline">\(a(\phi)=\phi\)</span> is</li>
</ul></li>
</ol>
<p><span class="math display">\[
\hat{\phi} = \frac{1}{n-p} \sum_{i=1}^n \frac{(y_i - g^{-1}(\hat{\eta}_i))^2}{V(g^{-1}(\hat{\eta}_i))}
\]</span></p>
</div>
</div>
<div id="inference-2" class="section level4" number="6.3.7.2">
<h4><span class="header-section-number">6.3.7.2</span> Inference</h4>
<p>We have</p>
<p><span class="math display">\[
\hat{var}(\beta) = a(\phi)(\mathbf{\hat{F}&#39;\hat{V}\hat{F}})^{-1}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{V}\)</span> is an n x n diagonal matrix with diagonal elements given by <span class="math inline">\(V(\mu_i)\)</span></li>
<li><span class="math inline">\(\mathbf{F}\)</span> is an n x p matrix given by <span class="math inline">\(\mathbf{F} = \frac{\partial \mu}{\partial \beta}\)</span></li>
<li>Both <span class="math inline">\(\mathbf{V,F}\)</span> are dependent on the mean <span class="math inline">\(\mu\)</span>, and thus <span class="math inline">\(\beta\)</span>. Hence, their estimates (<span class="math inline">\(\mathbf{\hat{V},\hat{F}}\)</span>) depend on <span class="math inline">\(\hat{\beta}\)</span>.</li>
</ul>
<p><span class="math display">\[
H_0: \mathbf{L\beta = d}
\]</span></p>
<p>where <span class="math inline">\(\mathbf{L}\)</span> is a q x p matrix with a <strong>Wald</strong> test</p>
<p><span class="math display">\[
W = \mathbf{(L \hat{\beta}-d)&#39;(a(\phi)L(\hat{F}&#39;\hat{V}^{-1}\hat{F})L&#39;)^{-1}(L \hat{\beta}-d)}
\]</span></p>
<p>which follows <span class="math inline">\(\chi_q^2\)</span> distribution (asymptotically), where q is the rank of <span class="math inline">\(\mathbf{L}\)</span></p>
<p>In the simple case <span class="math inline">\(H_0: \beta_j = 0\)</span> gives <span class="math inline">\(W = \frac{\hat{\beta}^2_j}{\hat{var}(\hat{\beta}_j)} \sim \chi^2_1\)</span> asymptotically</p>
<p>Likelihood ratio test</p>
<p><span class="math display">\[
\Lambda = 2 (l(\hat{\beta}_f)-l(\hat{\beta}_r)) \sim \chi^2_q
\]</span></p>
<p>where</p>
<ul>
<li>q is the number of constraints used to fit the reduced model <span class="math inline">\(\hat{\beta}_r\)</span>, and <span class="math inline">\(\hat{\beta}_r\)</span> is the fit under the full model.</li>
</ul>
<p>Wald test is easier to implement, but likelihood ratio test is better (especially for small samples).</p>
</div>
<div id="deviance" class="section level4" number="6.3.7.3">
<h4><span class="header-section-number">6.3.7.3</span> Deviance</h4>
<p><a href="generalized-linear-models.html#deviance">Deviance</a> is necessary for goodness of fit, inference and for alternative estimation of the dispersion parameter. We define and consider <a href="generalized-linear-models.html#deviance">Deviance</a> from a likelihood ratio perspective.</p>
<ul>
<li><p>Assume that <span class="math inline">\(\phi\)</span> is known. Let <span class="math inline">\(\tilde{\theta}\)</span> denote the full and <span class="math inline">\(\hat{\theta}\)</span> denote the reduced model MLEs. Then, the likelihood ratio (2 times the difference in log-likelihoods) is <span class="math display">\[
2\sum_{i=1}^{n} \frac{y_i (\tilde{\theta}_i- \hat{\theta}_i)-b(\tilde{\theta}_i) + b(\hat{\theta}_i)}{a_i(\phi)}
\]</span></p></li>
<li><p>For exponential families, <span class="math inline">\(\mu = E(y) = b&#39;(\theta)\)</span>, so the natural parameter is a function of <span class="math inline">\(\mu: \theta = \theta(\mu) = b&#39;^{-1}(\mu)\)</span>, and the likelihood ratio turns into<br />
<span class="math display">\[
2 \sum_{i=1}^m \frac{y_i\{\theta(\tilde{\mu}_i - \theta(\hat{\mu}_i)\} - b(\theta(\tilde{\mu}_i)) + b(\theta(\hat{\mu}_i))}{a_i(\phi)}
\]</span></p></li>
<li><p>Comparing a fitted model to “the fullest possible model,” which is the <strong>saturated model</strong>: <span class="math inline">\(\tilde{\mu}_i = y_i\)</span>, i = 1,..,n. If <span class="math inline">\(\tilde{\theta}_i^* = \theta(y_i), \hat{\theta}_i^* = \theta (\hat{\mu})\)</span>, the likelihood ratio is<br />
<span class="math display">\[
2 \sum_{i=1}^{n} \frac{y_i (\tilde{\theta}_i^* - \hat{\theta}_i^* + b(\hat{\theta}_i^*))}{a_i(\phi)}
\]</span></p></li>
<li><p><span class="citation">(<a href="references.html#ref-McCullagh_2019" role="doc-biblioref">McCullagh and Nelder 2019</a>)</span> specify <span class="math inline">\(a(\phi) = \phi\)</span>, then the likelihood ratio can be written as<br />
<span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) = \frac{2}{\phi}\sum_{i=1}^n\{y_i (\tilde{\theta}_i^*- \hat{\theta}_i^*)- b(\tilde{\theta}_i^*) +b(\hat{\theta}_i^*)  \}  
\]</span> where</p></li>
<li><p><span class="math inline">\(D^*(\mathbf{y, \hat{\mu}})\)</span> = <strong>scaled deviance</strong></p></li>
<li><p><span class="math inline">\(D(\mathbf{y, \hat{\mu}}) = \phi D^*(\mathbf{y, \hat{\mu}})\)</span> = <strong>deviance</strong></p></li>
</ul>
<p><br></p>
<p><strong>Note</strong>:</p>
<ul>
<li><p>in some random component distributions, we can write <span class="math inline">\(a_i(\phi) = \phi m_i\)</span>, where</p>
<ul>
<li><span class="math inline">\(m_i\)</span> is some known scalar that may change with the observations. THen, the scaled deviance components are divided by <span class="math inline">\(m_i\)</span>:<br />
<span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) \equiv 2\sum_{i=1}^n\{y_i (\tilde{\theta}_i^*- \hat{\theta}_i^*)- b(\tilde{\theta}_i^*) +b(\hat{\theta}_i^*)\} / (\phi m_i)  
\]</span></li>
</ul></li>
<li><p><span class="math inline">\(D^*(\mathbf{y, \hat{\mu}}) = \sum_{i=1}^n d_i\)</span>m where <span class="math inline">\(d_i\)</span> is the deviance contribution from the ith observation.</p></li>
<li><p>D is used in model selection</p></li>
<li><p><span class="math inline">\(D^*\)</span> is used in goodness of fit tests (as it is a likelihood ratio statistic). <span class="math display">\[
D^*(\mathbf{y, \hat{\mu}}) = 2\{l(\mathbf{y,\tilde{\mu}})-l(\mathbf{y,\hat{\mu}})\}
\]</span></p></li>
<li><p><span class="math inline">\(d_i\)</span> are used to form <strong>deviance residuals</strong></p></li>
</ul>
<p><br></p>
<p><strong>Example</strong>:</p>
<p><br></p>
<p><strong>Normal</strong></p>
<p>We have</p>
<p><span class="math display">\[
\theta = \mu \\
\phi = \sigma^2 \\
b(\theta) = \frac{1}{2} \theta^2 \\
a(\phi) = \phi
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\tilde{\theta}_i = y_i \\
\hat{\theta}_i = \hat{\mu}_i = g^{-1}(\hat{\eta}_i) 
\]</span></p>
<p>And</p>
<p><span class="math display">\[
\begin{align}
D &amp;= 2 \sum_{1=1}^n Y^2_i - y_i \hat{\mu}_i - \frac{1}{2}y^2_i + \frac{1}{2} \hat{\mu}_i^2 \\
&amp;= \sum_{i=1}^n y_i^2 - 2y_i \hat{\mu}_i + \hat{\mu}_i^2 \\
&amp;= \sum_{i=1}^n (y_i - \hat{\mu}_i)^2
\end{align}
\]</span></p>
<p>which is the <strong>residual sum of squares</strong></p>
<p><br></p>
<p><strong>Poisson</strong></p>
<p><span class="math display">\[
f(y) = \exp\{y\log(\mu) - \mu - \log(y!)\} \\
\theta = \log(\mu) \\
b(\theta) = \exp(\theta) \\
a(\phi) = 1 \\
\tilde{\theta}_i = \log(y_i) \\
\hat{\theta}_i = \log(\hat{\mu}_i) \\
\hat{\mu}_i = g^{-1}(\hat{\eta}_i)
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
\begin{align}
D &amp;= 2 \sum_{i = 1}^n y_i \log(y_i) - y_i \log(\hat{\mu}_i) - y_i + \hat{\mu}_i \\
&amp;= 2 \sum_{i = 1}^n y_i \log(\frac{y_i}{\hat{\mu}_i}) - (y_i - \hat{\mu}_i)
\end{align}
\]</span></p>
<p>and</p>
<p><span class="math display">\[
d_i = 2\{y_i \log(\frac{y_i}{\hat{\mu}})- (y_i - \hat{\mu}_i)\}
\]</span></p>
<p><br></p>
<div id="analysis-of-deviance" class="section level5" number="6.3.7.3.1">
<h5><span class="header-section-number">6.3.7.3.1</span> Analysis of Deviance</h5>
<p>The difference in deviance between a reduced and full model, where q is the difference in the number of free parameters, has an asymptotic <span class="math inline">\(\chi^2_q\)</span>. The likelihood ratio test</p>
<p><span class="math display">\[
D^*(\mathbf{y;\hat{\mu}_r}) - D^*(\mathbf{y;\hat{\mu}_f}) = 2\{l(\mathbf{y;\hat{\mu}_f})-l(\mathbf{y;\hat{\mu}_r})\}
\]</span></p>
<p>this comparison of models is <strong>Analysis of Deviance</strong>. <a href="generalized-linear-models.html#generalized-linear-models">GLM</a> uses this analysis for model selection.</p>
<p>An estimation of <span class="math inline">\(\phi\)</span> is</p>
<p><span class="math display">\[
\hat{\phi} = \frac{D(\mathbf{y, \hat{\mu}})}{n - p}
\]</span></p>
<p>where p = number of parameters fit.</p>
<p>Excessive use of <span class="math inline">\(\chi^2\)</span> test could be problematic since it is asymptotic <span class="citation">(<a href="references.html#ref-McCullagh_2019" role="doc-biblioref">McCullagh and Nelder 2019</a>)</span></p>
<p><br></p>
</div>
<div id="deviance-residuals" class="section level5" number="6.3.7.3.2">
<h5><span class="header-section-number">6.3.7.3.2</span> Deviance Residuals</h5>
<p>We have <span class="math inline">\(D = \sum_{i=1}^{n}d_i\)</span>. Then, we define <strong>deviance residuals</strong></p>
<p><span class="math display">\[
r_{D_i} = \text{sign}(y_i -\hat{\mu}_i)\sqrt{d_i}
\]</span></p>
<p>Standardized version of deviance residuals is</p>
<p><span class="math display">\[
r_{s,i} = \frac{y_i -\hat{\mu}}{\hat{\sigma}(1-h_{ii})^{1/2}}
\]</span></p>
<p>Let <span class="math inline">\(\mathbf{H^{GLM} = W^{1/2}X(X&#39;WX)^{-1}X&#39;W^{-1/2}}\)</span>, where <span class="math inline">\(\mathbf{W}\)</span> is an n x n diagonal matrix with (i,i)th element given by <span class="math inline">\(w_i\)</span> (see <a href="generalized-linear-models.html#estimation-of-beta">Estimation of <span class="math inline">\(\beta\)</span></a>). Then Standardized deviance residuals is equivalently</p>
<p><span class="math display">\[
r_{s, D_i} = \frac{r_{D_i}}{\{\hat{\phi}(1-h_{ii}^{glm}\}^{1/2}}
\]</span></p>
<p>where <span class="math inline">\(h_{ii}^{glm}\)</span> is the ith diagonal of <span class="math inline">\(\mathbf{H}^{GLM}\)</span></p>
<p><br></p>
</div>
<div id="pearson-chi-square-residuals" class="section level5" number="6.3.7.3.3">
<h5><span class="header-section-number">6.3.7.3.3</span> Pearson Chi-square Residuals</h5>
<p>Another <span class="math inline">\(\chi^2\)</span> statistic is <strong>Pearson</strong> <span class="math inline">\(\chi^2\)</span> statistics: (assume <span class="math inline">\(m_i = 1\)</span>)</p>
<p><span class="math display">\[
X^2 = \sum_{i=1}^{n} \frac{(y_i - \hat{\mu}_i)^2}{V(\hat{\mu}_i)}
\]</span></p>
<p>where <span class="math inline">\(\hat{\mu}_i\)</span> is the fitted mean response fo the model of interest.</p>
<p>The <strong>Scaled Pearson</strong> <span class="math inline">\(\chi^2\)</span> statistic is given by <span class="math inline">\(\frac{X^2}{\phi} \sim \chi^2_{n-p}\)</span> where p is the number of parameters esitamted. Hence, the <strong>Pearson</strong> <span class="math inline">\(\chi^2\)</span> residuals are</p>
<p><span class="math display">\[
X^2_i = \frac{(y_i - \hat{\mu}_i)^2}{V(\hat{\mu}_i)}
\]</span></p>
<p>If we have the following assumptions:</p>
<ul>
<li>Independent samples<br />
</li>
<li>No over-dispersion: If <span class="math inline">\(\phi = 1\)</span>, <span class="math inline">\(\frac{D(\mathbf{y;\hat{\mu}})}{n-p}\)</span> and <span class="math inline">\(\frac{X^2}{n-p}\)</span> have a value substantially larger 1 indicates <strong>improperly specified model</strong> or <strong>overdispersion</strong><br />
</li>
<li>Multiple groups</li>
</ul>
<p>then <span class="math inline">\(\frac{X^2}{\phi}\)</span> and <span class="math inline">\(D^*(\mathbf{y; \hat{\mu}})\)</span> both follow <span class="math inline">\(\chi^2_{n-p}\)</span></p>
<p><br></p>
</div>
</div>
<div id="diagnostic-plots" class="section level4" number="6.3.7.4">
<h4><span class="header-section-number">6.3.7.4</span> Diagnostic Plots</h4>
<ul>
<li><p>Standardized residual Plots:</p>
<ul>
<li>plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(\hat{\mu}_i\)</span>) or plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(T(\hat{\mu}_i)\)</span>) where <span class="math inline">\(T(\hat{\mu}_i)\)</span> is transformation(<span class="math inline">\(\hat{\mu}_i\)</span>) called <strong>constant information scale</strong>:<br />
</li>
<li>plot(<span class="math inline">\(r_{s, D_i}\)</span>, <span class="math inline">\(\hat{\eta}_i\)</span>)</li>
</ul></li>
</ul>
<table>
<thead>
<tr class="header">
<th align="center">Random Component</th>
<th align="center"><span class="math inline">\(T(\hat{\mu}_i)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Normal</td>
<td align="center"><span class="math inline">\(\hat{\mu}\)</span></td>
</tr>
<tr class="even">
<td align="center">Poisson</td>
<td align="center"><span class="math inline">\(2\sqrt{\mu}\)</span></td>
</tr>
<tr class="odd">
<td align="center">Binomial</td>
<td align="center"><span class="math inline">\(2 \sin^{-1}(\sqrt{\hat{\mu}})\)</span></td>
</tr>
<tr class="even">
<td align="center">Gamma</td>
<td align="center"><span class="math inline">\(2 \log(\hat{\mu})\)</span></td>
</tr>
<tr class="odd">
<td align="center">Inverse Gaussian</td>
<td align="center"><span class="math inline">\(-2\hat{\mu}^{-1/2}\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li><p>If we see:</p>
<ul>
<li>Trend, it means we might have a wrong link function, or choice of scale<br />
</li>
<li>Systematic change in range of residuals with a change in <span class="math inline">\(T(\hat{\mu})\)</span> (incorrect random component) (systematic <span class="math inline">\(\neq\)</span> random)<br />
</li>
</ul></li>
<li><p>plot(<span class="math inline">\(|r_{D_i}|,\hat{\mu}_i\)</span>) to check <strong>Variance Function</strong>.</p></li>
</ul>
</div>
<div id="goodness-of-fit" class="section level4" number="6.3.7.5">
<h4><span class="header-section-number">6.3.7.5</span> Goodness of Fit</h4>
<p>To assess goodness of fit, we can use</p>
<ul>
<li><a href="generalized-linear-models.html#deviance">Deviance</a><br />
</li>
<li><a href="generalized-linear-models.html#pearson-chi-square-residuals">Pearson Chi-square Residuals</a></li>
</ul>
<p>In nested model, we could use likelihood-based information measures:</p>
<p><span class="math display">\[
AIC = -2l(\mathbf{\hat{\mu}}) + 2p \\
AICC = -2l(\mathbf{\hat{\mu}}) + 2p(\frac{n}{n-p-1}) \\
BIC = 2l(\hat{\mu}) + p \log(n)
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(l(\hat{\mu})\)</span> is the log-likelihood evaluated at the parameter estimates<br />
</li>
<li>p is the number of parameters<br />
</li>
<li>n is the number of observations.</li>
</ul>
<p>Note: you have to use the same data with the same model (i.e., same link function, same random underlying random distribution). but you can have different number of parameters.</p>
<p>Even though statisticians try to come up with measures that are similar to <span class="math inline">\(R^2\)</span>, in practice, it is not so appropriate. For example, they comapre the log-likelihood of the fitted model against the that of a model with jsut the intercept:</p>
<p><span class="math display">\[
R^2_p = 1 - \frac{l(\hat{\mu})}{l(\hat{\mu}_0)}
\]</span></p>
<p>For certain specific random components such as binary response model, we have **rescaled generalized <span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
\bar{R}^2 = \frac{R^2_*}{\max(R^2_*)} = \frac{1-\exp\{-\frac{2}{n}(l(\hat{\mu}) - l(\hat{\mu}_0) \}}{1 - \exp\{\frac{2}{n}l(\hat{\mu}_0)\}}
\]</span></p>
</div>
<div id="over-dispersion" class="section level4" number="6.3.7.6">
<h4><span class="header-section-number">6.3.7.6</span> Over-Dispersion</h4>
<table>
<thead>
<tr class="header">
<th>Random Components</th>
<th><span class="math inline">\(var(Y)\)</span></th>
<th><span class="math inline">\(V(\mu)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Binomial</td>
<td><span class="math inline">\(var(Y) = n \mu (1- \mu)\)</span></td>
<td><span class="math inline">\(V(\mu) = \phi n \mu(1- \mu)\)</span> where <span class="math inline">\(m_i =n\)</span></td>
</tr>
<tr class="even">
<td>Poisson</td>
<td><span class="math inline">\(var(Y) = \mu\)</span></td>
<td><span class="math inline">\(V(\mu) = \phi \mu\)</span></td>
</tr>
</tbody>
</table>
<p>In both cases <span class="math inline">\(\phi = 1\)</span>. Recall <span class="math inline">\(b&#39;&#39;(\theta)= V(\mu)\)</span> check <a href="generalized-linear-models.html#estimation-of-phi">Estimation of <span class="math inline">\(\phi\)</span></a>.</p>
<p>If we find</p>
<ul>
<li><span class="math inline">\(\phi &gt;1\)</span>: over-dispersion (i.e., too much variation for an independent binomial or Poisson distribution).</li>
<li><span class="math inline">\(\phi&lt;1\)</span>: under-dispersion (i.e., too little variation for an independent binomial or Poisson distribution).</li>
</ul>
<p>If we have either over or under-dispersion, it means we might have unspecified random component, we could</p>
<ul>
<li>Select a different random component distribution that can accommodate over or under-dispersion (e.g., negative binomial, Conway-Maxwell Poisson)</li>
<li>use <a href="generalized-linear-mixed-models.html#generalized-linear-mixed-models">Generalized Linear Mixed Models</a> to handle random effects in generalized linear models.</li>
</ul>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="non-linear-least-squares.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="generalized-linear-mixed-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/06-2-nonlinear_regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Data Analysis.pdf", "Data Analysis.epub", "Data Analysis.mobi"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
