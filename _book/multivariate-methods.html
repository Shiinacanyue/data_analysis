<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 16 Multivariate Methods | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct data analysis" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 16 Multivariate Methods | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="/images/cover.jpg" />
  <meta property="og:description" content="This is a guide on how to conduct data analysis" />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 16 Multivariate Methods | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis" />
  <meta name="twitter:image" content="/images/cover.jpg" />

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2021-10-23" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="logo.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="single-factor-covariance-model.html"/>
<link rel="next" href="manova.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-8.1.2/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-8.1.2/highcharts.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-3d.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-more.js"></script>
<script src="libs/highcharts-8.1.2/modules/stock.js"></script>
<script src="libs/highcharts-8.1.2/modules/map.js"></script>
<script src="libs/highcharts-8.1.2/modules/annotations.js"></script>
<script src="libs/highcharts-8.1.2/modules/data.js"></script>
<script src="libs/highcharts-8.1.2/modules/drilldown.js"></script>
<script src="libs/highcharts-8.1.2/modules/item-series.js"></script>
<script src="libs/highcharts-8.1.2/modules/offline-exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-8.1.2/modules/exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/export-data.js"></script>
<script src="libs/highcharts-8.1.2/modules/funnel.js"></script>
<script src="libs/highcharts-8.1.2/modules/heatmap.js"></script>
<script src="libs/highcharts-8.1.2/modules/treemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/sankey.js"></script>
<script src="libs/highcharts-8.1.2/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-8.1.2/modules/organization.js"></script>
<script src="libs/highcharts-8.1.2/modules/solid-gauge.js"></script>
<script src="libs/highcharts-8.1.2/modules/streamgraph.js"></script>
<script src="libs/highcharts-8.1.2/modules/sunburst.js"></script>
<script src="libs/highcharts-8.1.2/modules/vector.js"></script>
<script src="libs/highcharts-8.1.2/modules/wordcloud.js"></script>
<script src="libs/highcharts-8.1.2/modules/xrange.js"></script>
<script src="libs/highcharts-8.1.2/modules/tilemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/venn.js"></script>
<script src="libs/highcharts-8.1.2/modules/gantt.js"></script>
<script src="libs/highcharts-8.1.2/modules/timeline.js"></script>
<script src="libs/highcharts-8.1.2/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-8.1.2/modules/bullet.js"></script>
<script src="libs/highcharts-8.1.2/modules/coloraxis.js"></script>
<script src="libs/highcharts-8.1.2/modules/dumbbell.js"></script>
<script src="libs/highcharts-8.1.2/modules/lollipop.js"></script>
<script src="libs/highcharts-8.1.2/modules/series-label.js"></script>
<script src="libs/highcharts-8.1.2/plugins/motion.js"></script>
<script src="libs/highcharts-8.1.2/custom/reset.js"></script>
<script src="libs/highcharts-8.1.2/modules/boost.js"></script>
<script src="libs/highchart-binding-0.8.2/highchart.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DMNX2X65HQ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a>
<ul>
<li class="chapter" data-level="2.1" data-path="matrix-theory.html"><a href="matrix-theory.html"><i class="fa fa-check"></i><b>2.1</b> Matrix Theory</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="matrix-theory.html"><a href="matrix-theory.html#rank"><i class="fa fa-check"></i><b>2.1.1</b> Rank</a></li>
<li class="chapter" data-level="2.1.2" data-path="matrix-theory.html"><a href="matrix-theory.html#inverse"><i class="fa fa-check"></i><b>2.1.2</b> Inverse</a></li>
<li class="chapter" data-level="2.1.3" data-path="matrix-theory.html"><a href="matrix-theory.html#definiteness"><i class="fa fa-check"></i><b>2.1.3</b> Definiteness</a></li>
<li class="chapter" data-level="2.1.4" data-path="matrix-theory.html"><a href="matrix-theory.html#matrix-calculus"><i class="fa fa-check"></i><b>2.1.4</b> Matrix Calculus</a></li>
<li class="chapter" data-level="2.1.5" data-path="matrix-theory.html"><a href="matrix-theory.html#optimization"><i class="fa fa-check"></i><b>2.1.5</b> Optimization</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2.2</b> Probability Theory</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="probability-theory.html"><a href="probability-theory.html#axiom-and-theorems-of-probability"><i class="fa fa-check"></i><b>2.2.1</b> Axiom and Theorems of Probability</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-theory.html"><a href="probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.3" data-path="probability-theory.html"><a href="probability-theory.html#random-variable"><i class="fa fa-check"></i><b>2.2.3</b> Random variable</a></li>
<li class="chapter" data-level="2.2.4" data-path="probability-theory.html"><a href="probability-theory.html#moment-generating-function"><i class="fa fa-check"></i><b>2.2.4</b> Moment generating function</a></li>
<li class="chapter" data-level="2.2.5" data-path="probability-theory.html"><a href="probability-theory.html#moment"><i class="fa fa-check"></i><b>2.2.5</b> Moment</a></li>
<li class="chapter" data-level="2.2.6" data-path="probability-theory.html"><a href="probability-theory.html#distributions"><i class="fa fa-check"></i><b>2.2.6</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="general-math.html"><a href="general-math.html"><i class="fa fa-check"></i><b>2.3</b> General Math</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="general-math.html"><a href="general-math.html#law-of-large-numbers"><i class="fa fa-check"></i><b>2.3.1</b> Law of large numbers</a></li>
<li class="chapter" data-level="2.3.2" data-path="general-math.html"><a href="general-math.html#law-of-iterated-expectation"><i class="fa fa-check"></i><b>2.3.2</b> Law of Iterated Expectation</a></li>
<li class="chapter" data-level="2.3.3" data-path="general-math.html"><a href="general-math.html#convergence"><i class="fa fa-check"></i><b>2.3.3</b> Convergence</a></li>
<li class="chapter" data-level="2.3.4" data-path="general-math.html"><a href="general-math.html#sufficient-statistics"><i class="fa fa-check"></i><b>2.3.4</b> Sufficient Statistics</a></li>
<li class="chapter" data-level="2.3.5" data-path="general-math.html"><a href="general-math.html#parameter-transformations"><i class="fa fa-check"></i><b>2.3.5</b> Parameter transformations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>2.4</b> Methods</a></li>
<li class="chapter" data-level="2.5" data-path="data-importexport.html"><a href="data-importexport.html"><i class="fa fa-check"></i><b>2.5</b> Data Import/Export</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="data-importexport.html"><a href="data-importexport.html#medium-size"><i class="fa fa-check"></i><b>2.5.1</b> Medium size</a></li>
<li class="chapter" data-level="2.5.2" data-path="data-importexport.html"><a href="data-importexport.html#large-size"><i class="fa fa-check"></i><b>2.5.2</b> Large size</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>2.6</b> Data Manipulation</a></li>
</ul></li>
<li class="part"><span><b>I BASIC</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-stat.html"><a href="descriptive-stat.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="numerical-measures.html"><a href="numerical-measures.html"><i class="fa fa-check"></i><b>3.1</b> Numerical Measures</a></li>
<li class="chapter" data-level="3.2" data-path="graphical-measures.html"><a href="graphical-measures.html"><i class="fa fa-check"></i><b>3.2</b> Graphical Measures</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="graphical-measures.html"><a href="graphical-measures.html#shape"><i class="fa fa-check"></i><b>3.2.1</b> Shape</a></li>
<li class="chapter" data-level="3.2.2" data-path="graphical-measures.html"><a href="graphical-measures.html#scatterplot"><i class="fa fa-check"></i><b>3.2.2</b> Scatterplot</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="normality-assessment.html"><a href="normality-assessment.html"><i class="fa fa-check"></i><b>3.3</b> Normality Assessment</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="normality-assessment.html"><a href="normality-assessment.html#graphical-assessment"><i class="fa fa-check"></i><b>3.3.1</b> Graphical Assessment</a></li>
<li class="chapter" data-level="3.3.2" data-path="normality-assessment.html"><a href="normality-assessment.html#summary-statistics"><i class="fa fa-check"></i><b>3.3.2</b> Summary Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-statistical-inference.html"><a href="basic-statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="4.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>4.1</b> One Sample Inference</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#the-mean"><i class="fa fa-check"></i><b>4.1.1</b> The Mean</a></li>
<li class="chapter" data-level="4.1.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-variance"><i class="fa fa-check"></i><b>4.1.2</b> Single Variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-proportion-p"><i class="fa fa-check"></i><b>4.1.3</b> Single Proportion (p)</a></li>
<li class="chapter" data-level="4.1.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#power"><i class="fa fa-check"></i><b>4.1.4</b> Power</a></li>
<li class="chapter" data-level="4.1.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#sample-size"><i class="fa fa-check"></i><b>4.1.5</b> Sample Size</a></li>
<li class="chapter" data-level="4.1.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#note"><i class="fa fa-check"></i><b>4.1.6</b> Note</a></li>
<li class="chapter" data-level="4.1.7" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-non-parametric-methods"><i class="fa fa-check"></i><b>4.1.7</b> One-sample Non-parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>4.2</b> Two Sample Inference</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#means"><i class="fa fa-check"></i><b>4.2.1</b> Means</a></li>
<li class="chapter" data-level="4.2.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#variances"><i class="fa fa-check"></i><b>4.2.2</b> Variances</a></li>
<li class="chapter" data-level="4.2.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#power-1"><i class="fa fa-check"></i><b>4.2.3</b> Power</a></li>
<li class="chapter" data-level="4.2.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#sample-size-1"><i class="fa fa-check"></i><b>4.2.4</b> Sample Size</a></li>
<li class="chapter" data-level="4.2.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#matched-pair-designs"><i class="fa fa-check"></i><b>4.2.5</b> Matched Pair Designs</a></li>
<li class="chapter" data-level="4.2.6" data-path="two-sample-inference.html"><a href="two-sample-inference.html#nonparametric-tests-for-two-samples"><i class="fa fa-check"></i><b>4.2.6</b> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html"><i class="fa fa-check"></i><b>4.3</b> Categorical Data Analysis</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#inferences-for-small-samples"><i class="fa fa-check"></i><b>4.3.1</b> Inferences for Small Samples</a></li>
<li class="chapter" data-level="4.3.2" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#test-of-association"><i class="fa fa-check"></i><b>4.3.2</b> Test of Association</a></li>
<li class="chapter" data-level="4.3.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-association"><i class="fa fa-check"></i><b>4.3.3</b> Ordinal Association</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II REGRESSION</b></span></li>
<li class="chapter" data-level="5" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>5</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5.1</b> Ordinary Least Squares</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#simple-regression-basic-model"><i class="fa fa-check"></i><b>5.1.1</b> Simple Regression (Basic Model)</a></li>
<li class="chapter" data-level="5.1.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="5.1.3" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#ols-assumptions"><i class="fa fa-check"></i><b>5.1.3</b> OLS Assumptions</a></li>
<li class="chapter" data-level="5.1.4" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#theorems"><i class="fa fa-check"></i><b>5.1.4</b> Theorems</a></li>
<li class="chapter" data-level="5.1.5" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#variable-selection"><i class="fa fa-check"></i><b>5.1.5</b> Variable Selection</a></li>
<li class="chapter" data-level="5.1.6" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#diagnostics-1"><i class="fa fa-check"></i><b>5.1.6</b> Diagnostics</a></li>
<li class="chapter" data-level="5.1.7" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#model-validation"><i class="fa fa-check"></i><b>5.1.7</b> Model Validation</a></li>
<li class="chapter" data-level="5.1.8" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#finite-sample-properties"><i class="fa fa-check"></i><b>5.1.8</b> Finite Sample Properties</a></li>
<li class="chapter" data-level="5.1.9" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#large-sample-properties"><i class="fa fa-check"></i><b>5.1.9</b> Large Sample Properties</a></li>
<li class="chapter" data-level="5.1.10" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#application"><i class="fa fa-check"></i><b>5.1.10</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html"><i class="fa fa-check"></i><b>5.2</b> Feasible Generalized Least Squares</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#heteroskedasticity"><i class="fa fa-check"></i><b>5.2.1</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="5.2.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#serial-correlation"><i class="fa fa-check"></i><b>5.2.2</b> Serial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="weighted-least-squares.html"><a href="weighted-least-squares.html"><i class="fa fa-check"></i><b>5.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.4" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5.4</b> Generalized Least Squares</a></li>
<li class="chapter" data-level="5.5" data-path="feasiable-prais-winsten.html"><a href="feasiable-prais-winsten.html"><i class="fa fa-check"></i><b>5.5</b> Feasiable Prais Winsten</a></li>
<li class="chapter" data-level="5.6" data-path="feasible-group-level-random-effects.html"><a href="feasible-group-level-random-effects.html"><i class="fa fa-check"></i><b>5.6</b> Feasible group level Random Effects</a></li>
<li class="chapter" data-level="5.7" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>5.7</b> Ridge Regression</a></li>
<li class="chapter" data-level="5.8" data-path="principal-component-regression.html"><a href="principal-component-regression.html"><i class="fa fa-check"></i><b>5.8</b> Principal Component Regression</a></li>
<li class="chapter" data-level="5.9" data-path="robust-regression.html"><a href="robust-regression.html"><i class="fa fa-check"></i><b>5.9</b> Robust Regression</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="robust-regression.html"><a href="robust-regression.html#least-absolute-residuals-lar-regression"><i class="fa fa-check"></i><b>5.9.1</b> Least Absolute Residuals (LAR) Regression</a></li>
<li class="chapter" data-level="5.9.2" data-path="robust-regression.html"><a href="robust-regression.html#least-median-of-squares-lms-regression"><i class="fa fa-check"></i><b>5.9.2</b> Least Median of Squares (LMS) Regression</a></li>
<li class="chapter" data-level="5.9.3" data-path="robust-regression.html"><a href="robust-regression.html#iteratively-reweighted-least-squares-irls-robust-regression"><i class="fa fa-check"></i><b>5.9.3</b> Iteratively Reweighted Least Squares (IRLS) Robust Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html"><i class="fa fa-check"></i><b>5.10</b> Maximum Likelihood</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#motivation-for-mle"><i class="fa fa-check"></i><b>5.10.1</b> Motivation for MLE</a></li>
<li class="chapter" data-level="5.10.2" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#assumption"><i class="fa fa-check"></i><b>5.10.2</b> Assumption</a></li>
<li class="chapter" data-level="5.10.3" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#properties"><i class="fa fa-check"></i><b>5.10.3</b> Properties</a></li>
<li class="chapter" data-level="5.10.4" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#compare-to-ols"><i class="fa fa-check"></i><b>5.10.4</b> Compare to OLS</a></li>
<li class="chapter" data-level="5.10.5" data-path="maximum-likelihood-regression.html"><a href="maximum-likelihood-regression.html#application-1"><i class="fa fa-check"></i><b>5.10.5</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Non-linear Regression</a>
<ul>
<li class="chapter" data-level="6.1" data-path="inference-1.html"><a href="inference-1.html"><i class="fa fa-check"></i><b>6.1</b> Inference</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="inference-1.html"><a href="inference-1.html#linear-function-of-the-parameters"><i class="fa fa-check"></i><b>6.1.1</b> Linear Function of the Parameters</a></li>
<li class="chapter" data-level="6.1.2" data-path="inference-1.html"><a href="inference-1.html#nonlinear"><i class="fa fa-check"></i><b>6.1.2</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html"><i class="fa fa-check"></i><b>6.2</b> Non-linear Least Squares</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#alternative-of-gauss-newton-algorithm"><i class="fa fa-check"></i><b>6.2.1</b> Alternative of Gauss-Newton Algorithm</a></li>
<li class="chapter" data-level="6.2.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#practical-considerations"><i class="fa fa-check"></i><b>6.2.2</b> Practical Considerations</a></li>
<li class="chapter" data-level="6.2.3" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#modelestiamtion-adequcy"><i class="fa fa-check"></i><b>6.2.3</b> Model/Estiamtion Adequcy</a></li>
<li class="chapter" data-level="6.2.4" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#application-2"><i class="fa fa-check"></i><b>6.2.4</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>7</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>7.1</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#application-3"><i class="fa fa-check"></i><b>7.1.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="probit-regression.html"><a href="probit-regression.html"><i class="fa fa-check"></i><b>7.2</b> Probit Regression</a></li>
<li class="chapter" data-level="7.3" data-path="binomial-regression.html"><a href="binomial-regression.html"><i class="fa fa-check"></i><b>7.3</b> Binomial Regression</a></li>
<li class="chapter" data-level="7.4" data-path="poisson-regression.html"><a href="poisson-regression.html"><i class="fa fa-check"></i><b>7.4</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="poisson-regression.html"><a href="poisson-regression.html#application-4"><i class="fa fa-check"></i><b>7.4.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="negative-binomial-regression.html"><a href="negative-binomial-regression.html"><i class="fa fa-check"></i><b>7.5</b> Negative Binomial Regression</a></li>
<li class="chapter" data-level="7.6" data-path="multinomial.html"><a href="multinomial.html"><i class="fa fa-check"></i><b>7.6</b> Multinomial</a></li>
<li class="chapter" data-level="7.7" data-path="generalization.html"><a href="generalization.html"><i class="fa fa-check"></i><b>7.7</b> Generalization</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="generalization.html"><a href="generalization.html#estimation-1"><i class="fa fa-check"></i><b>7.7.1</b> Estimation</a></li>
<li class="chapter" data-level="7.7.2" data-path="generalization.html"><a href="generalization.html#inference-2"><i class="fa fa-check"></i><b>7.7.2</b> Inference</a></li>
<li class="chapter" data-level="7.7.3" data-path="generalization.html"><a href="generalization.html#deviance"><i class="fa fa-check"></i><b>7.7.3</b> Deviance</a></li>
<li class="chapter" data-level="7.7.4" data-path="generalization.html"><a href="generalization.html#diagnostic-plots"><i class="fa fa-check"></i><b>7.7.4</b> Diagnostic Plots</a></li>
<li class="chapter" data-level="7.7.5" data-path="generalization.html"><a href="generalization.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.7.5</b> Goodness of Fit</a></li>
<li class="chapter" data-level="7.7.6" data-path="generalization.html"><a href="generalization.html#over-dispersion"><i class="fa fa-check"></i><b>7.7.6</b> Over-Dispersion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-mixed-models.html"><a href="linear-mixed-models.html"><i class="fa fa-check"></i><b>8</b> Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="dependent-data.html"><a href="dependent-data.html"><i class="fa fa-check"></i><b>8.1</b> Dependent Data</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="dependent-data.html"><a href="dependent-data.html#random-intercepts-model"><i class="fa fa-check"></i><b>8.1.1</b> Random-Intercepts Model</a></li>
<li class="chapter" data-level="8.1.2" data-path="dependent-data.html"><a href="dependent-data.html#covariance-models"><i class="fa fa-check"></i><b>8.1.2</b> Covariance Models</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="estimation-2.html"><a href="estimation-2.html"><i class="fa fa-check"></i><b>8.2</b> Estimation</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="estimation-2.html"><a href="estimation-2.html#estimating-mathbfv"><i class="fa fa-check"></i><b>8.2.1</b> Estimating <span class="math inline">\(\mathbf{V}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="inference-3.html"><a href="inference-3.html"><i class="fa fa-check"></i><b>8.3</b> Inference</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="inference-3.html"><a href="inference-3.html#parameters-beta"><i class="fa fa-check"></i><b>8.3.1</b> Parameters <span class="math inline">\(\beta\)</span></a></li>
<li class="chapter" data-level="8.3.2" data-path="inference-3.html"><a href="inference-3.html#variance-components"><i class="fa fa-check"></i><b>8.3.2</b> Variance Components</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="information-criteria.html"><a href="information-criteria.html"><i class="fa fa-check"></i><b>8.4</b> Information Criteria</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="information-criteria.html"><a href="information-criteria.html#akaikes-information-criteria-aic"><i class="fa fa-check"></i><b>8.4.1</b> Akaike’s Information Criteria (AIC)</a></li>
<li class="chapter" data-level="8.4.2" data-path="information-criteria.html"><a href="information-criteria.html#corrected-aic-aicc"><i class="fa fa-check"></i><b>8.4.2</b> Corrected AIC (AICC)</a></li>
<li class="chapter" data-level="8.4.3" data-path="information-criteria.html"><a href="information-criteria.html#bayesian-information-criteria-bic"><i class="fa fa-check"></i><b>8.4.3</b> Bayesian Information Criteria (BIC)</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="split-plot-designs.html"><a href="split-plot-designs.html"><i class="fa fa-check"></i><b>8.5</b> Split-Plot Designs</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="split-plot-designs.html"><a href="split-plot-designs.html#application-5"><i class="fa fa-check"></i><b>8.5.1</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="repeated-measures-in-mixed-models.html"><a href="repeated-measures-in-mixed-models.html"><i class="fa fa-check"></i><b>8.6</b> Repeated Measures in Mixed Models</a></li>
<li class="chapter" data-level="8.7" data-path="unbalanced-or-unequally-spaced-data.html"><a href="unbalanced-or-unequally-spaced-data.html"><i class="fa fa-check"></i><b>8.7</b> Unbalanced or Unequally Spaced Data</a></li>
<li class="chapter" data-level="8.8" data-path="application-6.html"><a href="application-6.html"><i class="fa fa-check"></i><b>8.8</b> Application</a>
<ul>
<li class="chapter" data-level="8.8.1" data-path="application-6.html"><a href="application-6.html#example-1-pulps"><i class="fa fa-check"></i><b>8.8.1</b> Example 1 (Pulps)</a></li>
<li class="chapter" data-level="8.8.2" data-path="application-6.html"><a href="application-6.html#example-2-rats"><i class="fa fa-check"></i><b>8.8.2</b> Example 2 (Rats)</a></li>
<li class="chapter" data-level="8.8.3" data-path="application-6.html"><a href="application-6.html#example-3-agridat"><i class="fa fa-check"></i><b>8.8.3</b> Example 3 (Agridat)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="nonlinear-and-generalized-linear-mixed-models.html"><a href="nonlinear-and-generalized-linear-mixed-models.html"><i class="fa fa-check"></i><b>9</b> Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="estimation-3.html"><a href="estimation-3.html"><i class="fa fa-check"></i><b>9.1</b> Estimation</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="estimation-3.html"><a href="estimation-3.html#estimation-by-numerical-integration"><i class="fa fa-check"></i><b>9.1.1</b> Estimation by Numerical Integration</a></li>
<li class="chapter" data-level="9.1.2" data-path="estimation-3.html"><a href="estimation-3.html#estimation-by-linearization"><i class="fa fa-check"></i><b>9.1.2</b> Estimation by Linearization</a></li>
<li class="chapter" data-level="9.1.3" data-path="estimation-3.html"><a href="estimation-3.html#estimation-by-bayesian-hierarchical-models"><i class="fa fa-check"></i><b>9.1.3</b> Estimation by Bayesian Hierarchical Models</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="application-7.html"><a href="application-7.html"><i class="fa fa-check"></i><b>9.2</b> Application</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="application-7.html"><a href="application-7.html#binomial-cbpp-data"><i class="fa fa-check"></i><b>9.2.1</b> Binomial (CBPP Data)</a></li>
<li class="chapter" data-level="9.2.2" data-path="application-7.html"><a href="application-7.html#count-owl-data"><i class="fa fa-check"></i><b>9.2.2</b> Count (Owl Data)</a></li>
<li class="chapter" data-level="9.2.3" data-path="application-7.html"><a href="application-7.html#binomial-1"><i class="fa fa-check"></i><b>9.2.3</b> Binomial</a></li>
<li class="chapter" data-level="9.2.4" data-path="application-7.html"><a href="application-7.html#example-from-schabenberger_2001-section-8.4.1"><i class="fa fa-check"></i><b>9.2.4</b> Example from <span class="citation">(<span>Schabenberger and Pierce 2001</span>)</span> section 8.4.1</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="summary-1.html"><a href="summary-1.html"><i class="fa fa-check"></i><b>9.3</b> Summary</a></li>
</ul></li>
<li class="part"><span><b>III RAMIFICATIONS</b></span></li>
<li class="chapter" data-level="10" data-path="model-specification.html"><a href="model-specification.html"><i class="fa fa-check"></i><b>10</b> Model Specification</a>
<ul>
<li class="chapter" data-level="10.1" data-path="nested-model.html"><a href="nested-model.html"><i class="fa fa-check"></i><b>10.1</b> Nested Model</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="nested-model.html"><a href="nested-model.html#chow-test"><i class="fa fa-check"></i><b>10.1.1</b> Chow test</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="non-nested-model.html"><a href="non-nested-model.html"><i class="fa fa-check"></i><b>10.2</b> Non-Nested Model</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="non-nested-model.html"><a href="non-nested-model.html#davidson-mackinnon-test"><i class="fa fa-check"></i><b>10.2.1</b> Davidson-Mackinnon test</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html"><i class="fa fa-check"></i><b>10.3</b> Heteroskedasticity</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#breusch-pagan-test"><i class="fa fa-check"></i><b>10.3.1</b> Breusch-Pagan test</a></li>
<li class="chapter" data-level="10.3.2" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#white-test"><i class="fa fa-check"></i><b>10.3.2</b> White test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="imputation-missing-data.html"><a href="imputation-missing-data.html"><i class="fa fa-check"></i><b>11</b> Imputation (Missing Data)</a>
<ul>
<li class="chapter" data-level="11.1" data-path="assumptions-1.html"><a href="assumptions-1.html"><i class="fa fa-check"></i><b>11.1</b> Assumptions</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-completely-at-random-mcar"><i class="fa fa-check"></i><b>11.1.1</b> Missing Completely at Random (MCAR)</a></li>
<li class="chapter" data-level="11.1.2" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-at-random-mar"><i class="fa fa-check"></i><b>11.1.2</b> Missing at Random (MAR)</a></li>
<li class="chapter" data-level="11.1.3" data-path="assumptions-1.html"><a href="assumptions-1.html#ignorable"><i class="fa fa-check"></i><b>11.1.3</b> Ignorable</a></li>
<li class="chapter" data-level="11.1.4" data-path="assumptions-1.html"><a href="assumptions-1.html#nonignorable"><i class="fa fa-check"></i><b>11.1.4</b> Nonignorable</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html"><i class="fa fa-check"></i><b>11.2</b> Solutions to Missing data</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#listwise-deletion"><i class="fa fa-check"></i><b>11.2.1</b> Listwise Deletion</a></li>
<li class="chapter" data-level="11.2.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#pairwise-deletion"><i class="fa fa-check"></i><b>11.2.2</b> Pairwise Deletion</a></li>
<li class="chapter" data-level="11.2.3" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#dummy-variable-adjustment"><i class="fa fa-check"></i><b>11.2.3</b> Dummy Variable Adjustment</a></li>
<li class="chapter" data-level="11.2.4" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#imputation"><i class="fa fa-check"></i><b>11.2.4</b> Imputation</a></li>
<li class="chapter" data-level="11.2.5" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#other-methods"><i class="fa fa-check"></i><b>11.2.5</b> Other methods</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="criteria-for-choosing-an-effective-approach.html"><a href="criteria-for-choosing-an-effective-approach.html"><i class="fa fa-check"></i><b>11.3</b> Criteria for Choosing an Effective Approach</a></li>
<li class="chapter" data-level="11.4" data-path="another-perspective.html"><a href="another-perspective.html"><i class="fa fa-check"></i><b>11.4</b> Another Perspective</a></li>
<li class="chapter" data-level="11.5" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html"><i class="fa fa-check"></i><b>11.5</b> Diagnosing the Mechanism</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mar-vs.-mnar"><i class="fa fa-check"></i><b>11.5.1</b> MAR vs. MNAR</a></li>
<li class="chapter" data-level="11.5.2" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mcar-vs.-mar"><i class="fa fa-check"></i><b>11.5.2</b> MCAR vs. MAR</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="application-8.html"><a href="application-8.html"><i class="fa fa-check"></i><b>11.6</b> Application</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="application-8.html"><a href="application-8.html#imputation-with-mean-median-mode"><i class="fa fa-check"></i><b>11.6.1</b> Imputation with mean / median / mode</a></li>
<li class="chapter" data-level="11.6.2" data-path="application-8.html"><a href="application-8.html#knn"><i class="fa fa-check"></i><b>11.6.2</b> KNN</a></li>
<li class="chapter" data-level="11.6.3" data-path="application-8.html"><a href="application-8.html#rpart"><i class="fa fa-check"></i><b>11.6.3</b> rpart</a></li>
<li class="chapter" data-level="11.6.4" data-path="application-8.html"><a href="application-8.html#mice-multivariate-imputation-via-chained-equations"><i class="fa fa-check"></i><b>11.6.4</b> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li class="chapter" data-level="11.6.5" data-path="application-8.html"><a href="application-8.html#amelia"><i class="fa fa-check"></i><b>11.6.5</b> Amelia</a></li>
<li class="chapter" data-level="11.6.6" data-path="application-8.html"><a href="application-8.html#missforest"><i class="fa fa-check"></i><b>11.6.6</b> missForest</a></li>
<li class="chapter" data-level="11.6.7" data-path="application-8.html"><a href="application-8.html#hmisc"><i class="fa fa-check"></i><b>11.6.7</b> Hmisc</a></li>
<li class="chapter" data-level="11.6.8" data-path="application-8.html"><a href="application-8.html#mi"><i class="fa fa-check"></i><b>11.6.8</b> mi</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>12</b> Data</a>
<ul>
<li class="chapter" data-level="12.1" data-path="cross-sectional.html"><a href="cross-sectional.html"><i class="fa fa-check"></i><b>12.1</b> Cross-Sectional</a></li>
<li class="chapter" data-level="12.2" data-path="time-series-1.html"><a href="time-series-1.html"><i class="fa fa-check"></i><b>12.2</b> Time Series</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="time-series-1.html"><a href="time-series-1.html#deterministic-time-trend"><i class="fa fa-check"></i><b>12.2.1</b> Deterministic Time trend</a></li>
<li class="chapter" data-level="12.2.2" data-path="time-series-1.html"><a href="time-series-1.html#feedback-effect"><i class="fa fa-check"></i><b>12.2.2</b> Feedback Effect</a></li>
<li class="chapter" data-level="12.2.3" data-path="time-series-1.html"><a href="time-series-1.html#dynamic-specification"><i class="fa fa-check"></i><b>12.2.3</b> Dynamic Specification</a></li>
<li class="chapter" data-level="12.2.4" data-path="time-series-1.html"><a href="time-series-1.html#dynamically-complete"><i class="fa fa-check"></i><b>12.2.4</b> Dynamically Complete</a></li>
<li class="chapter" data-level="12.2.5" data-path="time-series-1.html"><a href="time-series-1.html#highly-persistent-data"><i class="fa fa-check"></i><b>12.2.5</b> Highly Persistent Data</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html"><i class="fa fa-check"></i><b>12.3</b> Repeated Cross Sections</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html#pooled-cross-section"><i class="fa fa-check"></i><b>12.3.1</b> Pooled Cross Section</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>12.4</b> Panel Data</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="panel-data.html"><a href="panel-data.html#pooled-ols-estimator"><i class="fa fa-check"></i><b>12.4.1</b> Pooled OLS Estimator</a></li>
<li class="chapter" data-level="12.4.2" data-path="panel-data.html"><a href="panel-data.html#individual-specific-effects-model"><i class="fa fa-check"></i><b>12.4.2</b> Individual-specific effects model</a></li>
<li class="chapter" data-level="12.4.3" data-path="panel-data.html"><a href="panel-data.html#tests-for-assumptions"><i class="fa fa-check"></i><b>12.4.3</b> Tests for Assumptions</a></li>
<li class="chapter" data-level="12.4.4" data-path="panel-data.html"><a href="panel-data.html#model-selection"><i class="fa fa-check"></i><b>12.4.4</b> Model Selection</a></li>
<li class="chapter" data-level="12.4.5" data-path="panel-data.html"><a href="panel-data.html#summary-2"><i class="fa fa-check"></i><b>12.4.5</b> Summary</a></li>
<li class="chapter" data-level="12.4.6" data-path="panel-data.html"><a href="panel-data.html#application-9"><i class="fa fa-check"></i><b>12.4.6</b> Application</a></li>
<li class="chapter" data-level="12.4.7" data-path="panel-data.html"><a href="panel-data.html#other-estimators"><i class="fa fa-check"></i><b>12.4.7</b> Other Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>13</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="13.1" data-path="types-of-hypothesis-testing.html"><a href="types-of-hypothesis-testing.html"><i class="fa fa-check"></i><b>13.1</b> Types of hypothesis testing</a></li>
<li class="chapter" data-level="13.2" data-path="wald-test.html"><a href="wald-test.html"><i class="fa fa-check"></i><b>13.2</b> Wald test</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="wald-test.html"><a href="wald-test.html#multiple-hypothesis"><i class="fa fa-check"></i><b>13.2.1</b> Multiple Hypothesis</a></li>
<li class="chapter" data-level="13.2.2" data-path="wald-test.html"><a href="wald-test.html#linear-combination"><i class="fa fa-check"></i><b>13.2.2</b> Linear Combination</a></li>
<li class="chapter" data-level="13.2.3" data-path="wald-test.html"><a href="wald-test.html#application-10"><i class="fa fa-check"></i><b>13.2.3</b> Application</a></li>
<li class="chapter" data-level="13.2.4" data-path="wald-test.html"><a href="wald-test.html#nonlinear-1"><i class="fa fa-check"></i><b>13.2.4</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="the-likelihood-ratio-test.html"><a href="the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>13.3</b> The likelihood ratio test</a></li>
<li class="chapter" data-level="13.4" data-path="lagrange-multiplier-score.html"><a href="lagrange-multiplier-score.html"><i class="fa fa-check"></i><b>13.4</b> Lagrange Multiplier (Score)</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="prediction-and-estimation.html"><a href="prediction-and-estimation.html"><i class="fa fa-check"></i><b>14</b> Prediction and Estimation</a></li>
<li class="part"><span><b>IV EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="15" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>15</b> Analysis of Variance (ANOVA)</a>
<ul>
<li class="chapter" data-level="15.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html"><i class="fa fa-check"></i><b>15.1</b> Completely Randomized Design (CRD)</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model"><i class="fa fa-check"></i><b>15.1.1</b> Single Factor Fixed Effects Model</a></li>
<li class="chapter" data-level="15.1.2" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-random-effects-model"><i class="fa fa-check"></i><b>15.1.2</b> Single Factor Random Effects Model</a></li>
<li class="chapter" data-level="15.1.3" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova"><i class="fa fa-check"></i><b>15.1.3</b> Two Factor Fixed Effect ANOVA</a></li>
<li class="chapter" data-level="15.1.4" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-random-effects-anova"><i class="fa fa-check"></i><b>15.1.4</b> Two-Way Random Effects ANOVA</a></li>
<li class="chapter" data-level="15.1.5" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova"><i class="fa fa-check"></i><b>15.1.5</b> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html"><i class="fa fa-check"></i><b>15.2</b> Nonparametric ANOVA</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#kruskal-wallis"><i class="fa fa-check"></i><b>15.2.1</b> Kruskal-Wallis</a></li>
<li class="chapter" data-level="15.2.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#friedman-test"><i class="fa fa-check"></i><b>15.2.2</b> Friedman Test</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html"><i class="fa fa-check"></i><b>15.3</b> Sample Size Planning for ANOVA</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#balanced-designs"><i class="fa fa-check"></i><b>15.3.1</b> Balanced Designs</a></li>
<li class="chapter" data-level="15.3.2" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#randomized-block-experiments"><i class="fa fa-check"></i><b>15.3.2</b> Randomized Block Experiments</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html"><i class="fa fa-check"></i><b>15.4</b> Randomized Block Designs</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html#tukey-test-of-additivity"><i class="fa fa-check"></i><b>15.4.1</b> Tukey Test of Additivity</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="nested-designs.html"><a href="nested-designs.html"><i class="fa fa-check"></i><b>15.5</b> Nested Designs</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="nested-designs.html"><a href="nested-designs.html#two-factor-nested-designs"><i class="fa fa-check"></i><b>15.5.1</b> Two-Factor Nested Designs</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html"><i class="fa fa-check"></i><b>15.6</b> Single Factor Covariance Model</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="multivariate-methods.html"><a href="multivariate-methods.html"><i class="fa fa-check"></i><b>16</b> Multivariate Methods</a>
<ul>
<li class="chapter" data-level="16.0.1" data-path="multivariate-methods.html"><a href="multivariate-methods.html#properties-of-mvn"><i class="fa fa-check"></i><b>16.0.1</b> Properties of MVN</a></li>
<li class="chapter" data-level="16.0.2" data-path="multivariate-methods.html"><a href="multivariate-methods.html#mean-vector-inference"><i class="fa fa-check"></i><b>16.0.2</b> Mean Vector Inference</a></li>
<li class="chapter" data-level="16.0.3" data-path="multivariate-methods.html"><a href="multivariate-methods.html#general-hypothesis-testing"><i class="fa fa-check"></i><b>16.0.3</b> General Hypothesis Testing</a></li>
<li class="chapter" data-level="16.1" data-path="manova.html"><a href="manova.html"><i class="fa fa-check"></i><b>16.1</b> MANOVA</a>
<ul>
<li class="chapter" data-level="16.1.1" data-path="manova.html"><a href="manova.html#testing-general-hypotheses"><i class="fa fa-check"></i><b>16.1.1</b> Testing General Hypotheses</a></li>
<li class="chapter" data-level="16.1.2" data-path="manova.html"><a href="manova.html#profile-analysis"><i class="fa fa-check"></i><b>16.1.2</b> Profile Analysis</a></li>
<li class="chapter" data-level="16.1.3" data-path="manova.html"><a href="manova.html#summary-4"><i class="fa fa-check"></i><b>16.1.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="principal-components.html"><a href="principal-components.html"><i class="fa fa-check"></i><b>16.2</b> Principal Components</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="principal-components.html"><a href="principal-components.html#population-principal-components"><i class="fa fa-check"></i><b>16.2.1</b> Population Principal Components</a></li>
<li class="chapter" data-level="16.2.2" data-path="principal-components.html"><a href="principal-components.html#sample-principal-components"><i class="fa fa-check"></i><b>16.2.2</b> Sample Principal Components</a></li>
<li class="chapter" data-level="16.2.3" data-path="principal-components.html"><a href="principal-components.html#application-11"><i class="fa fa-check"></i><b>16.2.3</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="factor-analysis.html"><a href="factor-analysis.html"><i class="fa fa-check"></i><b>16.3</b> Factor Analysis</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="factor-analysis.html"><a href="factor-analysis.html#methods-of-estimation"><i class="fa fa-check"></i><b>16.3.1</b> Methods of Estimation</a></li>
<li class="chapter" data-level="16.3.2" data-path="factor-analysis.html"><a href="factor-analysis.html#factor-rotation"><i class="fa fa-check"></i><b>16.3.2</b> Factor Rotation</a></li>
<li class="chapter" data-level="16.3.3" data-path="factor-analysis.html"><a href="factor-analysis.html#estimation-of-factor-scores"><i class="fa fa-check"></i><b>16.3.3</b> Estimation of Factor Scores</a></li>
<li class="chapter" data-level="16.3.4" data-path="factor-analysis.html"><a href="factor-analysis.html#model-diagnostic"><i class="fa fa-check"></i><b>16.3.4</b> Model Diagnostic</a></li>
<li class="chapter" data-level="16.3.5" data-path="factor-analysis.html"><a href="factor-analysis.html#application-12"><i class="fa fa-check"></i><b>16.3.5</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html"><i class="fa fa-check"></i><b>16.4</b> Discriminant Analysis</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#known-populations"><i class="fa fa-check"></i><b>16.4.1</b> Known Populations</a></li>
<li class="chapter" data-level="16.4.2" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#probabilities-of-misclassification"><i class="fa fa-check"></i><b>16.4.2</b> Probabilities of Misclassification</a></li>
<li class="chapter" data-level="16.4.3" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#unknown-populations-nonparametric-discrimination"><i class="fa fa-check"></i><b>16.4.3</b> Unknown Populations/ Nonparametric Discrimination</a></li>
<li class="chapter" data-level="16.4.4" data-path="discriminant-analysis.html"><a href="discriminant-analysis.html#application-13"><i class="fa fa-check"></i><b>16.4.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>16.5</b> Cluster Analysis</a></li>
</ul></li>
<li class="part"><span><b>V CAUSAL INFERENCE</b></span></li>
<li class="chapter" data-level="17" data-path="causal-inference.html"><a href="causal-inference.html"><i class="fa fa-check"></i><b>17</b> Causal Inference</a></li>
<li class="chapter" data-level="18" data-path="experimental-design.html"><a href="experimental-design.html"><i class="fa fa-check"></i><b>18</b> Experimental Design</a></li>
<li class="chapter" data-level="19" data-path="quasi-experimental.html"><a href="quasi-experimental.html"><i class="fa fa-check"></i><b>19</b> Quasi-experimental</a>
<ul>
<li class="chapter" data-level="19.1" data-path="regression-discontinuity.html"><a href="regression-discontinuity.html"><i class="fa fa-check"></i><b>19.1</b> Regression Discontinuity</a></li>
<li class="chapter" data-level="19.2" data-path="difference-in-differences.html"><a href="difference-in-differences.html"><i class="fa fa-check"></i><b>19.2</b> Difference-In-Differences</a></li>
<li class="chapter" data-level="19.3" data-path="synthetic-control.html"><a href="synthetic-control.html"><i class="fa fa-check"></i><b>19.3</b> Synthetic Control</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="synthetic-control.html"><a href="synthetic-control.html#example-1-1"><i class="fa fa-check"></i><b>19.3.1</b> Example 1</a></li>
<li class="chapter" data-level="19.3.2" data-path="synthetic-control.html"><a href="synthetic-control.html#example-2"><i class="fa fa-check"></i><b>19.3.2</b> Example 2</a></li>
<li class="chapter" data-level="19.3.3" data-path="synthetic-control.html"><a href="synthetic-control.html#example-3"><i class="fa fa-check"></i><b>19.3.3</b> Example 3</a></li>
<li class="chapter" data-level="19.3.4" data-path="synthetic-control.html"><a href="synthetic-control.html#example-4"><i class="fa fa-check"></i><b>19.3.4</b> Example 4</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="matching-methods.html"><a href="matching-methods.html"><i class="fa fa-check"></i><b>19.4</b> Matching Methods</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="matching-methods.html"><a href="matching-methods.html#matchit"><i class="fa fa-check"></i><b>19.4.1</b> MatchIt</a></li>
<li class="chapter" data-level="19.4.2" data-path="matching-methods.html"><a href="matching-methods.html#matchingfrontier"><i class="fa fa-check"></i><b>19.4.2</b> MatchingFrontier</a></li>
<li class="chapter" data-level="19.4.3" data-path="matching-methods.html"><a href="matching-methods.html#propensity-scores"><i class="fa fa-check"></i><b>19.4.3</b> Propensity Scores</a></li>
<li class="chapter" data-level="19.4.4" data-path="matching-methods.html"><a href="matching-methods.html#mahalanobis-distance"><i class="fa fa-check"></i><b>19.4.4</b> Mahalanobis Distance</a></li>
<li class="chapter" data-level="19.4.5" data-path="matching-methods.html"><a href="matching-methods.html#coarsened-exact-matching"><i class="fa fa-check"></i><b>19.4.5</b> Coarsened Exact Matching</a></li>
<li class="chapter" data-level="19.4.6" data-path="matching-methods.html"><a href="matching-methods.html#genetic-matching"><i class="fa fa-check"></i><b>19.4.6</b> Genetic Matching</a></li>
<li class="chapter" data-level="19.4.7" data-path="matching-methods.html"><a href="matching-methods.html#matching-for-time-series-cross-section-data"><i class="fa fa-check"></i><b>19.4.7</b> Matching for time series-cross-section data</a></li>
</ul></li>
<li class="chapter" data-level="19.5" data-path="interrupted-time-series.html"><a href="interrupted-time-series.html"><i class="fa fa-check"></i><b>19.5</b> Interrupted Time Series</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="endogeneity.html"><a href="endogeneity.html"><i class="fa fa-check"></i><b>20</b> Endogeneity</a>
<ul>
<li class="chapter" data-level="20.1" data-path="measurement-error.html"><a href="measurement-error.html"><i class="fa fa-check"></i><b>20.1</b> Measurement Error</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="measurement-error.html"><a href="measurement-error.html#classical-measurement-errors"><i class="fa fa-check"></i><b>20.1.1</b> Classical Measurement Errors</a></li>
<li class="chapter" data-level="20.1.2" data-path="measurement-error.html"><a href="measurement-error.html#non-classical-measurement-errors"><i class="fa fa-check"></i><b>20.1.2</b> Non-classical Measurement Errors</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="simultaneity.html"><a href="simultaneity.html"><i class="fa fa-check"></i><b>20.2</b> Simultaneity</a></li>
<li class="chapter" data-level="20.3" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html"><i class="fa fa-check"></i><b>20.3</b> Endogenous Treatment</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#instrumental-variable"><i class="fa fa-check"></i><b>20.3.1</b> Instrumental Variable</a></li>
<li class="chapter" data-level="20.3.2" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#internal-instrumental-variable"><i class="fa fa-check"></i><b>20.3.2</b> Internal instrumental variable</a></li>
<li class="chapter" data-level="20.3.3" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#proxy-variables"><i class="fa fa-check"></i><b>20.3.3</b> Proxy Variables</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html"><i class="fa fa-check"></i><b>20.4</b> Endogenous Sample Selection</a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-2"><i class="fa fa-check"></i><b>20.4.1</b> Tobit-2</a></li>
<li class="chapter" data-level="20.4.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-5"><i class="fa fa-check"></i><b>20.4.2</b> Tobit-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="mediation.html"><a href="mediation.html"><i class="fa fa-check"></i><b>21</b> Mediation</a>
<ul>
<li class="chapter" data-level="21.1" data-path="traditional.html"><a href="traditional.html"><i class="fa fa-check"></i><b>21.1</b> Traditional</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="traditional.html"><a href="traditional.html#example-1-mediation-traditional"><i class="fa fa-check"></i><b>21.1.1</b> Example 1</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="model-based-causal-mediation-analysis.html"><a href="model-based-causal-mediation-analysis.html"><i class="fa fa-check"></i><b>21.2</b> Model-based causal mediation analysis</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>22</b> Report</a>
<ul>
<li class="chapter" data-level="22.1" data-path="one-summary-table.html"><a href="one-summary-table.html"><i class="fa fa-check"></i><b>22.1</b> One summary table</a></li>
<li class="chapter" data-level="22.2" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>22.2</b> Model Comparison</a></li>
<li class="chapter" data-level="22.3" data-path="changes-in-an-estimate.html"><a href="changes-in-an-estimate.html"><i class="fa fa-check"></i><b>22.3</b> Changes in an estimate</a></li>
</ul></li>
<li class="appendix"><span><b>APPENDIX</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a>
<ul>
<li class="chapter" data-level="A.1" data-path="git.html"><a href="git.html"><i class="fa fa-check"></i><b>A.1</b> Git</a></li>
<li class="chapter" data-level="A.2" data-path="short-cut.html"><a href="short-cut.html"><i class="fa fa-check"></i><b>A.2</b> Short-cut</a></li>
<li class="chapter" data-level="A.3" data-path="function-short-cut.html"><a href="function-short-cut.html"><i class="fa fa-check"></i><b>A.3</b> Function short-cut</a></li>
<li class="chapter" data-level="A.4" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>A.4</b> Citation</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bookdown-cheat-sheet.html"><a href="bookdown-cheat-sheet.html"><i class="fa fa-check"></i><b>B</b> Bookdown cheat sheet</a>
<ul>
<li class="chapter" data-level="B.1" data-path="operation.html"><a href="operation.html"><i class="fa fa-check"></i><b>B.1</b> Operation</a></li>
<li class="chapter" data-level="B.2" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html"><i class="fa fa-check"></i><b>B.2</b> Math Expresssion/ Syntax</a>
<ul>
<li class="chapter" data-level="B.2.1" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html#statistics-notation"><i class="fa fa-check"></i><b>B.2.1</b> Statistics Notation</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="table.html"><a href="table.html"><i class="fa fa-check"></i><b>B.3</b> Table</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multivariate-methods" class="section level1" number="16">
<h1><span class="header-section-number">Chapter 16</span> Multivariate Methods</h1>
<p><span class="math inline">\(y_1,...,y_p\)</span> are possibly correlated random variables with means <span class="math inline">\(\mu_1,...,\mu_p\)</span></p>
<p><span class="math display">\[
\mathbf{y} = 
\left(
\begin{array}
{c}
y_1 \\
. \\
y_p \\
\end{array}
\right)
\]</span></p>
<p><span class="math display">\[
E(\mathbf{y}) = 
\left(
\begin{array}
{c}
\mu_1 \\
. \\
\mu_p \\
\end{array}
\right)
\]</span></p>
<p>Let <span class="math inline">\(\sigma_{ij} = cov(y_i, y_j)\)</span> for <span class="math inline">\(i,j = 1,…,p\)</span></p>
<p><span class="math display">\[
\mathbf{\Sigma} = (\sigma_{ij}) = 
\left(
\begin{array}
{cccc}
\sigma_{11} &amp; \sigma_{22} &amp; ... &amp;  \sigma_{1p} \\
\sigma_{21} &amp; \sigma_{22} &amp; ... &amp; \sigma_{2p} \\
. &amp; . &amp; . &amp; . \\
\sigma_{p1} &amp; \sigma_{p2} &amp; ... &amp; \sigma_{pp}
\end{array}
\right)
\]</span></p>
<p>where <span class="math inline">\(\mathbf{\Sigma}\)</span> (symmetric) is the variance-covariance or dispersion matrix</p>
<p>Let <span class="math inline">\(\mathbf{u}_{p \times 1}\)</span> and <span class="math inline">\(\mathbf{v}_{q \times 1}\)</span> be random vectors with means <span class="math inline">\(\mu_u\)</span> and <span class="math inline">\(\mu_v\)</span> . Then</p>
<p><span class="math display">\[
\mathbf{\Sigma}_{uv} = cov(\mathbf{u,v}) = E[(\mathbf{u} - \mu_u)(\mathbf{v} - \mu_v)&#39;]
\]</span></p>
<p>in which <span class="math inline">\(\mathbf{\Sigma}_{uv} \neq \mathbf{\Sigma}_{vu}\)</span> and <span class="math inline">\(\mathbf{\Sigma}_{uv} = \mathbf{\Sigma}_{vu}&#39;\)</span></p>
<p><br />
<strong>Properties of Covariance Matrices</strong></p>
<ol style="list-style-type: decimal">
<li>Symmetric <span class="math inline">\(\mathbf{\Sigma}&#39; = \mathbf{\Sigma}\)</span></li>
<li>Non-negative definite <span class="math inline">\(\mathbf{a&#39;\Sigma a} \ge 0\)</span> for any <span class="math inline">\(\mathbf{a} \in R^p\)</span>, which is equivalent to eigenvalues of <span class="math inline">\(\mathbf{\Sigma}\)</span>, <span class="math inline">\(\lambda_1 \ge \lambda_2 \ge ... \ge \lambda_p \ge 0\)</span></li>
<li><span class="math inline">\(|\mathbf{\Sigma}| = \lambda_1 \lambda_2 ... \lambda_p \ge 0\)</span> (<strong>generalized variance</strong>) (the bigger this number is, the more variation there is</li>
<li><span class="math inline">\(trace(\mathbf{\Sigma}) = tr(\mathbf{\Sigma}) = \lambda_1 + ... + \lambda_p = \sigma_{11} + ... + \sigma_{pp} =\)</span> sum of variance (<strong>total variance</strong>)</li>
</ol>
<p>Note:</p>
<ul>
<li><span class="math inline">\(\mathbf{\Sigma}\)</span> is typically required to be positive definite, which means all eigenvalues are positive, and <span class="math inline">\(\mathbf{\Sigma}\)</span> has an inverse <span class="math inline">\(\mathbf{\Sigma}^{-1}\)</span> such that <span class="math inline">\(\mathbf{\Sigma}^{-1}\mathbf{\Sigma} = \mathbf{I}_{p \times p} = \mathbf{\Sigma \Sigma}^{-1}\)</span></li>
</ul>
<p><br></p>
<p><strong>Correlation Matrices</strong></p>
<p><span class="math display">\[
\rho_{ij} = \frac{\sigma_{ij}}{\sqrt{\sigma_{ii} \sigma_{jj}}}
\]</span></p>
<p><span class="math display">\[
\mathbf{R} = 
\left(
\begin{array}
{cccc}
\rho_{11} &amp; \rho_{12} &amp; ... &amp; \rho_{1p} \\
\rho_{21} &amp; \rho_{22} &amp; ... &amp; \rho_{2p} \\
. &amp; . &amp; . &amp;. \\
\rho_{p1} &amp; \rho_{p2} &amp; ... &amp; \rho_{pp} \\
\end{array}
\right)
\]</span></p>
<p>where <span class="math inline">\(\rho_{ij}\)</span> is the correlation, and <span class="math inline">\(\rho_{ii} = 1\)</span> for all i</p>
<p>Alternatively,</p>
<p><span class="math display">\[
\mathbf{R} = [diag(\mathbf{\Sigma})]^{-1/2}\mathbf{\Sigma}[diag(\mathbf{\Sigma})]^{-1/2}
\]</span></p>
<p>where <span class="math inline">\(diag(\mathbf{\Sigma})\)</span> is the matrix which has the <span class="math inline">\(\sigma_{ii}\)</span>’s on the diagonal and 0’s elsewhere</p>
<p>and <span class="math inline">\(\mathbf{A}^{1/2}\)</span> (the square root of a symmetric matrix) is a symmetric matrix such as <span class="math inline">\(\mathbf{A} = \mathbf{A}^{1/2}\mathbf{A}^{1/2}\)</span></p>
<p><strong>Equalities</strong></p>
<p>Let</p>
<ul>
<li><p><span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> be random vectors with means <span class="math inline">\(\mu_x\)</span> and <span class="math inline">\(\mu_y\)</span> and variance -variance matrices <span class="math inline">\(\mathbf{\Sigma}_x\)</span> and <span class="math inline">\(\mathbf{\Sigma}_y\)</span>.</p></li>
<li><p><span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> be matrices of constants and <span class="math inline">\(\mathbf{c}\)</span> and <span class="math inline">\(\mathbf{d}\)</span> be vectors of constants</p></li>
</ul>
<p>Then</p>
<ul>
<li><p><span class="math inline">\(E(\mathbf{Ay + c} ) = \mathbf{A} \mu_y + c\)</span></p></li>
<li><p><span class="math inline">\(var(\mathbf{Ay + c}) = \mathbf{A} var(\mathbf{y})\mathbf{A}&#39; = \mathbf{A \Sigma_y A}&#39;\)</span></p></li>
<li><p><span class="math inline">\(cov(\mathbf{Ay + c, By+ d}) = \mathbf{A\Sigma_y B}&#39;\)</span></p></li>
<li><p><span class="math inline">\(E(\mathbf{Ay + Bx + c}) = \mathbf{A \mu_y + B \mu_x + c}\)</span></p></li>
<li><p><span class="math inline">\(var(\mathbf{Ay + Bx + c}) = \mathbf{A \Sigma_y A&#39; + B \Sigma_x B&#39; + A \Sigma_{yx}B&#39; + B\Sigma&#39;_{yx}A&#39;}\)</span></p></li>
</ul>
<p><strong>Multivariate Normal Distribution</strong></p>
<p>Let <span class="math inline">\(\mathbf{y}\)</span> be a multivariate normal (MVN) random variable with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\mathbf{\Sigma}\)</span>. Then the density of <span class="math inline">\(\mathbf{y}\)</span> is</p>
<p><span class="math display">\[
f(\mathbf{y}) = \frac{1}{(2\pi)^{p/2}|\mathbf{\Sigma}|^{1/2}} \exp(-\frac{1}{2} \mathbf{(y-\mu)&#39;\Sigma^{-1}(y-\mu)} )
\]</span></p>
<p><span class="math inline">\(\mathbf{y} \sim N_p(\mu, \mathbf{\Sigma})\)</span></p>
<div id="properties-of-mvn" class="section level3" number="16.0.1">
<h3><span class="header-section-number">16.0.1</span> Properties of MVN</h3>
<ul>
<li><p>Let <span class="math inline">\(\mathbf{A}_{r \times p}\)</span> be a fixed matrix. Then <span class="math inline">\(\mathbf{Ay} \sim N_r (\mathbf{A \mu, A \Sigma A&#39;})\)</span> . <span class="math inline">\(r \le p\)</span> and all rows of <span class="math inline">\(\mathbf{A}\)</span> must be linearly independent to guarantee that <span class="math inline">\(\mathbf{A \Sigma A}&#39;\)</span> is non-singular.</p></li>
<li><p>Let <span class="math inline">\(\mathbf{G}\)</span> be a matrix such that <span class="math inline">\(\mathbf{\Sigma}^{-1} = \mathbf{GG}&#39;\)</span>. Then <span class="math inline">\(\mathbf{G&#39;y} \sim N_p(\mathbf{G&#39; \mu, I})\)</span> and <span class="math inline">\(\mathbf{G&#39;(y-\mu)} \sim N_p (0,\mathbf{I})\)</span></p></li>
<li><p>Any fixed linear combination of <span class="math inline">\(y_1,...,y_p\)</span> (say <span class="math inline">\(\mathbf{c&#39;y}\)</span>) follows <span class="math inline">\(\mathbf{c&#39;y} \sim N_1 (\mathbf{c&#39; \mu, c&#39; \Sigma c})\)</span></p></li>
<li><p>Define a partition, <span class="math inline">\([\mathbf{y}&#39;_1,\mathbf{y}_2&#39;]&#39;\)</span> where</p>
<ul>
<li><p><span class="math inline">\(\mathbf{y}_1\)</span> is <span class="math inline">\(p_1 \times 1\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{y}_2\)</span> is <span class="math inline">\(p_2 \times 1\)</span>,</p></li>
<li><p><span class="math inline">\(p_1 + p_2 = p\)</span></p></li>
<li><p><span class="math inline">\(p_1,p_2 \ge 1\)</span> Then</p></li>
</ul></li>
</ul>
<p><span class="math display">\[
\left(
\begin{array}
{c}
\mathbf{y}_1 \\
\mathbf{y}_2 \\
\end{array}
\right)
\sim
N
\left(
\left(
\begin{array}
{c}
\mu_1 \\
\mu_2 \\
\end{array}
\right),
\left(
\begin{array}
{cc}
\mathbf{\Sigma}_{11} &amp; \mathbf{\Sigma}_{12} \\
\mathbf{\Sigma}_{21} &amp; \mathbf{\Sigma}_{22}\\
\end{array}
\right)
\right)
\]</span></p>
<ul>
<li><p>The marginal distributions of <span class="math inline">\(\mathbf{y}_1\)</span> and <span class="math inline">\(\mathbf{y}_2\)</span> are <span class="math inline">\(\mathbf{y}_1 \sim N_{p1}(\mathbf{\mu_1, \Sigma_{11}})\)</span> and <span class="math inline">\(\mathbf{y}_2 \sim N_{p2}(\mathbf{\mu_2, \Sigma_{22}})\)</span></p></li>
<li><p>Individual components <span class="math inline">\(y_1,...,y_p\)</span> are all normally distributed <span class="math inline">\(y_i \sim N_1(\mu_i, \sigma_{ii})\)</span></p></li>
<li><p>The conditional distribution of <span class="math inline">\(\mathbf{y}_1\)</span> and <span class="math inline">\(\mathbf{y}_2\)</span> is normal</p>
<ul>
<li><p><span class="math inline">\(\mathbf{y}_1 | \mathbf{y}_2 \sim N_{p1}(\mathbf{\mu_1 + \Sigma_{12} \Sigma_{22}^{-1}(y_2 - \mu_2),\Sigma_{11} - \Sigma_{12} \Sigma_{22}^{-1} \sigma_{21}})\)</span></p>
<ul>
<li>In this formula, we see if we know (have info about) <span class="math inline">\(\mathbf{y}_2\)</span>, we can re-weight <span class="math inline">\(\mathbf{y}_1\)</span> ’s mean, and the variance is reduced because we know more about <span class="math inline">\(\mathbf{y}_1\)</span> because we know <span class="math inline">\(\mathbf{y}_2\)</span></li>
</ul></li>
<li><p>which is analogous to <span class="math inline">\(\mathbf{y}_2 | \mathbf{y}_1\)</span>. And <span class="math inline">\(\mathbf{y}_1\)</span> and <span class="math inline">\(\mathbf{y}_2\)</span> are independently distrusted only if <span class="math inline">\(\mathbf{\Sigma}_{12} = 0\)</span></p></li>
</ul></li>
<li><p>If <span class="math inline">\(\mathbf{y} \sim N(\mathbf{\mu, \Sigma})\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> is positive definite, then <span class="math inline">\(\mathbf{(y-\mu)&#39; \Sigma^{-1} (y - \mu)} \sim \chi^2_{(p)}\)</span></p></li>
<li><p>If <span class="math inline">\(\mathbf{y}_i\)</span> are independent <span class="math inline">\(N_p (\mathbf{\mu}_i , \mathbf{\Sigma}_i)\)</span> random variables, then for fixed matrices <span class="math inline">\(\mathbf{A}_{i(m \times p)}\)</span>, <span class="math inline">\(\sum_{i=1}^k \mathbf{A}_i \mathbf{y}_i \sim N_m (\sum_{i=1}^{k} \mathbf{A}_i \mathbf{\mu}_i, \sum_{i=1}^k \mathbf{A}_i \mathbf{\Sigma}_i \mathbf{A}_i)\)</span></p></li>
</ul>
<p><strong>Multiple Regression</strong></p>
<p><span class="math display">\[
\left(
\begin{array}
{c}
Y \\
\mathbf{x}
\end{array}
\right)
\sim 
N_{p+1}
\left(
\left[
\begin{array}
{c}
\mu_y \\
\mathbf{\mu}_x
\end{array}
\right]
,
\left[
\begin{array}
{cc}
\sigma^2_Y &amp; \mathbf{\Sigma}_{yx} \\
\mathbf{\Sigma}_{yx} &amp; \mathbf{\Sigma}_{xx}
\end{array}
\right]
\right)
\]</span></p>
<p>The conditional distribution of Y given x follows a univariate normal distribution with</p>
<p><span class="math display">\[
\begin{aligned}
E(Y| \mathbf{x}) &amp;= \mu_y + \mathbf{\Sigma}_{yx} \Sigma_{xx}^{-1} (\mathbf{x}- \mu_x) \\
&amp;= \mu_y - \Sigma_{yx} \Sigma_{xx}^{-1}\mu_x + \Sigma_{yx} \Sigma_{xx}^{-1}\mathbf{x} \\
&amp;= \beta_0 + \mathbf{\beta&#39;x}
\end{aligned} 
\]</span></p>
<p>where <span class="math inline">\(\beta = (\beta_1,...,\beta_p)&#39; = \mathbf{\Sigma}_{xx}^{-1} \mathbf{\Sigma}_{yx}&#39;\)</span> (e.g., analogous to <span class="math inline">\(\mathbf{(x&#39;x)^{-1}x&#39;y}\)</span> but not the same if we consider <span class="math inline">\(Y_i\)</span> and <span class="math inline">\(\mathbf{x}_i\)</span>, <span class="math inline">\(i = 1,..,n\)</span> and use the empirical covariance formula: <span class="math inline">\(var(Y|\mathbf{x}) = \sigma^2_Y - \mathbf{\Sigma_{yx}\Sigma^{-1}_{xx} \Sigma&#39;_{yx}}\)</span>)</p>
<p><br></p>
<p><strong>Samples from Multivariate Normal Populations</strong></p>
<p>A random sample of size n, <span class="math inline">\(\mathbf{y}_1,.., \mathbf{y}_n\)</span> from <span class="math inline">\(N_p (\mathbf{\mu}, \mathbf{\Sigma})\)</span>. Then</p>
<ul>
<li><p>Since <span class="math inline">\(\mathbf{y}_1,..., \mathbf{y}_n\)</span> are iid, their sample mean, <span class="math inline">\(\bar{\mathbf{y}} = \sum_{i=1}^n \mathbf{y}_i/n \sim N_p (\mathbf{\mu}, \mathbf{\Sigma}/n)\)</span>. that is, <span class="math inline">\(\bar{\mathbf{y}}\)</span> is an unbiased estimator of <span class="math inline">\(\mathbf{\mu}\)</span></p></li>
<li><p>The <span class="math inline">\(p \times p\)</span> sample variance-covariance matrix, <span class="math inline">\(\mathbf{S}\)</span> is <span class="math inline">\(\mathbf{S} = \frac{1}{n-1}\sum_{i=1}^n (\mathbf{y}_i - \bar{\mathbf{y}})(\mathbf{y}_i - \bar{\mathbf{y}})&#39; = \frac{1}{n-1} (\sum_{i=1}^n \mathbf{y}_i \mathbf{y}_i&#39; - n \bar{\mathbf{y}}\bar{\mathbf{y}}&#39;)\)</span></p>
<ul>
<li>where <span class="math inline">\(\mathbf{S}\)</span> is symmetric, unbiased estimator of <span class="math inline">\(\mathbf{\Sigma}\)</span> and has <span class="math inline">\(p(p+1)/2\)</span> random variables.</li>
</ul></li>
<li><p><span class="math inline">\((n-1)\mathbf{S} \sim W_p (n-1, \mathbf{\Sigma})\)</span> is a Wishart distribution with n-1 degrees of freedom and expectation <span class="math inline">\((n-1) \mathbf{\Sigma}\)</span>. The Wishart distribution is a multivariate extension of the Chi-squared distribution.</p></li>
<li><p><span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{S}\)</span> are independent</p></li>
<li><p><span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{S}\)</span> are sufficient statistics. (All of the info in the data about <span class="math inline">\(\mathbf{\mu}\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span> is contained in <span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{S}\)</span> , regardless of sample size).</p></li>
</ul>
<p><br></p>
<p><strong>Large Sample Properties</strong></p>
<p><span class="math inline">\(\mathbf{y}_1,..., \mathbf{y}_n\)</span> are a random sample from some population with mean <span class="math inline">\(\mathbf{\mu}\)</span> and variance-covariance matrix <span class="math inline">\(\mathbf{\Sigma}\)</span></p>
<ul>
<li><p><span class="math inline">\(\bar{\mathbf{y}}\)</span> is a consistent estimator for <span class="math inline">\(\mu\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{S}\)</span> is a consistent estimator for <span class="math inline">\(\mathbf{\Sigma}\)</span></p></li>
<li><p><strong>Multivariate Central Limit Theorem</strong>: Similar to the univariate case, <span class="math inline">\(\sqrt{n}(\bar{\mathbf{y}} - \mu) \dot{\sim} N_p (\mathbf{0,\Sigma})\)</span> where n is large relative to p (<span class="math inline">\(n \ge 25p\)</span>), which is equivalent to <span class="math inline">\(\bar{\mathbf{y}} \dot{\sim} N_p (\mu, \mathbf{\Sigma}/n)\)</span></p></li>
<li><p><strong>Wald’s Theorem</strong>: <span class="math inline">\(n(\bar{\mathbf{y}} - \mu)&#39; \mathbf{S}^{-1} (\bar{\mathbf{y}} - \mu)\)</span> when n is large relative to p.</p></li>
</ul>
<p><br></p>
<p>Maximum Likelihood Estimation for MVN</p>
<p>Suppose iid <span class="math inline">\(\mathbf{y}_1 ,... \mathbf{y}_n \sim N_p (\mu, \mathbf{\Sigma})\)</span>, the likelihood function for the data is</p>
<p><span class="math display">\[
\begin{aligned}
L(\mu, \mathbf{\Sigma}) &amp;= \prod_{j=1}^n (\frac{1}{(2\pi)^{p/2}|\mathbf{\Sigma}|^{1/2}} \exp(-\frac{1}{2}(\mathbf{y}_j -\mu)&#39;\mathbf{\Sigma}^{-1})(\mathbf{y}_j -\mu)) \\
&amp;= \frac{1}{(2\pi)^{np/2}|\mathbf{\Sigma}|^{n/2}} \exp(-\frac{1}{2} \sum_{j=1}^n(\mathbf{y}_j -\mu)&#39;\mathbf{\Sigma}^{-1})(\mathbf{y}_j -\mu)
\end{aligned}
\]</span></p>
<p>Then, the MLEs are</p>
<p><span class="math display">\[
\hat{\mu} = \bar{\mathbf{y}}
\]</span></p>
<p><span class="math display">\[
\hat{\mathbf{\Sigma}} = \frac{n-1}{n} \mathbf{S}
\]</span></p>
<p>using derivatives of the log of the likelihood function with respect to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\mathbf{\Sigma}\)</span></p>
<p><br></p>
<p><strong>Properties of MLEs</strong></p>
<ul>
<li><p>Invariance: If <span class="math inline">\(\hat{\theta}\)</span> is the MLE of <span class="math inline">\(\theta\)</span>, then the MLE of <span class="math inline">\(h(\theta)\)</span> is <span class="math inline">\(h(\hat{\theta})\)</span> for any function h(.)</p></li>
<li><p>Consistency: MLEs are consistent estimators, but they are usually biased</p></li>
<li><p>Efficiency: MLEs are efficient estimators (no other estimator has a smaller variance for large samples)</p></li>
<li><p>Asymptotic normality: Suppose that <span class="math inline">\(\hat{\theta}_n\)</span> is the MLE for <span class="math inline">\(\theta\)</span> based upon n independent observations. Then <span class="math inline">\(\hat{\theta}_n \dot{\sim} N(\theta, \mathbf{H}^{-1})\)</span></p>
<ul>
<li><p><span class="math inline">\(\mathbf{H}\)</span> is the Fisher Information Matrix, which contains the expected values of the second partial derivatives fo the log-likelihood function. the (i,j)th element of <span class="math inline">\(\mathbf{H}\)</span> is <span class="math inline">\(-E(\frac{\partial^2 l(\mathbf{\theta})}{\partial \theta_i \partial \theta_j})\)</span></p></li>
<li><p>we can estimate <span class="math inline">\(\mathbf{H}\)</span> by finding the form determined above, and evaluate it at <span class="math inline">\(\theta = \hat{\theta}_n\)</span></p></li>
</ul></li>
<li><p>Likelihood ratio testing: for some null hypothesis, <span class="math inline">\(H_0\)</span> we can form a likelihood ratio test</p>
<ul>
<li><p>The statistic is: <span class="math inline">\(\Lambda = \frac{\max_{H_0}l(\mathbf{\mu}, \mathbf{\Sigma|Y})}{\max l(\mu, \mathbf{\Sigma | Y})}\)</span></p></li>
<li><p>For large n, <span class="math inline">\(-2 \log \Lambda \sim \chi^2_{(v)}\)</span> where v is the number of parameters in the unrestricted space minus the number of parameters under <span class="math inline">\(H_0\)</span></p></li>
</ul></li>
</ul>
<p><br></p>
<p><strong>Test of Multivariate Normality</strong></p>
<ul>
<li><p>Check univariate normality for each trait (X) separately</p>
<ul>
<li><p>Can check <a href="normality-assessment.html#normality-assessment">Normality Assessment</a></p></li>
<li><p>The good thing is that if any of the univariate trait is not normal, then the joint distribution is not normal (see again <a href="multivariate-methods.html#properties-of-mvn">Properties of MVN</a>). If a joint multivariate distribution is normal, then the marginal distribution has to be normal.</p></li>
<li><p>However, marginal normality of all traits does not imply joint MVN</p></li>
<li><p>Easily rule out multivariate normality, but not easy to prove it</p></li>
</ul></li>
<li><p>Mardia’s tests for multivariate normality</p>
<ul>
<li><p>Multivariate skewness is<span class="math display">\[
\beta_{1,p} = E[(\mathbf{y}- \mathbf{\mu})&#39; \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu})]^3
\]</span></p></li>
<li><p>where <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span> are independent, but have the same distribution (note: <span class="math inline">\(\beta\)</span> here is not regression coefficient)</p></li>
<li><p>Multivariate kurtosis is defined as</p></li>
<li><p><span class="math display">\[
\beta_{2,p} - E[(\mathbf{y}- \mathbf{\mu})&#39; \mathbf{\Sigma}^{-1} (\mathbf{x} - \mathbf{\mu})]^2
\]</span></p></li>
<li><p>For the MVN distribution, we have <span class="math inline">\(\beta_{1,p} = 0\)</span> and <span class="math inline">\(\beta_{2,p} = p(p+2)\)</span></p></li>
<li><p>For a sample of size n, we can estimate</p>
<p><span class="math display">\[
\hat{\beta}_{1,p} = \frac{1}{n^2}\sum_{i=1}^n \sum_{j=1}^n g^2_{ij}
\]</span></p>
<p><span class="math display">\[
\hat{\beta}_{2,p} = \frac{1}{n} \sum_{i=1}^n g^2_{ii}
\]</span></p>
<ul>
<li>where <span class="math inline">\(g_{ij} = (\mathbf{y}_i - \bar{\mathbf{y}})&#39; \mathbf{S}^{-1} (\mathbf{y}_j - \bar{\mathbf{y}})\)</span>. Note: <span class="math inline">\(g_{ii} = d^2_i\)</span> where <span class="math inline">\(d^2_i\)</span> is the Mahalanobis distance</li>
</ul></li>
<li><p><span class="citation">(<a href="#ref-MARDIA_1970" role="doc-biblioref">MARDIA 1970</a>)</span> shows for large n</p>
<p><span class="math display">\[
\kappa_1 = \frac{n \hat{\beta}_{1,p}}{6} \dot{\sim} \chi^2_{p(p+1)(p+2)/6}
\]</span></p>
<p><span class="math display">\[
\kappa_2 = \frac{\hat{\beta}_{2,p} - p(p+2)}{\sqrt{8p(p+2)/n}} \sim N(0,1)
\]</span></p>
<ul>
<li><p>Hence, we can use <span class="math inline">\(\kappa_1\)</span> and <span class="math inline">\(\kappa_2\)</span> to test the null hypothesis of MVN.</p></li>
<li><p>When the data are non-normal, normal theory tests on the mean are sensitive to <span class="math inline">\(\beta_{1,p}\)</span> , while tests on the covariance are sensitive to <span class="math inline">\(\beta_{2,p}\)</span></p></li>
</ul></li>
</ul></li>
<li><p>Chi-square Q-Q plot</p>
<ul>
<li><p>Let <span class="math inline">\(\mathbf{y}_i, i = 1,...,n\)</span> be a random sample sample from <span class="math inline">\(N_p(\mathbf{\mu}, \mathbf{\Sigma})\)</span></p></li>
<li><p>Then <span class="math inline">\(\mathbf{z}_i = \mathbf{\Sigma}^{-1/2}(\mathbf{y}_i - \mathbf{\mu}), i = 1,...,n\)</span> are iid <span class="math inline">\(N_p (\mathbf{0}, \mathbf{I})\)</span>. Thus, <span class="math inline">\(d_i^2 = \mathbf{z}_i&#39; \mathbf{z}_i \sim \chi^2_p , i = 1,...,n\)</span></p></li>
<li><p>plot the ordered <span class="math inline">\(d_i^2\)</span> values against the qualities of the <span class="math inline">\(\chi^2_p\)</span> distribution. When normality holds, the plot should approximately resemble a straight lien passing through the origin at a 45 degree</p></li>
<li><p>it requires large sample size (i.e., sensitive to sample size). Even if we generate data from a MVN, the tail of the Chi-square Q-Q plot can still be out of line.</p></li>
</ul></li>
<li><p>If the data are not normal, we can</p>
<ul>
<li><p>ignore it</p></li>
<li><p>use nonparametric methods</p></li>
<li><p>use models based upon an approximate distirubiton (e.g., GLMM)</p></li>
<li><p>try performing a transformation</p></li>
</ul></li>
</ul>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="multivariate-methods.html#cb737-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(heplots)</span></code></pre></div>
<pre><code>## Warning: package &#39;heplots&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;car&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="multivariate-methods.html#cb740-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ICSNP)</span></code></pre></div>
<pre><code>## Warning: package &#39;ICSNP&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;mvtnorm&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;ICS&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="multivariate-methods.html#cb744-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(MVN)</span></code></pre></div>
<pre><code>## Warning: package &#39;MVN&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="multivariate-methods.html#cb746-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<pre><code>## Warning: package &#39;tidyverse&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;readr&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb752"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb752-1"><a href="multivariate-methods.html#cb752-1" aria-hidden="true" tabindex="-1"></a>trees <span class="ot">=</span> <span class="fu">read.table</span>(<span class="st">&quot;images/trees.dat&quot;</span>)</span>
<span id="cb752-2"><a href="multivariate-methods.html#cb752-2" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(trees) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Nitrogen&quot;</span>,<span class="st">&quot;Phosphorous&quot;</span>,<span class="st">&quot;Potassium&quot;</span>,<span class="st">&quot;Ash&quot;</span>,<span class="st">&quot;Height&quot;</span>)</span>
<span id="cb752-3"><a href="multivariate-methods.html#cb752-3" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(trees)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    26 obs. of  5 variables:
##  $ Nitrogen   : num  2.2 2.1 1.52 2.88 2.18 1.87 1.52 2.37 2.06 1.84 ...
##  $ Phosphorous: num  0.417 0.354 0.208 0.335 0.314 0.271 0.164 0.302 0.373 0.265 ...
##  $ Potassium  : num  1.35 0.9 0.71 0.9 1.26 1.15 0.83 0.89 0.79 0.72 ...
##  $ Ash        : num  1.79 1.08 0.47 1.48 1.09 0.99 0.85 0.94 0.8 0.77 ...
##  $ Height     : int  351 249 171 373 321 191 225 291 284 213 ...</code></pre>
<div class="sourceCode" id="cb754"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb754-1"><a href="multivariate-methods.html#cb754-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(trees)</span></code></pre></div>
<pre><code>##     Nitrogen      Phosphorous       Potassium           Ash        
##  Min.   :1.130   Min.   :0.1570   Min.   :0.3800   Min.   :0.4500  
##  1st Qu.:1.532   1st Qu.:0.1963   1st Qu.:0.6050   1st Qu.:0.6375  
##  Median :1.855   Median :0.2250   Median :0.7150   Median :0.9300  
##  Mean   :1.896   Mean   :0.2506   Mean   :0.7619   Mean   :0.8873  
##  3rd Qu.:2.160   3rd Qu.:0.2975   3rd Qu.:0.8975   3rd Qu.:0.9825  
##  Max.   :2.880   Max.   :0.4170   Max.   :1.3500   Max.   :1.7900  
##      Height     
##  Min.   : 65.0  
##  1st Qu.:122.5  
##  Median :181.0  
##  Mean   :196.6  
##  3rd Qu.:276.0  
##  Max.   :373.0</code></pre>
<div class="sourceCode" id="cb756"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb756-1"><a href="multivariate-methods.html#cb756-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(trees, <span class="at">method =</span> <span class="st">&quot;pearson&quot;</span>) <span class="co"># correlation matrix</span></span></code></pre></div>
<pre><code>##              Nitrogen Phosphorous Potassium       Ash    Height
## Nitrogen    1.0000000   0.6023902 0.5462456 0.6509771 0.8181641
## Phosphorous 0.6023902   1.0000000 0.7037469 0.6707871 0.7739656
## Potassium   0.5462456   0.7037469 1.0000000 0.6710548 0.7915683
## Ash         0.6509771   0.6707871 0.6710548 1.0000000 0.7676771
## Height      0.8181641   0.7739656 0.7915683 0.7676771 1.0000000</code></pre>
<div class="sourceCode" id="cb758"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb758-1"><a href="multivariate-methods.html#cb758-1" aria-hidden="true" tabindex="-1"></a><span class="co"># qq-plot </span></span>
<span id="cb758-2"><a href="multivariate-methods.html#cb758-2" aria-hidden="true" tabindex="-1"></a>gg <span class="ot">&lt;-</span> trees <span class="sc">%&gt;%</span></span>
<span id="cb758-3"><a href="multivariate-methods.html#cb758-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="st">&quot;Var&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;Value&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb758-4"><a href="multivariate-methods.html#cb758-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">sample =</span> Value)) <span class="sc">+</span></span>
<span id="cb758-5"><a href="multivariate-methods.html#cb758-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_qq</span>() <span class="sc">+</span></span>
<span id="cb758-6"><a href="multivariate-methods.html#cb758-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_qq_line</span>() <span class="sc">+</span></span>
<span id="cb758-7"><a href="multivariate-methods.html#cb758-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">facet_wrap</span>(<span class="st">&quot;Var&quot;</span>, <span class="at">scales =</span> <span class="st">&quot;free&quot;</span>)</span>
<span id="cb758-8"><a href="multivariate-methods.html#cb758-8" aria-hidden="true" tabindex="-1"></a>gg</span></code></pre></div>
<p><img src="16-multivariate_files/figure-html/unnamed-chunk-1-1.png" width="672" /></p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="multivariate-methods.html#cb759-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Univariate normality</span></span>
<span id="cb759-2"><a href="multivariate-methods.html#cb759-2" aria-hidden="true" tabindex="-1"></a>sw_tests <span class="ot">&lt;-</span> <span class="fu">apply</span>(trees, <span class="at">MARGIN =</span> <span class="dv">2</span>, <span class="at">FUN =</span> shapiro.test)</span>
<span id="cb759-3"><a href="multivariate-methods.html#cb759-3" aria-hidden="true" tabindex="-1"></a>sw_tests</span></code></pre></div>
<pre><code>## $Nitrogen
## 
##  Shapiro-Wilk normality test
## 
## data:  newX[, i]
## W = 0.96829, p-value = 0.5794
## 
## 
## $Phosphorous
## 
##  Shapiro-Wilk normality test
## 
## data:  newX[, i]
## W = 0.93644, p-value = 0.1104
## 
## 
## $Potassium
## 
##  Shapiro-Wilk normality test
## 
## data:  newX[, i]
## W = 0.95709, p-value = 0.3375
## 
## 
## $Ash
## 
##  Shapiro-Wilk normality test
## 
## data:  newX[, i]
## W = 0.92071, p-value = 0.04671
## 
## 
## $Height
## 
##  Shapiro-Wilk normality test
## 
## data:  newX[, i]
## W = 0.94107, p-value = 0.1424</code></pre>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb761-1"><a href="multivariate-methods.html#cb761-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Kolmogorov-Smirnov test </span></span>
<span id="cb761-2"><a href="multivariate-methods.html#cb761-2" aria-hidden="true" tabindex="-1"></a>ks_tests <span class="ot">&lt;-</span> <span class="fu">map</span>(trees, <span class="sc">~</span> <span class="fu">ks.test</span>(<span class="fu">scale</span>(.x),<span class="st">&quot;pnorm&quot;</span>))</span></code></pre></div>
<pre><code>## Warning in ks.test(scale(.x), &quot;pnorm&quot;): ties should not be present for the
## Kolmogorov-Smirnov test</code></pre>
<pre><code>## Warning in ks.test(scale(.x), &quot;pnorm&quot;): ties should not be present for the
## Kolmogorov-Smirnov test

## Warning in ks.test(scale(.x), &quot;pnorm&quot;): ties should not be present for the
## Kolmogorov-Smirnov test

## Warning in ks.test(scale(.x), &quot;pnorm&quot;): ties should not be present for the
## Kolmogorov-Smirnov test

## Warning in ks.test(scale(.x), &quot;pnorm&quot;): ties should not be present for the
## Kolmogorov-Smirnov test</code></pre>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="multivariate-methods.html#cb764-1" aria-hidden="true" tabindex="-1"></a>ks_tests</span></code></pre></div>
<pre><code>## $Nitrogen
## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  scale(.x)
## D = 0.12182, p-value = 0.8351
## alternative hypothesis: two-sided
## 
## 
## $Phosphorous
## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  scale(.x)
## D = 0.17627, p-value = 0.3944
## alternative hypothesis: two-sided
## 
## 
## $Potassium
## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  scale(.x)
## D = 0.10542, p-value = 0.9348
## alternative hypothesis: two-sided
## 
## 
## $Ash
## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  scale(.x)
## D = 0.14503, p-value = 0.6449
## alternative hypothesis: two-sided
## 
## 
## $Height
## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  scale(.x)
## D = 0.1107, p-value = 0.9076
## alternative hypothesis: two-sided</code></pre>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="multivariate-methods.html#cb766-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Mardia&#39;s test, need large sample size for power</span></span>
<span id="cb766-2"><a href="multivariate-methods.html#cb766-2" aria-hidden="true" tabindex="-1"></a>mardia_test <span class="ot">&lt;-</span></span>
<span id="cb766-3"><a href="multivariate-methods.html#cb766-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mvn</span>(</span>
<span id="cb766-4"><a href="multivariate-methods.html#cb766-4" aria-hidden="true" tabindex="-1"></a>        trees,</span>
<span id="cb766-5"><a href="multivariate-methods.html#cb766-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">mvnTest =</span> <span class="st">&quot;mardia&quot;</span>,</span>
<span id="cb766-6"><a href="multivariate-methods.html#cb766-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">covariance =</span> <span class="cn">FALSE</span>,</span>
<span id="cb766-7"><a href="multivariate-methods.html#cb766-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">multivariatePlot =</span> <span class="st">&quot;qq&quot;</span></span>
<span id="cb766-8"><a href="multivariate-methods.html#cb766-8" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div>
<p><img src="16-multivariate_files/figure-html/unnamed-chunk-1-2.png" width="672" /></p>
<div class="sourceCode" id="cb767"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb767-1"><a href="multivariate-methods.html#cb767-1" aria-hidden="true" tabindex="-1"></a>mardia_test<span class="sc">$</span>multivariateNormality</span></code></pre></div>
<pre><code>##              Test         Statistic            p value Result
## 1 Mardia Skewness  29.7248528871795   0.72054426745778    YES
## 2 Mardia Kurtosis -1.67743173185383 0.0934580886477281    YES
## 3             MVN              &lt;NA&gt;               &lt;NA&gt;    YES</code></pre>
<p><br></p>
</div>
<div id="mean-vector-inference" class="section level3" number="16.0.2">
<h3><span class="header-section-number">16.0.2</span> Mean Vector Inference</h3>
<p>In the univariate normal distribution, we test <span class="math inline">\(H_0: \mu =\mu_0\)</span> by using</p>
<p><span class="math display">\[
T = \frac{\bar{y}- \mu_0}{s/\sqrt{n}} \sim t_{n-1}
\]</span></p>
<p>under the null hypothesis. And reject the null if <span class="math inline">\(|T|\)</span> is large relative to <span class="math inline">\(t_{(1-\alpha/2,n-1)}\)</span> because it means that seeing a value as large as what we observed is rare if the null is true</p>
<p>Equivalently,</p>
<p><span class="math display">\[
T^2 = \frac{(\bar{y}- \mu_0)^2}{s^2/n} = n(\bar{y}- \mu_0)(s^2)^{-1}(\bar{y}- \mu_0) \sim f_{(1,n-1)}
\]</span></p>
<div id="natural-multivariate-generalization" class="section level4" number="16.0.2.1">
<h4><span class="header-section-number">16.0.2.1</span> <strong>Natural Multivariate Generalization</strong></h4>
<p><span class="math display">\[
H_0: \mathbf{\mu} = \mathbf{\mu}_0 \\
H_a: \mathbf{\mu} \neq \mathbf{\mu}_0
\]</span></p>
<p>Define <strong>Hotelling’s</strong> <span class="math inline">\(T^2\)</span> by</p>
<p><span class="math display">\[
T^2 = n(\bar{\mathbf{y}} - \mathbf{\mu}_0)&#39;\mathbf{S}^{-1}(\bar{\mathbf{y}} - \mathbf{\mu}_0)
\]</span></p>
<p>which can be viewed as a generalized distance between <span class="math inline">\(\bar{\mathbf{y}}\)</span> and <span class="math inline">\(\mathbf{\mu}_0\)</span></p>
<p>Under the assumption of normality,</p>
<p><span class="math display">\[
F = \frac{n-p}{(n-1)p} T^2 \sim f_{(p,n-p)}
\]</span></p>
<p>and reject the null hypothesis when <span class="math inline">\(F &gt; f_{(1-\alpha, p, n-p)}\)</span></p>
<ul>
<li><p>The <span class="math inline">\(T^2\)</span> test is invariant to changes in measurement units.</p>
<ul>
<li>If <span class="math inline">\(\mathbf{z = Cy + d}\)</span> where <span class="math inline">\(\mathbf{C}\)</span> and <span class="math inline">\(\mathbf{d}\)</span> do not depend on <span class="math inline">\(\mathbf{y}\)</span>, then <span class="math inline">\(T^2(\mathbf{z}) - T^2(\mathbf{y})\)</span></li>
</ul></li>
<li><p>The <span class="math inline">\(T^2\)</span> test can be derived as a <strong>likelihood ratio</strong> test of <span class="math inline">\(H_0: \mu = \mu_0\)</span></p></li>
</ul>
<p><br></p>
</div>
<div id="confidence-intervals" class="section level4" number="16.0.2.2">
<h4><span class="header-section-number">16.0.2.2</span> Confidence Intervals</h4>
<div id="confidence-region" class="section level5" number="16.0.2.2.1">
<h5><span class="header-section-number">16.0.2.2.1</span> Confidence Region</h5>
<p>An “exact” <span class="math inline">\(100(1-\alpha)\%\)</span> confidence region for <span class="math inline">\(\mathbf{\mu}\)</span> is the set of all vectors, <span class="math inline">\(\mathbf{v}\)</span>, which are “close enough” to the observed mean vector, <span class="math inline">\(\bar{\mathbf{y}}\)</span> to satisfy</p>
<p><span class="math display">\[
n(\bar{\mathbf{y}} - \mathbf{\mu}_0)&#39;\mathbf{S}^{-1}(\bar{\mathbf{y}} - \mathbf{\mu}_0) \le \frac{(n-1)p}{n-p} f_{(1-\alpha, p, n-p)}
\]</span></p>
<ul>
<li><span class="math inline">\(\mathbf{v}\)</span> are just the mean vectors that are not rejected by the <span class="math inline">\(T^2\)</span> test when <span class="math inline">\(\mathbf{\bar{y}}\)</span> is observed.</li>
</ul>
<p>In case that you have 2 parameters, the confidence region is a “hyper-ellipsoid.”</p>
<p>In this region, it consists of all <span class="math inline">\(\mathbf{\mu}_0\)</span> vectors for which the <span class="math inline">\(T^2\)</span> test would not reject <span class="math inline">\(H_0\)</span> at significance level <span class="math inline">\(\alpha\)</span></p>
<p>Even though the confidence region better assesses the joint knowledge concerning plausible values of <span class="math inline">\(\mathbf{\mu}\)</span> , people typically include confidence statement about the individual component means. We’d like all of the separate confidence statements to hold <strong>simultaneously</strong> with a specified high probability. Simultaneous confidence intervals: intervals <strong>against</strong> any statement being incorrect</p>
<p><br></p>
<div id="simultaneous-confidence-statements" class="section level6" number="16.0.2.2.1.1">
<h6><span class="header-section-number">16.0.2.2.1.1</span> Simultaneous Confidence Statements</h6>
<ul>
<li>Intervals based on a rectangular confidence region by projecting the previous region onto the coordinate axes:</li>
</ul>
<p><span class="math display">\[
\bar{y}_{i} \pm \sqrt{\frac{(n-1)p}{n-p}f_{(1-\alpha, p,n-p)}\frac{s_{ii}}{n}}
\]</span></p>
<p>for all <span class="math inline">\(i = 1,..,p\)</span></p>
<p>which implied confidence region is conservative; it has at least <span class="math inline">\(100(1- \alpha)\%\)</span></p>
<p>Generally, simultaneous <span class="math inline">\(100(1-\alpha) \%\)</span> confidence intervals for all linear combinations , <span class="math inline">\(\mathbf{a}\)</span> of the elements of the mean vector are given by</p>
<p><span class="math display">\[
\mathbf{a&#39;\bar{y}} \pm \sqrt{\frac{(n-1)p}{n-p}f_{(1-\alpha, p,n-p)}\frac{\mathbf{a&#39;Sa}}{n}}
\]</span></p>
<ul>
<li><p>works for any arbitrary linear combination <span class="math inline">\(\mathbf{a&#39;\mu} = a_1 \mu_1 + ... + a_p \mu_p\)</span>, which is a projection onto the axis in the direction of <span class="math inline">\(\mathbf{a}\)</span></p></li>
<li><p>These intervals have the property that the probability that at least one such interval does not contain the appropriate <span class="math inline">\(\mathbf{a&#39; \mu}\)</span> is no more than <span class="math inline">\(\alpha\)</span></p></li>
<li><p>These types of intervals can be used for “data snooping” (like <a href="completely-randomized-design-crd.html#scheffe">Scheffe</a>)</p></li>
</ul>
<p><br></p>
</div>
<div id="one-mu-at-a-time" class="section level6" number="16.0.2.2.1.2">
<h6><span class="header-section-number">16.0.2.2.1.2</span> One <span class="math inline">\(\mu\)</span> at a time</h6>
<ul>
<li>One at a time confidence intervals:</li>
</ul>
<p><span class="math display">\[
\bar{y}_i \pm t_{(1 - \alpha/2, n-1} \sqrt{\frac{s_{ii}}{n}}
\]</span></p>
<ul>
<li><p>Each of these intervals has a probability of <span class="math inline">\(1-\alpha\)</span> of covering the appropriate <span class="math inline">\(\mu_i\)</span></p></li>
<li><p>But they ignore the covariance structure of the <span class="math inline">\(p\)</span> variables</p></li>
<li><p>If we only care about <span class="math inline">\(k\)</span> simultaneous intervals, we can use “one at a time” method with the <a href="completely-randomized-design-crd.html#bonferroni">Bonferroni</a> correction.</p></li>
<li><p>This method gets more conservative as the number of intervals <span class="math inline">\(k\)</span> increases.</p></li>
</ul>
<p><br></p>
</div>
</div>
</div>
</div>
<div id="general-hypothesis-testing" class="section level3" number="16.0.3">
<h3><span class="header-section-number">16.0.3</span> General Hypothesis Testing</h3>
<div id="one-sample-tests" class="section level4" number="16.0.3.1">
<h4><span class="header-section-number">16.0.3.1</span> One-sample Tests</h4>
<p><span class="math display">\[
H_0: \mathbf{C \mu= 0} 
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{C}\)</span> is a <span class="math inline">\(c \times p\)</span> matrix of rank c where <span class="math inline">\(c \le p\)</span></li>
</ul>
<p>We can test this hypothesis using the following statistic</p>
<p><span class="math display">\[
F = \frac{n - c}{(n-1)c} T^2
\]</span></p>
<p>where <span class="math inline">\(T^2 = n(\mathbf{C\bar{y}})&#39; (\mathbf{CSC&#39;})^{-1} (\mathbf{C\bar{y}})\)</span></p>
<p>Example:</p>
<p><span class="math display">\[
H_0: \mu_1 = \mu_2 = ... = \mu_p
\]</span></p>
<p>Equivalently,</p>
<p><span class="math display">\[
\mu_1 - \mu_2 = 0 \\
\vdots \\
\mu_{p-1} - \mu_p = 0
\]</span></p>
<p>a total of <span class="math inline">\(p-1\)</span> tests. Hence, we have <span class="math inline">\(\mathbf{C}\)</span> as the <span class="math inline">\(p - 1 \times p\)</span> matrix</p>
<p><span class="math display">\[
\mathbf{C} = 
\left(
\begin{array}
{ccccc}
1 &amp; -1 &amp; 0 &amp; \ldots &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; \ldots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \ldots &amp; 1 &amp; -1 
\end{array}
\right)
\]</span></p>
<p>number of rows = <span class="math inline">\(c = p -1\)</span></p>
<p>Equivalently, we can also compare all of the other means to the first mean. Then, we test <span class="math inline">\(\mu_1 - \mu_2 = 0, \mu_1 - \mu_3 = 0,..., \mu_1 - \mu_p = 0\)</span>, the <span class="math inline">\((p-1) \times p\)</span> matrix <span class="math inline">\(\mathbf{C}\)</span> is</p>
<p><span class="math display">\[
\mathbf{C} = 
\left(
\begin{array}
{ccccc}
-1 &amp; 1 &amp; 0 &amp; \ldots &amp; 0 \\
-1 &amp; 0 &amp; 1 &amp; \ldots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
-1 &amp; 0 &amp; \ldots &amp; 0 &amp; 1 
\end{array}
\right)
\]</span></p>
<p>The value of <span class="math inline">\(T^2\)</span> is invariant to these equivalent choices of <span class="math inline">\(\mathbf{C}\)</span></p>
<p>This is often used for <strong>repeated measures designs</strong>, where each subject receives each treatment once over successive periods of time (all treatments are administered to each unit).</p>
<p><br></p>
<p>Example:</p>
<p>Let <span class="math inline">\(y_{ij}\)</span> be the response from subject i at time j for <span class="math inline">\(i = 1,..,n, j = 1,...,T\)</span>. In this case, <span class="math inline">\(\mathbf{y}_i = (y_{i1}, ..., y_{iT})&#39;, i = 1,...,n\)</span> are a random sample from <span class="math inline">\(N_T (\mathbf{\mu}, \mathbf{\Sigma})\)</span></p>
<p>Let <span class="math inline">\(n=8\)</span> subjects, <span class="math inline">\(T = 6\)</span>. We are interested in <span class="math inline">\(\mu_1, .., \mu_6\)</span></p>
<p><span class="math display">\[
H_0: \mu_1 = \mu_2 = ... = \mu_6
\]</span></p>
<p>Equivalently,</p>
<p><span class="math display">\[
\mu_1 - \mu_2 = 0 \\
\mu_2 - \mu_3 = 0 \\
... \\
\mu_5  - \mu_6 = 0
\]</span></p>
<p>We can test orthogonal polynomials for 4 equally spaced time points. To test for example the null hypothesis that quadratic and cubic effects are jointly equal to 0, we would define <span class="math inline">\(\mathbf{C}\)</span></p>
<p><span class="math display">\[
\mathbf{C} = 
\left(
\begin{array}
{cccc}
1 &amp; -1 &amp; -1 &amp; 1 \\
-1 &amp; 3 &amp; -3 &amp; 1
\end{array}
\right)
\]</span></p>
</div>
<div id="two-sample-tests" class="section level4" number="16.0.3.2">
<h4><span class="header-section-number">16.0.3.2</span> Two-Sample Tests</h4>
<p>Consider the analogous two sample multivariate tests.</p>
<p>Example: we have data on two independent random samples, one sample from each of two populations</p>
<p><span class="math display">\[
\mathbf{y}_{1i} \sim N_p (\mathbf{\mu_1, \Sigma}) \\
\mathbf{y}_{2j} \sim N_p (\mathbf{\mu_2, \Sigma})
\]</span></p>
<p>We <strong>assume</strong></p>
<ul>
<li><p>normality</p></li>
<li><p>equal variance-covariance matrices</p></li>
<li><p>independent random samples</p></li>
</ul>
<p>We can summarize our data using the <strong>sufficient statistics</strong> <span class="math inline">\(\mathbf{\bar{y}}_1, \mathbf{S}_1, \mathbf{\bar{y}}_2, \mathbf{S}_2\)</span> with respective sample sizes, <span class="math inline">\(n_1,n_2\)</span></p>
<p>Since we assume that <span class="math inline">\(\mathbf{\Sigma}_1 = \mathbf{\Sigma}_2 = \mathbf{\Sigma}\)</span>, compute a pooled estimate of the variance-covariance matrix on <span class="math inline">\(n_1 + n_2 - 2\)</span> df</p>
<p><span class="math display">\[
\mathbf{S} = \frac{(n_1 - 1)\mathbf{S}_1 + (n_2-1) \mathbf{S}_2}{(n_1 -1) + (n_2 - 1)}
\]</span></p>
<p><span class="math display">\[
H_0: \mathbf{\mu}_1 = \mathbf{\mu}_2 \\
H_a: \mathbf{\mu}_1 \neq \mathbf{\mu}_2
\]</span></p>
<p>At least one element of the mean vectors is different</p>
<p>We use</p>
<ul>
<li><p><span class="math inline">\(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2\)</span> to estimate <span class="math inline">\(\mu_1 - \mu_2\)</span></p></li>
<li><p><span class="math inline">\(\mathbf{S}\)</span> to estimate <span class="math inline">\(\mathbf{\Sigma}\)</span></p>
<p>Note: because we assume the two populations are independent, there is no covariance</p>
<p><span class="math inline">\(cov(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2) = var(\mathbf{\bar{y}}_1) + var(\mathbf{\bar{y}}_2) = \frac{\mathbf{\Sigma_1}}{n_1} + \frac{\mathbf{\Sigma_2}}{n_2} = \mathbf{\Sigma}(\frac{1}{n_1} + \frac{1}{n_2})\)</span></p></li>
</ul>
<p>Reject <span class="math inline">\(H_0\)</span> if</p>
<p><span class="math display">\[
\begin{aligned}
T^2 &amp;= (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)&#39;\{ \mathbf{S} (\frac{1}{n_1} + \frac{1}{n_2})\}^{-1} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)\\
&amp;= \frac{n_1 n_2}{n_1 +n_2} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)&#39;\{ \mathbf{S} \}^{-1} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)\\
&amp; \ge \frac{(n_1 + n_2 -2)p}{n_1 + n_2 - p - 1} f_{(1- \alpha,n_1 + n_2 - p -1)}
\end{aligned}
\]</span></p>
<p>or equivalently, if</p>
<p><span class="math display">\[
F = \frac{n_1 + n_2 - p -1}{(n_1 + n_2 -2)p} T^2 \ge f_{(1- \alpha, p , n_1 + n_2 -p -1)}
\]</span></p>
<p>A <span class="math inline">\(100(1-\alpha) \%\)</span> confidence region for <span class="math inline">\(\mu_1 - \mu_2\)</span> consists of all vector <span class="math inline">\(\delta\)</span> which satisfy</p>
<p><span class="math display">\[
\frac{n_1 n_2}{n_1 + n_2} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2 - \mathbf{\delta})&#39; \mathbf{S}^{-1}(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2 - \mathbf{\delta}) \le \frac{(n_1 + n_2 - 2)p}{n_1 + n_2 -p - 1}f_{(1-\alpha, p , n_1 + n_2 - p -1)}
\]</span></p>
<p>The simultaneous confidence intervals for all linear combinations of <span class="math inline">\(\mu_1 - \mu_2\)</span> have the form</p>
<p><span class="math display">\[
\mathbf{a&#39;}(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2) \pm \sqrt{\frac{(n_1 + n_2 -2)p}{n_1 + n_2 - p -1}}f_{(1-\alpha, p, n_1 + n_2 -p -1)} \times \sqrt{\mathbf{a&#39;Sa}(\frac{1}{n_1} + \frac{1}{n_2})}
\]</span></p>
<p>Bonferroni intervals, for k combinations</p>
<p><span class="math display">\[
(\bar{y}_{1i} - \bar{y}_{2i}) \pm t_{(1-\alpha/2k, n_1 + n_2 - 2)}\sqrt{(\frac{1}{n_1}  + \frac{1}{n_2})s_{ii}}
\]</span></p>
</div>
<div id="model-assumptions" class="section level4" number="16.0.3.3">
<h4><span class="header-section-number">16.0.3.3</span> Model Assumptions</h4>
<p>If model assumption are not met</p>
<ul>
<li><p>Unequal Covariance Matrices</p>
<ul>
<li><p>If <span class="math inline">\(n_1 = n_2\)</span> (large samples) there is little effect on the Type I error rate and power fo the two sample test</p></li>
<li><p>If <span class="math inline">\(n_1 &gt; n_2\)</span> and the eigenvalues of <span class="math inline">\(\mathbf{\Sigma}_1 \mathbf{\Sigma}^{-1}_2\)</span> are less than 1, the Type I error level is inflated</p></li>
<li><p>If <span class="math inline">\(n_1 &gt; n_2\)</span> and some eigenvalues of <span class="math inline">\(\mathbf{\Sigma}_1 \mathbf{\Sigma}_2^{-1}\)</span> are greater than 1, the Type I error rate is too small, leading to a reduction in power</p></li>
</ul></li>
<li><p>Sample Not Normal</p>
<ul>
<li><p>Type I error level of the two sample <span class="math inline">\(T^2\)</span> test isn’t much affect by moderate departures from normality if the two populations being sampled have similar distributions</p></li>
<li><p>One sample <span class="math inline">\(T^2\)</span> test is much more sensitive to lack of normality, especially when the distribution is skewed.</p></li>
<li><p>Intuitively, you can think that in one sample your distribution will be sensitive, but the distribution of the difference between two similar distributions will not be as sensitive.</p></li>
<li><p>Solutions:</p>
<ul>
<li><p>Transform to make the data more normal</p></li>
<li><p>Large large samples, use the <span class="math inline">\(\chi^2\)</span> (Wald) test, in which populations don’t need to be normal, or equal sample sizes, or equal variance-covariance matrices</p>
<ul>
<li><span class="math inline">\(H_0: \mu_1 - \mu_2 =0\)</span> use <span class="math inline">\((\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)&#39;( \frac{1}{n_1} \mathbf{S}_1 + \frac{1}{n_2}\mathbf{S}_2)^{-1}(\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2) \dot{\sim} \chi^2_{(p)}\)</span></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p><br></p>
<div id="equal-covariance-matrices-tests" class="section level5" number="16.0.3.3.1">
<h5><span class="header-section-number">16.0.3.3.1</span> Equal Covariance Matrices Tests</h5>
<p>With independent random samples from k populations of p-dimensional vectors. We compute the sample covariance matrix for each, <span class="math inline">\(\mathbf{S}_i\)</span>, where <span class="math inline">\(i = 1,...,k\)</span></p>
<p><span class="math display">\[
H_0: \mathbf{\Sigma}_1 = \mathbf{\Sigma}_2 = \ldots = \mathbf{\Sigma}_k = \mathbf{\Sigma} \\
H_a: \text{at least 2 are different}
\]</span></p>
<p>Assume <span class="math inline">\(H_0\)</span> is true, we would use a pooled estimate of the common covariance matrix, <span class="math inline">\(\mathbf{\Sigma}\)</span></p>
<p><span class="math display">\[
\mathbf{S} = \frac{\sum_{i=1}^k (n_i -1)\mathbf{S}_i}{\sum_{i=1}^k (n_i - 1)}
\]</span></p>
<p>with <span class="math inline">\(\sum_{i=1}^k (n_i -1)\)</span></p>
<p><br></p>
<div id="bartletts-test" class="section level6" number="16.0.3.3.1.1">
<h6><span class="header-section-number">16.0.3.3.1.1</span> Bartlett’s Test</h6>
<p>(a modification of the likelihood ratio test). Define</p>
<p><span class="math display">\[
N = \sum_{i=1}^k n_i
\]</span></p>
<p>and (note: <span class="math inline">\(| |\)</span> are determinants here, not absolute value)</p>
<p><span class="math display">\[
M = (N - k) \log|\mathbf{S}| - \sum_{i=1}^k (n_i - 1)  \log|\mathbf{S}_i|
\]</span></p>
<p><span class="math display">\[
C^{-1} = 1 - \frac{2p^2 + 3p - 1}{6(p+1)(k-1)} \{\sum_{i=1}^k (\frac{1}{n_i - 1}) - \frac{1}{N-k} \}
\]</span></p>
<ul>
<li><p>Reject <span class="math inline">\(H_0\)</span> when <span class="math inline">\(MC^{-1} &gt; \chi^2_{1- \alpha, (k-1)p(p+1)/2}\)</span></p></li>
<li><p>If not all samples are from normal populations, <span class="math inline">\(MC^{-1}\)</span> has a distribution which is often shifted to the right of the nominal <span class="math inline">\(\chi^2\)</span> distribution, which means <span class="math inline">\(H_0\)</span> is often rejected even when it is true (the Type I error level is inflated). Hence, it is better to test individual normality first, or then multivariate normality before you do Bartlett’s test.</p></li>
</ul>
<p><br></p>
</div>
</div>
</div>
<div id="two-sample-repeated-measurements" class="section level4" number="16.0.3.4">
<h4><span class="header-section-number">16.0.3.4</span> Two-Sample Repeated Measurements</h4>
<ul>
<li><p>Define <span class="math inline">\(\mathbf{y}_{hi} = (y_{hi1}, ..., y_{hit})&#39;\)</span> to be the observations from the i-th subject in the h-th group for times 1 through T</p></li>
<li><p>Assume that <span class="math inline">\(\mathbf{y}_{11}, ..., \mathbf{y}_{1n_1}\)</span> are iid <span class="math inline">\(N_t(\mathbf{\mu}_1, \mathbf{\Sigma})\)</span> and that <span class="math inline">\(\mathbf{y}_{21},...,\mathbf{y}_{2n_2}\)</span> are iid <span class="math inline">\(N_t(\mathbf{\mu}_2, \mathbf{\Sigma})\)</span></p></li>
<li><p><span class="math inline">\(H_0: \mathbf{C}(\mathbf{\mu}_1 - \mathbf{\mu}_2) = \mathbf{0}_c\)</span> where <span class="math inline">\(\mathbf{C}\)</span> is a <span class="math inline">\(c \times t\)</span> matrix of rank <span class="math inline">\(c\)</span> where <span class="math inline">\(c \le t\)</span></p></li>
<li><p>The test statistic has the form</p></li>
</ul>
<p><span class="math display">\[
T^2 = \frac{n_1 n_2}{n_1 + n_2} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)&#39; \mathbf{C}&#39;(\mathbf{CSC}&#39;)^{-1}\mathbf{C} (\mathbf{\bar{y}}_1 - \mathbf{\bar{y}}_2)
\]</span></p>
<p>where <span class="math inline">\(\mathbf{S}\)</span> is the pooled covariance estimate. Then,</p>
<p><span class="math display">\[
F = \frac{n_1 + n_2 - c -1}{(n_1 + n_2-2)c} T^2 \sim f_{(c, n_1 + n_2 - c-1)}
\]</span></p>
<p>when <span class="math inline">\(H_0\)</span> is true</p>
<p>If the null hypothesis <span class="math inline">\(H_0: \mu_1 = \mu_2\)</span> is rejected. A weaker hypothesis is that the profiles for the two groups are parallel.</p>
<p><span class="math display">\[
\mu_{11} - \mu_{21} = \mu_{12} - \mu_{22} \\
\vdots \\
\mu_{1t-1} - \mu_{2t-1} = \mu_{1t} - \mu_{2t}
\]</span></p>
<p>The null hypothesis matrix term is then</p>
<p><span class="math inline">\(H_0: \mathbf{C}(\mu_1 - \mu_2) = \mathbf{0}_c\)</span> , where <span class="math inline">\(c = t - 1\)</span> and</p>
<p><span class="math display">\[
\mathbf{C} = 
\left(
\begin{array}
{ccccc}
1 &amp; -1 &amp; 0 &amp; \ldots &amp; 0 \\
0 &amp; 1 &amp; -1 &amp; \ldots &amp; 0 \\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; 0 &amp; \ldots &amp; -1 
\end{array}
\right)_{(t-1) \times t}
\]</span></p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb769-1"><a href="multivariate-methods.html#cb769-1" aria-hidden="true" tabindex="-1"></a><span class="co"># One-sample Hotelling&#39;s T^2 test</span></span>
<span id="cb769-2"><a href="multivariate-methods.html#cb769-2" aria-hidden="true" tabindex="-1"></a><span class="co">#  Create data frame</span></span>
<span id="cb769-3"><a href="multivariate-methods.html#cb769-3" aria-hidden="true" tabindex="-1"></a>plants <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb769-4"><a href="multivariate-methods.html#cb769-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">y1 =</span> <span class="fu">c</span>(<span class="fl">2.11</span>, <span class="fl">2.36</span>, <span class="fl">2.13</span>, <span class="fl">2.78</span>, <span class="fl">2.17</span>),</span>
<span id="cb769-5"><a href="multivariate-methods.html#cb769-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">y2 =</span> <span class="fu">c</span>(<span class="fl">10.1</span>, <span class="fl">35.0</span>, <span class="fl">2.0</span>, <span class="fl">6.0</span>, <span class="fl">2.0</span>),</span>
<span id="cb769-6"><a href="multivariate-methods.html#cb769-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">y3 =</span> <span class="fu">c</span>(<span class="fl">3.4</span>, <span class="fl">4.1</span>, <span class="fl">1.9</span>, <span class="fl">3.8</span>, <span class="fl">1.7</span>)</span>
<span id="cb769-7"><a href="multivariate-methods.html#cb769-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb769-8"><a href="multivariate-methods.html#cb769-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb769-9"><a href="multivariate-methods.html#cb769-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Center the data with the hypothesized means and make a matrix</span></span>
<span id="cb769-10"><a href="multivariate-methods.html#cb769-10" aria-hidden="true" tabindex="-1"></a>plants_ctr <span class="ot">&lt;-</span> plants <span class="sc">%&gt;%</span></span>
<span id="cb769-11"><a href="multivariate-methods.html#cb769-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transmute</span>(<span class="at">y1_ctr =</span> y1 <span class="sc">-</span> <span class="fl">2.85</span>,</span>
<span id="cb769-12"><a href="multivariate-methods.html#cb769-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">y2_ctr =</span> y2 <span class="sc">-</span> <span class="fl">15.0</span>,</span>
<span id="cb769-13"><a href="multivariate-methods.html#cb769-13" aria-hidden="true" tabindex="-1"></a>              <span class="at">y3_ctr =</span> y3 <span class="sc">-</span> <span class="fl">6.0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb769-14"><a href="multivariate-methods.html#cb769-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">as.matrix</span>()</span>
<span id="cb769-15"><a href="multivariate-methods.html#cb769-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb769-16"><a href="multivariate-methods.html#cb769-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Use anova.mlm to calculate Wilks&#39; lambda</span></span>
<span id="cb769-17"><a href="multivariate-methods.html#cb769-17" aria-hidden="true" tabindex="-1"></a>onesamp_fit <span class="ot">&lt;-</span> <span class="fu">anova</span>(<span class="fu">lm</span>(plants_ctr <span class="sc">~</span> <span class="dv">1</span>), <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>)</span>
<span id="cb769-18"><a href="multivariate-methods.html#cb769-18" aria-hidden="true" tabindex="-1"></a>onesamp_fit <span class="co"># can&#39;t reject the null of hypothesized vector of means</span></span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
##             Df    Wilks approx F num Df den Df  Pr(&gt;F)  
## (Intercept)  1 0.054219   11.629      3      2 0.08022 .
## Residuals    4                                          
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb771-1"><a href="multivariate-methods.html#cb771-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Paired-Sample Hotelling&#39;s T^2 test</span></span>
<span id="cb771-2"><a href="multivariate-methods.html#cb771-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ICSNP)</span>
<span id="cb771-3"><a href="multivariate-methods.html#cb771-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb771-4"><a href="multivariate-methods.html#cb771-4" aria-hidden="true" tabindex="-1"></a><span class="co">#  Create data frame</span></span>
<span id="cb771-5"><a href="multivariate-methods.html#cb771-5" aria-hidden="true" tabindex="-1"></a>waste <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb771-6"><a href="multivariate-methods.html#cb771-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">case =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">11</span>,</span>
<span id="cb771-7"><a href="multivariate-methods.html#cb771-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">com_y1 =</span> <span class="fu">c</span>(<span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">18</span>, <span class="dv">8</span>, <span class="dv">11</span>, <span class="dv">34</span>, <span class="dv">28</span>, <span class="dv">71</span>, <span class="dv">43</span>, <span class="dv">33</span>, <span class="dv">20</span>),</span>
<span id="cb771-8"><a href="multivariate-methods.html#cb771-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">com_y2 =</span> <span class="fu">c</span>(<span class="dv">27</span>, <span class="dv">23</span>, <span class="dv">64</span>, <span class="dv">44</span>, <span class="dv">30</span>, <span class="dv">75</span>, <span class="dv">26</span>, <span class="dv">124</span>, <span class="dv">54</span>, <span class="dv">30</span>, <span class="dv">14</span>),</span>
<span id="cb771-9"><a href="multivariate-methods.html#cb771-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">state_y1 =</span> <span class="fu">c</span>(<span class="dv">25</span>, <span class="dv">28</span>, <span class="dv">36</span>, <span class="dv">35</span>, <span class="dv">15</span>, <span class="dv">44</span>, <span class="dv">42</span>, <span class="dv">54</span>, <span class="dv">34</span>, <span class="dv">29</span>, <span class="dv">39</span>),</span>
<span id="cb771-10"><a href="multivariate-methods.html#cb771-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">state_y2 =</span> <span class="fu">c</span>(<span class="dv">15</span>, <span class="dv">13</span>, <span class="dv">22</span>, <span class="dv">29</span>, <span class="dv">31</span>, <span class="dv">64</span>, <span class="dv">30</span>, <span class="dv">64</span>, <span class="dv">56</span>, <span class="dv">20</span>, <span class="dv">21</span>)</span>
<span id="cb771-11"><a href="multivariate-methods.html#cb771-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb771-12"><a href="multivariate-methods.html#cb771-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb771-13"><a href="multivariate-methods.html#cb771-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate the difference between commercial and state labs</span></span>
<span id="cb771-14"><a href="multivariate-methods.html#cb771-14" aria-hidden="true" tabindex="-1"></a>waste_diff <span class="ot">&lt;-</span> waste <span class="sc">%&gt;%</span></span>
<span id="cb771-15"><a href="multivariate-methods.html#cb771-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">transmute</span>(<span class="at">y1_diff =</span> com_y1 <span class="sc">-</span> state_y1,</span>
<span id="cb771-16"><a href="multivariate-methods.html#cb771-16" aria-hidden="true" tabindex="-1"></a>              <span class="at">y2_diff =</span> com_y2 <span class="sc">-</span> state_y2)</span>
<span id="cb771-17"><a href="multivariate-methods.html#cb771-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Run the test</span></span>
<span id="cb771-18"><a href="multivariate-methods.html#cb771-18" aria-hidden="true" tabindex="-1"></a>paired_fit <span class="ot">&lt;-</span> <span class="fu">HotellingsT2</span>(waste_diff)</span>
<span id="cb771-19"><a href="multivariate-methods.html#cb771-19" aria-hidden="true" tabindex="-1"></a>paired_fit <span class="co"># value T.2 in the output corresponds to the approximate F-value in the output from anova.mlm</span></span></code></pre></div>
<pre><code>## 
##  Hotelling&#39;s one sample T2-test
## 
## data:  waste_diff
## T.2 = 6.1377, df1 = 2, df2 = 9, p-value = 0.02083
## alternative hypothesis: true location is not equal to c(0,0)</code></pre>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb773-1"><a href="multivariate-methods.html#cb773-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reject the null that the two labs&#39; measurements are equal</span></span></code></pre></div>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="multivariate-methods.html#cb774-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Independent-Sample Hotelling&#39;s T^2 test with Bartlett&#39;s test</span></span>
<span id="cb774-2"><a href="multivariate-methods.html#cb774-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb774-3"><a href="multivariate-methods.html#cb774-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Read in data</span></span>
<span id="cb774-4"><a href="multivariate-methods.html#cb774-4" aria-hidden="true" tabindex="-1"></a>steel <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;images/steel.dat&quot;</span>)</span>
<span id="cb774-5"><a href="multivariate-methods.html#cb774-5" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(steel) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Temp&quot;</span>, <span class="st">&quot;Yield&quot;</span>, <span class="st">&quot;Strength&quot;</span>)</span>
<span id="cb774-6"><a href="multivariate-methods.html#cb774-6" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(steel)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    12 obs. of  3 variables:
##  $ Temp    : int  1 1 1 1 1 2 2 2 2 2 ...
##  $ Yield   : int  33 36 35 38 40 35 36 38 39 41 ...
##  $ Strength: int  60 61 64 63 65 57 59 59 61 63 ...</code></pre>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb776-1"><a href="multivariate-methods.html#cb776-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the data</span></span>
<span id="cb776-2"><a href="multivariate-methods.html#cb776-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(steel, <span class="fu">aes</span>(<span class="at">x =</span> Yield, <span class="at">y =</span> Strength)) <span class="sc">+</span></span>
<span id="cb776-3"><a href="multivariate-methods.html#cb776-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> Temp), <span class="at">size =</span> <span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb776-4"><a href="multivariate-methods.html#cb776-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_segment</span>(<span class="fu">aes</span>(</span>
<span id="cb776-5"><a href="multivariate-methods.html#cb776-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">x =</span> <span class="dv">33</span>,</span>
<span id="cb776-6"><a href="multivariate-methods.html#cb776-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">y =</span> <span class="fl">57.5</span>,</span>
<span id="cb776-7"><a href="multivariate-methods.html#cb776-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">xend =</span> <span class="dv">42</span>,</span>
<span id="cb776-8"><a href="multivariate-methods.html#cb776-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">yend =</span> <span class="dv">65</span></span>
<span id="cb776-9"><a href="multivariate-methods.html#cb776-9" aria-hidden="true" tabindex="-1"></a>    ), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="16-multivariate_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<div class="sourceCode" id="cb777"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb777-1"><a href="multivariate-methods.html#cb777-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bartlett&#39;s test for equality of covariance matrices</span></span>
<span id="cb777-2"><a href="multivariate-methods.html#cb777-2" aria-hidden="true" tabindex="-1"></a><span class="co"># same thing as Box&#39;s M test in the multivariate setting</span></span>
<span id="cb777-3"><a href="multivariate-methods.html#cb777-3" aria-hidden="true" tabindex="-1"></a>bart_test <span class="ot">&lt;-</span> <span class="fu">boxM</span>(steel[, <span class="sc">-</span><span class="dv">1</span>], steel<span class="sc">$</span>Temp)</span>
<span id="cb777-4"><a href="multivariate-methods.html#cb777-4" aria-hidden="true" tabindex="-1"></a>bart_test <span class="co"># fail to reject the null of equal covariances </span></span></code></pre></div>
<pre><code>## 
##  Box&#39;s M-test for Homogeneity of Covariance Matrices
## 
## data:  steel[, -1]
## Chi-Sq (approx.) = 0.38077, df = 3, p-value = 0.9442</code></pre>
<div class="sourceCode" id="cb779"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb779-1"><a href="multivariate-methods.html#cb779-1" aria-hidden="true" tabindex="-1"></a><span class="co"># anova.mlm</span></span>
<span id="cb779-2"><a href="multivariate-methods.html#cb779-2" aria-hidden="true" tabindex="-1"></a>twosamp_fit <span class="ot">&lt;-</span></span>
<span id="cb779-3"><a href="multivariate-methods.html#cb779-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">anova</span>(<span class="fu">lm</span>(<span class="fu">cbind</span>(Yield, Strength) <span class="sc">~</span> <span class="fu">factor</span>(Temp), <span class="at">data =</span> steel), <span class="at">test =</span> <span class="st">&quot;Wilks&quot;</span>)</span>
<span id="cb779-4"><a href="multivariate-methods.html#cb779-4" aria-hidden="true" tabindex="-1"></a>twosamp_fit</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
##              Df    Wilks approx F num Df den Df    Pr(&gt;F)    
## (Intercept)   1 0.001177   3818.1      2      9 6.589e-14 ***
## factor(Temp)  1 0.294883     10.8      2      9  0.004106 ** 
## Residuals    10                                              
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb781"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb781-1"><a href="multivariate-methods.html#cb781-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ICSNP package</span></span>
<span id="cb781-2"><a href="multivariate-methods.html#cb781-2" aria-hidden="true" tabindex="-1"></a>twosamp_fit2 <span class="ot">&lt;-</span></span>
<span id="cb781-3"><a href="multivariate-methods.html#cb781-3" aria-hidden="true" tabindex="-1"></a>    <span class="fu">HotellingsT2</span>(<span class="fu">cbind</span>(steel<span class="sc">$</span>Yield, steel<span class="sc">$</span>Strength) <span class="sc">~</span> <span class="fu">factor</span>(steel<span class="sc">$</span>Temp))</span>
<span id="cb781-4"><a href="multivariate-methods.html#cb781-4" aria-hidden="true" tabindex="-1"></a>twosamp_fit2</span></code></pre></div>
<pre><code>## 
##  Hotelling&#39;s two sample T2-test
## 
## data:  cbind(steel$Yield, steel$Strength) by factor(steel$Temp)
## T.2 = 10.76, df1 = 2, df2 = 9, p-value = 0.004106
## alternative hypothesis: true location difference is not equal to c(0,0)</code></pre>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb783-1"><a href="multivariate-methods.html#cb783-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reject null. Hence, there is a difference in the means of the bivariate normal distributions </span></span></code></pre></div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-MARDIA_1970" class="csl-entry">
MARDIA, K. V. 1970. <span>“Measures of Multivariate Skewness and Kurtosis with Applications.”</span> <em>Biometrika</em> 57 (3): 519–30. <a href="https://doi.org/10.1093/biomet/57.3.519">https://doi.org/10.1093/biomet/57.3.519</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="single-factor-covariance-model.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="manova.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/16-multivariate.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Data Analysis.pdf", "Data Analysis.epub", "Data Analysis.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
