<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6.2 Non-linear Least Squares | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="6.2 Non-linear Least Squares | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://bookdown.org/mike/data_analysis/" />
  <meta property="og:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />
  <meta property="og:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6.2 Non-linear Least Squares | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct data analysis in the field of data science, statistics, or machine learning." />
  <meta name="twitter:image" content="https://bookdown.org/mike/data_analysis//images/cover.jpg" />

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2022-09-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  <link rel="apple-touch-icon-precomposed" sizes="120x120" href="logo.png" />
  <link rel="shortcut icon" href="favicon.ico" type="image/x-icon" />
<link rel="prev" href="inference-1.html"/>
<link rel="next" href="generalized-linear-models.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-9.3.1/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-9.3.1/highcharts.js"></script>
<script src="libs/highcharts-9.3.1/highcharts-3d.js"></script>
<script src="libs/highcharts-9.3.1/highcharts-more.js"></script>
<script src="libs/highcharts-9.3.1/modules/stock.js"></script>
<script src="libs/highcharts-9.3.1/modules/map.js"></script>
<script src="libs/highcharts-9.3.1/modules/data.js"></script>
<script src="libs/highcharts-9.3.1/modules/exporting.js"></script>
<script src="libs/highcharts-9.3.1/modules/offline-exporting.js"></script>
<script src="libs/highcharts-9.3.1/modules/drilldown.js"></script>
<script src="libs/highcharts-9.3.1/modules/item-series.js"></script>
<script src="libs/highcharts-9.3.1/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-9.3.1/modules/annotations.js"></script>
<script src="libs/highcharts-9.3.1/modules/export-data.js"></script>
<script src="libs/highcharts-9.3.1/modules/funnel.js"></script>
<script src="libs/highcharts-9.3.1/modules/heatmap.js"></script>
<script src="libs/highcharts-9.3.1/modules/treemap.js"></script>
<script src="libs/highcharts-9.3.1/modules/sankey.js"></script>
<script src="libs/highcharts-9.3.1/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-9.3.1/modules/organization.js"></script>
<script src="libs/highcharts-9.3.1/modules/solid-gauge.js"></script>
<script src="libs/highcharts-9.3.1/modules/streamgraph.js"></script>
<script src="libs/highcharts-9.3.1/modules/sunburst.js"></script>
<script src="libs/highcharts-9.3.1/modules/vector.js"></script>
<script src="libs/highcharts-9.3.1/modules/wordcloud.js"></script>
<script src="libs/highcharts-9.3.1/modules/xrange.js"></script>
<script src="libs/highcharts-9.3.1/modules/tilemap.js"></script>
<script src="libs/highcharts-9.3.1/modules/venn.js"></script>
<script src="libs/highcharts-9.3.1/modules/gantt.js"></script>
<script src="libs/highcharts-9.3.1/modules/timeline.js"></script>
<script src="libs/highcharts-9.3.1/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-9.3.1/modules/bullet.js"></script>
<script src="libs/highcharts-9.3.1/modules/coloraxis.js"></script>
<script src="libs/highcharts-9.3.1/modules/dumbbell.js"></script>
<script src="libs/highcharts-9.3.1/modules/lollipop.js"></script>
<script src="libs/highcharts-9.3.1/modules/series-label.js"></script>
<script src="libs/highcharts-9.3.1/plugins/motion.js"></script>
<script src="libs/highcharts-9.3.1/custom/reset.js"></script>
<script src="libs/highcharts-9.3.1/modules/boost.js"></script>
<script src="libs/highchart-binding-0.9.4/highchart.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){window.dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-DMNX2X65HQ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li><a href="index.html#preface" id="toc-preface">Preface</a></li>
<li><a href="introduction.html#introduction" id="toc-introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="prerequisites.html#prerequisites" id="toc-prerequisites"><span class="toc-section-number">2</span> Prerequisites</a>
<ul>
<li><a href="matrix-theory.html#matrix-theory" id="toc-matrix-theory"><span class="toc-section-number">2.1</span> Matrix Theory</a>
<ul>
<li><a href="matrix-theory.html#rank" id="toc-rank"><span class="toc-section-number">2.1.1</span> Rank</a></li>
<li><a href="matrix-theory.html#inverse" id="toc-inverse"><span class="toc-section-number">2.1.2</span> Inverse</a></li>
<li><a href="matrix-theory.html#definiteness" id="toc-definiteness"><span class="toc-section-number">2.1.3</span> Definiteness</a></li>
<li><a href="matrix-theory.html#matrix-calculus" id="toc-matrix-calculus"><span class="toc-section-number">2.1.4</span> Matrix Calculus</a></li>
<li><a href="matrix-theory.html#optimization" id="toc-optimization"><span class="toc-section-number">2.1.5</span> Optimization</a></li>
</ul></li>
<li><a href="probability-theory.html#probability-theory" id="toc-probability-theory"><span class="toc-section-number">2.2</span> Probability Theory</a>
<ul>
<li><a href="probability-theory.html#axiom-and-theorems-of-probability" id="toc-axiom-and-theorems-of-probability"><span class="toc-section-number">2.2.1</span> Axiom and Theorems of Probability</a></li>
<li><a href="probability-theory.html#central-limit-theorem" id="toc-central-limit-theorem"><span class="toc-section-number">2.2.2</span> Central Limit Theorem</a></li>
<li><a href="probability-theory.html#random-variable" id="toc-random-variable"><span class="toc-section-number">2.2.3</span> Random variable</a></li>
<li><a href="probability-theory.html#moment-generating-function" id="toc-moment-generating-function"><span class="toc-section-number">2.2.4</span> Moment generating function</a></li>
<li><a href="probability-theory.html#moment" id="toc-moment"><span class="toc-section-number">2.2.5</span> Moment</a></li>
<li><a href="probability-theory.html#distributions" id="toc-distributions"><span class="toc-section-number">2.2.6</span> Distributions</a></li>
</ul></li>
<li><a href="general-math.html#general-math" id="toc-general-math"><span class="toc-section-number">2.3</span> General Math</a>
<ul>
<li><a href="general-math.html#law-of-large-numbers" id="toc-law-of-large-numbers"><span class="toc-section-number">2.3.1</span> Law of large numbers</a></li>
<li><a href="general-math.html#law-of-iterated-expectation" id="toc-law-of-iterated-expectation"><span class="toc-section-number">2.3.2</span> Law of Iterated Expectation</a></li>
<li><a href="general-math.html#convergence" id="toc-convergence"><span class="toc-section-number">2.3.3</span> Convergence</a></li>
<li><a href="general-math.html#sufficient-statistics" id="toc-sufficient-statistics"><span class="toc-section-number">2.3.4</span> Sufficient Statistics</a></li>
<li><a href="general-math.html#parameter-transformations" id="toc-parameter-transformations"><span class="toc-section-number">2.3.5</span> Parameter transformations</a></li>
</ul></li>
<li><a href="data-importexport.html#data-importexport" id="toc-data-importexport"><span class="toc-section-number">2.4</span> Data Import/Export</a>
<ul>
<li><a href="data-importexport.html#medium-size" id="toc-medium-size"><span class="toc-section-number">2.4.1</span> Medium size</a></li>
<li><a href="data-importexport.html#large-size" id="toc-large-size"><span class="toc-section-number">2.4.2</span> Large size</a></li>
</ul></li>
<li><a href="data-manipulation.html#data-manipulation" id="toc-data-manipulation"><span class="toc-section-number">2.5</span> Data Manipulation</a></li>
</ul></li>
<li><a href="#part-i.-basic" id="toc-part-i.-basic">(PART*) I. BASIC</a></li>
<li><a href="descriptive-stat.html#descriptive-stat" id="toc-descriptive-stat"><span class="toc-section-number">3</span> Descriptive Statistics</a>
<ul>
<li><a href="numerical-measures.html#numerical-measures" id="toc-numerical-measures"><span class="toc-section-number">3.1</span> Numerical Measures</a></li>
<li><a href="graphical-measures.html#graphical-measures" id="toc-graphical-measures"><span class="toc-section-number">3.2</span> Graphical Measures</a>
<ul>
<li><a href="graphical-measures.html#shape" id="toc-shape"><span class="toc-section-number">3.2.1</span> Shape</a></li>
<li><a href="graphical-measures.html#scatterplot" id="toc-scatterplot"><span class="toc-section-number">3.2.2</span> Scatterplot</a></li>
</ul></li>
<li><a href="normality-assessment.html#normality-assessment" id="toc-normality-assessment"><span class="toc-section-number">3.3</span> Normality Assessment</a>
<ul>
<li><a href="normality-assessment.html#graphical-assessment" id="toc-graphical-assessment"><span class="toc-section-number">3.3.1</span> Graphical Assessment</a></li>
<li><a href="normality-assessment.html#summary-statistics" id="toc-summary-statistics"><span class="toc-section-number">3.3.2</span> Summary Statistics</a></li>
</ul></li>
<li><a href="bivariate-statistics.html#bivariate-statistics" id="toc-bivariate-statistics"><span class="toc-section-number">3.4</span> Bivariate Statistics</a></li>
<li><a href="two-continuous.html#two-continuous" id="toc-two-continuous"><span class="toc-section-number">3.5</span> Two Continuous</a>
<ul>
<li><a href="two-continuous.html#pearson-correlation" id="toc-pearson-correlation"><span class="toc-section-number">3.5.1</span> Pearson Correlation</a></li>
<li><a href="two-continuous.html#spearman-correlation" id="toc-spearman-correlation"><span class="toc-section-number">3.5.2</span> Spearman Correlation</a></li>
</ul></li>
<li><a href="categorical-and-continuous.html#categorical-and-continuous" id="toc-categorical-and-continuous"><span class="toc-section-number">3.6</span> Categorical and Continuous</a>
<ul>
<li><a href="categorical-and-continuous.html#point-biserial-correlation" id="toc-point-biserial-correlation"><span class="toc-section-number">3.6.1</span> Point-Biserial Correlation</a></li>
<li><a href="categorical-and-continuous.html#logistic-regression" id="toc-logistic-regression"><span class="toc-section-number">3.6.2</span> Logistic Regression</a></li>
</ul></li>
<li><a href="two-discrete.html#two-discrete" id="toc-two-discrete"><span class="toc-section-number">3.7</span> Two Discrete</a>
<ul>
<li><a href="two-discrete.html#distance-metrics" id="toc-distance-metrics"><span class="toc-section-number">3.7.1</span> Distance Metrics</a></li>
<li><a href="two-discrete.html#statistical-metrics" id="toc-statistical-metrics"><span class="toc-section-number">3.7.2</span> Statistical Metrics</a></li>
<li><a href="two-discrete.html#ordinal-association-rank-correlation" id="toc-ordinal-association-rank-correlation"><span class="toc-section-number">3.7.3</span> Ordinal Association (Rank correlation)</a></li>
<li><a href="two-discrete.html#summary-1" id="toc-summary-1"><span class="toc-section-number">3.7.4</span> Summary</a></li>
<li><a href="two-discrete.html#visualization" id="toc-visualization"><span class="toc-section-number">3.7.5</span> Visualization</a></li>
</ul></li>
</ul></li>
<li><a href="basic-statistical-inference.html#basic-statistical-inference" id="toc-basic-statistical-inference"><span class="toc-section-number">4</span> Basic Statistical Inference</a>
<ul>
<li><a href="one-sample-inference.html#one-sample-inference" id="toc-one-sample-inference"><span class="toc-section-number">4.1</span> One Sample Inference</a>
<ul>
<li><a href="one-sample-inference.html#the-mean" id="toc-the-mean"><span class="toc-section-number">4.1.1</span> The Mean</a></li>
<li><a href="one-sample-inference.html#single-variance" id="toc-single-variance"><span class="toc-section-number">4.1.2</span> Single Variance</a></li>
<li><a href="one-sample-inference.html#single-proportion-p" id="toc-single-proportion-p"><span class="toc-section-number">4.1.3</span> Single Proportion (p)</a></li>
<li><a href="one-sample-inference.html#power" id="toc-power"><span class="toc-section-number">4.1.4</span> Power</a></li>
<li><a href="one-sample-inference.html#sample-size" id="toc-sample-size"><span class="toc-section-number">4.1.5</span> Sample Size</a></li>
<li><a href="one-sample-inference.html#note" id="toc-note"><span class="toc-section-number">4.1.6</span> Note</a></li>
<li><a href="one-sample-inference.html#one-sample-non-parametric-methods" id="toc-one-sample-non-parametric-methods"><span class="toc-section-number">4.1.7</span> One-sample Non-parametric Methods</a></li>
</ul></li>
<li><a href="two-sample-inference.html#two-sample-inference" id="toc-two-sample-inference"><span class="toc-section-number">4.2</span> Two Sample Inference</a>
<ul>
<li><a href="two-sample-inference.html#means" id="toc-means"><span class="toc-section-number">4.2.1</span> Means</a></li>
<li><a href="two-sample-inference.html#variances" id="toc-variances"><span class="toc-section-number">4.2.2</span> Variances</a></li>
<li><a href="two-sample-inference.html#power-1" id="toc-power-1"><span class="toc-section-number">4.2.3</span> Power</a></li>
<li><a href="two-sample-inference.html#sample-size-1" id="toc-sample-size-1"><span class="toc-section-number">4.2.4</span> Sample Size</a></li>
<li><a href="two-sample-inference.html#matched-pair-designs" id="toc-matched-pair-designs"><span class="toc-section-number">4.2.5</span> Matched Pair Designs</a></li>
<li><a href="two-sample-inference.html#nonparametric-tests-for-two-samples" id="toc-nonparametric-tests-for-two-samples"><span class="toc-section-number">4.2.6</span> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li><a href="categorical-data-analysis.html#categorical-data-analysis" id="toc-categorical-data-analysis"><span class="toc-section-number">4.3</span> Categorical Data Analysis</a>
<ul>
<li><a href="categorical-data-analysis.html#inferences-for-small-samples" id="toc-inferences-for-small-samples"><span class="toc-section-number">4.3.1</span> Inferences for Small Samples</a></li>
<li><a href="categorical-data-analysis.html#test-of-association" id="toc-test-of-association"><span class="toc-section-number">4.3.2</span> Test of Association</a></li>
<li><a href="categorical-data-analysis.html#ordinal-association" id="toc-ordinal-association"><span class="toc-section-number">4.3.3</span> Ordinal Association</a></li>
</ul></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#divergence-metrics-and-test-for-comparing-distributions" id="toc-divergence-metrics-and-test-for-comparing-distributions"><span class="toc-section-number">4.4</span> Divergence Metrics and Test for Comparing Distributions</a>
<ul>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#kullback-leibler-divergence" id="toc-kullback-leibler-divergence"><span class="toc-section-number">4.4.1</span> Kullback-Leibler Divergence</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#jensen-shannon-divergence" id="toc-jensen-shannon-divergence"><span class="toc-section-number">4.4.2</span> Jensen-Shannon Divergence</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#wasserstein-distance" id="toc-wasserstein-distance"><span class="toc-section-number">4.4.3</span> Wasserstein Distance</a></li>
<li><a href="divergence-metrics-and-test-for-comparing-distributions.html#kolmogorov-smirnov-test-1" id="toc-kolmogorov-smirnov-test-1"><span class="toc-section-number">4.4.4</span> Kolmogorov-Smirnov Test</a></li>
</ul></li>
</ul></li>
<li><a href="#part-ii.-regression" id="toc-part-ii.-regression">(PART*) II. REGRESSION</a></li>
<li><a href="linear-regression.html#linear-regression" id="toc-linear-regression"><span class="toc-section-number">5</span> Linear Regression</a>
<ul>
<li><a href="ordinary-least-squares.html#ordinary-least-squares" id="toc-ordinary-least-squares"><span class="toc-section-number">5.1</span> Ordinary Least Squares</a>
<ul>
<li><a href="ordinary-least-squares.html#simple-regression-basic-model" id="toc-simple-regression-basic-model"><span class="toc-section-number">5.1.1</span> Simple Regression (Basic Model)</a></li>
<li><a href="ordinary-least-squares.html#multiple-linear-regression" id="toc-multiple-linear-regression"><span class="toc-section-number">5.1.2</span> Multiple Linear Regression</a></li>
<li><a href="ordinary-least-squares.html#ols-assumptions" id="toc-ols-assumptions"><span class="toc-section-number">5.1.3</span> OLS Assumptions</a></li>
<li><a href="ordinary-least-squares.html#theorems" id="toc-theorems"><span class="toc-section-number">5.1.4</span> Theorems</a></li>
<li><a href="ordinary-least-squares.html#variable-selection" id="toc-variable-selection"><span class="toc-section-number">5.1.5</span> Variable Selection</a></li>
<li><a href="ordinary-least-squares.html#diagnostics-1" id="toc-diagnostics-1"><span class="toc-section-number">5.1.6</span> Diagnostics</a></li>
<li><a href="ordinary-least-squares.html#model-validation" id="toc-model-validation"><span class="toc-section-number">5.1.7</span> Model Validation</a></li>
<li><a href="ordinary-least-squares.html#finite-sample-properties" id="toc-finite-sample-properties"><span class="toc-section-number">5.1.8</span> Finite Sample Properties</a></li>
<li><a href="ordinary-least-squares.html#large-sample-properties" id="toc-large-sample-properties"><span class="toc-section-number">5.1.9</span> Large Sample Properties</a></li>
</ul></li>
<li><a href="feasible-generalized-least-squares.html#feasible-generalized-least-squares" id="toc-feasible-generalized-least-squares"><span class="toc-section-number">5.2</span> Feasible Generalized Least Squares</a>
<ul>
<li><a href="feasible-generalized-least-squares.html#heteroskedasticity" id="toc-heteroskedasticity"><span class="toc-section-number">5.2.1</span> Heteroskedasticity</a></li>
<li><a href="feasible-generalized-least-squares.html#serial-correlation" id="toc-serial-correlation"><span class="toc-section-number">5.2.2</span> Serial Correlation</a></li>
</ul></li>
<li><a href="weighted-least-squares.html#weighted-least-squares" id="toc-weighted-least-squares"><span class="toc-section-number">5.3</span> Weighted Least Squares</a></li>
<li><a href="generalized-least-squares.html#generalized-least-squares" id="toc-generalized-least-squares"><span class="toc-section-number">5.4</span> Generalized Least Squares</a></li>
<li><a href="feasiable-prais-winsten.html#feasiable-prais-winsten" id="toc-feasiable-prais-winsten"><span class="toc-section-number">5.5</span> Feasiable Prais Winsten</a></li>
<li><a href="feasible-group-level-random-effects.html#feasible-group-level-random-effects" id="toc-feasible-group-level-random-effects"><span class="toc-section-number">5.6</span> Feasible group level Random Effects</a></li>
<li><a href="ridge-regression.html#ridge-regression" id="toc-ridge-regression"><span class="toc-section-number">5.7</span> Ridge Regression</a></li>
<li><a href="principal-component-regression.html#principal-component-regression" id="toc-principal-component-regression"><span class="toc-section-number">5.8</span> Principal Component Regression</a></li>
<li><a href="robust-regression.html#robust-regression" id="toc-robust-regression"><span class="toc-section-number">5.9</span> Robust Regression</a>
<ul>
<li><a href="robust-regression.html#least-absolute-residuals-lar-regression" id="toc-least-absolute-residuals-lar-regression"><span class="toc-section-number">5.9.1</span> Least Absolute Residuals (LAR) Regression</a></li>
<li><a href="robust-regression.html#least-median-of-squares-lms-regression" id="toc-least-median-of-squares-lms-regression"><span class="toc-section-number">5.9.2</span> Least Median of Squares (LMS) Regression</a></li>
<li><a href="robust-regression.html#iteratively-reweighted-least-squares-irls-robust-regression" id="toc-iteratively-reweighted-least-squares-irls-robust-regression"><span class="toc-section-number">5.9.3</span> Iteratively Reweighted Least Squares (IRLS) Robust Regression</a></li>
</ul></li>
<li><a href="maximum-likelihood-regression.html#maximum-likelihood-regression" id="toc-maximum-likelihood-regression"><span class="toc-section-number">5.10</span> Maximum Likelihood</a>
<ul>
<li><a href="maximum-likelihood-regression.html#motivation-for-mle" id="toc-motivation-for-mle"><span class="toc-section-number">5.10.1</span> Motivation for MLE</a></li>
<li><a href="maximum-likelihood-regression.html#assumption" id="toc-assumption"><span class="toc-section-number">5.10.2</span> Assumption</a></li>
<li><a href="maximum-likelihood-regression.html#properties" id="toc-properties"><span class="toc-section-number">5.10.3</span> Properties</a></li>
<li><a href="maximum-likelihood-regression.html#compare-to-ols" id="toc-compare-to-ols"><span class="toc-section-number">5.10.4</span> Compare to OLS</a></li>
<li><a href="maximum-likelihood-regression.html#application" id="toc-application"><span class="toc-section-number">5.10.5</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="non-linear-regression.html#non-linear-regression" id="toc-non-linear-regression"><span class="toc-section-number">6</span> Non-linear Regression</a>
<ul>
<li><a href="inference-1.html#inference-1" id="toc-inference-1"><span class="toc-section-number">6.1</span> Inference</a>
<ul>
<li><a href="inference-1.html#linear-function-of-the-parameters" id="toc-linear-function-of-the-parameters"><span class="toc-section-number">6.1.1</span> Linear Function of the Parameters</a></li>
<li><a href="inference-1.html#nonlinear" id="toc-nonlinear"><span class="toc-section-number">6.1.2</span> Nonlinear</a></li>
</ul></li>
<li><a href="non-linear-least-squares.html#non-linear-least-squares" id="toc-non-linear-least-squares"><span class="toc-section-number">6.2</span> Non-linear Least Squares</a>
<ul>
<li><a href="non-linear-least-squares.html#alternative-of-gauss-newton-algorithm" id="toc-alternative-of-gauss-newton-algorithm"><span class="toc-section-number">6.2.1</span> Alternative of Gauss-Newton Algorithm</a></li>
<li><a href="non-linear-least-squares.html#practical-considerations" id="toc-practical-considerations"><span class="toc-section-number">6.2.2</span> Practical Considerations</a></li>
<li><a href="non-linear-least-squares.html#modelestiamtion-adequcy" id="toc-modelestiamtion-adequcy"><span class="toc-section-number">6.2.3</span> Model/Estiamtion Adequcy</a></li>
<li><a href="non-linear-least-squares.html#application-1" id="toc-application-1"><span class="toc-section-number">6.2.4</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="generalized-linear-models.html#generalized-linear-models" id="toc-generalized-linear-models"><span class="toc-section-number">7</span> Generalized Linear Models</a>
<ul>
<li><a href="logistic-regression-1.html#logistic-regression-1" id="toc-logistic-regression-1"><span class="toc-section-number">7.1</span> Logistic Regression</a>
<ul>
<li><a href="logistic-regression-1.html#application-2" id="toc-application-2"><span class="toc-section-number">7.1.1</span> Application</a></li>
</ul></li>
<li><a href="probit-regression.html#probit-regression" id="toc-probit-regression"><span class="toc-section-number">7.2</span> Probit Regression</a></li>
<li><a href="binomial-regression.html#binomial-regression" id="toc-binomial-regression"><span class="toc-section-number">7.3</span> Binomial Regression</a></li>
<li><a href="poisson-regression.html#poisson-regression" id="toc-poisson-regression"><span class="toc-section-number">7.4</span> Poisson Regression</a>
<ul>
<li><a href="poisson-regression.html#application-3" id="toc-application-3"><span class="toc-section-number">7.4.1</span> Application</a></li>
</ul></li>
<li><a href="negative-binomial-regression.html#negative-binomial-regression" id="toc-negative-binomial-regression"><span class="toc-section-number">7.5</span> Negative Binomial Regression</a></li>
<li><a href="multinomial.html#multinomial" id="toc-multinomial"><span class="toc-section-number">7.6</span> Multinomial</a></li>
<li><a href="generalization.html#generalization" id="toc-generalization"><span class="toc-section-number">7.7</span> Generalization</a>
<ul>
<li><a href="generalization.html#estimation-1" id="toc-estimation-1"><span class="toc-section-number">7.7.1</span> Estimation</a></li>
<li><a href="generalization.html#inference-2" id="toc-inference-2"><span class="toc-section-number">7.7.2</span> Inference</a></li>
<li><a href="generalization.html#deviance" id="toc-deviance"><span class="toc-section-number">7.7.3</span> Deviance</a></li>
<li><a href="generalization.html#diagnostic-plots" id="toc-diagnostic-plots"><span class="toc-section-number">7.7.4</span> Diagnostic Plots</a></li>
<li><a href="generalization.html#goodness-of-fit" id="toc-goodness-of-fit"><span class="toc-section-number">7.7.5</span> Goodness of Fit</a></li>
<li><a href="generalization.html#over-dispersion" id="toc-over-dispersion"><span class="toc-section-number">7.7.6</span> Over-Dispersion</a></li>
</ul></li>
</ul></li>
<li><a href="linear-mixed-models.html#linear-mixed-models" id="toc-linear-mixed-models"><span class="toc-section-number">8</span> Linear Mixed Models</a>
<ul>
<li><a href="dependent-data.html#dependent-data" id="toc-dependent-data"><span class="toc-section-number">8.1</span> Dependent Data</a>
<ul>
<li><a href="dependent-data.html#random-intercepts-model" id="toc-random-intercepts-model"><span class="toc-section-number">8.1.1</span> Random-Intercepts Model</a></li>
<li><a href="dependent-data.html#covariance-models" id="toc-covariance-models"><span class="toc-section-number">8.1.2</span> Covariance Models</a></li>
</ul></li>
<li><a href="estimation-2.html#estimation-2" id="toc-estimation-2"><span class="toc-section-number">8.2</span> Estimation</a>
<ul>
<li><a href="estimation-2.html#estimating-mathbfv" id="toc-estimating-mathbfv"><span class="toc-section-number">8.2.1</span> Estimating <span class="math inline">\(\mathbf{V}\)</span></a></li>
</ul></li>
<li><a href="inference-3.html#inference-3" id="toc-inference-3"><span class="toc-section-number">8.3</span> Inference</a>
<ul>
<li><a href="inference-3.html#parameters-beta" id="toc-parameters-beta"><span class="toc-section-number">8.3.1</span> Parameters <span class="math inline">\(\beta\)</span></a></li>
<li><a href="inference-3.html#variance-components" id="toc-variance-components"><span class="toc-section-number">8.3.2</span> Variance Components</a></li>
</ul></li>
<li><a href="information-criteria.html#information-criteria" id="toc-information-criteria"><span class="toc-section-number">8.4</span> Information Criteria</a>
<ul>
<li><a href="information-criteria.html#akaikes-information-criteria-aic" id="toc-akaikes-information-criteria-aic"><span class="toc-section-number">8.4.1</span> Akaike’s Information Criteria (AIC)</a></li>
<li><a href="information-criteria.html#corrected-aic-aicc" id="toc-corrected-aic-aicc"><span class="toc-section-number">8.4.2</span> Corrected AIC (AICC)</a></li>
<li><a href="information-criteria.html#bayesian-information-criteria-bic" id="toc-bayesian-information-criteria-bic"><span class="toc-section-number">8.4.3</span> Bayesian Information Criteria (BIC)</a></li>
</ul></li>
<li><a href="split-plot-designs.html#split-plot-designs" id="toc-split-plot-designs"><span class="toc-section-number">8.5</span> Split-Plot Designs</a>
<ul>
<li><a href="split-plot-designs.html#application-4" id="toc-application-4"><span class="toc-section-number">8.5.1</span> Application</a></li>
</ul></li>
<li><a href="repeated-measures-in-mixed-models.html#repeated-measures-in-mixed-models" id="toc-repeated-measures-in-mixed-models"><span class="toc-section-number">8.6</span> Repeated Measures in Mixed Models</a></li>
<li><a href="unbalanced-or-unequally-spaced-data.html#unbalanced-or-unequally-spaced-data" id="toc-unbalanced-or-unequally-spaced-data"><span class="toc-section-number">8.7</span> Unbalanced or Unequally Spaced Data</a></li>
<li><a href="application-5.html#application-5" id="toc-application-5"><span class="toc-section-number">8.8</span> Application</a>
<ul>
<li><a href="application-5.html#example-1-pulps" id="toc-example-1-pulps"><span class="toc-section-number">8.8.1</span> Example 1 (Pulps)</a></li>
<li><a href="application-5.html#example-2-rats" id="toc-example-2-rats"><span class="toc-section-number">8.8.2</span> Example 2 (Rats)</a></li>
<li><a href="application-5.html#example-3-agridat" id="toc-example-3-agridat"><span class="toc-section-number">8.8.3</span> Example 3 (Agridat)</a></li>
</ul></li>
</ul></li>
<li><a href="nonlinear-and-generalized-linear-mixed-models.html#nonlinear-and-generalized-linear-mixed-models" id="toc-nonlinear-and-generalized-linear-mixed-models"><span class="toc-section-number">9</span> Nonlinear and Generalized Linear Mixed Models</a>
<ul>
<li><a href="estimation-3.html#estimation-3" id="toc-estimation-3"><span class="toc-section-number">9.1</span> Estimation</a>
<ul>
<li><a href="estimation-3.html#estimation-by-numerical-integration" id="toc-estimation-by-numerical-integration"><span class="toc-section-number">9.1.1</span> Estimation by Numerical Integration</a></li>
<li><a href="estimation-3.html#estimation-by-linearization" id="toc-estimation-by-linearization"><span class="toc-section-number">9.1.2</span> Estimation by Linearization</a></li>
<li><a href="estimation-3.html#estimation-by-bayesian-hierarchical-models" id="toc-estimation-by-bayesian-hierarchical-models"><span class="toc-section-number">9.1.3</span> Estimation by Bayesian Hierarchical Models</a></li>
</ul></li>
<li><a href="application-6.html#application-6" id="toc-application-6"><span class="toc-section-number">9.2</span> Application</a>
<ul>
<li><a href="application-6.html#binomial-cbpp-data" id="toc-binomial-cbpp-data"><span class="toc-section-number">9.2.1</span> Binomial (CBPP Data)</a></li>
<li><a href="application-6.html#count-owl-data" id="toc-count-owl-data"><span class="toc-section-number">9.2.2</span> Count (Owl Data)</a></li>
<li><a href="application-6.html#binomial-1" id="toc-binomial-1"><span class="toc-section-number">9.2.3</span> Binomial</a></li>
<li><a href="application-6.html#example-from-schabenberger_2001-section-8.4.1" id="toc-example-from-schabenberger_2001-section-8.4.1"><span class="toc-section-number">9.2.4</span> Example from <span class="citation">(<span>Schabenberger and Pierce 2001</span>)</span> section 8.4.1</a></li>
</ul></li>
<li><a href="summary-2.html#summary-2" id="toc-summary-2"><span class="toc-section-number">9.3</span> Summary</a></li>
</ul></li>
<li><a href="#part-iii.-ramifications" id="toc-part-iii.-ramifications">(PART*) III. RAMIFICATIONS</a></li>
<li><a href="model-specification.html#model-specification" id="toc-model-specification"><span class="toc-section-number">10</span> Model Specification</a>
<ul>
<li><a href="nested-model.html#nested-model" id="toc-nested-model"><span class="toc-section-number">10.1</span> Nested Model</a>
<ul>
<li><a href="nested-model.html#chow-test" id="toc-chow-test"><span class="toc-section-number">10.1.1</span> Chow test</a></li>
</ul></li>
<li><a href="non-nested-model.html#non-nested-model" id="toc-non-nested-model"><span class="toc-section-number">10.2</span> Non-Nested Model</a>
<ul>
<li><a href="non-nested-model.html#davidson-mackinnon-test" id="toc-davidson-mackinnon-test"><span class="toc-section-number">10.2.1</span> Davidson-Mackinnon test</a></li>
</ul></li>
<li><a href="heteroskedasticity-1.html#heteroskedasticity-1" id="toc-heteroskedasticity-1"><span class="toc-section-number">10.3</span> Heteroskedasticity</a>
<ul>
<li><a href="heteroskedasticity-1.html#breusch-pagan-test" id="toc-breusch-pagan-test"><span class="toc-section-number">10.3.1</span> Breusch-Pagan test</a></li>
<li><a href="heteroskedasticity-1.html#white-test" id="toc-white-test"><span class="toc-section-number">10.3.2</span> White test</a></li>
</ul></li>
</ul></li>
<li><a href="imputation-missing-data.html#imputation-missing-data" id="toc-imputation-missing-data"><span class="toc-section-number">11</span> Imputation (Missing Data)</a>
<ul>
<li><a href="assumptions-1.html#assumptions-1" id="toc-assumptions-1"><span class="toc-section-number">11.1</span> Assumptions</a>
<ul>
<li><a href="assumptions-1.html#missing-completely-at-random-mcar" id="toc-missing-completely-at-random-mcar"><span class="toc-section-number">11.1.1</span> Missing Completely at Random (MCAR)</a></li>
<li><a href="assumptions-1.html#missing-at-random-mar" id="toc-missing-at-random-mar"><span class="toc-section-number">11.1.2</span> Missing at Random (MAR)</a></li>
<li><a href="assumptions-1.html#ignorable" id="toc-ignorable"><span class="toc-section-number">11.1.3</span> Ignorable</a></li>
<li><a href="assumptions-1.html#nonignorable" id="toc-nonignorable"><span class="toc-section-number">11.1.4</span> Nonignorable</a></li>
</ul></li>
<li><a href="solutions-to-missing-data.html#solutions-to-missing-data" id="toc-solutions-to-missing-data"><span class="toc-section-number">11.2</span> Solutions to Missing data</a>
<ul>
<li><a href="solutions-to-missing-data.html#listwise-deletion" id="toc-listwise-deletion"><span class="toc-section-number">11.2.1</span> Listwise Deletion</a></li>
<li><a href="solutions-to-missing-data.html#pairwise-deletion" id="toc-pairwise-deletion"><span class="toc-section-number">11.2.2</span> Pairwise Deletion</a></li>
<li><a href="solutions-to-missing-data.html#dummy-variable-adjustment" id="toc-dummy-variable-adjustment"><span class="toc-section-number">11.2.3</span> Dummy Variable Adjustment</a></li>
<li><a href="solutions-to-missing-data.html#imputation" id="toc-imputation"><span class="toc-section-number">11.2.4</span> Imputation</a></li>
<li><a href="solutions-to-missing-data.html#other-methods" id="toc-other-methods"><span class="toc-section-number">11.2.5</span> Other methods</a></li>
</ul></li>
<li><a href="criteria-for-choosing-an-effective-approach.html#criteria-for-choosing-an-effective-approach" id="toc-criteria-for-choosing-an-effective-approach"><span class="toc-section-number">11.3</span> Criteria for Choosing an Effective Approach</a></li>
<li><a href="another-perspective.html#another-perspective" id="toc-another-perspective"><span class="toc-section-number">11.4</span> Another Perspective</a></li>
<li><a href="diagnosing-the-mechanism.html#diagnosing-the-mechanism" id="toc-diagnosing-the-mechanism"><span class="toc-section-number">11.5</span> Diagnosing the Mechanism</a>
<ul>
<li><a href="diagnosing-the-mechanism.html#mar-vs.-mnar" id="toc-mar-vs.-mnar"><span class="toc-section-number">11.5.1</span> MAR vs. MNAR</a></li>
<li><a href="diagnosing-the-mechanism.html#mcar-vs.-mar" id="toc-mcar-vs.-mar"><span class="toc-section-number">11.5.2</span> MCAR vs. MAR</a></li>
</ul></li>
<li><a href="application-7.html#application-7" id="toc-application-7"><span class="toc-section-number">11.6</span> Application</a>
<ul>
<li><a href="application-7.html#imputation-with-mean-median-mode" id="toc-imputation-with-mean-median-mode"><span class="toc-section-number">11.6.1</span> Imputation with mean / median / mode</a></li>
<li><a href="application-7.html#knn" id="toc-knn"><span class="toc-section-number">11.6.2</span> KNN</a></li>
<li><a href="application-7.html#rpart" id="toc-rpart"><span class="toc-section-number">11.6.3</span> rpart</a></li>
<li><a href="application-7.html#mice-multivariate-imputation-via-chained-equations" id="toc-mice-multivariate-imputation-via-chained-equations"><span class="toc-section-number">11.6.4</span> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li><a href="application-7.html#amelia" id="toc-amelia"><span class="toc-section-number">11.6.5</span> Amelia</a></li>
<li><a href="application-7.html#missforest" id="toc-missforest"><span class="toc-section-number">11.6.6</span> missForest</a></li>
<li><a href="application-7.html#hmisc" id="toc-hmisc"><span class="toc-section-number">11.6.7</span> Hmisc</a></li>
<li><a href="application-7.html#mi" id="toc-mi"><span class="toc-section-number">11.6.8</span> mi</a></li>
</ul></li>
</ul></li>
<li><a href="data.html#data" id="toc-data"><span class="toc-section-number">12</span> Data</a>
<ul>
<li><a href="cross-sectional.html#cross-sectional" id="toc-cross-sectional"><span class="toc-section-number">12.1</span> Cross-Sectional</a></li>
<li><a href="time-series-1.html#time-series-1" id="toc-time-series-1"><span class="toc-section-number">12.2</span> Time Series</a>
<ul>
<li><a href="time-series-1.html#deterministic-time-trend" id="toc-deterministic-time-trend"><span class="toc-section-number">12.2.1</span> Deterministic Time trend</a></li>
<li><a href="time-series-1.html#feedback-effect" id="toc-feedback-effect"><span class="toc-section-number">12.2.2</span> Feedback Effect</a></li>
<li><a href="time-series-1.html#dynamic-specification" id="toc-dynamic-specification"><span class="toc-section-number">12.2.3</span> Dynamic Specification</a></li>
<li><a href="time-series-1.html#dynamically-complete" id="toc-dynamically-complete"><span class="toc-section-number">12.2.4</span> Dynamically Complete</a></li>
<li><a href="time-series-1.html#highly-persistent-data" id="toc-highly-persistent-data"><span class="toc-section-number">12.2.5</span> Highly Persistent Data</a></li>
</ul></li>
<li><a href="repeated-cross-sections.html#repeated-cross-sections" id="toc-repeated-cross-sections"><span class="toc-section-number">12.3</span> Repeated Cross Sections</a>
<ul>
<li><a href="repeated-cross-sections.html#pooled-cross-section" id="toc-pooled-cross-section"><span class="toc-section-number">12.3.1</span> Pooled Cross Section</a></li>
</ul></li>
<li><a href="panel-data.html#panel-data" id="toc-panel-data"><span class="toc-section-number">12.4</span> Panel Data</a>
<ul>
<li><a href="panel-data.html#pooled-ols-estimator" id="toc-pooled-ols-estimator"><span class="toc-section-number">12.4.1</span> Pooled OLS Estimator</a></li>
<li><a href="panel-data.html#individual-specific-effects-model" id="toc-individual-specific-effects-model"><span class="toc-section-number">12.4.2</span> Individual-specific effects model</a></li>
<li><a href="panel-data.html#tests-for-assumptions" id="toc-tests-for-assumptions"><span class="toc-section-number">12.4.3</span> Tests for Assumptions</a></li>
<li><a href="panel-data.html#model-selection" id="toc-model-selection"><span class="toc-section-number">12.4.4</span> Model Selection</a></li>
<li><a href="panel-data.html#summary-3" id="toc-summary-3"><span class="toc-section-number">12.4.5</span> Summary</a></li>
<li><a href="panel-data.html#application-8" id="toc-application-8"><span class="toc-section-number">12.4.6</span> Application</a></li>
<li><a href="panel-data.html#other-estimators" id="toc-other-estimators"><span class="toc-section-number">12.4.7</span> Other Estimators</a></li>
</ul></li>
</ul></li>
<li><a href="hypothesis-testing.html#hypothesis-testing" id="toc-hypothesis-testing"><span class="toc-section-number">13</span> Hypothesis Testing</a>
<ul>
<li><a href="types-of-hypothesis-testing.html#types-of-hypothesis-testing" id="toc-types-of-hypothesis-testing"><span class="toc-section-number">13.1</span> Types of hypothesis testing</a></li>
<li><a href="wald-test.html#wald-test" id="toc-wald-test"><span class="toc-section-number">13.2</span> Wald test</a>
<ul>
<li><a href="wald-test.html#multiple-hypothesis" id="toc-multiple-hypothesis"><span class="toc-section-number">13.2.1</span> Multiple Hypothesis</a></li>
<li><a href="wald-test.html#linear-combination" id="toc-linear-combination"><span class="toc-section-number">13.2.2</span> Linear Combination</a></li>
<li><a href="wald-test.html#estimate-difference-in-coefficients" id="toc-estimate-difference-in-coefficients"><span class="toc-section-number">13.2.3</span> Estimate Difference in Coefficients</a></li>
<li><a href="wald-test.html#application-9" id="toc-application-9"><span class="toc-section-number">13.2.4</span> Application</a></li>
<li><a href="wald-test.html#nonlinear-1" id="toc-nonlinear-1"><span class="toc-section-number">13.2.5</span> Nonlinear</a></li>
</ul></li>
<li><a href="the-likelihood-ratio-test.html#the-likelihood-ratio-test" id="toc-the-likelihood-ratio-test"><span class="toc-section-number">13.3</span> The likelihood ratio test</a></li>
<li><a href="lagrange-multiplier-score.html#lagrange-multiplier-score" id="toc-lagrange-multiplier-score"><span class="toc-section-number">13.4</span> Lagrange Multiplier (Score)</a></li>
</ul></li>
<li><a href="prediction-and-estimation.html#prediction-and-estimation" id="toc-prediction-and-estimation"><span class="toc-section-number">14</span> Prediction and Estimation</a></li>
<li><a href="moderation.html#moderation" id="toc-moderation"><span class="toc-section-number">15</span> Moderation</a>
<ul>
<li><a href="emmeans-package.html#emmeans-package" id="toc-emmeans-package"><span class="toc-section-number">15.1</span> emmeans package</a>
<ul>
<li><a href="emmeans-package.html#continuous-by-continuous" id="toc-continuous-by-continuous"><span class="toc-section-number">15.1.1</span> Continuous by continuous</a></li>
<li><a href="emmeans-package.html#continuous-by-categorical" id="toc-continuous-by-categorical"><span class="toc-section-number">15.1.2</span> Continuous by categorical</a></li>
<li><a href="emmeans-package.html#categorical-by-categorical" id="toc-categorical-by-categorical"><span class="toc-section-number">15.1.3</span> Categorical by categorical</a></li>
</ul></li>
<li><a href="probmod-package.html#probmod-package" id="toc-probmod-package"><span class="toc-section-number">15.2</span> probmod package</a></li>
<li><a href="interactions-package.html#interactions-package" id="toc-interactions-package"><span class="toc-section-number">15.3</span> interactions package</a>
<ul>
<li><a href="interactions-package.html#continuous-interaction" id="toc-continuous-interaction"><span class="toc-section-number">15.3.1</span> Continuous interaction</a></li>
<li><a href="interactions-package.html#categorical-interaction" id="toc-categorical-interaction"><span class="toc-section-number">15.3.2</span> Categorical interaction</a></li>
</ul></li>
<li><a href="interactionr-package.html#interactionr-package" id="toc-interactionr-package"><span class="toc-section-number">15.4</span> interactionR package</a></li>
<li><a href="sjplot-package.html#sjplot-package" id="toc-sjplot-package"><span class="toc-section-number">15.5</span> sjPlot package</a></li>
</ul></li>
<li><a href="bootstrap.html#bootstrap" id="toc-bootstrap"><span class="toc-section-number">16</span> Bootstrap</a></li>
<li><a href="#part-iv.-causal-inference" id="toc-part-iv.-causal-inference">(PART*) IV. CAUSAL INFERENCE</a></li>
<li><a href="causal-inference.html#causal-inference" id="toc-causal-inference"><span class="toc-section-number">17</span> Causal Inference</a>
<ul>
<li><a href="intro-to-dag-framework.html#intro-to-dag-framework" id="toc-intro-to-dag-framework"><span class="toc-section-number">17.1</span> Intro to DAG Framework</a></li>
<li><a href="intro-to-po-framework.html#intro-to-po-framework" id="toc-intro-to-po-framework"><span class="toc-section-number">17.2</span> Intro to PO Framework</a>
<ul>
<li><a href="intro-to-po-framework.html#typical-assumptions" id="toc-typical-assumptions"><span class="toc-section-number">17.2.1</span> Typical Assumptions</a></li>
<li><a href="intro-to-po-framework.html#treatment-effect-types" id="toc-treatment-effect-types"><span class="toc-section-number">17.2.2</span> Treatment effect types</a></li>
</ul></li>
<li><a href="controls-under-causal-inference.html#controls-under-causal-inference" id="toc-controls-under-causal-inference"><span class="toc-section-number">17.3</span> Controls under causal inference</a>
<ul>
<li><a href="controls-under-causal-inference.html#good-controls" id="toc-good-controls"><span class="toc-section-number">17.3.1</span> Good Controls</a></li>
<li><a href="controls-under-causal-inference.html#bad-controls" id="toc-bad-controls"><span class="toc-section-number">17.3.2</span> Bad Controls</a></li>
</ul></li>
<li><a href="sensitivity-analysis.html#sensitivity-analysis" id="toc-sensitivity-analysis"><span class="toc-section-number">17.4</span> Sensitivity Analysis</a></li>
</ul></li>
<li><a href="#part-a.-experimental-design" id="toc-part-a.-experimental-design">(PART*) A. EXPERIMENTAL DESIGN</a></li>
<li><a href="experimental-design.html#experimental-design" id="toc-experimental-design"><span class="toc-section-number">18</span> Experimental Design</a>
<ul>
<li><a href="simulation.html#simulation" id="toc-simulation"><span class="toc-section-number">18.1</span> Simulation</a></li>
<li><a href="semi-random-experiment.html#semi-random-experiment" id="toc-semi-random-experiment"><span class="toc-section-number">18.2</span> Semi-random Experiment</a></li>
<li><a href="rerandomization.html#rerandomization" id="toc-rerandomization"><span class="toc-section-number">18.3</span> Rerandomization</a></li>
</ul></li>
<li><a href="sampling.html#sampling" id="toc-sampling"><span class="toc-section-number">19</span> Sampling</a>
<ul>
<li><a href="simple-sampling.html#simple-sampling" id="toc-simple-sampling"><span class="toc-section-number">19.1</span> Simple Sampling</a></li>
<li><a href="stratified-sampling.html#stratified-sampling" id="toc-stratified-sampling"><span class="toc-section-number">19.2</span> Stratified Sampling</a></li>
<li><a href="unequal-probability-sampling.html#unequal-probability-sampling" id="toc-unequal-probability-sampling"><span class="toc-section-number">19.3</span> Unequal Probability Sampling</a></li>
<li><a href="balanced-sampling.html#balanced-sampling" id="toc-balanced-sampling"><span class="toc-section-number">19.4</span> Balanced Sampling</a>
<ul>
<li><a href="balanced-sampling.html#cube" id="toc-cube"><span class="toc-section-number">19.4.1</span> Cube</a></li>
<li><a href="balanced-sampling.html#stratification" id="toc-stratification"><span class="toc-section-number">19.4.2</span> Stratification</a></li>
<li><a href="balanced-sampling.html#cluster-1" id="toc-cluster-1"><span class="toc-section-number">19.4.3</span> Cluster</a></li>
<li><a href="balanced-sampling.html#two-stage" id="toc-two-stage"><span class="toc-section-number">19.4.4</span> Two-stage</a></li>
</ul></li>
</ul></li>
<li><a href="analysis-of-variance-anova.html#analysis-of-variance-anova" id="toc-analysis-of-variance-anova"><span class="toc-section-number">20</span> Analysis of Variance (ANOVA)</a>
<ul>
<li><a href="completely-randomized-design-crd.html#completely-randomized-design-crd" id="toc-completely-randomized-design-crd"><span class="toc-section-number">20.1</span> Completely Randomized Design (CRD)</a>
<ul>
<li><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model" id="toc-single-factor-fixed-effects-model"><span class="toc-section-number">20.1.1</span> Single Factor Fixed Effects Model</a></li>
<li><a href="completely-randomized-design-crd.html#single-factor-random-effects-model" id="toc-single-factor-random-effects-model"><span class="toc-section-number">20.1.2</span> Single Factor Random Effects Model</a></li>
<li><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova" id="toc-two-factor-fixed-effect-anova"><span class="toc-section-number">20.1.3</span> Two Factor Fixed Effect ANOVA</a></li>
<li><a href="completely-randomized-design-crd.html#two-way-random-effects-anova" id="toc-two-way-random-effects-anova"><span class="toc-section-number">20.1.4</span> Two-Way Random Effects ANOVA</a></li>
<li><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova" id="toc-two-way-mixed-effects-anova"><span class="toc-section-number">20.1.5</span> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li><a href="nonparametric-anova.html#nonparametric-anova" id="toc-nonparametric-anova"><span class="toc-section-number">20.2</span> Nonparametric ANOVA</a>
<ul>
<li><a href="nonparametric-anova.html#kruskal-wallis" id="toc-kruskal-wallis"><span class="toc-section-number">20.2.1</span> Kruskal-Wallis</a></li>
<li><a href="nonparametric-anova.html#friedman-test" id="toc-friedman-test"><span class="toc-section-number">20.2.2</span> Friedman Test</a></li>
</ul></li>
<li><a href="sample-size-planning-for-anova.html#sample-size-planning-for-anova" id="toc-sample-size-planning-for-anova"><span class="toc-section-number">20.3</span> Sample Size Planning for ANOVA</a>
<ul>
<li><a href="sample-size-planning-for-anova.html#balanced-designs" id="toc-balanced-designs"><span class="toc-section-number">20.3.1</span> Balanced Designs</a></li>
<li><a href="sample-size-planning-for-anova.html#randomized-block-experiments" id="toc-randomized-block-experiments"><span class="toc-section-number">20.3.2</span> Randomized Block Experiments</a></li>
</ul></li>
<li><a href="randomized-block-designs.html#randomized-block-designs" id="toc-randomized-block-designs"><span class="toc-section-number">20.4</span> Randomized Block Designs</a>
<ul>
<li><a href="randomized-block-designs.html#tukey-test-of-additivity" id="toc-tukey-test-of-additivity"><span class="toc-section-number">20.4.1</span> Tukey Test of Additivity</a></li>
</ul></li>
<li><a href="nested-designs.html#nested-designs" id="toc-nested-designs"><span class="toc-section-number">20.5</span> Nested Designs</a>
<ul>
<li><a href="nested-designs.html#two-factor-nested-designs" id="toc-two-factor-nested-designs"><span class="toc-section-number">20.5.1</span> Two-Factor Nested Designs</a></li>
</ul></li>
<li><a href="single-factor-covariance-model.html#single-factor-covariance-model" id="toc-single-factor-covariance-model"><span class="toc-section-number">20.6</span> Single Factor Covariance Model</a></li>
</ul></li>
<li><a href="multivariate-methods.html#multivariate-methods" id="toc-multivariate-methods"><span class="toc-section-number">21</span> Multivariate Methods</a>
<ul>
<li><a href="multivariate-methods.html#properties-of-mvn" id="toc-properties-of-mvn"><span class="toc-section-number">21.0.1</span> Properties of MVN</a></li>
<li><a href="multivariate-methods.html#mean-vector-inference" id="toc-mean-vector-inference"><span class="toc-section-number">21.0.2</span> Mean Vector Inference</a></li>
<li><a href="multivariate-methods.html#general-hypothesis-testing" id="toc-general-hypothesis-testing"><span class="toc-section-number">21.0.3</span> General Hypothesis Testing</a></li>
<li><a href="manova.html#manova" id="toc-manova"><span class="toc-section-number">21.1</span> MANOVA</a>
<ul>
<li><a href="manova.html#testing-general-hypotheses" id="toc-testing-general-hypotheses"><span class="toc-section-number">21.1.1</span> Testing General Hypotheses</a></li>
<li><a href="manova.html#profile-analysis" id="toc-profile-analysis"><span class="toc-section-number">21.1.2</span> Profile Analysis</a></li>
<li><a href="manova.html#summary-5" id="toc-summary-5"><span class="toc-section-number">21.1.3</span> Summary</a></li>
</ul></li>
<li><a href="principal-components.html#principal-components" id="toc-principal-components"><span class="toc-section-number">21.2</span> Principal Components</a>
<ul>
<li><a href="principal-components.html#population-principal-components" id="toc-population-principal-components"><span class="toc-section-number">21.2.1</span> Population Principal Components</a></li>
<li><a href="principal-components.html#sample-principal-components" id="toc-sample-principal-components"><span class="toc-section-number">21.2.2</span> Sample Principal Components</a></li>
<li><a href="principal-components.html#application-10" id="toc-application-10"><span class="toc-section-number">21.2.3</span> Application</a></li>
</ul></li>
<li><a href="factor-analysis.html#factor-analysis" id="toc-factor-analysis"><span class="toc-section-number">21.3</span> Factor Analysis</a>
<ul>
<li><a href="factor-analysis.html#methods-of-estimation" id="toc-methods-of-estimation"><span class="toc-section-number">21.3.1</span> Methods of Estimation</a></li>
<li><a href="factor-analysis.html#factor-rotation" id="toc-factor-rotation"><span class="toc-section-number">21.3.2</span> Factor Rotation</a></li>
<li><a href="factor-analysis.html#estimation-of-factor-scores" id="toc-estimation-of-factor-scores"><span class="toc-section-number">21.3.3</span> Estimation of Factor Scores</a></li>
<li><a href="factor-analysis.html#model-diagnostic" id="toc-model-diagnostic"><span class="toc-section-number">21.3.4</span> Model Diagnostic</a></li>
<li><a href="factor-analysis.html#application-11" id="toc-application-11"><span class="toc-section-number">21.3.5</span> Application</a></li>
</ul></li>
<li><a href="discriminant-analysis.html#discriminant-analysis" id="toc-discriminant-analysis"><span class="toc-section-number">21.4</span> Discriminant Analysis</a>
<ul>
<li><a href="discriminant-analysis.html#known-populations" id="toc-known-populations"><span class="toc-section-number">21.4.1</span> Known Populations</a></li>
<li><a href="discriminant-analysis.html#probabilities-of-misclassification" id="toc-probabilities-of-misclassification"><span class="toc-section-number">21.4.2</span> Probabilities of Misclassification</a></li>
<li><a href="discriminant-analysis.html#unknown-populations-nonparametric-discrimination" id="toc-unknown-populations-nonparametric-discrimination"><span class="toc-section-number">21.4.3</span> Unknown Populations/ Nonparametric Discrimination</a></li>
<li><a href="discriminant-analysis.html#application-12" id="toc-application-12"><span class="toc-section-number">21.4.4</span> Application</a></li>
</ul></li>
</ul></li>
<li><a href="#part-b.-quasi-experimental-design" id="toc-part-b.-quasi-experimental-design">(PART*) B. QUASI-EXPERIMENTAL DESIGN</a></li>
<li><a href="quasi-experimental.html#quasi-experimental" id="toc-quasi-experimental"><span class="toc-section-number">22</span> Quasi-experimental</a></li>
<li><a href="regression-discontinuity.html#regression-discontinuity" id="toc-regression-discontinuity"><span class="toc-section-number">23</span> Regression Discontinuity</a>
<ul>
<li><a href="specification-checks.html#specification-checks" id="toc-specification-checks"><span class="toc-section-number">23.1</span> Specification Checks</a>
<ul>
<li><a href="specification-checks.html#balance-checks" id="toc-balance-checks"><span class="toc-section-number">23.1.1</span> Balance Checks</a></li>
<li><a href="specification-checks.html#sortingbunchingmanipulation" id="toc-sortingbunchingmanipulation"><span class="toc-section-number">23.1.2</span> Sorting/Bunching/Manipulation</a></li>
<li><a href="specification-checks.html#placebo-tests" id="toc-placebo-tests"><span class="toc-section-number">23.1.3</span> Placebo Tests</a></li>
<li><a href="specification-checks.html#sensitivity-to-bandwidth-choice" id="toc-sensitivity-to-bandwidth-choice"><span class="toc-section-number">23.1.4</span> Sensitivity to Bandwidth Choice</a></li>
<li><a href="specification-checks.html#fuzzy-rd-design" id="toc-fuzzy-rd-design"><span class="toc-section-number">23.1.5</span> Fuzzy RD Design</a></li>
<li><a href="specification-checks.html#regression-kink-design" id="toc-regression-kink-design"><span class="toc-section-number">23.1.6</span> Regression Kink Design</a></li>
<li><a href="specification-checks.html#mutli-cutoff-multi-score-geographic-rd" id="toc-mutli-cutoff-multi-score-geographic-rd"><span class="toc-section-number">23.1.7</span> Mutli-cutoff, Multi-score, geographic RD</a></li>
</ul></li>
<li><a href="steps-for-sharp-rd.html#steps-for-sharp-rd" id="toc-steps-for-sharp-rd"><span class="toc-section-number">23.2</span> Steps for Sharp RD</a></li>
<li><a href="steps-for-fuzzy-rd.html#steps-for-fuzzy-rd" id="toc-steps-for-fuzzy-rd"><span class="toc-section-number">23.3</span> Steps for Fuzzy RD</a></li>
<li><a href="steps-for-rdit-regression-discontinuity-in-time.html#steps-for-rdit-regression-discontinuity-in-time" id="toc-steps-for-rdit-regression-discontinuity-in-time"><span class="toc-section-number">23.4</span> Steps for RDiT (Regression Discontinuity in Time)</a></li>
<li><a href="evaluation-of-an-rd.html#evaluation-of-an-rd" id="toc-evaluation-of-an-rd"><span class="toc-section-number">23.5</span> Evaluation of an RD</a></li>
<li><a href="applications.html#applications" id="toc-applications"><span class="toc-section-number">23.6</span> Applications</a>
<ul>
<li><a href="applications.html#example-1-1" id="toc-example-1-1"><span class="toc-section-number">23.6.1</span> Example 1</a></li>
<li><a href="applications.html#example-2" id="toc-example-2"><span class="toc-section-number">23.6.2</span> Example 2</a></li>
<li><a href="applications.html#example-3" id="toc-example-3"><span class="toc-section-number">23.6.3</span> Example 3</a></li>
<li><a href="applications.html#example-4" id="toc-example-4"><span class="toc-section-number">23.6.4</span> Example 4</a></li>
</ul></li>
</ul></li>
<li><a href="difference-in-differences.html#difference-in-differences" id="toc-difference-in-differences"><span class="toc-section-number">24</span> Difference-in-differences</a>
<ul>
<li><a href="simple-dif-n-dif.html#simple-dif-n-dif" id="toc-simple-dif-n-dif"><span class="toc-section-number">24.1</span> Simple Dif-n-dif</a>
<ul>
<li><a href="simple-dif-n-dif.html#assumptions-2" id="toc-assumptions-2"><span class="toc-section-number">24.1.1</span> Assumptions</a></li>
<li><a href="simple-dif-n-dif.html#examples" id="toc-examples"><span class="toc-section-number">24.1.2</span> Examples</a></li>
</ul></li>
<li><a href="multiple-periods-and-variation-in-treatment-timing.html#multiple-periods-and-variation-in-treatment-timing" id="toc-multiple-periods-and-variation-in-treatment-timing"><span class="toc-section-number">24.2</span> Multiple periods and variation in treatment timing</a>
<ul>
<li><a href="multiple-periods-and-variation-in-treatment-timing.html#staggered-dif-n-dif" id="toc-staggered-dif-n-dif"><span class="toc-section-number">24.2.1</span> Staggered Dif-n-dif</a></li>
</ul></li>
<li><a href="augmented-dif-n-dif.html#augmented-dif-n-dif" id="toc-augmented-dif-n-dif"><span class="toc-section-number">24.3</span> Augmented Dif-n-dif</a></li>
<li><a href="applications-1.html#applications-1" id="toc-applications-1"><span class="toc-section-number">24.4</span> Applications</a>
<ul>
<li><a href="applications-1.html#two-way-fixed-effects" id="toc-two-way-fixed-effects"><span class="toc-section-number">24.4.1</span> Two-way Fixed-effects</a></li>
</ul></li>
</ul></li>
<li><a href="synthetic-control.html#synthetic-control" id="toc-synthetic-control"><span class="toc-section-number">25</span> Synthetic Control</a>
<ul>
<li><a href="applications-2.html#applications-2" id="toc-applications-2"><span class="toc-section-number">25.1</span> Applications</a>
<ul>
<li><a href="applications-2.html#example-1-2" id="toc-example-1-2"><span class="toc-section-number">25.1.1</span> Example 1</a></li>
<li><a href="applications-2.html#example-2-1" id="toc-example-2-1"><span class="toc-section-number">25.1.2</span> Example 2</a></li>
<li><a href="applications-2.html#example-3-1" id="toc-example-3-1"><span class="toc-section-number">25.1.3</span> Example 3</a></li>
<li><a href="applications-2.html#example-4-1" id="toc-example-4-1"><span class="toc-section-number">25.1.4</span> Example 4</a></li>
</ul></li>
<li><a href="synthetic-difference-in-differences.html#synthetic-difference-in-differences" id="toc-synthetic-difference-in-differences"><span class="toc-section-number">25.2</span> Synthetic Difference-in-differences</a></li>
<li><a href="modified-synthetic-control.html#modified-synthetic-control" id="toc-modified-synthetic-control"><span class="toc-section-number">25.3</span> Modified Synthetic Control</a></li>
<li><a href="generalized-synthetic-control.html#generalized-synthetic-control" id="toc-generalized-synthetic-control"><span class="toc-section-number">25.4</span> Generalized Synthetic Control</a></li>
</ul></li>
<li><a href="panel-data-methods.html#panel-data-methods" id="toc-panel-data-methods"><span class="toc-section-number">26</span> Panel Data Methods</a></li>
<li><a href="event-studies.html#event-studies" id="toc-event-studies"><span class="toc-section-number">27</span> Event Studies</a>
<ul>
<li><a href="other-issues.html#other-issues" id="toc-other-issues"><span class="toc-section-number">27.1</span> Other Issues</a>
<ul>
<li><a href="other-issues.html#economic-significance" id="toc-economic-significance"><span class="toc-section-number">27.1.1</span> Economic significance</a></li>
<li><a href="other-issues.html#statistical-power" id="toc-statistical-power"><span class="toc-section-number">27.1.2</span> Statistical Power</a></li>
<li><a href="other-issues.html#testing" id="toc-testing"><span class="toc-section-number">27.1.3</span> Testing</a></li>
<li><a href="other-issues.html#confounders" id="toc-confounders"><span class="toc-section-number">27.1.4</span> Confounders</a></li>
<li><a href="other-issues.html#biases" id="toc-biases"><span class="toc-section-number">27.1.5</span> Biases</a></li>
<li><a href="other-issues.html#long-run-event-studies" id="toc-long-run-event-studies"><span class="toc-section-number">27.1.6</span> Long-run event studies</a></li>
</ul></li>
<li><a href="aggregation.html#aggregation" id="toc-aggregation"><span class="toc-section-number">27.2</span> Aggregation</a>
<ul>
<li><a href="aggregation.html#over-time" id="toc-over-time"><span class="toc-section-number">27.2.1</span> Over Time</a></li>
<li><a href="aggregation.html#across-firms-over-time" id="toc-across-firms-over-time"><span class="toc-section-number">27.2.2</span> Across Firms + Over Time</a></li>
</ul></li>
<li><a href="heterogeneity-in-the-event-effect.html#heterogeneity-in-the-event-effect" id="toc-heterogeneity-in-the-event-effect"><span class="toc-section-number">27.3</span> Heterogeneity in the event effect</a></li>
<li><a href="expected-return-calculation.html#expected-return-calculation" id="toc-expected-return-calculation"><span class="toc-section-number">27.4</span> Expected Return Calculation</a>
<ul>
<li><a href="expected-return-calculation.html#statistical-models" id="toc-statistical-models"><span class="toc-section-number">27.4.1</span> Statistical Models</a></li>
<li><a href="expected-return-calculation.html#economic-model" id="toc-economic-model"><span class="toc-section-number">27.4.2</span> Economic Model</a></li>
</ul></li>
<li><a href="application-13.html#application-13" id="toc-application-13"><span class="toc-section-number">27.5</span> Application</a></li>
</ul></li>
<li><a href="matching-methods.html#matching-methods" id="toc-matching-methods"><span class="toc-section-number">28</span> Matching Methods</a>
<ul>
<li><a href="matching-vs.-regression.html#matching-vs.-regression" id="toc-matching-vs.-regression"><span class="toc-section-number">28.1</span> Matching vs. Regression</a></li>
<li><a href="weighting-vs.-balancing.html#weighting-vs.-balancing" id="toc-weighting-vs.-balancing"><span class="toc-section-number">28.2</span> Weighting vs. Balancing</a></li>
<li><a href="matchit.html#matchit" id="toc-matchit"><span class="toc-section-number">28.3</span> MatchIt</a></li>
<li><a href="matchingfrontier.html#matchingfrontier" id="toc-matchingfrontier"><span class="toc-section-number">28.4</span> MatchingFrontier</a></li>
<li><a href="propensity-scores.html#propensity-scores" id="toc-propensity-scores"><span class="toc-section-number">28.5</span> Propensity Scores</a></li>
<li><a href="mahalanobis-distance.html#mahalanobis-distance" id="toc-mahalanobis-distance"><span class="toc-section-number">28.6</span> Mahalanobis Distance</a></li>
<li><a href="coarsened-exact-matching.html#coarsened-exact-matching" id="toc-coarsened-exact-matching"><span class="toc-section-number">28.7</span> Coarsened Exact Matching</a></li>
<li><a href="genetic-matching.html#genetic-matching" id="toc-genetic-matching"><span class="toc-section-number">28.8</span> Genetic Matching</a></li>
<li><a href="matching-for-time-series-cross-section-data.html#matching-for-time-series-cross-section-data" id="toc-matching-for-time-series-cross-section-data"><span class="toc-section-number">28.9</span> Matching for time series-cross-section data</a></li>
</ul></li>
<li><a href="interrupted-time-series.html#interrupted-time-series" id="toc-interrupted-time-series"><span class="toc-section-number">29</span> Interrupted Time Series</a></li>
<li><a href="#part-c.-other-concerns" id="toc-part-c.-other-concerns">(PART*) C. OTHER CONCERNS</a></li>
<li><a href="doubly-robust-estimator.html#doubly-robust-estimator" id="toc-doubly-robust-estimator"><span class="toc-section-number">30</span> Doubly Robust Estimator</a>
<ul>
<li><a href="regression-adjustments.html#regression-adjustments" id="toc-regression-adjustments"><span class="toc-section-number">30.1</span> Regression Adjustments</a></li>
<li><a href="inverse-propensity-weighting.html#inverse-propensity-weighting" id="toc-inverse-propensity-weighting"><span class="toc-section-number">30.2</span> Inverse Propensity Weighting</a></li>
<li><a href="augmented-inverse-propensity-weighting.html#augmented-inverse-propensity-weighting" id="toc-augmented-inverse-propensity-weighting"><span class="toc-section-number">30.3</span> Augmented Inverse Propensity Weighting</a></li>
</ul></li>
<li><a href="endogeneity.html#endogeneity" id="toc-endogeneity"><span class="toc-section-number">31</span> Endogeneity</a>
<ul>
<li><a href="measurement-error.html#measurement-error" id="toc-measurement-error"><span class="toc-section-number">31.1</span> Measurement Error</a>
<ul>
<li><a href="measurement-error.html#classical-measurement-errors" id="toc-classical-measurement-errors"><span class="toc-section-number">31.1.1</span> Classical Measurement Errors</a></li>
<li><a href="measurement-error.html#non-classical-measurement-errors" id="toc-non-classical-measurement-errors"><span class="toc-section-number">31.1.2</span> Non-classical Measurement Errors</a></li>
<li><a href="measurement-error.html#solution-to-measurement-errors" id="toc-solution-to-measurement-errors"><span class="toc-section-number">31.1.3</span> Solution to Measurement Errors</a></li>
</ul></li>
<li><a href="simultaneity.html#simultaneity" id="toc-simultaneity"><span class="toc-section-number">31.2</span> Simultaneity</a></li>
<li><a href="endogenous-treatment.html#endogenous-treatment" id="toc-endogenous-treatment"><span class="toc-section-number">31.3</span> Endogenous Treatment</a>
<ul>
<li><a href="endogenous-treatment.html#instrumental-variable" id="toc-instrumental-variable"><span class="toc-section-number">31.3.1</span> Instrumental Variable</a></li>
<li><a href="endogenous-treatment.html#internal-instrumental-variable" id="toc-internal-instrumental-variable"><span class="toc-section-number">31.3.2</span> Internal instrumental variable</a></li>
<li><a href="endogenous-treatment.html#proxy-variables" id="toc-proxy-variables"><span class="toc-section-number">31.3.3</span> Proxy Variables</a></li>
</ul></li>
<li><a href="endogenous-sample-selection.html#endogenous-sample-selection" id="toc-endogenous-sample-selection"><span class="toc-section-number">31.4</span> Endogenous Sample Selection</a>
<ul>
<li><a href="endogenous-sample-selection.html#tobit-2" id="toc-tobit-2"><span class="toc-section-number">31.4.1</span> Tobit-2</a></li>
<li><a href="endogenous-sample-selection.html#tobit-5" id="toc-tobit-5"><span class="toc-section-number">31.4.2</span> Tobit-5</a></li>
</ul></li>
</ul></li>
<li><a href="mediation.html#mediation" id="toc-mediation"><span class="toc-section-number">32</span> Mediation</a>
<ul>
<li><a href="traditional.html#traditional" id="toc-traditional"><span class="toc-section-number">32.1</span> Traditional</a>
<ul>
<li><a href="traditional.html#example-1-mediation-traditional" id="toc-example-1-mediation-traditional"><span class="toc-section-number">32.1.1</span> Example 1</a></li>
</ul></li>
<li><a href="model-based-causal-mediation-analysis.html#model-based-causal-mediation-analysis" id="toc-model-based-causal-mediation-analysis"><span class="toc-section-number">32.2</span> Model-based causal mediation analysis</a></li>
</ul></li>
<li><a href="directed-acyclic-graph.html#directed-acyclic-graph" id="toc-directed-acyclic-graph"><span class="toc-section-number">33</span> Directed Acyclic Graph</a></li>
<li><a href="#part-v.-miscellaneous" id="toc-part-v.-miscellaneous">(PART*) V. MISCELLANEOUS</a></li>
<li><a href="report.html#report" id="toc-report"><span class="toc-section-number">34</span> Report</a>
<ul>
<li><a href="one-summary-table.html#one-summary-table" id="toc-one-summary-table"><span class="toc-section-number">34.1</span> One summary table</a></li>
<li><a href="model-comparison.html#model-comparison" id="toc-model-comparison"><span class="toc-section-number">34.2</span> Model Comparison</a></li>
<li><a href="changes-in-an-estimate.html#changes-in-an-estimate" id="toc-changes-in-an-estimate"><span class="toc-section-number">34.3</span> Changes in an estimate</a></li>
</ul></li>
<li><a href="exploratory-data-analysis.html#exploratory-data-analysis" id="toc-exploratory-data-analysis"><span class="toc-section-number">35</span> Exploratory Data Analysis</a></li>
<li><a href="sensitivity-analysis-robustness-check.html#sensitivity-analysis-robustness-check" id="toc-sensitivity-analysis-robustness-check"><span class="toc-section-number">36</span> Sensitivity Analysis/ Robustness Check</a>
<ul>
<li><a href="specification-curve.html#specification-curve" id="toc-specification-curve"><span class="toc-section-number">36.1</span> Specification curve</a>
<ul>
<li><a href="specification-curve.html#starbility" id="toc-starbility"><span class="toc-section-number">36.1.1</span> starbility</a></li>
<li><a href="specification-curve.html#rdfanalysis" id="toc-rdfanalysis"><span class="toc-section-number">36.1.2</span> rdfanalysis</a></li>
</ul></li>
<li><a href="coefficient-stability.html#coefficient-stability" id="toc-coefficient-stability"><span class="toc-section-number">36.2</span> Coefficient stability</a></li>
</ul></li>
<li><a href="#appendix-appendix" id="toc-appendix-appendix">(APPENDIX) APPENDIX</a></li>
<li><a href="appendix.html#appendix" id="toc-appendix"><span class="toc-section-number">37</span> Appendix</a>
<ul>
<li><a href="git.html#git" id="toc-git"><span class="toc-section-number">37.1</span> Git</a></li>
<li><a href="short-cut.html#short-cut" id="toc-short-cut"><span class="toc-section-number">37.2</span> Short-cut</a></li>
<li><a href="function-short-cut.html#function-short-cut" id="toc-function-short-cut"><span class="toc-section-number">37.3</span> Function short-cut</a></li>
<li><a href="citation.html#citation" id="toc-citation"><span class="toc-section-number">37.4</span> Citation</a></li>
<li><a href="install-all-necessary-packageslibaries-on-your-local-machine.html#install-all-necessary-packageslibaries-on-your-local-machine" id="toc-install-all-necessary-packageslibaries-on-your-local-machine"><span class="toc-section-number">37.5</span> Install all necessary packages/libaries on your local machine</a></li>
</ul></li>
<li><a href="bookdown-cheat-sheet.html#bookdown-cheat-sheet" id="toc-bookdown-cheat-sheet"><span class="toc-section-number">38</span> Bookdown cheat sheet</a>
<ul>
<li><a href="operation.html#operation" id="toc-operation"><span class="toc-section-number">38.1</span> Operation</a></li>
<li><a href="math-expresssion-syntax.html#math-expresssion-syntax" id="toc-math-expresssion-syntax"><span class="toc-section-number">38.2</span> Math Expresssion/ Syntax</a>
<ul>
<li><a href="math-expresssion-syntax.html#statistics-notation" id="toc-statistics-notation"><span class="toc-section-number">38.2.1</span> Statistics Notation</a></li>
</ul></li>
<li><a href="table.html#table" id="toc-table"><span class="toc-section-number">38.3</span> Table</a></li>
</ul></li>
<li><a href="references.html#references" id="toc-references">References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="non-linear-least-squares" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Non-linear Least Squares</h2>
<ul>
<li>The LS estimate of <span class="math inline">\(\theta\)</span>, <span class="math inline">\(\hat{\theta}\)</span> is the set of parameters that minimizes the residual sum of squares:<br />
<span class="math display">\[
S(\hat{\theta}) = SSE(\hat{\theta}) = \sum_{i=1}^{n}\{Y_i - f(\mathbf{x_i};\hat{\theta})\}^2
\]</span></li>
<li>to obtain the solution, we can consider the partial derivatives of <span class="math inline">\(S(\theta)\)</span> with respect to each <span class="math inline">\(\theta_j\)</span> and set them to 0, which gives a system of p equations. Each normal equation is <span class="math display">\[
\frac{\partial S(\theta)}{\partial \theta_j} = -2\sum_{i=1}^{n}\{Y_i -f(\mathbf{x}_i;\theta)\}[\frac{\partial(\mathbf{x}_i;\theta)}{\partial \theta_j}] = 0
\]</span></li>
<li>but we can’t obtain a solution directly/analytically for this equation.</li>
</ul>
<p><strong>Numerical Solutions</strong></p>
<ul>
<li><p>Grid search</p>
<ul>
<li>A “grid” of possible parameter values and see which one minimize the residual sum of squares.</li>
<li>finer grid = greater accuracy</li>
<li>could be inefficient, and hard when p is large.</li>
</ul></li>
<li><p>Gauss-Newton Algorithm</p>
<ul>
<li>we have an initial estimate of <span class="math inline">\(\theta\)</span> denoted as <span class="math inline">\(\hat{\theta}^{(0)}\)</span></li>
<li>use a Taylor expansions of <span class="math inline">\(f(\mathbf{x}_i;\theta)\)</span> as a function of <span class="math inline">\(\theta\)</span> about the point <span class="math inline">\(\hat{\theta}^{(0)}\)</span></li>
</ul></li>
</ul>
<p><span class="math display">\[
\begin{aligned}
Y_i &amp;= f(x_i;\theta) + \epsilon_i \\
&amp;= f(x_i;\theta) + \sum_{j=1}^{p}\{\frac{\partial f(x_i;\theta)}{\partial \theta_j}\}_{\theta = \hat{\theta}^{(0)}} (\theta_j - \hat{\theta}^{(0)}) + \text{remainder} + \epsilon_i
\end{aligned}
\]</span></p>
<p>Equivalently,</p>
<p>In matrix notation,</p>
<p><span class="math display">\[
\mathbf{Y} =
\left[
\begin{array}
{c}
Y_1 \\
. \\
Y_n
\end{array}
\right]
\]</span></p>
<p><span class="math display">\[
\mathbf{f}(\hat{\theta}^{(0)}) =
\left[
\begin{array}
{c}
f(\mathbf{x_1,\hat{\theta}}^{(0)}) \\
. \\
f(\mathbf{x_n,\hat{\theta}}^{(0)})
\end{array}
\right]
\]</span></p>
<p><span class="math display">\[
\mathbf{\epsilon} =
\left[
\begin{array}
{c}
\epsilon_1 \\
. \\
\epsilon_n
\end{array}
\right]
\]</span></p>
<p><span class="math display">\[
\mathbf{F}(\hat{\theta}^{(0)}) =
\left[
\begin{array}
{ccc}
\frac{\partial f(x_1,\mathbf{\theta})}{\partial \theta_1} &amp; ... &amp; \frac{\partial f(x_1,\mathbf{\theta})}{\partial \theta_p}\\
. &amp; . &amp; . \\
\frac{\partial f(x_n,\mathbf{\theta})}{\partial \theta_1} &amp; ... &amp; \frac{\partial f(x_n,\mathbf{\theta})}{\partial \theta_p}
\end{array} \right]_{\theta = \hat{\theta}^{(0)}}
\]</span></p>
<p>Hence,</p>
<p><span class="math display">\[
\mathbf{Y} = \mathbf{f}(\hat{\theta}^{(0)}) + \mathbf{F}(\hat{\theta}^{(0)})(\theta - \hat{\theta}^{(0)}) + \epsilon + \text{remainder}
\]</span></p>
<p>where we assume that the remainder is small and the error term is only assumed to be iid with mean 0 and variance <span class="math inline">\(\sigma^2\)</span>.</p>
<p>We can rewrite the above equation as</p>
<p><span class="math display">\[
\mathbf{Y} - \mathbf{f}(\hat{\theta}^{(0)}) \approx \mathbf{F}(\hat{\theta}^{(0)})(\theta - \hat{\theta}^{(0)}) + \epsilon
\]</span></p>
<p>where it is in the form of linear model. After we solve for <span class="math inline">\((\theta - \hat{\theta}^{(0)})\)</span> and let it equal to <span class="math inline">\(\hat{\delta}^{(1)}\)</span><br />
Then we new estimate is given by adding the Gauss increment adjustment to the initial estimate <span class="math inline">\(\hat{\theta}^{(1)} = \hat{\theta}^{(0)} + \hat{\delta}^{(1)}\)</span><br />
We can repeat this process.</p>
<p>Gauss-Newton Algorithm Steps:</p>
<ol style="list-style-type: decimal">
<li>initial estimate <span class="math inline">\(\hat{\theta}^{(0)}\)</span>, set j = 0</li>
<li>Taylor series expansion and calculate <span class="math inline">\(\mathbf{f}(\hat{\theta}^{(j)})\)</span> and <span class="math inline">\(\mathbf{F}(\hat{\theta}^{(j)})\)</span></li>
<li>Use OLS to get <span class="math inline">\(\hat{\delta}^{(j+1)}\)</span></li>
<li>get the new estimate <span class="math inline">\(\hat{\theta}^{(j+1)}\)</span>, return to step 2</li>
<li>continue until “convergence”</li>
<li>With the final parameter estimate <span class="math inline">\(\hat{\theta}\)</span>, we can estimate <span class="math inline">\(\sigma^2\)</span> if <span class="math inline">\(\epsilon \sim (\mathbf{0}, \sigma^2 \mathbf{I})\)</span> by</li>
</ol>
<p><span class="math display">\[
\hat{\sigma}^2= \frac{1}{n-p}(\mathbf{Y}-\mathbf{f}(x;\hat{\theta}))&#39;(\mathbf{Y}-\mathbf{f}(x;\hat{\theta}))
\]</span></p>
<p><br></p>
<p><strong>Criteria for convergence</strong></p>
<ol style="list-style-type: decimal">
<li>Minor change in the objective function (SSE = residual sum of squares)<br />
<span class="math display">\[
\frac{|SSE(\hat{\theta}^{(j+1)})-SSE(\hat{\theta}^{(j)})|}{SSE(\hat{\theta}^{(j)})} &lt; \gamma_1
\]</span></li>
<li>Minor change in the parameter estimates<br />
<span class="math display">\[
|\hat{\theta}^{(j+1)}-\hat{\theta}^{(j)}| &lt; \gamma_2
\]</span></li>
<li>“residual projection” criterion of <span class="citation">(<a href="#ref-Bates_1981" role="doc-biblioref">Bates and Watts 1981</a>)</span></li>
</ol>
<div id="alternative-of-gauss-newton-algorithm" class="section level3" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Alternative of Gauss-Newton Algorithm</h3>
<div id="gauss-newton-algorithm" class="section level4" number="6.2.1.1">
<h4><span class="header-section-number">6.2.1.1</span> Gauss-Newton Algorithm</h4>
<p>Normal equations:</p>
<p><span class="math display">\[
\frac{\partial SSE(\theta)}{\partial \theta} = 2\mathbf{F}(\theta)&#39;[\mathbf{Y}-\mathbf{f}(\theta)]
\]</span></p>
<p><span class="math display">\[
\begin{aligned}
\hat{\theta}^{(j+1)} &amp;= \hat{\theta}^{(j)} + \hat{\delta}^{(j+1)} \\
&amp;= \hat{\theta}^{(j)} + [\mathbf{F}((\hat{\theta})^{(j)})&#39;\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\mathbf{F}(\hat{\theta})^{(j)} \\
&amp;= \hat{\theta}^{(j)} - \frac{1}{2}[\mathbf{F}(\hat{\theta}^{(j)})&#39;\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\frac{\partial SSE(\hat{\theta}^{(j)})}{\partial \theta}
\end{aligned}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\frac{\partial SSE(\hat{\theta}^{(j)})}{\partial \theta}\)</span> is a gradient vecotr (points in the direction in which the SSE increases most rapidly). This path is known as steepest ascent.<br />
</li>
<li><span class="math inline">\([\mathbf{F}(\hat{\theta}^{(j)})&#39;\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\)</span> indicates how far to move<br />
</li>
<li><span class="math inline">\(-1/2\)</span>: indicator of the direction of steepest descent.</li>
</ul>
</div>
<div id="modified-gauss-newton-algorithm" class="section level4" number="6.2.1.2">
<h4><span class="header-section-number">6.2.1.2</span> Modified Gauss-Newton Algorithm</h4>
<p>To avoid overstepping (the local min), we can use the modified Gauss-Newton Algorithm. We define a new proposal for <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} + \alpha_j \hat{\delta}^{(j+1)}, 0 &lt; \alpha_j &lt; 1
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\alpha_j\)</span> (called the “learning rate”): is used to modify the step length.</li>
</ul>
<p>We could also have <span class="math inline">\(\alpha *1/2\)</span>, but typically it is assumed to be absorbed into the learning rate.</p>
<p>A way to choose <span class="math inline">\(\alpha_j\)</span>, we can use <strong>step halving</strong></p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} + \frac{1}{2^k}\hat{\delta}^{(j+1)}
\]</span></p>
<p>where</p>
<ul>
<li>k is the smallest non-negative integer such that<br />
<span class="math display">\[
SSE(\hat{\theta}^{(j)}+\frac{1}{2^k}\hat{\delta}^{(j+1)}) &lt; SSE(\hat{\theta}^{(j)})
\]</span> which means we try <span class="math inline">\(\hat{\delta}^{(j+1)}\)</span>, then <span class="math inline">\(\hat{\delta}^{(j+1)}/2\)</span>, <span class="math inline">\(\hat{\delta}^{(j+1)}/4\)</span>, etc.</li>
</ul>
<p>The most general form of the convergence algorithm is</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j \mathbf{A}_j \frac{\partial Q(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>where</p>
<ul>
<li><span class="math inline">\(\mathbf{A}_j\)</span> is a positive definite matrix<br />
</li>
<li><span class="math inline">\(\alpha_j\)</span> is the learning rate<br />
</li>
<li><span class="math inline">\(\frac{\partial Q(\hat{\theta}^{(j)})}{\partial \theta}\)</span>is the gradient based on some objective function Q (a function of <span class="math inline">\(\theta\)</span>), which is typically the SSE in nonlinear regression applications (e.g., cross-entropy for classification).</li>
</ul>
<p>Refer back to the <strong>Modified Gauss-Newton Algorithm</strong>, we can see it is in this form</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} =\hat{\theta}^{(j)} - \alpha_j[\mathbf{F}(\hat{\theta}^{(j)})&#39;\mathbf{F}(\hat{\theta}^{(j)})]^{-1}\frac{\partial SSE(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>where Q = SSE, <span class="math inline">\([\mathbf{F}(\hat{\theta}^{(j)})&#39;\mathbf{F}(\hat{\theta}^{(j)})]^{-1} = \mathbf{A}\)</span></p>
</div>
<div id="steepest-descent" class="section level4" number="6.2.1.3">
<h4><span class="header-section-number">6.2.1.3</span> Steepest Descent</h4>
<p>(also known just “gradient descent”)</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j \mathbf{I}_{p \times p}\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<ul>
<li>slow to converge, moves rapidly initially.<br />
</li>
<li>could be use for starting values</li>
</ul>
</div>
<div id="levenberg--marquardt" class="section level4" number="6.2.1.4">
<h4><span class="header-section-number">6.2.1.4</span> Levenberg -Marquardt</h4>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j [\mathbf{F}(\hat{\theta}^{(j)})&#39;\mathbf{F}(\hat{\theta}^{(j)})+ \tau \mathbf{I}_{p \times p}]\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>which is a compromise between the <a href="non-linear-least-squares.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a> and the <a href="non-linear-least-squares.html#steepest-descent">Steepest Descent</a>.</p>
<ul>
<li>best when <span class="math inline">\(\mathbf{F}(\hat{\theta}^{(j)})&#39;\mathbf{F}(\hat{\theta}^{(j)})\)</span> is nearly singular (<span class="math inline">\(\mathbf{F}(\hat{\theta}^{(j)})\)</span> isn’t of full rank)<br />
</li>
<li>similar to ridge regression<br />
</li>
<li>If <span class="math inline">\(SSE(\hat{\theta}^{(j+1)}) &lt; SSE(\hat{\theta}^{(j)})\)</span>, then <span class="math inline">\(\tau= \tau/10\)</span> for the next iteration. Otherwise, <span class="math inline">\(\tau = 10 \tau\)</span></li>
</ul>
</div>
<div id="newton-raphson" class="section level4" number="6.2.1.5">
<h4><span class="header-section-number">6.2.1.5</span> Newton-Raphson</h4>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j [\frac{\partial^2Q(\hat{\theta}^{(j)})}{\partial \theta \partial \theta&#39;}]^{-1}\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>The <strong>Hessian matrix</strong> can be rewritten as:</p>
<p><span class="math display">\[
\frac{ \partial^2Q(\hat{ \theta}^{(j)})}{ \partial \theta \partial \theta&#39;} = 2 \mathbf{F}((\hat{ \theta})^{(j)})&#39; \mathbf{F} ( \hat{\theta}^{(j)}) - 2\sum_{i=1}^{n} [Y_i - f(x_i;\theta)] \frac{\partial^2f(x_i;\theta)}{\partial \theta \partial \theta&#39;}
\]</span></p>
<p>which contains the same term that <a href="non-linear-least-squares.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a>, combined with one containing the second partial derivatives of f(). (methods that require the second derivatives of the objective function are known as “second-order methods”.)<br />
However, the last term <span class="math inline">\(\frac{\partial^2f(x_i;\theta)}{\partial \theta \partial \theta&#39;}\)</span> can sometimes be nonsingular.</p>
</div>
<div id="quasi-newton" class="section level4" number="6.2.1.6">
<h4><span class="header-section-number">6.2.1.6</span> Quasi-Newton</h4>
<p>update <span class="math inline">\(\theta\)</span> according to</p>
<p><span class="math display">\[
\hat{\theta}^{(j+1)} = \hat{\theta}^{(j)} - \alpha_j \mathbf{H}_j^{-1}\frac{\partial \mathbf{Q}(\hat{\theta}^{(j)})}{\partial \theta}
\]</span></p>
<p>where <span class="math inline">\(H_j\)</span> is a symmetric positive definite approximation to the Hessian, which gets closer as <span class="math inline">\(j \to \infty\)</span>.</p>
<ul>
<li><span class="math inline">\(\mathbf{H}_j\)</span> is computed iteratively<br />
</li>
<li>AMong first-order methods(where only first derivatives are required), this method performs best.</li>
</ul>
</div>
<div id="derivative-free-methods" class="section level4" number="6.2.1.7">
<h4><span class="header-section-number">6.2.1.7</span> Derivative Free Methods</h4>
<ul>
<li><strong>secant Method</strong>: like <a href="non-linear-least-squares.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a>, but calculates the derivatives numerically from past iterations.<br />
</li>
<li><strong>Simplex Methods</strong><br />
</li>
<li><strong>Genetic Algorithm</strong><br />
</li>
<li><strong>Differential Evolution Algorithms</strong><br />
</li>
<li><strong>Particle Swarm Optimization</strong><br />
</li>
<li><strong>Ant Colony Optimization</strong></li>
</ul>
</div>
</div>
<div id="practical-considerations" class="section level3" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Practical Considerations</h3>
<p>To converge, algorithm need good initial estimates.</p>
<ul>
<li><p>Starting values:</p>
<ul>
<li>Prior or theoretical info<br />
</li>
<li>A grid search or a graph of <span class="math inline">\(SSE(\theta)\)</span><br />
</li>
<li>could also use OLS to get starting values.<br />
</li>
<li>Model interpretation: if you have some idea regarding the form of the objective function, then you can try to guess the initial value.<br />
</li>
<li>Expected Value Parameterization<br />
</li>
</ul></li>
<li><p>Constrained Parameters: (constraints on parameters like <span class="math inline">\(\theta_i&gt;a,a&lt; \theta_i &lt;b\)</span>)</p>
<ul>
<li>fit the model first to see if the converged parameter estimates satisfy the constraints.</li>
<li>if they dont’ satisfy, then try re-parameterizing</li>
</ul></li>
</ul>
<div id="failure-to-converge" class="section level4" number="6.2.2.1">
<h4><span class="header-section-number">6.2.2.1</span> Failure to converge</h4>
<ul>
<li><span class="math inline">\(SSE(\theta)\)</span> may be “flat” in a neighborhood of the minimum.<br />
</li>
<li>You can try different or “better” starting values.<br />
</li>
<li>Might suggest the model is too complex for the data, might consider simpler model.</li>
</ul>
</div>
<div id="convergence-to-a-local-minimum" class="section level4" number="6.2.2.2">
<h4><span class="header-section-number">6.2.2.2</span> Convergence to a Local Minimum</h4>
<ul>
<li>Linear least squares has the property that <span class="math inline">\(SSE(\theta) = \mathbf{(Y-X\beta)&#39;(Y-X\beta)}\)</span>, which is quadratic and has a unique minimum (or maximum).</li>
<li>Nonlinear east squares need not have a unique minimum</li>
<li>Using different starting values can help</li>
<li>If the dimension of <span class="math inline">\(\theta\)</span> is low, graph <span class="math inline">\(SSE(\theta)\)</span> as a function of <span class="math inline">\(\theta_i\)</span></li>
<li>Different algorithm can help (e.g., genetic algorithm, particle swarm)</li>
</ul>
<p>To converge, algorithms need good initial estimates.</p>
<ul>
<li><p>Starting values:</p>
<ul>
<li>prior or theoretical info</li>
<li>A grid search or a graph</li>
<li>OLS estimates as starting values</li>
<li>Model interpretation</li>
<li>Expected Value Parameterization</li>
</ul></li>
<li><p>Constrained Parameters:</p>
<ul>
<li>try the model without the constraints first.</li>
<li>If the resulted parameter estimates does not satisfy the constraint, try re-parameterizing</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb105"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb105-1"><a href="non-linear-least-squares.html#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Grid search</span></span>
<span id="cb105-2"><a href="non-linear-least-squares.html#cb105-2" aria-hidden="true" tabindex="-1"></a><span class="co">#choose grid of a and b values</span></span>
<span id="cb105-3"><a href="non-linear-least-squares.html#cb105-3" aria-hidden="true" tabindex="-1"></a>aseq <span class="ot">=</span> <span class="fu">seq</span>(<span class="dv">10</span>,<span class="dv">18</span>,.<span class="dv">2</span>)</span>
<span id="cb105-4"><a href="non-linear-least-squares.html#cb105-4" aria-hidden="true" tabindex="-1"></a>bseq <span class="ot">=</span> <span class="fu">seq</span>(.<span class="dv">001</span>,.<span class="dv">075</span>,.<span class="dv">001</span>)</span>
<span id="cb105-5"><a href="non-linear-least-squares.html#cb105-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-6"><a href="non-linear-least-squares.html#cb105-6" aria-hidden="true" tabindex="-1"></a>na <span class="ot">=</span> <span class="fu">length</span>(aseq)</span>
<span id="cb105-7"><a href="non-linear-least-squares.html#cb105-7" aria-hidden="true" tabindex="-1"></a>nb <span class="ot">=</span> <span class="fu">length</span>(bseq)</span>
<span id="cb105-8"><a href="non-linear-least-squares.html#cb105-8" aria-hidden="true" tabindex="-1"></a>SSout <span class="ot">=</span> <span class="fu">matrix</span>(<span class="dv">0</span>,na<span class="sc">*</span>nb,<span class="dv">3</span>) <span class="co">#matrix to save output</span></span>
<span id="cb105-9"><a href="non-linear-least-squares.html#cb105-9" aria-hidden="true" tabindex="-1"></a>cnt <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb105-10"><a href="non-linear-least-squares.html#cb105-10" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>na){</span>
<span id="cb105-11"><a href="non-linear-least-squares.html#cb105-11" aria-hidden="true" tabindex="-1"></a>   <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>nb){</span>
<span id="cb105-12"><a href="non-linear-least-squares.html#cb105-12" aria-hidden="true" tabindex="-1"></a>      cnt <span class="ot">=</span> cnt<span class="sc">+</span><span class="dv">1</span></span>
<span id="cb105-13"><a href="non-linear-least-squares.html#cb105-13" aria-hidden="true" tabindex="-1"></a>      ypred <span class="ot">=</span> <span class="fu">mod</span>(aseq[k],bseq[j],x) <span class="co">#evaluate model w/ these parms</span></span>
<span id="cb105-14"><a href="non-linear-least-squares.html#cb105-14" aria-hidden="true" tabindex="-1"></a>      ss <span class="ot">=</span> <span class="fu">sum</span>((y<span class="sc">-</span>ypred)<span class="sc">^</span><span class="dv">2</span>)  <span class="co">#this is our SSE objective function</span></span>
<span id="cb105-15"><a href="non-linear-least-squares.html#cb105-15" aria-hidden="true" tabindex="-1"></a>      <span class="co">#save values of a, b, and SSE</span></span>
<span id="cb105-16"><a href="non-linear-least-squares.html#cb105-16" aria-hidden="true" tabindex="-1"></a>      SSout[cnt,<span class="dv">1</span>]<span class="ot">=</span>aseq[k]</span>
<span id="cb105-17"><a href="non-linear-least-squares.html#cb105-17" aria-hidden="true" tabindex="-1"></a>      SSout[cnt,<span class="dv">2</span>]<span class="ot">=</span>bseq[j]</span>
<span id="cb105-18"><a href="non-linear-least-squares.html#cb105-18" aria-hidden="true" tabindex="-1"></a>      SSout[cnt,<span class="dv">3</span>]<span class="ot">=</span>ss</span>
<span id="cb105-19"><a href="non-linear-least-squares.html#cb105-19" aria-hidden="true" tabindex="-1"></a>   }</span>
<span id="cb105-20"><a href="non-linear-least-squares.html#cb105-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb105-21"><a href="non-linear-least-squares.html#cb105-21" aria-hidden="true" tabindex="-1"></a><span class="co">#find minimum SSE and associated a,b values</span></span>
<span id="cb105-22"><a href="non-linear-least-squares.html#cb105-22" aria-hidden="true" tabindex="-1"></a>mn_indx <span class="ot">=</span> <span class="fu">which.min</span>(SSout[,<span class="dv">3</span>])</span>
<span id="cb105-23"><a href="non-linear-least-squares.html#cb105-23" aria-hidden="true" tabindex="-1"></a>astrt <span class="ot">=</span> SSout[mn_indx,<span class="dv">1</span>]</span>
<span id="cb105-24"><a href="non-linear-least-squares.html#cb105-24" aria-hidden="true" tabindex="-1"></a>bstrt <span class="ot">=</span> SSout[mn_indx,<span class="dv">2</span>]</span>
<span id="cb105-25"><a href="non-linear-least-squares.html#cb105-25" aria-hidden="true" tabindex="-1"></a><span class="co">#now, run nls function with these starting values</span></span>
<span id="cb105-26"><a href="non-linear-least-squares.html#cb105-26" aria-hidden="true" tabindex="-1"></a>nlin_modG<span class="ot">=</span><span class="fu">nls</span>(y<span class="sc">~</span><span class="fu">mod</span>(a,b,x),<span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span>astrt,<span class="at">b=</span>bstrt)) </span>
<span id="cb105-27"><a href="non-linear-least-squares.html#cb105-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-28"><a href="non-linear-least-squares.html#cb105-28" aria-hidden="true" tabindex="-1"></a>nlin_modG</span>
<span id="cb105-29"><a href="non-linear-least-squares.html#cb105-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Nonlinear regression model</span></span>
<span id="cb105-30"><a href="non-linear-least-squares.html#cb105-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   model: y ~ mod(a, b, x)</span></span>
<span id="cb105-31"><a href="non-linear-least-squares.html#cb105-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    data: parent.frame()</span></span>
<span id="cb105-32"><a href="non-linear-least-squares.html#cb105-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        a        b </span></span>
<span id="cb105-33"><a href="non-linear-least-squares.html#cb105-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 13.60391  0.01911 </span></span>
<span id="cb105-34"><a href="non-linear-least-squares.html#cb105-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  residual sum-of-squares: 235.5</span></span>
<span id="cb105-35"><a href="non-linear-least-squares.html#cb105-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb105-36"><a href="non-linear-least-squares.html#cb105-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 3 </span></span>
<span id="cb105-37"><a href="non-linear-least-squares.html#cb105-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 2.293e-07</span></span>
<span id="cb105-38"><a href="non-linear-least-squares.html#cb105-38" aria-hidden="true" tabindex="-1"></a><span class="co"># Note, the package `nls_multstart` will allow you to do a grid search without programming your own loop</span></span></code></pre></div>
<p>For prediction interval</p>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="non-linear-least-squares.html#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plotFit</span>(</span>
<span id="cb106-2"><a href="non-linear-least-squares.html#cb106-2" aria-hidden="true" tabindex="-1"></a>  nlin_modG,</span>
<span id="cb106-3"><a href="non-linear-least-squares.html#cb106-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">interval =</span> <span class="st">&quot;both&quot;</span>,</span>
<span id="cb106-4"><a href="non-linear-least-squares.html#cb106-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb106-5"><a href="non-linear-least-squares.html#cb106-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">shade =</span> <span class="cn">TRUE</span>,</span>
<span id="cb106-6"><a href="non-linear-least-squares.html#cb106-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.conf =</span> <span class="st">&quot;skyblue4&quot;</span>,</span>
<span id="cb106-7"><a href="non-linear-least-squares.html#cb106-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.pred =</span> <span class="st">&quot;lightskyblue2&quot;</span>,</span>
<span id="cb106-8"><a href="non-linear-least-squares.html#cb106-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> datf</span>
<span id="cb106-9"><a href="non-linear-least-squares.html#cb106-9" aria-hidden="true" tabindex="-1"></a>)  </span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-5-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Based on the forms of your function, you can also have programmed starting values from <code>nls</code> function (e.e.g, logistic growth, asymptotic regression, etc).</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="non-linear-least-squares.html#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="fu">apropos</span>(<span class="st">&quot;^SS&quot;</span>)</span>
<span id="cb107-2"><a href="non-linear-least-squares.html#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] &quot;ss&quot;          &quot;SSasymp&quot;     &quot;SSasympOff&quot;  &quot;SSasympOrig&quot; &quot;SSbiexp&quot;    </span></span>
<span id="cb107-3"><a href="non-linear-least-squares.html#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [6] &quot;SSD&quot;         &quot;SSfol&quot;       &quot;SSfpl&quot;       &quot;SSgompertz&quot;  &quot;SSlogis&quot;    </span></span>
<span id="cb107-4"><a href="non-linear-least-squares.html#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [11] &quot;SSmicmen&quot;    &quot;SSout&quot;       &quot;SSweibull&quot;</span></span></code></pre></div>
<p>For example, a logistic growth model:</p>
<p><span class="math display">\[
P = \frac{K}{1+ exp(P_0+ rt)} + \epsilon
\]</span></p>
<p>where</p>
<ul>
<li>P = population at time t</li>
<li>K = carrying capacity</li>
<li>r = population growth rate</li>
</ul>
<p>but in <code>R</code> you have slight different parameterization:</p>
<p><span class="math display">\[
P = \frac{asym}{1 + exp(\frac{xmid - t}{scal})}
\]</span></p>
<p>where</p>
<ul>
<li>asym = carrying capacity</li>
<li>xmid = the x value at the inflection point of the curve</li>
<li>scal = scaling parameter.</li>
</ul>
<p>Hence, you have</p>
<ul>
<li>K = asym</li>
<li>r = -1/scal</li>
<li><span class="math inline">\(P_0 = -rxmid\)</span></li>
</ul>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="non-linear-least-squares.html#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="co"># simulated data</span></span>
<span id="cb108-2"><a href="non-linear-least-squares.html#cb108-2" aria-hidden="true" tabindex="-1"></a>time <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>, <span class="dv">30</span>, <span class="dv">35</span>)</span>
<span id="cb108-3"><a href="non-linear-least-squares.html#cb108-3" aria-hidden="true" tabindex="-1"></a>population <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">2.8</span>, <span class="fl">4.2</span>, <span class="fl">3.5</span>, <span class="fl">6.3</span>, <span class="fl">15.7</span>, <span class="fl">21.3</span>, <span class="fl">23.7</span>, <span class="fl">25.1</span>, <span class="fl">25.8</span>, <span class="fl">25.9</span>)</span>
<span id="cb108-4"><a href="non-linear-least-squares.html#cb108-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(time, population, <span class="at">las =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-7-1.png" width="90%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="non-linear-least-squares.html#cb109-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-2"><a href="non-linear-least-squares.html#cb109-2" aria-hidden="true" tabindex="-1"></a><span class="co"># model fitting</span></span>
<span id="cb109-3"><a href="non-linear-least-squares.html#cb109-3" aria-hidden="true" tabindex="-1"></a>logisticModelSS <span class="ot">&lt;-</span> <span class="fu">nls</span>(population <span class="sc">~</span> <span class="fu">SSlogis</span>(time, Asym, xmid, scal))</span>
<span id="cb109-4"><a href="non-linear-least-squares.html#cb109-4" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logisticModelSS)</span>
<span id="cb109-5"><a href="non-linear-least-squares.html#cb109-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb109-6"><a href="non-linear-least-squares.html#cb109-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Formula: population ~ SSlogis(time, Asym, xmid, scal)</span></span>
<span id="cb109-7"><a href="non-linear-least-squares.html#cb109-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb109-8"><a href="non-linear-least-squares.html#cb109-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Parameters:</span></span>
<span id="cb109-9"><a href="non-linear-least-squares.html#cb109-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb109-10"><a href="non-linear-least-squares.html#cb109-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Asym  25.5029     0.3666   69.56 3.34e-11 ***</span></span>
<span id="cb109-11"><a href="non-linear-least-squares.html#cb109-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; xmid   8.7347     0.3007   29.05 1.48e-08 ***</span></span>
<span id="cb109-12"><a href="non-linear-least-squares.html#cb109-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; scal   3.6353     0.2186   16.63 6.96e-07 ***</span></span>
<span id="cb109-13"><a href="non-linear-least-squares.html#cb109-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb109-14"><a href="non-linear-least-squares.html#cb109-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb109-15"><a href="non-linear-least-squares.html#cb109-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb109-16"><a href="non-linear-least-squares.html#cb109-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 0.6528 on 7 degrees of freedom</span></span>
<span id="cb109-17"><a href="non-linear-least-squares.html#cb109-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb109-18"><a href="non-linear-least-squares.html#cb109-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 1 </span></span>
<span id="cb109-19"><a href="non-linear-least-squares.html#cb109-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 1.908e-06</span></span>
<span id="cb109-20"><a href="non-linear-least-squares.html#cb109-20" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(logisticModelSS)</span>
<span id="cb109-21"><a href="non-linear-least-squares.html#cb109-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      Asym      xmid      scal </span></span>
<span id="cb109-22"><a href="non-linear-least-squares.html#cb109-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 25.502890  8.734698  3.635333</span></span></code></pre></div>
<p>Other parameterization</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="non-linear-least-squares.html#cb110-1" aria-hidden="true" tabindex="-1"></a><span class="co">#convert to other parameterization</span></span>
<span id="cb110-2"><a href="non-linear-least-squares.html#cb110-2" aria-hidden="true" tabindex="-1"></a>Ks <span class="ot">=</span> <span class="fu">as.numeric</span>(<span class="fu">coef</span>(logisticModelSS)[<span class="dv">1</span>])</span>
<span id="cb110-3"><a href="non-linear-least-squares.html#cb110-3" aria-hidden="true" tabindex="-1"></a>rs <span class="ot">=</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="fu">as.numeric</span>(<span class="fu">coef</span>(logisticModelSS)[<span class="dv">3</span>])</span>
<span id="cb110-4"><a href="non-linear-least-squares.html#cb110-4" aria-hidden="true" tabindex="-1"></a>Pos <span class="ot">=</span> <span class="sc">-</span> rs <span class="sc">*</span> <span class="fu">as.numeric</span>(<span class="fu">coef</span>(logisticModelSS)[<span class="dv">2</span>])</span>
<span id="cb110-5"><a href="non-linear-least-squares.html#cb110-5" aria-hidden="true" tabindex="-1"></a><span class="co">#let&#39;s refit with these parameters</span></span>
<span id="cb110-6"><a href="non-linear-least-squares.html#cb110-6" aria-hidden="true" tabindex="-1"></a>logisticModel <span class="ot">&lt;-</span> <span class="fu">nls</span>(population <span class="sc">~</span> K <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(Po <span class="sc">+</span> r <span class="sc">*</span> time)),<span class="at">start=</span><span class="fu">list</span>(<span class="at">Po=</span>Pos,<span class="at">r=</span>rs,<span class="at">K=</span>Ks))</span>
<span id="cb110-7"><a href="non-linear-least-squares.html#cb110-7" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(logisticModel)</span>
<span id="cb110-8"><a href="non-linear-least-squares.html#cb110-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb110-9"><a href="non-linear-least-squares.html#cb110-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Formula: population ~ K/(1 + exp(Po + r * time))</span></span>
<span id="cb110-10"><a href="non-linear-least-squares.html#cb110-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb110-11"><a href="non-linear-least-squares.html#cb110-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Parameters:</span></span>
<span id="cb110-12"><a href="non-linear-least-squares.html#cb110-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb110-13"><a href="non-linear-least-squares.html#cb110-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Po  2.40272    0.12702   18.92 2.87e-07 ***</span></span>
<span id="cb110-14"><a href="non-linear-least-squares.html#cb110-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; r  -0.27508    0.01654  -16.63 6.96e-07 ***</span></span>
<span id="cb110-15"><a href="non-linear-least-squares.html#cb110-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; K  25.50289    0.36665   69.56 3.34e-11 ***</span></span>
<span id="cb110-16"><a href="non-linear-least-squares.html#cb110-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb110-17"><a href="non-linear-least-squares.html#cb110-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb110-18"><a href="non-linear-least-squares.html#cb110-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb110-19"><a href="non-linear-least-squares.html#cb110-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 0.6528 on 7 degrees of freedom</span></span>
<span id="cb110-20"><a href="non-linear-least-squares.html#cb110-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb110-21"><a href="non-linear-least-squares.html#cb110-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 0 </span></span>
<span id="cb110-22"><a href="non-linear-least-squares.html#cb110-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 1.924e-06</span></span></code></pre></div>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="non-linear-least-squares.html#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="co">#note: initial values =  solution (highly unusual, but ok)</span></span>
<span id="cb111-2"><a href="non-linear-least-squares.html#cb111-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(time, population, <span class="at">las =</span> <span class="dv">1</span>, <span class="at">pch =</span> <span class="dv">16</span>)</span>
<span id="cb111-3"><a href="non-linear-least-squares.html#cb111-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(time, <span class="fu">predict</span>(logisticModel), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-9-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>If can also define your own self-starting fucntion if your models are uncommon (built in <code>nls</code>)</p>
<p>Example is based on <span class="citation">(<a href="#ref-Schabenberger_2001" role="doc-biblioref">Schabenberger and Pierce 2001</a>)</span></p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="non-linear-least-squares.html#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Load data</span></span>
<span id="cb112-2"><a href="non-linear-least-squares.html#cb112-2" aria-hidden="true" tabindex="-1"></a>dat <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;images/dat.txt&quot;</span>, <span class="at">header =</span> T)</span>
<span id="cb112-3"><a href="non-linear-least-squares.html#cb112-3" aria-hidden="true" tabindex="-1"></a><span class="co"># plot</span></span>
<span id="cb112-4"><a href="non-linear-least-squares.html#cb112-4" aria-hidden="true" tabindex="-1"></a>dat.plot <span class="ot">&lt;-</span></span>
<span id="cb112-5"><a href="non-linear-least-squares.html#cb112-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(dat) <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="fu">aes</span>(</span>
<span id="cb112-6"><a href="non-linear-least-squares.html#cb112-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> no3,</span>
<span id="cb112-7"><a href="non-linear-least-squares.html#cb112-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> ryp,</span>
<span id="cb112-8"><a href="non-linear-least-squares.html#cb112-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="fu">as.factor</span>(depth)</span>
<span id="cb112-9"><a href="non-linear-least-squares.html#cb112-9" aria-hidden="true" tabindex="-1"></a>  )) <span class="sc">+</span></span>
<span id="cb112-10"><a href="non-linear-least-squares.html#cb112-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">color =</span> <span class="st">&#39;Depth (cm)&#39;</span>) <span class="sc">+</span> <span class="fu">xlab</span>(<span class="st">&#39;Soil NO3&#39;</span>) <span class="sc">+</span> <span class="fu">ylab</span>(<span class="st">&#39;relative yield percent&#39;</span>)</span>
<span id="cb112-11"><a href="non-linear-least-squares.html#cb112-11" aria-hidden="true" tabindex="-1"></a>dat.plot</span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-10-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>The suggested model (known as plateau model) is</p>
<p><span class="math display">\[
E(Y_{ij}) = (\beta_{0j} + \beta_{1j}N_{ij})I_{N_{ij}\le \alpha_j} + (\beta_{0j} + \beta_{1j}\alpha_j)I_{N_{ij} &gt; \alpha_j}
\]</span></p>
<p>where</p>
<ul>
<li>N is an observation</li>
<li>i is a particular observation</li>
<li>j = 1,2 corresponding to depths (30,60)</li>
</ul>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="non-linear-least-squares.html#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co">#First define model as a function</span></span>
<span id="cb113-2"><a href="non-linear-least-squares.html#cb113-2" aria-hidden="true" tabindex="-1"></a>nonlinModel <span class="ot">&lt;-</span> <span class="cf">function</span>(predictor,b0,b1,alpha){</span>
<span id="cb113-3"><a href="non-linear-least-squares.html#cb113-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ifelse</span>(predictor<span class="sc">&lt;=</span>alpha, </span>
<span id="cb113-4"><a href="non-linear-least-squares.html#cb113-4" aria-hidden="true" tabindex="-1"></a>         b0<span class="sc">+</span>b1<span class="sc">*</span>predictor, <span class="co">#if observation less than cutoff simple linear model</span></span>
<span id="cb113-5"><a href="non-linear-least-squares.html#cb113-5" aria-hidden="true" tabindex="-1"></a>         b0<span class="sc">+</span>b1<span class="sc">*</span>alpha) <span class="co">#otherwise flat line</span></span>
<span id="cb113-6"><a href="non-linear-least-squares.html#cb113-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>define <code>selfStart</code> function. Because we defined our model to be linear in the first part and then plateau (remain constant) we can use the first half of our predictors (sorted by increasing value) to get an initial estimate for the slope and intercept of the model, and the last predictor value (alpha) can be the starting value for the plateau parameter.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="non-linear-least-squares.html#cb114-1" aria-hidden="true" tabindex="-1"></a>nonlinModelInit <span class="ot">&lt;-</span> <span class="cf">function</span>(mCall,LHS,data){</span>
<span id="cb114-2"><a href="non-linear-least-squares.html#cb114-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#sort data by increasing predictor value - </span></span>
<span id="cb114-3"><a href="non-linear-least-squares.html#cb114-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#done so we can just use the low level no3 conc to fit a simple model</span></span>
<span id="cb114-4"><a href="non-linear-least-squares.html#cb114-4" aria-hidden="true" tabindex="-1"></a>  xy <span class="ot">&lt;-</span> <span class="fu">sortedXyData</span>(mCall[[<span class="st">&#39;predictor&#39;</span>]],LHS,data)</span>
<span id="cb114-5"><a href="non-linear-least-squares.html#cb114-5" aria-hidden="true" tabindex="-1"></a>  n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(xy)</span>
<span id="cb114-6"><a href="non-linear-least-squares.html#cb114-6" aria-hidden="true" tabindex="-1"></a>  <span class="co">#For the first half of the data a simple linear model is fit</span></span>
<span id="cb114-7"><a href="non-linear-least-squares.html#cb114-7" aria-hidden="true" tabindex="-1"></a>  lmFit <span class="ot">&lt;-</span> <span class="fu">lm</span>(xy[<span class="dv">1</span><span class="sc">:</span>(n<span class="sc">/</span><span class="dv">2</span>),<span class="st">&#39;y&#39;</span>]<span class="sc">~</span>xy[<span class="dv">1</span><span class="sc">:</span>(n<span class="sc">/</span><span class="dv">2</span>),<span class="st">&#39;x&#39;</span>])</span>
<span id="cb114-8"><a href="non-linear-least-squares.html#cb114-8" aria-hidden="true" tabindex="-1"></a>  b0 <span class="ot">&lt;-</span> <span class="fu">coef</span>(lmFit)[<span class="dv">1</span>]</span>
<span id="cb114-9"><a href="non-linear-least-squares.html#cb114-9" aria-hidden="true" tabindex="-1"></a>  b1 <span class="ot">&lt;-</span> <span class="fu">coef</span>(lmFit)[<span class="dv">2</span>]</span>
<span id="cb114-10"><a href="non-linear-least-squares.html#cb114-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">#for the cut off to the flat part select the last x value used in creating linear model</span></span>
<span id="cb114-11"><a href="non-linear-least-squares.html#cb114-11" aria-hidden="true" tabindex="-1"></a>  alpha <span class="ot">&lt;-</span> xy[(n<span class="sc">/</span><span class="dv">2</span>),<span class="st">&#39;x&#39;</span>]</span>
<span id="cb114-12"><a href="non-linear-least-squares.html#cb114-12" aria-hidden="true" tabindex="-1"></a>  value <span class="ot">&lt;-</span> <span class="fu">c</span>(b0,b1,alpha)</span>
<span id="cb114-13"><a href="non-linear-least-squares.html#cb114-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">names</span>(value) <span class="ot">&lt;-</span> mCall[<span class="fu">c</span>(<span class="st">&#39;b0&#39;</span>,<span class="st">&#39;b1&#39;</span>,<span class="st">&#39;alpha&#39;</span>)]</span>
<span id="cb114-14"><a href="non-linear-least-squares.html#cb114-14" aria-hidden="true" tabindex="-1"></a>  value</span>
<span id="cb114-15"><a href="non-linear-least-squares.html#cb114-15" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>combine model and custom function to calculate starting values.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="non-linear-least-squares.html#cb115-1" aria-hidden="true" tabindex="-1"></a>SS_nonlinModel <span class="ot">&lt;-</span> <span class="fu">selfStart</span>(nonlinModel,nonlinModelInit,<span class="fu">c</span>(<span class="st">&#39;b0&#39;</span>,<span class="st">&#39;b1&#39;</span>,<span class="st">&#39;alpha&#39;</span>))</span></code></pre></div>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="non-linear-least-squares.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="co">#Above code defined model and selfStart now just need to call it for each of the depths</span></span>
<span id="cb116-2"><a href="non-linear-least-squares.html#cb116-2" aria-hidden="true" tabindex="-1"></a>sep30_nls <span class="ot">&lt;-</span></span>
<span id="cb116-3"><a href="non-linear-least-squares.html#cb116-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nls</span>(ryp <span class="sc">~</span> <span class="fu">SS_nonlinModel</span>(<span class="at">predictor =</span> no3, b0, b1, alpha), <span class="at">data =</span> dat[dat<span class="sc">$</span>depth <span class="sc">==</span></span>
<span id="cb116-4"><a href="non-linear-least-squares.html#cb116-4" aria-hidden="true" tabindex="-1"></a>                                                                         <span class="dv">30</span>, ])</span>
<span id="cb116-5"><a href="non-linear-least-squares.html#cb116-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-6"><a href="non-linear-least-squares.html#cb116-6" aria-hidden="true" tabindex="-1"></a>sep60_nls <span class="ot">&lt;-</span></span>
<span id="cb116-7"><a href="non-linear-least-squares.html#cb116-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nls</span>(ryp <span class="sc">~</span> <span class="fu">SS_nonlinModel</span>(<span class="at">predictor =</span> no3, b0, b1, alpha), <span class="at">data =</span> dat[dat<span class="sc">$</span>depth <span class="sc">==</span></span>
<span id="cb116-8"><a href="non-linear-least-squares.html#cb116-8" aria-hidden="true" tabindex="-1"></a>                                                                         <span class="dv">60</span>, ])</span>
<span id="cb116-9"><a href="non-linear-least-squares.html#cb116-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb116-10"><a href="non-linear-least-squares.html#cb116-10" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb116-11"><a href="non-linear-least-squares.html#cb116-11" aria-hidden="true" tabindex="-1"></a><span class="fu">plotFit</span>(</span>
<span id="cb116-12"><a href="non-linear-least-squares.html#cb116-12" aria-hidden="true" tabindex="-1"></a>  sep30_nls,</span>
<span id="cb116-13"><a href="non-linear-least-squares.html#cb116-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">interval =</span> <span class="st">&quot;both&quot;</span>,</span>
<span id="cb116-14"><a href="non-linear-least-squares.html#cb116-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb116-15"><a href="non-linear-least-squares.html#cb116-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">shade =</span> <span class="cn">TRUE</span>,</span>
<span id="cb116-16"><a href="non-linear-least-squares.html#cb116-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.conf =</span> <span class="st">&quot;skyblue4&quot;</span>,</span>
<span id="cb116-17"><a href="non-linear-least-squares.html#cb116-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.pred =</span> <span class="st">&quot;lightskyblue2&quot;</span>,</span>
<span id="cb116-18"><a href="non-linear-least-squares.html#cb116-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dat[dat<span class="sc">$</span>depth <span class="sc">==</span> <span class="dv">30</span>, ],</span>
<span id="cb116-19"><a href="non-linear-least-squares.html#cb116-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&#39;Results 30 cm depth&#39;</span>,</span>
<span id="cb116-20"><a href="non-linear-least-squares.html#cb116-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&#39;relative yield percent&#39;</span>,</span>
<span id="cb116-21"><a href="non-linear-least-squares.html#cb116-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&#39;Soil NO3 concentration&#39;</span>,</span>
<span id="cb116-22"><a href="non-linear-least-squares.html#cb116-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">120</span>)</span>
<span id="cb116-23"><a href="non-linear-least-squares.html#cb116-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb116-24"><a href="non-linear-least-squares.html#cb116-24" aria-hidden="true" tabindex="-1"></a><span class="fu">plotFit</span>(</span>
<span id="cb116-25"><a href="non-linear-least-squares.html#cb116-25" aria-hidden="true" tabindex="-1"></a>  sep60_nls,</span>
<span id="cb116-26"><a href="non-linear-least-squares.html#cb116-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">interval =</span> <span class="st">&quot;both&quot;</span>,</span>
<span id="cb116-27"><a href="non-linear-least-squares.html#cb116-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb116-28"><a href="non-linear-least-squares.html#cb116-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">shade =</span> <span class="cn">TRUE</span>,</span>
<span id="cb116-29"><a href="non-linear-least-squares.html#cb116-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.conf =</span> <span class="st">&quot;lightpink4&quot;</span>,</span>
<span id="cb116-30"><a href="non-linear-least-squares.html#cb116-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.pred =</span> <span class="st">&quot;lightpink2&quot;</span>,</span>
<span id="cb116-31"><a href="non-linear-least-squares.html#cb116-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dat[dat<span class="sc">$</span>depth <span class="sc">==</span> <span class="dv">60</span>, ],</span>
<span id="cb116-32"><a href="non-linear-least-squares.html#cb116-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&#39;Results 60 cm depth&#39;</span>,</span>
<span id="cb116-33"><a href="non-linear-least-squares.html#cb116-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&#39;relative yield percent&#39;</span>,</span>
<span id="cb116-34"><a href="non-linear-least-squares.html#cb116-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&#39;Soil NO3 concentration&#39;</span>,</span>
<span id="cb116-35"><a href="non-linear-least-squares.html#cb116-35" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">120</span>)</span>
<span id="cb116-36"><a href="non-linear-least-squares.html#cb116-36" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-14-1.png" width="90%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="non-linear-least-squares.html#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sep30_nls)</span>
<span id="cb117-2"><a href="non-linear-least-squares.html#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-3"><a href="non-linear-least-squares.html#cb117-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Formula: ryp ~ SS_nonlinModel(predictor = no3, b0, b1, alpha)</span></span>
<span id="cb117-4"><a href="non-linear-least-squares.html#cb117-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-5"><a href="non-linear-least-squares.html#cb117-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Parameters:</span></span>
<span id="cb117-6"><a href="non-linear-least-squares.html#cb117-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb117-7"><a href="non-linear-least-squares.html#cb117-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b0     15.1943     2.9781   5.102 6.89e-07 ***</span></span>
<span id="cb117-8"><a href="non-linear-least-squares.html#cb117-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b1      3.5760     0.1853  19.297  &lt; 2e-16 ***</span></span>
<span id="cb117-9"><a href="non-linear-least-squares.html#cb117-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; alpha  23.1324     0.5098  45.373  &lt; 2e-16 ***</span></span>
<span id="cb117-10"><a href="non-linear-least-squares.html#cb117-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb117-11"><a href="non-linear-least-squares.html#cb117-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb117-12"><a href="non-linear-least-squares.html#cb117-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-13"><a href="non-linear-least-squares.html#cb117-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 8.258 on 237 degrees of freedom</span></span>
<span id="cb117-14"><a href="non-linear-least-squares.html#cb117-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-15"><a href="non-linear-least-squares.html#cb117-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 6 </span></span>
<span id="cb117-16"><a href="non-linear-least-squares.html#cb117-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 3.608e-09</span></span>
<span id="cb117-17"><a href="non-linear-least-squares.html#cb117-17" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(sep60_nls)</span>
<span id="cb117-18"><a href="non-linear-least-squares.html#cb117-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-19"><a href="non-linear-least-squares.html#cb117-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Formula: ryp ~ SS_nonlinModel(predictor = no3, b0, b1, alpha)</span></span>
<span id="cb117-20"><a href="non-linear-least-squares.html#cb117-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-21"><a href="non-linear-least-squares.html#cb117-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Parameters:</span></span>
<span id="cb117-22"><a href="non-linear-least-squares.html#cb117-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb117-23"><a href="non-linear-least-squares.html#cb117-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b0      5.4519     2.9785    1.83   0.0684 .  </span></span>
<span id="cb117-24"><a href="non-linear-least-squares.html#cb117-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b1      5.6820     0.2529   22.46   &lt;2e-16 ***</span></span>
<span id="cb117-25"><a href="non-linear-least-squares.html#cb117-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; alpha  16.2863     0.2818   57.80   &lt;2e-16 ***</span></span>
<span id="cb117-26"><a href="non-linear-least-squares.html#cb117-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb117-27"><a href="non-linear-least-squares.html#cb117-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb117-28"><a href="non-linear-least-squares.html#cb117-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-29"><a href="non-linear-least-squares.html#cb117-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 7.427 on 237 degrees of freedom</span></span>
<span id="cb117-30"><a href="non-linear-least-squares.html#cb117-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb117-31"><a href="non-linear-least-squares.html#cb117-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 5 </span></span>
<span id="cb117-32"><a href="non-linear-least-squares.html#cb117-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 8.571e-09</span></span></code></pre></div>
<p>Instead of modeling the depths model separately we model them together - so there is a common slope, intercept, and plateau.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="non-linear-least-squares.html#cb118-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-2"><a href="non-linear-least-squares.html#cb118-2" aria-hidden="true" tabindex="-1"></a>red_nls <span class="ot">&lt;-</span></span>
<span id="cb118-3"><a href="non-linear-least-squares.html#cb118-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">nls</span>(ryp <span class="sc">~</span> <span class="fu">SS_nonlinModel</span>(<span class="at">predictor =</span> no3, b0, b1, alpha), <span class="at">data =</span> dat)</span>
<span id="cb118-4"><a href="non-linear-least-squares.html#cb118-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-5"><a href="non-linear-least-squares.html#cb118-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(red_nls)</span>
<span id="cb118-6"><a href="non-linear-least-squares.html#cb118-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb118-7"><a href="non-linear-least-squares.html#cb118-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Formula: ryp ~ SS_nonlinModel(predictor = no3, b0, b1, alpha)</span></span>
<span id="cb118-8"><a href="non-linear-least-squares.html#cb118-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb118-9"><a href="non-linear-least-squares.html#cb118-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Parameters:</span></span>
<span id="cb118-10"><a href="non-linear-least-squares.html#cb118-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb118-11"><a href="non-linear-least-squares.html#cb118-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b0      8.7901     2.7688   3.175   0.0016 ** </span></span>
<span id="cb118-12"><a href="non-linear-least-squares.html#cb118-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b1      4.8995     0.2207  22.203   &lt;2e-16 ***</span></span>
<span id="cb118-13"><a href="non-linear-least-squares.html#cb118-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; alpha  18.0333     0.3242  55.630   &lt;2e-16 ***</span></span>
<span id="cb118-14"><a href="non-linear-least-squares.html#cb118-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb118-15"><a href="non-linear-least-squares.html#cb118-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb118-16"><a href="non-linear-least-squares.html#cb118-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb118-17"><a href="non-linear-least-squares.html#cb118-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 9.13 on 477 degrees of freedom</span></span>
<span id="cb118-18"><a href="non-linear-least-squares.html#cb118-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb118-19"><a href="non-linear-least-squares.html#cb118-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 7 </span></span>
<span id="cb118-20"><a href="non-linear-least-squares.html#cb118-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 7.126e-09</span></span>
<span id="cb118-21"><a href="non-linear-least-squares.html#cb118-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-22"><a href="non-linear-least-squares.html#cb118-22" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb118-23"><a href="non-linear-least-squares.html#cb118-23" aria-hidden="true" tabindex="-1"></a><span class="fu">plotFit</span>(</span>
<span id="cb118-24"><a href="non-linear-least-squares.html#cb118-24" aria-hidden="true" tabindex="-1"></a>  red_nls,</span>
<span id="cb118-25"><a href="non-linear-least-squares.html#cb118-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">interval =</span> <span class="st">&quot;both&quot;</span>,</span>
<span id="cb118-26"><a href="non-linear-least-squares.html#cb118-26" aria-hidden="true" tabindex="-1"></a>  <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb118-27"><a href="non-linear-least-squares.html#cb118-27" aria-hidden="true" tabindex="-1"></a>  <span class="at">shade =</span> <span class="cn">TRUE</span>,</span>
<span id="cb118-28"><a href="non-linear-least-squares.html#cb118-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.conf =</span> <span class="st">&quot;lightblue4&quot;</span>,</span>
<span id="cb118-29"><a href="non-linear-least-squares.html#cb118-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">col.pred =</span> <span class="st">&quot;lightblue2&quot;</span>,</span>
<span id="cb118-30"><a href="non-linear-least-squares.html#cb118-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> dat,</span>
<span id="cb118-31"><a href="non-linear-least-squares.html#cb118-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&#39;Results combined&#39;</span>,</span>
<span id="cb118-32"><a href="non-linear-least-squares.html#cb118-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&#39;relative yield percent&#39;</span>,</span>
<span id="cb118-33"><a href="non-linear-least-squares.html#cb118-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&#39;Soil NO3 concentration&#39;</span></span>
<span id="cb118-34"><a href="non-linear-least-squares.html#cb118-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/reduce-model-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>Examine residual values for the combined model.</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="non-linear-least-squares.html#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nlstools)</span>
<span id="cb119-2"><a href="non-linear-least-squares.html#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="co">#using nlstools nlsResiduals function to get some quick residual plots</span></span>
<span id="cb119-3"><a href="non-linear-least-squares.html#cb119-3" aria-hidden="true" tabindex="-1"></a><span class="co">#can also use test.nlsResiduals(resid)</span></span>
<span id="cb119-4"><a href="non-linear-least-squares.html#cb119-4" aria-hidden="true" tabindex="-1"></a><span class="co"># https://www.rdocumentation.org/packages/nlstools/versions/1.0-2</span></span>
<span id="cb119-5"><a href="non-linear-least-squares.html#cb119-5" aria-hidden="true" tabindex="-1"></a>resid <span class="ot">&lt;-</span> <span class="fu">nlsResiduals</span>(red_nls)</span>
<span id="cb119-6"><a href="non-linear-least-squares.html#cb119-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(resid)</span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/reduce-model-resid-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>can we test whether the parameters for the two soil depth fits are significantly different? To know if the combined model is appropriate, we consider a parameterization where we let the parameters for the 60cm model be equal to the parameters from the 30cm model plus some increment:</p>
<p><span class="math display">\[
\beta_{02} = \beta_{01} + d_0 \\
\beta_{12} = \beta_{11} + d_1 \\
\alpha_{2} = \alpha_{1} + d_a
\]</span></p>
<p>We can implement this in the following function:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="non-linear-least-squares.html#cb120-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb120-2"><a href="non-linear-least-squares.html#cb120-2" aria-hidden="true" tabindex="-1"></a>nonlinModelF <span class="ot">&lt;-</span> <span class="cf">function</span>(predictor,soildep,b01,b11,a1,d0,d1,da){</span>
<span id="cb120-3"><a href="non-linear-least-squares.html#cb120-3" aria-hidden="true" tabindex="-1"></a>   b02 <span class="ot">=</span> b01 <span class="sc">+</span> d0 <span class="co">#make 60cm parms = 30cm parms + increment</span></span>
<span id="cb120-4"><a href="non-linear-least-squares.html#cb120-4" aria-hidden="true" tabindex="-1"></a>   b12 <span class="ot">=</span> b11 <span class="sc">+</span> d1</span>
<span id="cb120-5"><a href="non-linear-least-squares.html#cb120-5" aria-hidden="true" tabindex="-1"></a>   a2 <span class="ot">=</span> a1 <span class="sc">+</span> da</span>
<span id="cb120-6"><a href="non-linear-least-squares.html#cb120-6" aria-hidden="true" tabindex="-1"></a>   </span>
<span id="cb120-7"><a href="non-linear-least-squares.html#cb120-7" aria-hidden="true" tabindex="-1"></a>   y1 <span class="ot">=</span> <span class="fu">ifelse</span>(predictor<span class="sc">&lt;=</span>a1, </span>
<span id="cb120-8"><a href="non-linear-least-squares.html#cb120-8" aria-hidden="true" tabindex="-1"></a>         b01<span class="sc">+</span>b11<span class="sc">*</span>predictor, <span class="co">#if observation less than cutoff simple linear model</span></span>
<span id="cb120-9"><a href="non-linear-least-squares.html#cb120-9" aria-hidden="true" tabindex="-1"></a>         b01<span class="sc">+</span>b11<span class="sc">*</span>a1) <span class="co">#otherwise flat line</span></span>
<span id="cb120-10"><a href="non-linear-least-squares.html#cb120-10" aria-hidden="true" tabindex="-1"></a>   y2 <span class="ot">=</span> <span class="fu">ifelse</span>(predictor<span class="sc">&lt;=</span>a2, </span>
<span id="cb120-11"><a href="non-linear-least-squares.html#cb120-11" aria-hidden="true" tabindex="-1"></a>               b02<span class="sc">+</span>b12<span class="sc">*</span>predictor, </span>
<span id="cb120-12"><a href="non-linear-least-squares.html#cb120-12" aria-hidden="true" tabindex="-1"></a>               b02<span class="sc">+</span>b12<span class="sc">*</span>a2) </span>
<span id="cb120-13"><a href="non-linear-least-squares.html#cb120-13" aria-hidden="true" tabindex="-1"></a>   y <span class="ot">=</span>  y1<span class="sc">*</span>(soildep <span class="sc">==</span> <span class="dv">30</span>) <span class="sc">+</span> y2<span class="sc">*</span>(soildep <span class="sc">==</span> <span class="dv">60</span>)  <span class="co">#combine models</span></span>
<span id="cb120-14"><a href="non-linear-least-squares.html#cb120-14" aria-hidden="true" tabindex="-1"></a>   <span class="fu">return</span>(y)</span>
<span id="cb120-15"><a href="non-linear-least-squares.html#cb120-15" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Starting values are easy now because we fit each model individually.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="non-linear-least-squares.html#cb121-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-2"><a href="non-linear-least-squares.html#cb121-2" aria-hidden="true" tabindex="-1"></a>Soil_full<span class="ot">=</span><span class="fu">nls</span>(ryp<span class="sc">~</span><span class="fu">nonlinModelF</span>(<span class="at">predictor=</span>no3,<span class="at">soildep=</span>depth,b01,b11,a1,d0,d1,da),</span>
<span id="cb121-3"><a href="non-linear-least-squares.html#cb121-3" aria-hidden="true" tabindex="-1"></a>              <span class="at">data=</span>dat,</span>
<span id="cb121-4"><a href="non-linear-least-squares.html#cb121-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">start=</span><span class="fu">list</span>(<span class="at">b01=</span><span class="fl">15.2</span>,<span class="at">b11=</span><span class="fl">3.58</span>,<span class="at">a1=</span><span class="fl">23.13</span>,<span class="at">d0=</span><span class="sc">-</span><span class="fl">9.74</span>,<span class="at">d1=</span><span class="fl">2.11</span>,<span class="at">da=</span><span class="sc">-</span><span class="fl">6.85</span>)) </span>
<span id="cb121-5"><a href="non-linear-least-squares.html#cb121-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb121-6"><a href="non-linear-least-squares.html#cb121-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(Soil_full)</span>
<span id="cb121-7"><a href="non-linear-least-squares.html#cb121-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb121-8"><a href="non-linear-least-squares.html#cb121-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Formula: ryp ~ nonlinModelF(predictor = no3, soildep = depth, b01, b11, </span></span>
<span id="cb121-9"><a href="non-linear-least-squares.html#cb121-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     a1, d0, d1, da)</span></span>
<span id="cb121-10"><a href="non-linear-least-squares.html#cb121-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb121-11"><a href="non-linear-least-squares.html#cb121-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Parameters:</span></span>
<span id="cb121-12"><a href="non-linear-least-squares.html#cb121-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb121-13"><a href="non-linear-least-squares.html#cb121-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b01  15.1943     2.8322   5.365 1.27e-07 ***</span></span>
<span id="cb121-14"><a href="non-linear-least-squares.html#cb121-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; b11   3.5760     0.1762  20.291  &lt; 2e-16 ***</span></span>
<span id="cb121-15"><a href="non-linear-least-squares.html#cb121-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; a1   23.1324     0.4848  47.711  &lt; 2e-16 ***</span></span>
<span id="cb121-16"><a href="non-linear-least-squares.html#cb121-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; d0   -9.7424     4.2357  -2.300   0.0219 *  </span></span>
<span id="cb121-17"><a href="non-linear-least-squares.html#cb121-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; d1    2.1060     0.3203   6.575 1.29e-10 ***</span></span>
<span id="cb121-18"><a href="non-linear-least-squares.html#cb121-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; da   -6.8461     0.5691 -12.030  &lt; 2e-16 ***</span></span>
<span id="cb121-19"><a href="non-linear-least-squares.html#cb121-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb121-20"><a href="non-linear-least-squares.html#cb121-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb121-21"><a href="non-linear-least-squares.html#cb121-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb121-22"><a href="non-linear-least-squares.html#cb121-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 7.854 on 474 degrees of freedom</span></span>
<span id="cb121-23"><a href="non-linear-least-squares.html#cb121-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb121-24"><a href="non-linear-least-squares.html#cb121-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 1 </span></span>
<span id="cb121-25"><a href="non-linear-least-squares.html#cb121-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 3.742e-06</span></span></code></pre></div>
<p>So, the increment parameters, <span class="math inline">\(d_1\)</span>,<span class="math inline">\(d_2\)</span>,<span class="math inline">\(d_a\)</span> are all significantly different from 0, suggesting that we should have two models here.</p>
</div>
</div>
<div id="modelestiamtion-adequcy" class="section level3" number="6.2.3">
<h3><span class="header-section-number">6.2.3</span> Model/Estiamtion Adequcy</h3>
<p><span class="citation">(<a href="#ref-Bates_1980" role="doc-biblioref">Bates and Watts 1980</a>)</span> assess nonlinearity in terms of 2 components of curvature:</p>
<ul>
<li><p><strong>Intrinsic nonlinearity</strong>: the degree of bending and twisting in <span class="math inline">\(f(\theta)\)</span>; our estimation approach assumes that hte true function is relatively flat (planar) in the neighborhood fo <span class="math inline">\(\hat{\theta}\)</span>, which would not be true if <span class="math inline">\(f()\)</span> has a lot of “bending” int he neighborhood of <span class="math inline">\(\hat{\theta}\)</span> (independent of parameterizaiton)</p>
<ul>
<li><p>If bad, the distribution of residuals will be seriously distorted</p></li>
<li><p>slow to converge</p></li>
<li><p>difficult to identify ( could use this function <code>rms.curve</code>)</p></li>
<li><p>Solution:</p>
<ul>
<li>could use higher order Taylor expansions estimation</li>
<li>Bayesian method</li>
</ul></li>
</ul></li>
<li><p><strong>Parameter effects nonlinearity</strong>: degree to which curvature (nonlinearity) is affected by choice of <span class="math inline">\(\theta\)</span> (data dependent; dependent on parameterization)</p>
<ul>
<li>leads to problems with inferecne on <span class="math inline">\(\hat{\theta}\)</span></li>
<li><code>rms.curve</code> in <code>MASS</code> can identify</li>
<li>bootstrap-based inference can also be used</li>
<li>Solution: try to reparaemterize.</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="non-linear-least-squares.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="co">#check parameter effects and intrinsic curvature</span></span>
<span id="cb122-2"><a href="non-linear-least-squares.html#cb122-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-3"><a href="non-linear-least-squares.html#cb122-3" aria-hidden="true" tabindex="-1"></a>modD <span class="ot">=</span> <span class="fu">deriv3</span>(<span class="sc">~</span> a<span class="sc">*</span><span class="fu">exp</span>(b<span class="sc">*</span>x), <span class="fu">c</span>(<span class="st">&quot;a&quot;</span>,<span class="st">&quot;b&quot;</span>),<span class="cf">function</span>(a,b,x) <span class="cn">NULL</span>)</span>
<span id="cb122-4"><a href="non-linear-least-squares.html#cb122-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-5"><a href="non-linear-least-squares.html#cb122-5" aria-hidden="true" tabindex="-1"></a>nlin_modD<span class="ot">=</span><span class="fu">nls</span>(y<span class="sc">~</span><span class="fu">modD</span>(a,b,x),<span class="at">start=</span><span class="fu">list</span>(<span class="at">a=</span>astrt,<span class="at">b=</span>bstrt),<span class="at">data=</span>datf)</span>
<span id="cb122-6"><a href="non-linear-least-squares.html#cb122-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb122-7"><a href="non-linear-least-squares.html#cb122-7" aria-hidden="true" tabindex="-1"></a><span class="fu">rms.curv</span>(nlin_modD)</span>
<span id="cb122-8"><a href="non-linear-least-squares.html#cb122-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Parameter effects: c^theta x sqrt(F) = 0.0626 </span></span>
<span id="cb122-9"><a href="non-linear-least-squares.html#cb122-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         Intrinsic: c^iota  x sqrt(F) = 0.0062</span></span></code></pre></div>
<p>In linear model, we have <a href="linear-regression.html#linear-regression">Linear Regression</a>, we have goodness of fit measure as <span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
R^2 = \frac{SSR}{SSTO} = 1- \frac{SSE}{SSTO} \\
= \frac{\sum_{i=1}^n (\hat{Y}_i- \bar{Y})^2}{\sum_{i=1}^n (Y_i- \bar{Y})^2} = 1- \frac{\sum_{i=1}^n ({Y}_i- \hat{Y})^2}{\sum_{i=1}^n (Y_i- \bar{Y})^2}
\]</span></p>
<p>but not valid in the nonlinear case because the error sum of squares and model sum of squares do not add to the total corrected sum of squares</p>
<p><span class="math display">\[
SSR + SSE \neq SST
\]</span></p>
<p>but we can use pseudo-<span class="math inline">\(R^2\)</span>:</p>
<p><span class="math display">\[
R^2_{pseudo} = 1 - \frac{\sum_{i=1}^n ({Y}_i- \hat{Y})^2}{\sum_{i=1}^n (Y_i- \bar{Y})^2}
\]</span></p>
<p>But we can’t interpret this as the proportion of variability explained by the model. We should use as a relative comparison of different models.</p>
<p><strong>Residual Plots</strong>: standardize, similar to OLS. useful when the intrinsic curvature is small:</p>
<p>The studentized residuals</p>
<p><span class="math display">\[
r_i = \frac{e_i}{s\sqrt{1-\hat{c}_i}}
\]</span></p>
<p>where <span class="math inline">\(\hat{c}_i\)</span>is the i-th diagonal of <span class="math inline">\(\mathbf{\hat{H}= F(\hat{\theta})[F(\hat{\theta})&#39;F(\hat{\theta})]^{-1}F(\hat{\theta})&#39;}\)</span></p>
<p>We could have problems of</p>
<ul>
<li><p>Collinearity: the condition number of <span class="math inline">\(\mathbf{[F(\hat{\theta})&#39;F(\hat{\theta})]^{-1}}\)</span> should be less than 30. Follow <span class="citation">(<a href="#ref-Magel_1987" role="doc-biblioref">Magel and Hertsgaard 1987</a>)</span>; reparameterize if possible</p></li>
<li><p>Leverage: Like <a href="ordinary-least-squares.html#ordinary-least-squares">OLS</a>, but consider <span class="math inline">\(\mathbf{\hat{H}= F(\hat{\theta})[F(\hat{\theta})&#39;F(\hat{\theta})]^{-1}F(\hat{\theta})&#39;}\)</span> (also known as “tangent plant hat matrix”) <span class="citation">(<a href="#ref-Laurent_1992" role="doc-biblioref">Laurent and Cook 1992</a>)</span></p></li>
<li><p>Heterogeneous Errors: weighted Non-linear Least Squares</p></li>
<li><p>Correlated Errors:</p>
<ul>
<li>Generalized Nonlinear Least Squares</li>
<li>Nonlinear Mixed Models</li>
<li>Bayesian methods</li>
</ul></li>
</ul>
</div>
<div id="application-1" class="section level3" number="6.2.4">
<h3><span class="header-section-number">6.2.4</span> Application</h3>
<p><span class="math display">\[
y_i = \frac{\theta_0 + \theta_1 x_i}{1 + \theta_2 \exp(0.4 x_i)} + \epsilon_i
\]</span></p>
<p>where <span class="math inline">\(i = 1,..,n\)</span></p>
<p>Get the starting values</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="non-linear-least-squares.html#cb123-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_data)</span></code></pre></div>
<p><img src="06-nonlinear-regession_files/figure-html/unnamed-chunk-18-1.png" width="90%" style="display: block; margin: auto;" /></p>
<p>We notice that <span class="math inline">\(Y_{max} = \theta_0 + \theta_1 x_i\)</span> in which we can find x_i from data</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="non-linear-least-squares.html#cb124-1" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(my_data<span class="sc">$</span>y)</span>
<span id="cb124-2"><a href="non-linear-least-squares.html#cb124-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 2.6722</span></span>
<span id="cb124-3"><a href="non-linear-least-squares.html#cb124-3" aria-hidden="true" tabindex="-1"></a>my_data<span class="sc">$</span>x[<span class="fu">which.max</span>(my_data<span class="sc">$</span>y)]</span>
<span id="cb124-4"><a href="non-linear-least-squares.html#cb124-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.0094</span></span></code></pre></div>
<p>hence, x = 0.0094 when y = 2.6722 when we have the first equation as</p>
<p><span class="math display">\[
2.6722 = \theta_0 + 0.0094 \theta_1 \\
\theta_0 + 0.0094 \theta_1 + 0 \theta_2 = 2.6722
\]</span></p>
<p>Secondly, we notice that we can obtain the “average” of y when</p>
<p><span class="math display">\[
1+ \theta_2 exp(0.4 x) = 2
\]</span></p>
<p>then we can find this average numbers of x and y</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="non-linear-least-squares.html#cb125-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(my_data<span class="sc">$</span>y) <span class="co">#find mean y</span></span>
<span id="cb125-2"><a href="non-linear-least-squares.html#cb125-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -0.0747864</span></span>
<span id="cb125-3"><a href="non-linear-least-squares.html#cb125-3" aria-hidden="true" tabindex="-1"></a>my_data<span class="sc">$</span>y[<span class="fu">which.min</span>(<span class="fu">abs</span>(my_data<span class="sc">$</span>y<span class="sc">-</span>(<span class="fu">mean</span>(my_data<span class="sc">$</span>y))))] <span class="co"># find y closest to its mean</span></span>
<span id="cb125-4"><a href="non-linear-least-squares.html#cb125-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -0.0773</span></span>
<span id="cb125-5"><a href="non-linear-least-squares.html#cb125-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb125-6"><a href="non-linear-least-squares.html#cb125-6" aria-hidden="true" tabindex="-1"></a>my_data<span class="sc">$</span>x[<span class="fu">which.min</span>(<span class="fu">abs</span>(my_data<span class="sc">$</span>y<span class="sc">-</span>(<span class="fu">mean</span>(my_data<span class="sc">$</span>y))))] <span class="co">#find x closest to the mean y</span></span>
<span id="cb125-7"><a href="non-linear-least-squares.html#cb125-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 11.0648</span></span></code></pre></div>
<p>we have the second equation</p>
<p><span class="math display">\[
1 + \theta_2 exp(0.4*11.0648) = 2 \\
0 \theta_1 + 0 \theta_1 + 83.58967 \theta_2 = 1
\]</span></p>
<p>Thirdly, we can plug in the value of x closest to 1 to find the value of y</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="non-linear-least-squares.html#cb126-1" aria-hidden="true" tabindex="-1"></a>my_data<span class="sc">$</span>x[<span class="fu">which.min</span>(<span class="fu">abs</span>(my_data<span class="sc">$</span>x<span class="dv">-1</span>))] <span class="co"># find value of x closet to 1</span></span>
<span id="cb126-2"><a href="non-linear-least-squares.html#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.9895</span></span>
<span id="cb126-3"><a href="non-linear-least-squares.html#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="fu">match</span>(my_data<span class="sc">$</span>x[<span class="fu">which.min</span>(<span class="fu">abs</span>(my_data<span class="sc">$</span>x<span class="dv">-1</span>))], my_data<span class="sc">$</span>x) <span class="co"># find index of x closest to 1</span></span>
<span id="cb126-4"><a href="non-linear-least-squares.html#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 14</span></span>
<span id="cb126-5"><a href="non-linear-least-squares.html#cb126-5" aria-hidden="true" tabindex="-1"></a>my_data<span class="sc">$</span>y[<span class="fu">match</span>(my_data<span class="sc">$</span>x[<span class="fu">which.min</span>(<span class="fu">abs</span>(my_data<span class="sc">$</span>x<span class="dv">-1</span>))], my_data<span class="sc">$</span>x)]<span class="co"># find y value</span></span>
<span id="cb126-6"><a href="non-linear-least-squares.html#cb126-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.4577</span></span></code></pre></div>
<p>hence we have</p>
<p><span class="math display">\[
1.457 = \frac{\theta_0 + \theta_1*0.9895}{1 + \theta_2 exp(0.4*0.9895)} \\
1.457 + 2.164479 *\theta_2 = \theta_0 + \theta_1*0.9895 \\
\theta_0 + \theta_1*0.9895 -  2.164479 *\theta_2 = 1.457
\]</span></p>
<p>with 3 equations, we can solve them to get the starting value for <span class="math inline">\(\theta_0,\theta_1, \theta_2\)</span></p>
<p><span class="math display">\[
\theta_0 + 0.0094 \theta_1 + 0 \theta_2 = 2.6722 \\
0 \theta_1 + 0 \theta_1 + 83.58967 \theta_2 = 1 \\
\theta_0 + \theta_1*0.9895 -  2.164479 *\theta_2 = 1.457
\]</span></p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="non-linear-least-squares.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(matlib) </span>
<span id="cb127-2"><a href="non-linear-least-squares.html#cb127-2" aria-hidden="true" tabindex="-1"></a>A <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.0094</span>, <span class="dv">0</span>, <span class="dv">0</span>,<span class="dv">0</span>, <span class="fl">83.58967</span>, <span class="dv">1</span>, <span class="fl">0.9895</span>, <span class="sc">-</span> <span class="fl">2.164479</span>), <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> T)</span>
<span id="cb127-3"><a href="non-linear-least-squares.html#cb127-3" aria-hidden="true" tabindex="-1"></a>b <span class="ot">=</span> <span class="fu">c</span>(<span class="fl">2.6722</span>,<span class="dv">1</span>,<span class="fl">1.457</span> )</span>
<span id="cb127-4"><a href="non-linear-least-squares.html#cb127-4" aria-hidden="true" tabindex="-1"></a><span class="fu">showEqn</span>(A, b)</span>
<span id="cb127-5"><a href="non-linear-least-squares.html#cb127-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0*x1 + 0.0094*x2        + 0*x3  =  2.6722 </span></span>
<span id="cb127-6"><a href="non-linear-least-squares.html#cb127-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 0*x1      + 0*x2 + 83.58967*x3  =       1 </span></span>
<span id="cb127-7"><a href="non-linear-least-squares.html#cb127-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1*x1 + 0.9895*x2 - 2.164479*x3  =   1.457</span></span>
<span id="cb127-8"><a href="non-linear-least-squares.html#cb127-8" aria-hidden="true" tabindex="-1"></a><span class="fu">Solve</span>(A, b, <span class="at">fractions =</span> F)</span>
<span id="cb127-9"><a href="non-linear-least-squares.html#cb127-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; x1      =  -279.80879739 </span></span>
<span id="cb127-10"><a href="non-linear-least-squares.html#cb127-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   x2    =   284.27659574 </span></span>
<span id="cb127-11"><a href="non-linear-least-squares.html#cb127-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;     x3  =      0.0119632</span></span></code></pre></div>
<p>Construct manually <a href="non-linear-least-squares.html#gauss-newton-algorithm">Gauss-Newton Algorithm</a></p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="non-linear-least-squares.html#cb128-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-2"><a href="non-linear-least-squares.html#cb128-2" aria-hidden="true" tabindex="-1"></a><span class="co">#starting value</span></span>
<span id="cb128-3"><a href="non-linear-least-squares.html#cb128-3" aria-hidden="true" tabindex="-1"></a>theta_0_strt <span class="ot">=</span> <span class="sc">-</span><span class="fl">279.80879739</span> </span>
<span id="cb128-4"><a href="non-linear-least-squares.html#cb128-4" aria-hidden="true" tabindex="-1"></a>theta_1_strt <span class="ot">=</span>  <span class="fl">284.27659574</span> </span>
<span id="cb128-5"><a href="non-linear-least-squares.html#cb128-5" aria-hidden="true" tabindex="-1"></a>theta_2_strt <span class="ot">=</span> <span class="fl">0.0119632</span> </span>
<span id="cb128-6"><a href="non-linear-least-squares.html#cb128-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-7"><a href="non-linear-least-squares.html#cb128-7" aria-hidden="true" tabindex="-1"></a><span class="co">#model</span></span>
<span id="cb128-8"><a href="non-linear-least-squares.html#cb128-8" aria-hidden="true" tabindex="-1"></a>mod_4 <span class="ot">=</span> <span class="cf">function</span>(theta_0,theta_1,theta_2,x){</span>
<span id="cb128-9"><a href="non-linear-least-squares.html#cb128-9" aria-hidden="true" tabindex="-1"></a>    (theta_0 <span class="sc">+</span> theta_1<span class="sc">*</span>x)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span> theta_2<span class="sc">*</span><span class="fu">exp</span>(<span class="fl">0.4</span><span class="sc">*</span>x))</span>
<span id="cb128-10"><a href="non-linear-least-squares.html#cb128-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb128-11"><a href="non-linear-least-squares.html#cb128-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-12"><a href="non-linear-least-squares.html#cb128-12" aria-hidden="true" tabindex="-1"></a><span class="co">#define a function</span></span>
<span id="cb128-13"><a href="non-linear-least-squares.html#cb128-13" aria-hidden="true" tabindex="-1"></a>f_4 <span class="ot">=</span> <span class="fu">expression</span>((theta_0 <span class="sc">+</span> theta_1<span class="sc">*</span>x)<span class="sc">/</span>(<span class="dv">1</span><span class="sc">+</span> theta_2<span class="sc">*</span><span class="fu">exp</span>(<span class="fl">0.4</span><span class="sc">*</span>x)))</span>
<span id="cb128-14"><a href="non-linear-least-squares.html#cb128-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-15"><a href="non-linear-least-squares.html#cb128-15" aria-hidden="true" tabindex="-1"></a><span class="co">#take the first derivative</span></span>
<span id="cb128-16"><a href="non-linear-least-squares.html#cb128-16" aria-hidden="true" tabindex="-1"></a>df_4.d_theta_0<span class="ot">=</span><span class="fu">D</span>(f_4,<span class="st">&#39;theta_0&#39;</span>)</span>
<span id="cb128-17"><a href="non-linear-least-squares.html#cb128-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-18"><a href="non-linear-least-squares.html#cb128-18" aria-hidden="true" tabindex="-1"></a>df_4.d_theta_1<span class="ot">=</span><span class="fu">D</span>(f_4,<span class="st">&#39;theta_1&#39;</span>)</span>
<span id="cb128-19"><a href="non-linear-least-squares.html#cb128-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-20"><a href="non-linear-least-squares.html#cb128-20" aria-hidden="true" tabindex="-1"></a>df_4.d_theta_2<span class="ot">=</span><span class="fu">D</span>(f_4,<span class="st">&#39;theta_2&#39;</span>)</span>
<span id="cb128-21"><a href="non-linear-least-squares.html#cb128-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-22"><a href="non-linear-least-squares.html#cb128-22" aria-hidden="true" tabindex="-1"></a><span class="co"># save the result of all iterations</span></span>
<span id="cb128-23"><a href="non-linear-least-squares.html#cb128-23" aria-hidden="true" tabindex="-1"></a>theta_vec <span class="ot">=</span> <span class="fu">matrix</span>(<span class="fu">c</span>(theta_0_strt,theta_1_strt,theta_2_strt))</span>
<span id="cb128-24"><a href="non-linear-least-squares.html#cb128-24" aria-hidden="true" tabindex="-1"></a>delta<span class="ot">=</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow=</span><span class="dv">3</span>,<span class="at">ncol =</span> <span class="dv">1</span>)</span>
<span id="cb128-25"><a href="non-linear-least-squares.html#cb128-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-26"><a href="non-linear-least-squares.html#cb128-26" aria-hidden="true" tabindex="-1"></a>f_theta <span class="ot">=</span> <span class="fu">as.matrix</span>(<span class="fu">eval</span>(f_4,<span class="fu">list</span>(<span class="at">x=</span>my_data<span class="sc">$</span>x,<span class="at">theta_0 =</span> theta_vec[<span class="dv">1</span>,<span class="dv">1</span>],<span class="at">theta_1 =</span> theta_vec[<span class="dv">2</span>,<span class="dv">1</span>],<span class="at">theta_2 =</span> theta_vec[<span class="dv">3</span>,<span class="dv">1</span>])))</span>
<span id="cb128-27"><a href="non-linear-least-squares.html#cb128-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-28"><a href="non-linear-least-squares.html#cb128-28" aria-hidden="true" tabindex="-1"></a>i <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb128-29"><a href="non-linear-least-squares.html#cb128-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-30"><a href="non-linear-least-squares.html#cb128-30" aria-hidden="true" tabindex="-1"></a><span class="cf">repeat</span> {</span>
<span id="cb128-31"><a href="non-linear-least-squares.html#cb128-31" aria-hidden="true" tabindex="-1"></a>    F_theta_0 <span class="ot">=</span> <span class="fu">as.matrix</span>(<span class="fu">cbind</span>(</span>
<span id="cb128-32"><a href="non-linear-least-squares.html#cb128-32" aria-hidden="true" tabindex="-1"></a>        <span class="fu">eval</span>(</span>
<span id="cb128-33"><a href="non-linear-least-squares.html#cb128-33" aria-hidden="true" tabindex="-1"></a>            df_4.d_theta_0,</span>
<span id="cb128-34"><a href="non-linear-least-squares.html#cb128-34" aria-hidden="true" tabindex="-1"></a>            <span class="fu">list</span>(</span>
<span id="cb128-35"><a href="non-linear-least-squares.html#cb128-35" aria-hidden="true" tabindex="-1"></a>                <span class="at">x =</span> my_data<span class="sc">$</span>x,</span>
<span id="cb128-36"><a href="non-linear-least-squares.html#cb128-36" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_0 =</span> theta_vec[<span class="dv">1</span>, i],</span>
<span id="cb128-37"><a href="non-linear-least-squares.html#cb128-37" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_1 =</span> theta_vec[<span class="dv">2</span>, i],</span>
<span id="cb128-38"><a href="non-linear-least-squares.html#cb128-38" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_2 =</span> theta_vec[<span class="dv">3</span>, i]</span>
<span id="cb128-39"><a href="non-linear-least-squares.html#cb128-39" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb128-40"><a href="non-linear-least-squares.html#cb128-40" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb128-41"><a href="non-linear-least-squares.html#cb128-41" aria-hidden="true" tabindex="-1"></a>        <span class="fu">eval</span>(</span>
<span id="cb128-42"><a href="non-linear-least-squares.html#cb128-42" aria-hidden="true" tabindex="-1"></a>            df_4.d_theta_1,</span>
<span id="cb128-43"><a href="non-linear-least-squares.html#cb128-43" aria-hidden="true" tabindex="-1"></a>            <span class="fu">list</span>(</span>
<span id="cb128-44"><a href="non-linear-least-squares.html#cb128-44" aria-hidden="true" tabindex="-1"></a>                <span class="at">x =</span> my_data<span class="sc">$</span>x,</span>
<span id="cb128-45"><a href="non-linear-least-squares.html#cb128-45" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_0 =</span> theta_vec[<span class="dv">1</span>, i],</span>
<span id="cb128-46"><a href="non-linear-least-squares.html#cb128-46" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_1 =</span> theta_vec[<span class="dv">2</span>, i],</span>
<span id="cb128-47"><a href="non-linear-least-squares.html#cb128-47" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_2 =</span> theta_vec[<span class="dv">3</span>, i]</span>
<span id="cb128-48"><a href="non-linear-least-squares.html#cb128-48" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb128-49"><a href="non-linear-least-squares.html#cb128-49" aria-hidden="true" tabindex="-1"></a>        ),</span>
<span id="cb128-50"><a href="non-linear-least-squares.html#cb128-50" aria-hidden="true" tabindex="-1"></a>        <span class="fu">eval</span>(</span>
<span id="cb128-51"><a href="non-linear-least-squares.html#cb128-51" aria-hidden="true" tabindex="-1"></a>            df_4.d_theta_2,</span>
<span id="cb128-52"><a href="non-linear-least-squares.html#cb128-52" aria-hidden="true" tabindex="-1"></a>            <span class="fu">list</span>(</span>
<span id="cb128-53"><a href="non-linear-least-squares.html#cb128-53" aria-hidden="true" tabindex="-1"></a>                <span class="at">x =</span> my_data<span class="sc">$</span>x,</span>
<span id="cb128-54"><a href="non-linear-least-squares.html#cb128-54" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_0 =</span> theta_vec[<span class="dv">1</span>, i],</span>
<span id="cb128-55"><a href="non-linear-least-squares.html#cb128-55" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_1 =</span> theta_vec[<span class="dv">2</span>, i],</span>
<span id="cb128-56"><a href="non-linear-least-squares.html#cb128-56" aria-hidden="true" tabindex="-1"></a>                <span class="at">theta_2 =</span> theta_vec[<span class="dv">3</span>, i]</span>
<span id="cb128-57"><a href="non-linear-least-squares.html#cb128-57" aria-hidden="true" tabindex="-1"></a>            )</span>
<span id="cb128-58"><a href="non-linear-least-squares.html#cb128-58" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb128-59"><a href="non-linear-least-squares.html#cb128-59" aria-hidden="true" tabindex="-1"></a>    ))</span>
<span id="cb128-60"><a href="non-linear-least-squares.html#cb128-60" aria-hidden="true" tabindex="-1"></a>    delta[, i] <span class="ot">=</span> (<span class="fu">solve</span>(<span class="fu">t</span>(F_theta_0) <span class="sc">%*%</span> F_theta_0)) <span class="sc">%*%</span> <span class="fu">t</span>(F_theta_0) <span class="sc">%*%</span> (my_data<span class="sc">$</span>y <span class="sc">-</span> f_theta[,i])</span>
<span id="cb128-61"><a href="non-linear-least-squares.html#cb128-61" aria-hidden="true" tabindex="-1"></a>    theta_vec <span class="ot">=</span> <span class="fu">cbind</span>(theta_vec, <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">1</span>))</span>
<span id="cb128-62"><a href="non-linear-least-squares.html#cb128-62" aria-hidden="true" tabindex="-1"></a>    theta_vec[, i<span class="sc">+</span><span class="dv">1</span>] <span class="ot">=</span> theta_vec[, i] <span class="sc">+</span> delta[, i]</span>
<span id="cb128-63"><a href="non-linear-least-squares.html#cb128-63" aria-hidden="true" tabindex="-1"></a>    i <span class="ot">=</span> i <span class="sc">+</span> <span class="dv">1</span></span>
<span id="cb128-64"><a href="non-linear-least-squares.html#cb128-64" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb128-65"><a href="non-linear-least-squares.html#cb128-65" aria-hidden="true" tabindex="-1"></a>    f_theta <span class="ot">=</span> <span class="fu">cbind</span>(f_theta, <span class="fu">as.matrix</span>(<span class="fu">eval</span>(</span>
<span id="cb128-66"><a href="non-linear-least-squares.html#cb128-66" aria-hidden="true" tabindex="-1"></a>        f_4,</span>
<span id="cb128-67"><a href="non-linear-least-squares.html#cb128-67" aria-hidden="true" tabindex="-1"></a>        <span class="fu">list</span>(</span>
<span id="cb128-68"><a href="non-linear-least-squares.html#cb128-68" aria-hidden="true" tabindex="-1"></a>            <span class="at">x =</span> my_data<span class="sc">$</span>x,</span>
<span id="cb128-69"><a href="non-linear-least-squares.html#cb128-69" aria-hidden="true" tabindex="-1"></a>            <span class="at">theta_0 =</span> theta_vec[<span class="dv">1</span>, i],</span>
<span id="cb128-70"><a href="non-linear-least-squares.html#cb128-70" aria-hidden="true" tabindex="-1"></a>            <span class="at">theta_1 =</span> theta_vec[<span class="dv">2</span>, i],</span>
<span id="cb128-71"><a href="non-linear-least-squares.html#cb128-71" aria-hidden="true" tabindex="-1"></a>            <span class="at">theta_2 =</span> theta_vec[<span class="dv">3</span>, i]</span>
<span id="cb128-72"><a href="non-linear-least-squares.html#cb128-72" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb128-73"><a href="non-linear-least-squares.html#cb128-73" aria-hidden="true" tabindex="-1"></a>    )))</span>
<span id="cb128-74"><a href="non-linear-least-squares.html#cb128-74" aria-hidden="true" tabindex="-1"></a>    delta <span class="ot">=</span> <span class="fu">cbind</span>(delta, <span class="fu">matrix</span>(<span class="cn">NA</span>, <span class="at">nrow =</span> <span class="dv">3</span>, <span class="at">ncol =</span> <span class="dv">1</span>))</span>
<span id="cb128-75"><a href="non-linear-least-squares.html#cb128-75" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb128-76"><a href="non-linear-least-squares.html#cb128-76" aria-hidden="true" tabindex="-1"></a>    <span class="co">#convergence criteria based on SSE</span></span>
<span id="cb128-77"><a href="non-linear-least-squares.html#cb128-77" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">abs</span>(<span class="fu">sum</span>((my_data<span class="sc">$</span>y <span class="sc">-</span> f_theta[,i])<span class="sc">^</span><span class="dv">2</span>)<span class="sc">-</span><span class="fu">sum</span>((my_data<span class="sc">$</span>y <span class="sc">-</span> f_theta[,i<span class="dv">-1</span>])<span class="sc">^</span><span class="dv">2</span>))<span class="sc">/</span>(<span class="fu">sum</span>((my_data<span class="sc">$</span>y <span class="sc">-</span> f_theta[,i<span class="dv">-1</span>])<span class="sc">^</span><span class="dv">2</span>))<span class="sc">&lt;</span><span class="fl">0.001</span>){</span>
<span id="cb128-78"><a href="non-linear-least-squares.html#cb128-78" aria-hidden="true" tabindex="-1"></a>        <span class="cf">break</span></span>
<span id="cb128-79"><a href="non-linear-least-squares.html#cb128-79" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb128-80"><a href="non-linear-least-squares.html#cb128-80" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb128-81"><a href="non-linear-least-squares.html#cb128-81" aria-hidden="true" tabindex="-1"></a>delta</span>
<span id="cb128-82"><a href="non-linear-least-squares.html#cb128-82" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               [,1]        [,2]        [,3]       [,4]       [,5]       [,6]</span></span>
<span id="cb128-83"><a href="non-linear-least-squares.html#cb128-83" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  2.811840e+02 -0.03929013  0.43160654  0.6904856  0.6746748  0.4056460</span></span>
<span id="cb128-84"><a href="non-linear-least-squares.html#cb128-84" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] -2.846545e+02  0.03198446 -0.16403964 -0.2895487 -0.2933345 -0.1734087</span></span>
<span id="cb128-85"><a href="non-linear-least-squares.html#cb128-85" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,] -1.804567e-05  0.01530258  0.05137285  0.1183271  0.1613129  0.1160404</span></span>
<span id="cb128-86"><a href="non-linear-least-squares.html#cb128-86" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             [,7] [,8]</span></span>
<span id="cb128-87"><a href="non-linear-least-squares.html#cb128-87" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  0.09517681   NA</span></span>
<span id="cb128-88"><a href="non-linear-least-squares.html#cb128-88" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] -0.03928239   NA</span></span>
<span id="cb128-89"><a href="non-linear-least-squares.html#cb128-89" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]  0.03004911   NA</span></span>
<span id="cb128-90"><a href="non-linear-least-squares.html#cb128-90" aria-hidden="true" tabindex="-1"></a>theta_vec</span>
<span id="cb128-91"><a href="non-linear-least-squares.html#cb128-91" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;              [,1]        [,2]        [,3]        [,4]       [,5]       [,6]</span></span>
<span id="cb128-92"><a href="non-linear-least-squares.html#cb128-92" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,] -279.8087974  1.37521388  1.33592375  1.76753029  2.4580158  3.1326907</span></span>
<span id="cb128-93"><a href="non-linear-least-squares.html#cb128-93" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,]  284.2765957 -0.37788712 -0.34590266 -0.50994230 -0.7994910 -1.0928255</span></span>
<span id="cb128-94"><a href="non-linear-least-squares.html#cb128-94" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]    0.0119632  0.01194515  0.02724773  0.07862059  0.1969477  0.3582607</span></span>
<span id="cb128-95"><a href="non-linear-least-squares.html#cb128-95" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            [,7]       [,8]</span></span>
<span id="cb128-96"><a href="non-linear-least-squares.html#cb128-96" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  3.5383367  3.6335135</span></span>
<span id="cb128-97"><a href="non-linear-least-squares.html#cb128-97" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] -1.2662342 -1.3055166</span></span>
<span id="cb128-98"><a href="non-linear-least-squares.html#cb128-98" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]  0.4743011  0.5043502</span></span>
<span id="cb128-99"><a href="non-linear-least-squares.html#cb128-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-100"><a href="non-linear-least-squares.html#cb128-100" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(f_theta)</span>
<span id="cb128-101"><a href="non-linear-least-squares.html#cb128-101" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]     [,8]</span></span>
<span id="cb128-102"><a href="non-linear-least-squares.html#cb128-102" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,] -273.8482 1.355410 1.297194 1.633802 2.046023 2.296554 2.389041 2.404144</span></span>
<span id="cb128-103"><a href="non-linear-least-squares.html#cb128-103" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] -209.0859 1.268192 1.216738 1.514575 1.863098 2.059505 2.126009 2.135969</span></span>
<span id="cb128-104"><a href="non-linear-least-squares.html#cb128-104" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,] -190.3323 1.242916 1.193433 1.480136 1.810629 1.992095 2.051603 2.060202</span></span>
<span id="cb128-105"><a href="non-linear-least-squares.html#cb128-105" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4,] -177.1891 1.225196 1.177099 1.456024 1.774000 1.945197 1.999945 2.007625</span></span>
<span id="cb128-106"><a href="non-linear-least-squares.html#cb128-106" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [5,] -148.5872 1.186618 1.141549 1.403631 1.694715 1.844154 1.888953 1.894730</span></span>
<span id="cb128-107"><a href="non-linear-least-squares.html#cb128-107" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [6,] -119.9585 1.147980 1.105961 1.351301 1.615968 1.744450 1.779859 1.783866</span></span>
<span id="cb128-108"><a href="non-linear-least-squares.html#cb128-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-109"><a href="non-linear-least-squares.html#cb128-109" aria-hidden="true" tabindex="-1"></a><span class="co"># estimate sigma^2 </span></span>
<span id="cb128-110"><a href="non-linear-least-squares.html#cb128-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb128-111"><a href="non-linear-least-squares.html#cb128-111" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">=</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="fu">nrow</span>(my_data) <span class="sc">-</span> <span class="dv">3</span>) <span class="sc">*</span> (<span class="fu">t</span>(my_data<span class="sc">$</span>y <span class="sc">-</span> (f_theta[, <span class="fu">ncol</span>(f_theta)]))) <span class="sc">%*%</span></span>
<span id="cb128-112"><a href="non-linear-least-squares.html#cb128-112" aria-hidden="true" tabindex="-1"></a>    (my_data<span class="sc">$</span>y <span class="sc">-</span> (f_theta[, <span class="fu">ncol</span>(f_theta)])) <span class="co"># p = 3</span></span>
<span id="cb128-113"><a href="non-linear-least-squares.html#cb128-113" aria-hidden="true" tabindex="-1"></a>sigma2</span>
<span id="cb128-114"><a href="non-linear-least-squares.html#cb128-114" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;           [,1]</span></span>
<span id="cb128-115"><a href="non-linear-least-squares.html#cb128-115" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,] 0.0801686</span></span></code></pre></div>
<p>After 8 iterations, my function has converged. And objective function value at convergence is</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="non-linear-least-squares.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>((my_data<span class="sc">$</span>y <span class="sc">-</span> f_theta[,i])<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb129-2"><a href="non-linear-least-squares.html#cb129-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 19.80165</span></span></code></pre></div>
<p>and the parameters of <span class="math inline">\(\theta\)</span>s are</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="non-linear-least-squares.html#cb130-1" aria-hidden="true" tabindex="-1"></a>theta_vec[,<span class="fu">ncol</span>(theta_vec)]</span>
<span id="cb130-2"><a href="non-linear-least-squares.html#cb130-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1]  3.6335135 -1.3055166  0.5043502</span></span></code></pre></div>
<p>and the asymptotic variance covariance matrix is</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="non-linear-least-squares.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">as.numeric</span>(sigma2)<span class="sc">*</span><span class="fu">as.matrix</span>(<span class="fu">solve</span>(<span class="fu">crossprod</span>(F_theta_0)))</span>
<span id="cb131-2"><a href="non-linear-least-squares.html#cb131-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             [,1]        [,2]        [,3]</span></span>
<span id="cb131-3"><a href="non-linear-least-squares.html#cb131-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,]  0.11552571 -0.04817428  0.02685848</span></span>
<span id="cb131-4"><a href="non-linear-least-squares.html#cb131-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] -0.04817428  0.02100861 -0.01158212</span></span>
<span id="cb131-5"><a href="non-linear-least-squares.html#cb131-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,]  0.02685848 -0.01158212  0.00703916</span></span></code></pre></div>
<p>Issue that I encounter in this problem was that it was very sensitive to starting values. when I tried the value of 1 for all <span class="math inline">\(\theta\)</span>s, I have vastly different parameter estimates. Then, I try to use the model interpretation to try to find reasonable starting values.</p>
<p>Check with predefined function in nls</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="non-linear-least-squares.html#cb132-1" aria-hidden="true" tabindex="-1"></a>nlin_4 <span class="ot">=</span> <span class="fu">nls</span>(y <span class="sc">~</span> <span class="fu">mod_4</span>(theta_0,theta_1, theta_2, x), <span class="at">start =</span> <span class="fu">list</span>(<span class="at">theta_0=</span><span class="sc">-</span><span class="fl">279.80879739</span> ,<span class="at">theta_1=</span><span class="fl">284.27659574</span> , <span class="at">theta_2=</span><span class="fl">0.0119632</span>), <span class="at">data =</span> my_data)</span>
<span id="cb132-2"><a href="non-linear-least-squares.html#cb132-2" aria-hidden="true" tabindex="-1"></a>nlin_4</span>
<span id="cb132-3"><a href="non-linear-least-squares.html#cb132-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Nonlinear regression model</span></span>
<span id="cb132-4"><a href="non-linear-least-squares.html#cb132-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   model: y ~ mod_4(theta_0, theta_1, theta_2, x)</span></span>
<span id="cb132-5"><a href="non-linear-least-squares.html#cb132-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    data: my_data</span></span>
<span id="cb132-6"><a href="non-linear-least-squares.html#cb132-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; theta_0 theta_1 theta_2 </span></span>
<span id="cb132-7"><a href="non-linear-least-squares.html#cb132-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3.6359 -1.3064  0.5053 </span></span>
<span id="cb132-8"><a href="non-linear-least-squares.html#cb132-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  residual sum-of-squares: 19.8</span></span>
<span id="cb132-9"><a href="non-linear-least-squares.html#cb132-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb132-10"><a href="non-linear-least-squares.html#cb132-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Number of iterations to convergence: 9 </span></span>
<span id="cb132-11"><a href="non-linear-least-squares.html#cb132-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Achieved convergence tolerance: 2.294e-07</span></span></code></pre></div>

</div>
</div>
<!-- </div> -->
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Bates_1980" class="csl-entry">
Bates, Douglas M., and Donald G. Watts. 1980. <span>“Relative Curvature Measures of Nonlinearity.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 42 (1): 1–16. <a href="https://doi.org/10.1111/j.2517-6161.1980.tb01094.x">https://doi.org/10.1111/j.2517-6161.1980.tb01094.x</a>.
</div>
<div id="ref-Bates_1981" class="csl-entry">
———. 1981. <span>“A Relative Offset Orthogonality Convergence Criterion for Nonlinear Least Squares.”</span> <em>Technometrics</em> 23 (2): 179. <a href="https://doi.org/10.2307/1268035">https://doi.org/10.2307/1268035</a>.
</div>
<div id="ref-Laurent_1992" class="csl-entry">
Laurent, Roy T. St., and R. Dennis Cook. 1992. <span>“Leverage and Superleverage in Nonlinear Regression.”</span> <em>Journal of the American Statistical Association</em> 87 (420): 985. <a href="https://doi.org/10.2307/2290635">https://doi.org/10.2307/2290635</a>.
</div>
<div id="ref-Magel_1987" class="csl-entry">
Magel, Rhonda C., and Doris Hertsgaard. 1987. <span>“A Collinearity Diagnostic for Nonlinear Regression.”</span> <em>Communications in Statistics - Simulation and Computation</em> 16 (1): 85–97. <a href="https://doi.org/10.1080/03610918708812579">https://doi.org/10.1080/03610918708812579</a>.
</div>
<div id="ref-Schabenberger_2001" class="csl-entry">
Schabenberger, Oliver, and Francis J. Pierce. 2001. <em>Contemporary Statistical Models for the Plant and Soil Sciences</em>. <span>CRC</span> Press. <a href="https://doi.org/10.1201/9781420040197">https://doi.org/10.1201/9781420040197</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="inference-1.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="generalized-linear-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/06-nonlinear-regession.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": "https://github.com/mikenguyen13/data_analysis/blob/main/06-nonlinear-regession.Rmd",
"text": null
},
"download": ["data_analysis.pdf", "data_analysis.epub", "data_analysis.mobi"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": "https://github.com/mikenguyen13/data_analysis/edit/main/%s"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
