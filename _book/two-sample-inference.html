<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.2 Two Sample Inference | A Guide on Data Analysis</title>
  <meta name="description" content="This is a guide on how to conduct a data analysis routine" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4.2 Two Sample Inference | A Guide on Data Analysis" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a guide on how to conduct a data analysis routine" />
  <meta name="github-repo" content="mikenguyen13/data_analysis" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.2 Two Sample Inference | A Guide on Data Analysis" />
  
  <meta name="twitter:description" content="This is a guide on how to conduct a data analysis routine" />
  

<meta name="author" content="Mike Nguyen" />


<meta name="date" content="2021-02-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="one-sample-inference.html"/>
<link rel="next" href="categorical-data-analysis.html"/>
<script src="libs/jquery-3.5.0/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/proj4js-2.3.15/proj4.js"></script>
<link href="libs/highcharts-8.1.2/css/motion.css" rel="stylesheet" />
<script src="libs/highcharts-8.1.2/highcharts.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-3d.js"></script>
<script src="libs/highcharts-8.1.2/highcharts-more.js"></script>
<script src="libs/highcharts-8.1.2/modules/stock.js"></script>
<script src="libs/highcharts-8.1.2/modules/map.js"></script>
<script src="libs/highcharts-8.1.2/modules/annotations.js"></script>
<script src="libs/highcharts-8.1.2/modules/data.js"></script>
<script src="libs/highcharts-8.1.2/modules/drilldown.js"></script>
<script src="libs/highcharts-8.1.2/modules/item-series.js"></script>
<script src="libs/highcharts-8.1.2/modules/offline-exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/overlapping-datalabels.js"></script>
<script src="libs/highcharts-8.1.2/modules/exporting.js"></script>
<script src="libs/highcharts-8.1.2/modules/export-data.js"></script>
<script src="libs/highcharts-8.1.2/modules/funnel.js"></script>
<script src="libs/highcharts-8.1.2/modules/heatmap.js"></script>
<script src="libs/highcharts-8.1.2/modules/treemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/sankey.js"></script>
<script src="libs/highcharts-8.1.2/modules/dependency-wheel.js"></script>
<script src="libs/highcharts-8.1.2/modules/organization.js"></script>
<script src="libs/highcharts-8.1.2/modules/solid-gauge.js"></script>
<script src="libs/highcharts-8.1.2/modules/streamgraph.js"></script>
<script src="libs/highcharts-8.1.2/modules/sunburst.js"></script>
<script src="libs/highcharts-8.1.2/modules/vector.js"></script>
<script src="libs/highcharts-8.1.2/modules/wordcloud.js"></script>
<script src="libs/highcharts-8.1.2/modules/xrange.js"></script>
<script src="libs/highcharts-8.1.2/modules/tilemap.js"></script>
<script src="libs/highcharts-8.1.2/modules/venn.js"></script>
<script src="libs/highcharts-8.1.2/modules/gantt.js"></script>
<script src="libs/highcharts-8.1.2/modules/timeline.js"></script>
<script src="libs/highcharts-8.1.2/modules/parallel-coordinates.js"></script>
<script src="libs/highcharts-8.1.2/modules/bullet.js"></script>
<script src="libs/highcharts-8.1.2/modules/coloraxis.js"></script>
<script src="libs/highcharts-8.1.2/modules/dumbbell.js"></script>
<script src="libs/highcharts-8.1.2/modules/lollipop.js"></script>
<script src="libs/highcharts-8.1.2/modules/series-label.js"></script>
<script src="libs/highcharts-8.1.2/plugins/motion.js"></script>
<script src="libs/highcharts-8.1.2/custom/reset.js"></script>
<script src="libs/highcharts-8.1.2/modules/boost.js"></script>
<script src="libs/highchart-binding-0.8.2/highchart.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">A Guide on Data Analysis</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="prerequisites.html"><a href="prerequisites.html"><i class="fa fa-check"></i><b>2</b> Prerequisites</a><ul>
<li class="chapter" data-level="2.1" data-path="matrix-theory.html"><a href="matrix-theory.html"><i class="fa fa-check"></i><b>2.1</b> Matrix Theory</a><ul>
<li class="chapter" data-level="2.1.1" data-path="matrix-theory.html"><a href="matrix-theory.html#rank"><i class="fa fa-check"></i><b>2.1.1</b> Rank</a></li>
<li class="chapter" data-level="2.1.2" data-path="matrix-theory.html"><a href="matrix-theory.html#inverse"><i class="fa fa-check"></i><b>2.1.2</b> Inverse</a></li>
<li class="chapter" data-level="2.1.3" data-path="matrix-theory.html"><a href="matrix-theory.html#definiteness"><i class="fa fa-check"></i><b>2.1.3</b> Definiteness</a></li>
<li class="chapter" data-level="2.1.4" data-path="matrix-theory.html"><a href="matrix-theory.html#matrix-calculus"><i class="fa fa-check"></i><b>2.1.4</b> Matrix Calculus</a></li>
<li class="chapter" data-level="2.1.5" data-path="matrix-theory.html"><a href="matrix-theory.html#optimization"><i class="fa fa-check"></i><b>2.1.5</b> Optimization</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="probability-theory.html"><a href="probability-theory.html"><i class="fa fa-check"></i><b>2.2</b> Probability Theory</a><ul>
<li class="chapter" data-level="2.2.1" data-path="probability-theory.html"><a href="probability-theory.html#axiom-and-theorems-of-probability"><i class="fa fa-check"></i><b>2.2.1</b> Axiom and Theorems of Probability</a></li>
<li class="chapter" data-level="2.2.2" data-path="probability-theory.html"><a href="probability-theory.html#central-limit-theorem"><i class="fa fa-check"></i><b>2.2.2</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="2.2.3" data-path="probability-theory.html"><a href="probability-theory.html#random-variable"><i class="fa fa-check"></i><b>2.2.3</b> Random variable</a></li>
<li class="chapter" data-level="2.2.4" data-path="probability-theory.html"><a href="probability-theory.html#moment-generating-function"><i class="fa fa-check"></i><b>2.2.4</b> Moment generating function</a></li>
<li class="chapter" data-level="2.2.5" data-path="probability-theory.html"><a href="probability-theory.html#moment"><i class="fa fa-check"></i><b>2.2.5</b> Moment</a></li>
<li class="chapter" data-level="2.2.6" data-path="probability-theory.html"><a href="probability-theory.html#distributions"><i class="fa fa-check"></i><b>2.2.6</b> Distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="general-math.html"><a href="general-math.html"><i class="fa fa-check"></i><b>2.3</b> General Math</a><ul>
<li class="chapter" data-level="2.3.1" data-path="general-math.html"><a href="general-math.html#law-of-large-numbers"><i class="fa fa-check"></i><b>2.3.1</b> Law of large numbers</a></li>
<li class="chapter" data-level="2.3.2" data-path="general-math.html"><a href="general-math.html#law-of-iterated-expectation"><i class="fa fa-check"></i><b>2.3.2</b> Law of Iterated Expectation</a></li>
<li class="chapter" data-level="2.3.3" data-path="general-math.html"><a href="general-math.html#convergence"><i class="fa fa-check"></i><b>2.3.3</b> Convergence</a></li>
<li class="chapter" data-level="2.3.4" data-path="general-math.html"><a href="general-math.html#sufficient-statistics"><i class="fa fa-check"></i><b>2.3.4</b> Sufficient Statistics</a></li>
<li class="chapter" data-level="2.3.5" data-path="general-math.html"><a href="general-math.html#parameter-transformations"><i class="fa fa-check"></i><b>2.3.5</b> Parameter transformations</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="methods.html"><a href="methods.html"><i class="fa fa-check"></i><b>2.4</b> Methods</a></li>
<li class="chapter" data-level="2.5" data-path="data-manipulation.html"><a href="data-manipulation.html"><i class="fa fa-check"></i><b>2.5</b> Data Manipulation</a></li>
</ul></li>
<li class="part"><span><b>I BASIC</b></span></li>
<li class="chapter" data-level="3" data-path="descriptive-stat.html"><a href="descriptive-stat.html"><i class="fa fa-check"></i><b>3</b> Descriptive Statistics</a><ul>
<li class="chapter" data-level="3.1" data-path="numerical-measures.html"><a href="numerical-measures.html"><i class="fa fa-check"></i><b>3.1</b> Numerical Measures</a></li>
<li class="chapter" data-level="3.2" data-path="graphical-measures.html"><a href="graphical-measures.html"><i class="fa fa-check"></i><b>3.2</b> Graphical Measures</a><ul>
<li class="chapter" data-level="3.2.1" data-path="graphical-measures.html"><a href="graphical-measures.html#shape"><i class="fa fa-check"></i><b>3.2.1</b> Shape</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="normality-assessment.html"><a href="normality-assessment.html"><i class="fa fa-check"></i><b>3.3</b> Normality Assessment</a><ul>
<li class="chapter" data-level="3.3.1" data-path="normality-assessment.html"><a href="normality-assessment.html#graphical-assessment"><i class="fa fa-check"></i><b>3.3.1</b> Graphical Assessment</a></li>
<li class="chapter" data-level="3.3.2" data-path="normality-assessment.html"><a href="normality-assessment.html#summary-statistics"><i class="fa fa-check"></i><b>3.3.2</b> Summary Statistics</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="basic-statistical-inference.html"><a href="basic-statistical-inference.html"><i class="fa fa-check"></i><b>4</b> Basic Statistical Inference</a><ul>
<li class="chapter" data-level="4.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html"><i class="fa fa-check"></i><b>4.1</b> One Sample Inference</a><ul>
<li class="chapter" data-level="4.1.1" data-path="one-sample-inference.html"><a href="one-sample-inference.html#the-mean"><i class="fa fa-check"></i><b>4.1.1</b> The Mean</a></li>
<li class="chapter" data-level="4.1.2" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-variance"><i class="fa fa-check"></i><b>4.1.2</b> Single Variance</a></li>
<li class="chapter" data-level="4.1.3" data-path="one-sample-inference.html"><a href="one-sample-inference.html#single-proportion-p"><i class="fa fa-check"></i><b>4.1.3</b> Single Proportion (p)</a></li>
<li class="chapter" data-level="4.1.4" data-path="one-sample-inference.html"><a href="one-sample-inference.html#power"><i class="fa fa-check"></i><b>4.1.4</b> Power</a></li>
<li class="chapter" data-level="4.1.5" data-path="one-sample-inference.html"><a href="one-sample-inference.html#sample-size"><i class="fa fa-check"></i><b>4.1.5</b> Sample Size</a></li>
<li class="chapter" data-level="4.1.6" data-path="one-sample-inference.html"><a href="one-sample-inference.html#note"><i class="fa fa-check"></i><b>4.1.6</b> Note</a></li>
<li class="chapter" data-level="4.1.7" data-path="one-sample-inference.html"><a href="one-sample-inference.html#one-sample-non-parametric-methods"><i class="fa fa-check"></i><b>4.1.7</b> One-sample Non-parametric Methods</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html"><i class="fa fa-check"></i><b>4.2</b> Two Sample Inference</a><ul>
<li class="chapter" data-level="4.2.1" data-path="two-sample-inference.html"><a href="two-sample-inference.html#means"><i class="fa fa-check"></i><b>4.2.1</b> Means</a></li>
<li class="chapter" data-level="4.2.2" data-path="two-sample-inference.html"><a href="two-sample-inference.html#variances"><i class="fa fa-check"></i><b>4.2.2</b> Variances</a></li>
<li class="chapter" data-level="4.2.3" data-path="two-sample-inference.html"><a href="two-sample-inference.html#power-1"><i class="fa fa-check"></i><b>4.2.3</b> Power</a></li>
<li class="chapter" data-level="4.2.4" data-path="two-sample-inference.html"><a href="two-sample-inference.html#sample-size-1"><i class="fa fa-check"></i><b>4.2.4</b> Sample Size</a></li>
<li class="chapter" data-level="4.2.5" data-path="two-sample-inference.html"><a href="two-sample-inference.html#matched-pair-designs"><i class="fa fa-check"></i><b>4.2.5</b> Matched Pair Designs</a></li>
<li class="chapter" data-level="4.2.6" data-path="two-sample-inference.html"><a href="two-sample-inference.html#nonparametric-tests-for-two-samples"><i class="fa fa-check"></i><b>4.2.6</b> Nonparametric Tests for Two Samples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html"><i class="fa fa-check"></i><b>4.3</b> Categorical Data Analysis</a><ul>
<li class="chapter" data-level="4.3.1" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#inferences-for-small-samples"><i class="fa fa-check"></i><b>4.3.1</b> Inferences for Small Samples</a></li>
<li class="chapter" data-level="4.3.2" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#test-of-association"><i class="fa fa-check"></i><b>4.3.2</b> Test of Association</a></li>
<li class="chapter" data-level="4.3.3" data-path="categorical-data-analysis.html"><a href="categorical-data-analysis.html#ordinal-association"><i class="fa fa-check"></i><b>4.3.3</b> Ordinal Association</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II REGRESSION</b></span></li>
<li class="chapter" data-level="5" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>5</b> Linear Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>5.1</b> Ordinary Least Squares</a><ul>
<li class="chapter" data-level="5.1.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#simple-regression-basic-model"><i class="fa fa-check"></i><b>5.1.1</b> Simple Regression (Basic Model)</a></li>
<li class="chapter" data-level="5.1.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#multiple-linear-regression"><i class="fa fa-check"></i><b>5.1.2</b> Multiple Linear Regression</a></li>
<li class="chapter" data-level="5.1.3" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#ols-assumptions"><i class="fa fa-check"></i><b>5.1.3</b> OLS Assumptions</a></li>
<li class="chapter" data-level="5.1.4" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#theorems"><i class="fa fa-check"></i><b>5.1.4</b> Theorems</a></li>
<li class="chapter" data-level="5.1.5" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#variable-selection"><i class="fa fa-check"></i><b>5.1.5</b> Variable Selection</a></li>
<li class="chapter" data-level="5.1.6" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#diagnostics-1"><i class="fa fa-check"></i><b>5.1.6</b> Diagnostics</a></li>
<li class="chapter" data-level="5.1.7" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#model-validation"><i class="fa fa-check"></i><b>5.1.7</b> Model Validation</a></li>
<li class="chapter" data-level="5.1.8" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#finite-sample-properties"><i class="fa fa-check"></i><b>5.1.8</b> Finite Sample Properties</a></li>
<li class="chapter" data-level="5.1.9" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#large-sample-properties"><i class="fa fa-check"></i><b>5.1.9</b> Large Sample Properties</a></li>
<li class="chapter" data-level="5.1.10" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#application"><i class="fa fa-check"></i><b>5.1.10</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html"><i class="fa fa-check"></i><b>5.2</b> Feasible Generalized Least Squares</a><ul>
<li class="chapter" data-level="5.2.1" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#heteroskedasticity"><i class="fa fa-check"></i><b>5.2.1</b> Heteroskedasticity</a></li>
<li class="chapter" data-level="5.2.2" data-path="feasible-generalized-least-squares.html"><a href="feasible-generalized-least-squares.html#serial-correlation"><i class="fa fa-check"></i><b>5.2.2</b> Serial Correlation</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="weighted-least-squares.html"><a href="weighted-least-squares.html"><i class="fa fa-check"></i><b>5.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.4" data-path="generalized-least-squares.html"><a href="generalized-least-squares.html"><i class="fa fa-check"></i><b>5.4</b> Generalized Least Squares</a></li>
<li class="chapter" data-level="5.5" data-path="feasiable-prais-winsten.html"><a href="feasiable-prais-winsten.html"><i class="fa fa-check"></i><b>5.5</b> Feasiable Prais Winsten</a></li>
<li class="chapter" data-level="5.6" data-path="feasible-group-level-random-effects.html"><a href="feasible-group-level-random-effects.html"><i class="fa fa-check"></i><b>5.6</b> Feasible group level Random Effects</a></li>
<li class="chapter" data-level="5.7" data-path="ridge-regression.html"><a href="ridge-regression.html"><i class="fa fa-check"></i><b>5.7</b> Ridge Regression</a></li>
<li class="chapter" data-level="5.8" data-path="principal-component-regression.html"><a href="principal-component-regression.html"><i class="fa fa-check"></i><b>5.8</b> Principal Component Regression</a></li>
<li class="chapter" data-level="5.9" data-path="robust-regression.html"><a href="robust-regression.html"><i class="fa fa-check"></i><b>5.9</b> Robust Regression</a><ul>
<li class="chapter" data-level="5.9.1" data-path="robust-regression.html"><a href="robust-regression.html#least-absolute-residuals-lar-regression"><i class="fa fa-check"></i><b>5.9.1</b> Least Absolute Residuals (LAR) Regression</a></li>
<li class="chapter" data-level="5.9.2" data-path="robust-regression.html"><a href="robust-regression.html#least-median-of-squares-lms-regression"><i class="fa fa-check"></i><b>5.9.2</b> Least Median of Squares (LMS) Regression</a></li>
<li class="chapter" data-level="5.9.3" data-path="robust-regression.html"><a href="robust-regression.html#iteratively-reweighted-least-squares-irls-robust-regression"><i class="fa fa-check"></i><b>5.9.3</b> Iteratively Reweighted Least Squares (IRLS) Robust Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>5.10</b> Maximum Likelihood</a><ul>
<li class="chapter" data-level="5.10.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#motivation-for-mle"><i class="fa fa-check"></i><b>5.10.1</b> Motivation for MLE</a></li>
<li class="chapter" data-level="5.10.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#assumption"><i class="fa fa-check"></i><b>5.10.2</b> Assumption</a></li>
<li class="chapter" data-level="5.10.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>5.10.3</b> Properties</a></li>
<li class="chapter" data-level="5.10.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#application-1"><i class="fa fa-check"></i><b>5.10.4</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="non-linear-regression.html"><a href="non-linear-regression.html"><i class="fa fa-check"></i><b>6</b> Non-linear Regression</a><ul>
<li class="chapter" data-level="6.1" data-path="inference-1.html"><a href="inference-1.html"><i class="fa fa-check"></i><b>6.1</b> Inference</a><ul>
<li class="chapter" data-level="6.1.1" data-path="inference-1.html"><a href="inference-1.html#linear-function-of-the-parameters"><i class="fa fa-check"></i><b>6.1.1</b> Linear Function of the Parameters</a></li>
<li class="chapter" data-level="6.1.2" data-path="inference-1.html"><a href="inference-1.html#nonlinear"><i class="fa fa-check"></i><b>6.1.2</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html"><i class="fa fa-check"></i><b>6.2</b> Non-linear Least Squares</a><ul>
<li class="chapter" data-level="6.2.1" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#alternative-of-gauss-newton-algorithm"><i class="fa fa-check"></i><b>6.2.1</b> Alternative of Gauss-Newton Algorithm</a></li>
<li class="chapter" data-level="6.2.2" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#practical-considerations"><i class="fa fa-check"></i><b>6.2.2</b> Practical Considerations</a></li>
<li class="chapter" data-level="6.2.3" data-path="non-linear-least-squares.html"><a href="non-linear-least-squares.html#modelestiamtion-adequcy"><i class="fa fa-check"></i><b>6.2.3</b> Model/Estiamtion Adequcy</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html"><i class="fa fa-check"></i><b>6.3</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="6.3.1" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#logistic-regression"><i class="fa fa-check"></i><b>6.3.1</b> Logistic Regression</a></li>
<li class="chapter" data-level="6.3.2" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#probit-regression"><i class="fa fa-check"></i><b>6.3.2</b> Probit Regression</a></li>
<li class="chapter" data-level="6.3.3" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#poisson-regression"><i class="fa fa-check"></i><b>6.3.3</b> Poisson Regression</a></li>
<li class="chapter" data-level="6.3.4" data-path="generalized-linear-models.html"><a href="generalized-linear-models.html#generalization"><i class="fa fa-check"></i><b>6.3.4</b> Generalization</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="genelized-method-of-moments.html"><a href="genelized-method-of-moments.html"><i class="fa fa-check"></i><b>6.4</b> Genelized Method of Moments</a></li>
<li class="chapter" data-level="6.5" data-path="minimum-distance.html"><a href="minimum-distance.html"><i class="fa fa-check"></i><b>6.5</b> Minimum Distance</a></li>
<li class="chapter" data-level="6.6" data-path="spline-regression.html"><a href="spline-regression.html"><i class="fa fa-check"></i><b>6.6</b> Spline Regression</a><ul>
<li class="chapter" data-level="6.6.1" data-path="spline-regression.html"><a href="spline-regression.html#regression-splines"><i class="fa fa-check"></i><b>6.6.1</b> Regression Splines</a></li>
<li class="chapter" data-level="6.6.2" data-path="spline-regression.html"><a href="spline-regression.html#natural-splines"><i class="fa fa-check"></i><b>6.6.2</b> Natural splines</a></li>
<li class="chapter" data-level="6.6.3" data-path="spline-regression.html"><a href="spline-regression.html#smoothing-spliness"><i class="fa fa-check"></i><b>6.6.3</b> Smoothing spliness</a></li>
<li class="chapter" data-level="6.6.4" data-path="spline-regression.html"><a href="spline-regression.html#application-2"><i class="fa fa-check"></i><b>6.6.4</b> Application</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="generalized-additive-models.html"><a href="generalized-additive-models.html"><i class="fa fa-check"></i><b>6.7</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="6.8" data-path="quantile-regression.html"><a href="quantile-regression.html"><i class="fa fa-check"></i><b>6.8</b> Quantile Regression</a><ul>
<li class="chapter" data-level="6.8.1" data-path="quantile-regression.html"><a href="quantile-regression.html#application-3"><i class="fa fa-check"></i><b>6.8.1</b> Application</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="model-specification.html"><a href="model-specification.html"><i class="fa fa-check"></i><b>7</b> Model Specification</a><ul>
<li class="chapter" data-level="7.1" data-path="nested-model.html"><a href="nested-model.html"><i class="fa fa-check"></i><b>7.1</b> Nested Model</a><ul>
<li class="chapter" data-level="7.1.1" data-path="nested-model.html"><a href="nested-model.html#chow-test"><i class="fa fa-check"></i><b>7.1.1</b> Chow test</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="non-nested-model.html"><a href="non-nested-model.html"><i class="fa fa-check"></i><b>7.2</b> Non-Nested Model</a><ul>
<li class="chapter" data-level="7.2.1" data-path="non-nested-model.html"><a href="non-nested-model.html#davidson-mackinnon-test"><i class="fa fa-check"></i><b>7.2.1</b> Davidson-Mackinnon test</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html"><i class="fa fa-check"></i><b>7.3</b> Heteroskedasticity</a><ul>
<li class="chapter" data-level="7.3.1" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#breusch-pagan-test"><i class="fa fa-check"></i><b>7.3.1</b> Breusch-Pagan test</a></li>
<li class="chapter" data-level="7.3.2" data-path="heteroskedasticity-1.html"><a href="heteroskedasticity-1.html#white-test"><i class="fa fa-check"></i><b>7.3.2</b> White test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="endogeneity.html"><a href="endogeneity.html"><i class="fa fa-check"></i><b>8</b> Endogeneity</a><ul>
<li class="chapter" data-level="8.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html"><i class="fa fa-check"></i><b>8.1</b> Endogenous Treatment</a><ul>
<li class="chapter" data-level="8.1.1" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#instrumental-variable"><i class="fa fa-check"></i><b>8.1.1</b> Instrumental Variable</a></li>
<li class="chapter" data-level="8.1.2" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#internal-instrumental-variable"><i class="fa fa-check"></i><b>8.1.2</b> Internal instrumental variable</a></li>
<li class="chapter" data-level="8.1.3" data-path="endogenous-treatment.html"><a href="endogenous-treatment.html#proxy-variables"><i class="fa fa-check"></i><b>8.1.3</b> Proxy Variables</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html"><i class="fa fa-check"></i><b>8.2</b> Endogenous Sample Selection</a><ul>
<li class="chapter" data-level="8.2.1" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-2"><i class="fa fa-check"></i><b>8.2.1</b> Tobit-2</a></li>
<li class="chapter" data-level="8.2.2" data-path="endogenous-sample-selection.html"><a href="endogenous-sample-selection.html#tobit-5"><i class="fa fa-check"></i><b>8.2.2</b> Tobit-5</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="data.html"><a href="data.html"><i class="fa fa-check"></i><b>9</b> Data</a><ul>
<li class="chapter" data-level="9.1" data-path="cross-sectional.html"><a href="cross-sectional.html"><i class="fa fa-check"></i><b>9.1</b> Cross-Sectional</a></li>
<li class="chapter" data-level="9.2" data-path="time-series-1.html"><a href="time-series-1.html"><i class="fa fa-check"></i><b>9.2</b> Time Series</a><ul>
<li class="chapter" data-level="9.2.1" data-path="time-series-1.html"><a href="time-series-1.html#deterministic-time-trend"><i class="fa fa-check"></i><b>9.2.1</b> Deterministic Time trend</a></li>
<li class="chapter" data-level="9.2.2" data-path="time-series-1.html"><a href="time-series-1.html#feedback-effect"><i class="fa fa-check"></i><b>9.2.2</b> Feedback Effect</a></li>
<li class="chapter" data-level="9.2.3" data-path="time-series-1.html"><a href="time-series-1.html#dynamic-specification"><i class="fa fa-check"></i><b>9.2.3</b> Dynamic Specification</a></li>
<li class="chapter" data-level="9.2.4" data-path="time-series-1.html"><a href="time-series-1.html#dynamically-complete"><i class="fa fa-check"></i><b>9.2.4</b> Dynamically Complete</a></li>
<li class="chapter" data-level="9.2.5" data-path="time-series-1.html"><a href="time-series-1.html#highly-persistent-data"><i class="fa fa-check"></i><b>9.2.5</b> Highly Persistent Data</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html"><i class="fa fa-check"></i><b>9.3</b> Repeated Cross Sections</a><ul>
<li class="chapter" data-level="9.3.1" data-path="repeated-cross-sections.html"><a href="repeated-cross-sections.html#pooled-cross-section"><i class="fa fa-check"></i><b>9.3.1</b> Pooled Cross Section</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="panel-data.html"><a href="panel-data.html"><i class="fa fa-check"></i><b>9.4</b> Panel Data</a><ul>
<li class="chapter" data-level="9.4.1" data-path="panel-data.html"><a href="panel-data.html#pooled-ols-esimator"><i class="fa fa-check"></i><b>9.4.1</b> Pooled OLS Esimator</a></li>
<li class="chapter" data-level="9.4.2" data-path="panel-data.html"><a href="panel-data.html#individual-specific-effects-model"><i class="fa fa-check"></i><b>9.4.2</b> Individual-specific effects model</a></li>
<li class="chapter" data-level="9.4.3" data-path="panel-data.html"><a href="panel-data.html#tests-for-assumptions"><i class="fa fa-check"></i><b>9.4.3</b> Tests for Assumptions</a></li>
<li class="chapter" data-level="9.4.4" data-path="panel-data.html"><a href="panel-data.html#model-selection"><i class="fa fa-check"></i><b>9.4.4</b> Model Selection</a></li>
<li class="chapter" data-level="9.4.5" data-path="panel-data.html"><a href="panel-data.html#summary-1"><i class="fa fa-check"></i><b>9.4.5</b> Summary</a></li>
<li class="chapter" data-level="9.4.6" data-path="panel-data.html"><a href="panel-data.html#application-4"><i class="fa fa-check"></i><b>9.4.6</b> Application</a></li>
<li class="chapter" data-level="9.4.7" data-path="panel-data.html"><a href="panel-data.html#other-estimators"><i class="fa fa-check"></i><b>9.4.7</b> Other Estimators</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>10</b> Hypothesis Testing</a><ul>
<li class="chapter" data-level="10.1" data-path="types-of-hypothesis-testing.html"><a href="types-of-hypothesis-testing.html"><i class="fa fa-check"></i><b>10.1</b> Types of hypothesis testing</a></li>
<li class="chapter" data-level="10.2" data-path="wald-test.html"><a href="wald-test.html"><i class="fa fa-check"></i><b>10.2</b> Wald test</a><ul>
<li class="chapter" data-level="10.2.1" data-path="wald-test.html"><a href="wald-test.html#multiple-hypothesis"><i class="fa fa-check"></i><b>10.2.1</b> Multiple Hypothesis</a></li>
<li class="chapter" data-level="10.2.2" data-path="wald-test.html"><a href="wald-test.html#linear-combination"><i class="fa fa-check"></i><b>10.2.2</b> Linear Combination</a></li>
<li class="chapter" data-level="10.2.3" data-path="wald-test.html"><a href="wald-test.html#application-5"><i class="fa fa-check"></i><b>10.2.3</b> Application</a></li>
<li class="chapter" data-level="10.2.4" data-path="wald-test.html"><a href="wald-test.html#nonlinear-1"><i class="fa fa-check"></i><b>10.2.4</b> Nonlinear</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="the-likelihood-ratio-test.html"><a href="the-likelihood-ratio-test.html"><i class="fa fa-check"></i><b>10.3</b> The likelihood ratio test</a></li>
<li class="chapter" data-level="10.4" data-path="lagrange-multiplier-score.html"><a href="lagrange-multiplier-score.html"><i class="fa fa-check"></i><b>10.4</b> Lagrange Multiplier (Score)</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="imputation-missing-data.html"><a href="imputation-missing-data.html"><i class="fa fa-check"></i><b>11</b> Imputation (Missing Data)</a><ul>
<li class="chapter" data-level="11.1" data-path="assumptions-1.html"><a href="assumptions-1.html"><i class="fa fa-check"></i><b>11.1</b> Assumptions</a><ul>
<li class="chapter" data-level="11.1.1" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-completely-at-random-mcar"><i class="fa fa-check"></i><b>11.1.1</b> Missing Completely at Random (MCAR)</a></li>
<li class="chapter" data-level="11.1.2" data-path="assumptions-1.html"><a href="assumptions-1.html#missing-at-random-mar"><i class="fa fa-check"></i><b>11.1.2</b> Missing at Random (MAR)</a></li>
<li class="chapter" data-level="11.1.3" data-path="assumptions-1.html"><a href="assumptions-1.html#ignorable"><i class="fa fa-check"></i><b>11.1.3</b> Ignorable</a></li>
<li class="chapter" data-level="11.1.4" data-path="assumptions-1.html"><a href="assumptions-1.html#nonignorable"><i class="fa fa-check"></i><b>11.1.4</b> Nonignorable</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html"><i class="fa fa-check"></i><b>11.2</b> Solutions to Missing data</a><ul>
<li class="chapter" data-level="11.2.1" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#listwise-deletion"><i class="fa fa-check"></i><b>11.2.1</b> Listwise Deletion</a></li>
<li class="chapter" data-level="11.2.2" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#pairwise-deletion"><i class="fa fa-check"></i><b>11.2.2</b> Pairwise Deletion</a></li>
<li class="chapter" data-level="11.2.3" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#dummy-variable-adjustment"><i class="fa fa-check"></i><b>11.2.3</b> Dummy Variable Adjustment</a></li>
<li class="chapter" data-level="11.2.4" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#imputation"><i class="fa fa-check"></i><b>11.2.4</b> Imputation</a></li>
<li class="chapter" data-level="11.2.5" data-path="solutions-to-missing-data.html"><a href="solutions-to-missing-data.html#heckmans-sample-selection-model"><i class="fa fa-check"></i><b>11.2.5</b> Heckman’s Sample Selection Model</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="criteria-for-choosing-an-effective-approach.html"><a href="criteria-for-choosing-an-effective-approach.html"><i class="fa fa-check"></i><b>11.3</b> Criteria for Choosing an Effective Approach</a></li>
<li class="chapter" data-level="11.4" data-path="another-perspective.html"><a href="another-perspective.html"><i class="fa fa-check"></i><b>11.4</b> Another Perspective</a></li>
<li class="chapter" data-level="11.5" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html"><i class="fa fa-check"></i><b>11.5</b> Diagnosing the Mechanism</a><ul>
<li class="chapter" data-level="11.5.1" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mar-vs.-mnar"><i class="fa fa-check"></i><b>11.5.1</b> MAR vs. MNAR</a></li>
<li class="chapter" data-level="11.5.2" data-path="diagnosing-the-mechanism.html"><a href="diagnosing-the-mechanism.html#mcar-vs.-mar"><i class="fa fa-check"></i><b>11.5.2</b> MCAR vs. MAR</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="application-6.html"><a href="application-6.html"><i class="fa fa-check"></i><b>11.6</b> Application</a><ul>
<li class="chapter" data-level="11.6.1" data-path="application-6.html"><a href="application-6.html#imputation-with-mean-median-mode"><i class="fa fa-check"></i><b>11.6.1</b> Imputation with mean / median / mode</a></li>
<li class="chapter" data-level="11.6.2" data-path="application-6.html"><a href="application-6.html#knn"><i class="fa fa-check"></i><b>11.6.2</b> KNN</a></li>
<li class="chapter" data-level="11.6.3" data-path="application-6.html"><a href="application-6.html#rpart"><i class="fa fa-check"></i><b>11.6.3</b> rpart</a></li>
<li class="chapter" data-level="11.6.4" data-path="application-6.html"><a href="application-6.html#mice-multivariate-imputation-via-chained-equations"><i class="fa fa-check"></i><b>11.6.4</b> MICE (Multivariate Imputation via Chained Equations)</a></li>
<li class="chapter" data-level="11.6.5" data-path="application-6.html"><a href="application-6.html#amelia"><i class="fa fa-check"></i><b>11.6.5</b> Amelia</a></li>
<li class="chapter" data-level="11.6.6" data-path="application-6.html"><a href="application-6.html#missforest"><i class="fa fa-check"></i><b>11.6.6</b> missForest</a></li>
<li class="chapter" data-level="11.6.7" data-path="application-6.html"><a href="application-6.html#hmisc"><i class="fa fa-check"></i><b>11.6.7</b> Hmisc</a></li>
<li class="chapter" data-level="11.6.8" data-path="application-6.html"><a href="application-6.html#mi"><i class="fa fa-check"></i><b>11.6.8</b> mi</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III EXPERIMENTAL DESIGN</b></span></li>
<li class="chapter" data-level="12" data-path="analysis-of-variance-anova.html"><a href="analysis-of-variance-anova.html"><i class="fa fa-check"></i><b>12</b> Analysis of Variance (ANOVA)</a><ul>
<li class="chapter" data-level="12.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html"><i class="fa fa-check"></i><b>12.1</b> Completely Randomized Design (CRD)</a><ul>
<li class="chapter" data-level="12.1.1" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-fixed-effects-model"><i class="fa fa-check"></i><b>12.1.1</b> Single Factor Fixed Effects Model</a></li>
<li class="chapter" data-level="12.1.2" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#single-factor-random-effects-model"><i class="fa fa-check"></i><b>12.1.2</b> Single Factor Random Effects Model</a></li>
<li class="chapter" data-level="12.1.3" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-factor-fixed-effect-anova"><i class="fa fa-check"></i><b>12.1.3</b> Two Factor Fixed Effect ANOVA</a></li>
<li class="chapter" data-level="12.1.4" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-random-effects-anova"><i class="fa fa-check"></i><b>12.1.4</b> Two-Way Random Effects ANOVA</a></li>
<li class="chapter" data-level="12.1.5" data-path="completely-randomized-design-crd.html"><a href="completely-randomized-design-crd.html#two-way-mixed-effects-anova"><i class="fa fa-check"></i><b>12.1.5</b> Two-Way Mixed Effects ANOVA</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html"><i class="fa fa-check"></i><b>12.2</b> Nonparametric ANOVA</a><ul>
<li class="chapter" data-level="12.2.1" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#kruskal-wallis"><i class="fa fa-check"></i><b>12.2.1</b> Kruskal-Wallis</a></li>
<li class="chapter" data-level="12.2.2" data-path="nonparametric-anova.html"><a href="nonparametric-anova.html#friedman-test"><i class="fa fa-check"></i><b>12.2.2</b> Friedman Test</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html"><i class="fa fa-check"></i><b>12.3</b> Sample Size Planning for ANOVA</a><ul>
<li class="chapter" data-level="12.3.1" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#balanced-designs"><i class="fa fa-check"></i><b>12.3.1</b> Balanced Designs</a></li>
<li class="chapter" data-level="12.3.2" data-path="sample-size-planning-for-anova.html"><a href="sample-size-planning-for-anova.html#randomized-block-experiments"><i class="fa fa-check"></i><b>12.3.2</b> Randomized Block Experiments</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html"><i class="fa fa-check"></i><b>12.4</b> Randomized Block Designs</a><ul>
<li class="chapter" data-level="12.4.1" data-path="randomized-block-designs.html"><a href="randomized-block-designs.html#tukey-test-of-additivity"><i class="fa fa-check"></i><b>12.4.1</b> Tukey Test of Additivity</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="nested-designs.html"><a href="nested-designs.html"><i class="fa fa-check"></i><b>12.5</b> Nested Designs</a><ul>
<li class="chapter" data-level="12.5.1" data-path="nested-designs.html"><a href="nested-designs.html#two-factor-nested-designs"><i class="fa fa-check"></i><b>12.5.1</b> Two-Factor Nested Designs</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="analysis-of-covariance.html"><a href="analysis-of-covariance.html"><i class="fa fa-check"></i><b>13</b> Analysis of Covariance</a><ul>
<li class="chapter" data-level="13.1" data-path="single-factor-covariance-model.html"><a href="single-factor-covariance-model.html"><i class="fa fa-check"></i><b>13.1</b> Single Factor Covariance Model</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="causality.html"><a href="causality.html"><i class="fa fa-check"></i><b>14</b> Causality</a></li>
<li class="chapter" data-level="15" data-path="report.html"><a href="report.html"><i class="fa fa-check"></i><b>15</b> Report</a><ul>
<li class="chapter" data-level="15.1" data-path="one-summary-table.html"><a href="one-summary-table.html"><i class="fa fa-check"></i><b>15.1</b> One summary table</a></li>
<li class="chapter" data-level="15.2" data-path="model-comparison.html"><a href="model-comparison.html"><i class="fa fa-check"></i><b>15.2</b> Model Comparison</a></li>
<li class="chapter" data-level="15.3" data-path="changes-in-an-estimate.html"><a href="changes-in-an-estimate.html"><i class="fa fa-check"></i><b>15.3</b> Changes in an estimate</a></li>
</ul></li>
<li class="appendix"><span><b>APPENDIX</b></span></li>
<li class="chapter" data-level="A" data-path="appendix.html"><a href="appendix.html"><i class="fa fa-check"></i><b>A</b> Appendix</a><ul>
<li class="chapter" data-level="A.1" data-path="short-cut.html"><a href="short-cut.html"><i class="fa fa-check"></i><b>A.1</b> Short-cut</a></li>
<li class="chapter" data-level="A.2" data-path="function-short-cut.html"><a href="function-short-cut.html"><i class="fa fa-check"></i><b>A.2</b> Function short-cut</a></li>
<li class="chapter" data-level="A.3" data-path="citation.html"><a href="citation.html"><i class="fa fa-check"></i><b>A.3</b> Citation</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="bookdown-cheat-sheet.html"><a href="bookdown-cheat-sheet.html"><i class="fa fa-check"></i><b>B</b> Bookdown cheat sheet</a><ul>
<li class="chapter" data-level="B.1" data-path="operation.html"><a href="operation.html"><i class="fa fa-check"></i><b>B.1</b> Operation</a></li>
<li class="chapter" data-level="B.2" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html"><i class="fa fa-check"></i><b>B.2</b> Math Expresssion/ Syntax</a><ul>
<li class="chapter" data-level="B.2.1" data-path="math-expresssion-syntax.html"><a href="math-expresssion-syntax.html#statistics-notation"><i class="fa fa-check"></i><b>B.2.1</b> Statistics Notation</a></li>
</ul></li>
<li class="chapter" data-level="B.3" data-path="table.html"><a href="table.html"><i class="fa fa-check"></i><b>B.3</b> Table</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">A Guide on Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="two-sample-inference" class="section level2">
<h2><span class="header-section-number">4.2</span> Two Sample Inference</h2>
<div id="means" class="section level3">
<h3><span class="header-section-number">4.2.1</span> Means</h3>
<p>Suppose we have 2 sets of observations,</p>
<ul>
<li><span class="math inline">\(y_1,..., y_{n_y}\)</span><br />
</li>
<li><span class="math inline">\(x_1,...,x_{n_x}\)</span></li>
</ul>
<p>that are random samples from two independent populations with means <span class="math inline">\(\mu_y\)</span> and <span class="math inline">\(\mu_x\)</span> and variances <span class="math inline">\(\sigma^2_y\)</span>,<span class="math inline">\(\sigma^2_x\)</span>.
Our goal is to compare <span class="math inline">\(\mu_x\)</span> and <span class="math inline">\(\mu_y\)</span> or <span class="math inline">\(\sigma^2_y = \sigma^2_x\)</span></p>
<div id="large-sample-tests" class="section level4">
<h4><span class="header-section-number">4.2.1.1</span> Large Sample Tests</h4>
<p>Assume that <span class="math inline">\(n_y\)</span> and <span class="math inline">\(n_x\)</span> are large (<span class="math inline">\(\ge 30\)</span>). Then,</p>
<p><span class="math display">\[
E(\bar{y} - \bar{x}) = \mu_y - \mu_x \\
Var(\bar{y} - \bar{x}) = \sigma^2_y /n_y + \sigma^2_x/n_x
\]</span></p>
<p>Then,</p>
<p><span class="math display">\[
Z = \frac{\bar{y}-\bar{x} - (\mu_y - \mu_x)}{\sqrt{\sigma^2_y /n_y + \sigma^2_x/n_x}} \sim N(0,1)
\]</span>
(according to <a href="probability-theory.html#central-limit-theorem">Central Limit Theorem</a>). For large samples, we can replace variances by their unbiased estimators (<span class="math inline">\(s^2_y,s^2_x\)</span>), and get the same large sample distribution.</p>
<p>An approximate <span class="math inline">\(100(1-\alpha) \%\)</span> CI for <span class="math inline">\(\mu_y - \mu_x\)</span> is given by:</p>
<p><span class="math display">\[
\bar{y} - \bar{x} \pm z_{\alpha/2}\sqrt{s^2_y/n_y + s^2_x/n_x}
\]</span></p>
<p><span class="math display">\[
H_0: \mu_y - \mu_x = \delta_0 \\
H_A: \mu_y - \mu_x \neq \delta_0
\]</span></p>
<p>at the <span class="math inline">\(\alpha\)</span>-level with the statistic:</p>
<p><span class="math display">\[
z = \frac{\bar{y}-\bar{x} - \delta_0}{\sqrt{s^2_y /n_y + s^2_x/n_x}}
\]</span></p>
<p>and reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|z| &gt; z_{\alpha/2}\)</span></p>
<p>If <span class="math inline">\(\delta = )\)</span>, it means that we are testing whether two means are equal.</p>
</div>
<div id="small-sample-tests" class="section level4">
<h4><span class="header-section-number">4.2.1.2</span> Small Sample Tests</h4>
<p>If the two samples are from normal distribution, iid <span class="math inline">\(N(\mu_y,\sigma^2_y)\)</span> and iid <span class="math inline">\(N(\mu_x,\sigma^2_x)\)</span> and the two samples are independent, we can do inference based on the <a href="probability-theory.html#student-t">t-distribution</a></p>
<p>Then we have 2 cases</p>
<ul>
<li><a href="two-sample-inference.html#equal-variance">Equal Variance</a></li>
<li><a href="two-sample-inference.html#unequal-variance">Unequal Variance</a></li>
</ul>
<div id="equal-variance" class="section level5">
<h5><span class="header-section-number">4.2.1.2.1</span> Equal variance</h5>
<p><strong>Assumptions</strong></p>
<ul>
<li>iid: so that <span class="math inline">\(var(\bar{y}) = \sigma^2_y / n_y ; var(\bar{x}) = \sigma^2_x / n_x\)</span><br />
</li>
<li>Independence between samples: No observation from one sample can influence any observation from the other sample, to have</li>
</ul>
<p><span class="math display">\[
\begin{align}
var(\bar{y} - \bar{x}) &amp;= var(\bar{y}) + var{\bar{x}} - 2cov(\bar{y},\bar{x}) \\
&amp;= var(\bar{y}) + var{\bar{x}} \\
&amp;= \sigma^2_y / n_y + \sigma^2_x / n_x 
\end{align}
\]</span></p>
<ul>
<li>Normality: Justifies the use of the <a href="probability-theory.html#student-t">t-distribution</a></li>
</ul>
<p>Let <span class="math inline">\(\sigma^2 = \sigma^2_y = \sigma^2_x\)</span>. Then, <span class="math inline">\(s^2_y\)</span> and <span class="math inline">\(s^2_x\)</span> are both unbiased estimators of <span class="math inline">\(\sigma^2\)</span>. We then can pool them.</p>
<p>Then the pooled variance estimate is
<span class="math display">\[
s^2 = \frac{(n_y - 1)s^2_y + (n_x - 1)s^2_x}{(n_y-1)+(n_x-1)}
\]</span>
has <span class="math inline">\(n_y + n_x -2\)</span> df.</p>
<p>Then the test statistic</p>
<p><span class="math display">\[
T = \frac{\bar{y}- \bar{x} -(\mu_y - \mu_x)}{s\sqrt{1/n_y + 1/n_x}} \sim t_{n_y + n_x -2}
\]</span></p>
<p><span class="math inline">\(100(1 - \alpha) \%\)</span> CI for <span class="math inline">\(\mu_y - \mu_x\)</span> is</p>
<p><span class="math display">\[
\bar{y} - \bar{x} \pm (t_{n_y + n_x -2})s\sqrt{1/n_y + 1/n_x}
\]</span></p>
<p>Hypothesis testing:<br />
<span class="math display">\[
H_0: \mu_y - \mu_x = \delta_0 \\
H_1: \mu_y - \mu_x \neq \delta_0
\]</span></p>
<p>we reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|t| &gt; t_{n_y + n_x -2;\alpha/2}\)</span></p>
</div>
<div id="unequal-variance" class="section level5">
<h5><span class="header-section-number">4.2.1.2.2</span> Unequal Variance</h5>
<p><strong>Assumptions</strong></p>
<ol style="list-style-type: decimal">
<li>Two samples are independent<br />
1. Scatter plots<br />
2. <a href="normality-assessment.html#correlation-coefficient-with-normal-probability-plots">Correlation coefficient (if normal)</a></li>
<li>Independence of observation in each sample<br />
1. Test for serial correlation<br />
</li>
<li>For each sample, homogeneity of variance<br />
1. Scatter plots<br />
2. Formal tests<br />
</li>
<li><a href="normality-assessment.html#normality-assessment">Normality</a><br />
</li>
<li>Equality of variances (homogeneity of variance between samples)<br />
1. <a href="two-sample-inference.html#f-test">F-test</a><br />
2. Barlett test<br />
3. [Modified Levene Test]</li>
</ol>
<p>To compare 2 normal <span class="math inline">\(\sigma^2_y \neq \sigma^2_x\)</span>, we use the test statistic:</p>
<p><span class="math display">\[
T = \frac{\bar{y}- \bar{x} -(\mu_y - \mu_x)}{\sqrt{s^2_y/n_y + s^2_x/n_x}} 
\]</span>
In this case, T does not follow the <a href="probability-theory.html#student-t">t-distribution</a> (its distribution depends on the ratio of the unknown variances <span class="math inline">\(\sigma^2_y,\sigma^2_x\)</span>). In the case of small sizes, we can can approximate tests by using the Welch-Satterthwaite method <span class="citation">(Satterthwaite <a href="#ref-Satterthwaite_1946" role="doc-biblioref">1946</a>)</span>. We assume T can be approximated by a <a href="probability-theory.html#student-t">t-distribution</a>, and adjust the degrees of freedom.</p>
<p>Let <span class="math inline">\(w_y = s^2_y /n_y\)</span> and <span class="math inline">\(w_x = s^2_x /n_x\)</span> (the w’s are the square of the respective standard errors)<br />
Then, the degrees of freedom are</p>
<p><span class="math display">\[
v = \frac{(w_y + w_x)^2}{w^2_y / (n_y-1) + w^2_x / (n_x-1)}
\]</span></p>
<p>Since v is usually fractional, we truncate down to the nearest integer.</p>
<p><span class="math inline">\(100 (1-\alpha) \%\)</span> CI for <span class="math inline">\(\mu_y - \mu_x\)</span> is</p>
<p><span class="math display">\[
\bar{y} - \bar{x} \pm t_{v,\alpha/2} \sqrt{s^2_y/n_y + s^2_x /n_x}
\]</span></p>
<p>Reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(|t| &gt; t_{v,\alpha/2}\)</span>, where</p>
<p><span class="math display">\[
t = \frac{\bar{y} - \bar{x}-\delta_0}{\sqrt{s^2_y/n_y + s^2_x /n_x}}
\]</span></p>
</div>
</div>
</div>
<div id="variances" class="section level3">
<h3><span class="header-section-number">4.2.2</span> Variances</h3>
<p><span class="math display">\[
F_{ndf,ddf}= \frac{s^2_1}{s^2_2}
\]</span></p>
<p>where <span class="math inline">\(s^2_1&gt;s^2_2, ndf = n_1-1,ddf = n_2-1\)</span></p>
<div id="f-test" class="section level4">
<h4><span class="header-section-number">4.2.2.1</span> F-test</h4>
<p>Test</p>
<p><span class="math display">\[
H_0: \sigma^2_y = \sigma^2_x \\
H_a: \sigma^2_y \neq \sigma^2_x
\]</span></p>
<p>Consider the test statistic,</p>
<p><span class="math display">\[
F= \frac{s^2_y}{s^2_x}
\]</span></p>
<p>Reject <span class="math inline">\(H_0\)</span> if</p>
<ul>
<li><span class="math inline">\(F&gt;f_{n_y -1,n_x -1,\alpha/2}\)</span> or<br />
</li>
<li><span class="math inline">\(F&lt;f_{n_y -1,n_x -1,1-\alpha/2}\)</span></li>
</ul>
<p>Where <span class="math inline">\(F&gt;f_{n_y -1,n_x -1,\alpha/2}\)</span> and <span class="math inline">\(F&lt;f_{n_y -1,n_x -1,1-\alpha/2}\)</span> are the upper and lower <span class="math inline">\(\alpha/2\)</span> critical points of an <a href="probability-theory.html#f-distribution">F-distribution</a>, with a <span class="math inline">\(n_y-1\)</span> and <span class="math inline">\(n_x-1\)</span> degrees of freedom.</p>
<p><strong>Note</strong></p>
<ul>
<li>This test depends heavily on the assumption Normality.<br />
</li>
<li>In particular, it could give to many significant results when observations come from long-tailed distributions (i.e., positive kurtosis).<br />
</li>
<li>If we cannot find support for <a href="normality-assessment.html#normality-assessment">normality</a>, then we can use nonparametric tests such as the [Modified Levene Test]</li>
</ul>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="two-sample-inference.html#cb122-1"></a><span class="kw">data</span>(iris)</span>
<span id="cb122-2"><a href="two-sample-inference.html#cb122-2"></a>irisVe=iris<span class="op">$</span>Petal.Width[iris<span class="op">$</span>Species<span class="op">==</span><span class="st">&quot;versicolor&quot;</span>] </span>
<span id="cb122-3"><a href="two-sample-inference.html#cb122-3"></a>irisVi=iris<span class="op">$</span>Petal.Width[iris<span class="op">$</span>Species<span class="op">==</span><span class="st">&quot;virginica&quot;</span>]</span>
<span id="cb122-4"><a href="two-sample-inference.html#cb122-4"></a></span>
<span id="cb122-5"><a href="two-sample-inference.html#cb122-5"></a><span class="kw">var.test</span>(irisVe,irisVi)</span></code></pre></div>
<pre><code>## 
##  F test to compare two variances
## 
## data:  irisVe and irisVi
## F = 0.51842, num df = 49, denom df = 49, p-value = 0.02335
## alternative hypothesis: true ratio of variances is not equal to 1
## 95 percent confidence interval:
##  0.2941935 0.9135614
## sample estimates:
## ratio of variances 
##          0.5184243</code></pre>
</div>
<div id="modified-levene-test-brown-forsythe-test" class="section level4">
<h4><span class="header-section-number">4.2.2.2</span> Modified Levene Test (Brown-Forsythe Test)</h4>
<ul>
<li>considers averages of absolute deviations rather than squared deviations. Hence, less sensitive to long-tailed distributions.<br />
</li>
<li>This test is still good for normal data</li>
</ul>
<p>For each sample, we consider the absolute deviation of each observation form the median:</p>
<p><span class="math display">\[
d_{y,i} = |y_i - y_{.5}| \\
d_{x,i} = |x_i - x_{.5}|
\]</span>
Then,</p>
<p><span class="math display">\[
t_L^* = \frac{\bar{d}_y-\bar{d}_x}{s \sqrt{1/n_y + 1/n_x}}
\]</span></p>
<p>The pooled variance <span class="math inline">\(s^2\)</span> is given by:</p>
<p><span class="math display">\[
s^2 = \frac{\sum_i^{n_y}(d_{y,i}-\bar{d}_y)^2 + \sum_j^{n_x}(d_{x,i}-\bar{d}_x)^2}{n_y + n_x -2}
\]</span></p>
<ul>
<li>If the error terms have constant variance and <span class="math inline">\(n_y\)</span> and <span class="math inline">\(n_x\)</span> are not extremely small, then <span class="math inline">\(t_L^* \sim t_{n_x + n_y -2}\)</span><br />
</li>
<li>We reject the null hypothesis when <span class="math inline">\(|t_L^*| &gt; t_{n_y + n_x -2;\alpha/2}\)</span><br />
</li>
<li>This is just the two-sample t-test applied to the absolute deviations.</li>
</ul>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="two-sample-inference.html#cb124-1"></a>dVe=<span class="kw">abs</span>(irisVe<span class="op">-</span><span class="kw">median</span>(irisVe)) </span>
<span id="cb124-2"><a href="two-sample-inference.html#cb124-2"></a>dVi=<span class="kw">abs</span>(irisVi<span class="op">-</span><span class="kw">median</span>(irisVi)) </span>
<span id="cb124-3"><a href="two-sample-inference.html#cb124-3"></a><span class="kw">t.test</span>(dVe,dVi,<span class="dt">var.equal=</span>T)</span></code></pre></div>
<pre><code>## 
##  Two Sample t-test
## 
## data:  dVe and dVi
## t = -2.5584, df = 98, p-value = 0.01205
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.12784786 -0.01615214
## sample estimates:
## mean of x mean of y 
##     0.154     0.226</code></pre>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="two-sample-inference.html#cb126-1"></a><span class="co"># small samples t-test  </span></span>
<span id="cb126-2"><a href="two-sample-inference.html#cb126-2"></a><span class="kw">t.test</span>(irisVe,irisVi,<span class="dt">var.equal=</span>F)</span></code></pre></div>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  irisVe and irisVi
## t = -14.625, df = 89.043, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -0.7951002 -0.6048998
## sample estimates:
## mean of x mean of y 
##     1.326     2.026</code></pre>
</div>
</div>
<div id="power-1" class="section level3">
<h3><span class="header-section-number">4.2.3</span> Power</h3>
<p>Consider <span class="math inline">\(\sigma^2_y = \sigma^2_x = \sigma^2\)</span><br />
Under the assumption of equal variances, we take size samples from both groups (<span class="math inline">\(n_y = n_x = n\)</span>)</p>
<p>For 1-sided testing,</p>
<p><span class="math display">\[
H_0: \mu_y - \mu_x \le 0 \\
H_a: \mu_y - \mu_x &gt; 0
\]</span></p>
<p><span class="math inline">\(\alpha\)</span>-level z-test rejects <span class="math inline">\(H_0\)</span> if</p>
<p><span class="math display">\[
z = \frac{\bar{y} - \bar{x}}{\sigma \sqrt{2/n}} &gt; z_{\alpha}
\]</span></p>
<p><span class="math display">\[
\pi(\mu_y - \mu_x) = \Phi(-z_{\alpha} + \frac{\mu_y -\mu_x}{\sigma}\sqrt{n/2})
\]</span></p>
<p>We need sample size n that gie at least <span class="math inline">\(1-\beta\)</span> power when <span class="math inline">\(\mu_y - \mu_x = \delta\)</span>, where <span class="math inline">\(\delta\)</span> is the smallest difference that we want to see.</p>
<p>Power is given by:</p>
<p><span class="math display">\[
\Phi(-z_{\alpha} + \frac{\delta}{\sigma}\sqrt{n/2}) = 1 - \beta
\]</span></p>
</div>
<div id="sample-size-1" class="section level3">
<h3><span class="header-section-number">4.2.4</span> Sample Size</h3>
<p>Then, the sample size is</p>
<p><span class="math display">\[
n = 2(\frac{\sigma (z_{\alpha} + z_{\beta}}{\delta})^2
\]</span></p>
<p>For 2-sided test, replace <span class="math inline">\(z_{\alpha}\)</span> with <span class="math inline">\(z_{\alpha/2}\)</span>.<br />
As with the one-sample case, to perform an exact 2-sample t-test sample size calculation, we must use a non-central <a href="probability-theory.html#student-t">t-distribution</a>.</p>
<p>A correction that gives the approximate t-test sample size can be obtained by using the z-test n value in the formula:<br />
<span class="math display">\[
n^* = 2(\frac{\sigma (t_{2n-2;\alpha} + t_{2n-2;\beta})}{\delta})^2
\]</span></p>
<p>where we use <span class="math inline">\(alpha/2\)</span> for the two-sided test</p>
</div>
<div id="matched-pair-designs" class="section level3">
<h3><span class="header-section-number">4.2.5</span> Matched Pair Designs</h3>
<p>We have two treatments</p>
<table>
<thead>
<tr class="header">
<th>Subject</th>
<th>Treatment A</th>
<th>Treatment B</th>
<th>Difference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td><span class="math inline">\(y_1\)</span></td>
<td><span class="math inline">\(x_1\)</span></td>
<td><span class="math inline">\(d_1 = y_1 - x_1\)</span></td>
</tr>
<tr class="even">
<td>2</td>
<td><span class="math inline">\(y_2\)</span></td>
<td><span class="math inline">\(x_2\)</span></td>
<td><span class="math inline">\(d_2 = y_2 - x_2\)</span></td>
</tr>
<tr class="odd">
<td>.</td>
<td>.</td>
<td>.</td>
<td>.</td>
</tr>
<tr class="even">
<td>n</td>
<td><span class="math inline">\(y_n\)</span></td>
<td><span class="math inline">\(x_n\)</span></td>
<td><span class="math inline">\(d_n = y_n - x_n\)</span></td>
</tr>
</tbody>
</table>
<p>we assume <span class="math inline">\(y_i \sim^{iid} N(\mu_y, \sigma^2_y)\)</span> and <span class="math inline">\(x_i \sim^{iid} N(\mu_x,\sigma^2_x)\)</span>, but since <span class="math inline">\(y_i\)</span> and <span class="math inline">\(x_i\)</span> are measured on the same subject, they are correlated.</p>
<p>Let</p>
<p><span class="math display">\[
\mu_D = E(y_i - x_i) = \mu_y -\mu_x \\
\sigma^2_D = var(y_i - x_i) = Var(y_i) + Var(x_i) -2cov(y_i,x_i)
\]</span></p>
<p>If the matching induces <strong>positive</strong> correlation, then the variance of the difference of the measurements is reduced as compared to the independent case. This is the point of <a href="two-sample-inference.html#matched-pair-designs">Matched Pair Designs</a>. Although covariance can be negative, giving a larger variance of the difference than the independent sample case, usually the covariance is positive. This means both <span class="math inline">\(y_i\)</span> and <span class="math inline">\(x_i\)</span> are large for many of the same subjects, and for others, both measurement are small. (we still assume that various subjects respond independently of each other, which is necessary for the iid assumption within groups).</p>
<p>Let <span class="math inline">\(d_i = y_i - x_i\)</span>, then</p>
<ul>
<li><span class="math inline">\(\bar{d} = \bar{y}-\bar{x}\)</span> is the sample mean of the <span class="math inline">\(d_i\)</span><br />
</li>
<li><span class="math inline">\(s_d^2=\frac{1}{n-1}\sum_{i=1}^n (d_i - \bar{d})^2\)</span> is the sample variance of the difference</li>
</ul>
<p>Once the data are converted to differences, we are back to <a href="one-sample-inference.html#one-sample-inference">One Sample Inference</a> and can use its tests and CIs.</p>
</div>
<div id="nonparametric-tests-for-two-samples" class="section level3">
<h3><span class="header-section-number">4.2.6</span> Nonparametric Tests for Two Samples</h3>
<p>For <a href="two-sample-inference.html#matched-pair-designs">Matched Pair Designs</a>, we can use the <a href="one-sample-inference.html#one-sample-non-parametric-methods">One-sample Non-parametric Methods</a>.</p>
<p>Assume that Y and X are random variables with CDF <span class="math inline">\(F_y\)</span> and <span class="math inline">\(F_x\)</span>. then, Y is <strong>stochastically</strong> larger than X for all real number u, <span class="math inline">\(P(Y &gt; u) \ge P(X &gt; u)\)</span>.</p>
<p>Equivalently, <span class="math inline">\(P(Y \le u) \le P(X \le u)\)</span>, which is <span class="math inline">\(F_Y(u) \le F_X(u)\)</span>, same thing as <span class="math inline">\(F_Y &lt; F_X\)</span></p>
<p>If two distributions are identical, except that one is shifted relative to the other, then each of distribution can be indexed by a location parameter, say <span class="math inline">\(\theta_y\)</span> and <span class="math inline">\(\theta_x\)</span>. In this case, <span class="math inline">\(Y&gt;X\)</span> if <span class="math inline">\(\theta_y &gt; \theta_x\)</span></p>
<p>Consider the hypotheses,</p>
<p><span class="math display">\[
H_0: F_Y = F_X \\
H_a: F_Y &lt; F_X
\]</span>
where the alternative is an upper one-sided alternative.</p>
<ul>
<li>We can also consider the lower one-sided alternative</li>
</ul>
<p><span class="math display">\[
H_a: F_Y &gt; F_X \text{ or} \\
H_a: F_Y &lt; F_X \text{ or } F_Y &gt; F_X
\]</span></p>
<ul>
<li>In this case, we don’t use <span class="math inline">\(H_a: F_Y \neq F_X\)</span> as that allows arbitrary differences between the distributions, without requiring one be stochastically larger than the other.</li>
</ul>
<p>If the distributions only differ in terms of their location parameters, we can focus hypothesis tests on the parameters (e.g., <span class="math inline">\(H_0: \theta_y = \theta_x\)</span> vs. <span class="math inline">\(\theta_y &gt; \theta_x\)</span>)</p>
<p>We have 2 equivalent nonparametric tests that consider the hypothesis mentioned above</p>
<ol style="list-style-type: decimal">
<li><a href="two-sample-inference.html#wilcoxon-rank-test">Wilcoxon rank test</a><br />
</li>
<li><a href="two-sample-inference.html#mann-whitney-u-test">Mann-Whitney U test</a></li>
</ol>
<div id="wilcoxon-rank-test" class="section level4">
<h4><span class="header-section-number">4.2.6.1</span> Wilcoxon rank test</h4>
<ol style="list-style-type: decimal">
<li>Combine all <span class="math inline">\(n= n_y + n_x\)</span> observations and rank them in ascending order.<br />
</li>
<li>Sum the ranks of the y’s and x’s separately. Let <span class="math inline">\(w_y\)</span> and <span class="math inline">\(w_x\)</span> be these sums. (<span class="math inline">\(w_y + w_x = 1 + 2 + ... + n = n(n+1)/2\)</span>)<br />
</li>
<li>Reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(w_y\)</span> is large (equivalently, <span class="math inline">\(w_x\)</span> is small)</li>
</ol>
<p>Under <span class="math inline">\(H_0\)</span>, any arrangement of the y’s and x’s is equally likely to occur, and there are <span class="math inline">\((n_y + n_x)!/(n_y! n_x!)\)</span> possible arrangements.</p>
<ul>
<li>Technically, for each arrangement we can compute the values of <span class="math inline">\(w_y\)</span> and <span class="math inline">\(w_x\)</span>, and thus generate the distribution of the statistic under the null hypothesis.<br />
</li>
<li>This could lead to computationally intensive.</li>
</ul>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="two-sample-inference.html#cb128-1"></a><span class="kw">wilcox.test</span>(irisVe,irisVi,<span class="dt">alternative=</span><span class="st">&quot;two.sided&quot;</span>,<span class="dt">conf.level=</span><span class="fl">0.95</span>, <span class="dt">exact=</span>F,<span class="dt">correct=</span>T)</span></code></pre></div>
<pre><code>## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  irisVe and irisVi
## W = 49, p-value &lt; 2.2e-16
## alternative hypothesis: true location shift is not equal to 0</code></pre>
</div>
<div id="mann-whitney-u-test" class="section level4">
<h4><span class="header-section-number">4.2.6.2</span> Mann-Whitney U test</h4>
<p>The Mann-Whitney test is computed as follows:</p>
<ol style="list-style-type: decimal">
<li>Compare each <span class="math inline">\(y_i\)</span> wiht each <span class="math inline">\(x_i\)</span>.<br />
Let <span class="math inline">\(u_y\)</span> be the number of pairs in which <span class="math inline">\(y_i &gt; x_i\)</span>
Let <span class="math inline">\(u_x\)</span> be the number of pairs in which <span class="math inline">\(y_i &lt; x_i\)</span>. (assume there are no ties).
There are <span class="math inline">\(n_y n_x\)</span> such comparisons and <span class="math inline">\(u_y + u_x = n_y n_x\)</span>.<br />
</li>
<li>Reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(u_y\)</span> is large (or <span class="math inline">\(u_x\)</span> is small)</li>
</ol>
<p><a href="two-sample-inference.html#mann-whitney-u-test">Mann-Whitney U test</a> and <a href="two-sample-inference.html#wilcoxon-rank-test">Wilcoxon rank test</a> are related:<br />
<span class="math display">\[
u_y = w_y - n_y(n_y+1) /2 \\
u_x = w_x - n_x(n_x +1)/2
\]</span></p>
<p>An <span class="math inline">\(\alpha\)</span>-level test rejects <span class="math inline">\(H_0\)</span> if <span class="math inline">\(u_y \ge u_{n_y,n_x,\alpha}\)</span>, where <span class="math inline">\(u_{n_y,n_x,\alpha}\)</span> is the upper <span class="math inline">\(\alpha\)</span> critical point of the null distribution of the random variable, U.</p>
<p>The p-value is defined to be <span class="math inline">\(P(Y \ge u_y) = P(U \le u_x)\)</span>. One advantage of <a href="two-sample-inference.html#mann-whitney-u-test">Mann-Whitney U test</a> is that we can use either <span class="math inline">\(u_y\)</span> or <span class="math inline">\(u_x\)</span> to carry out the test.</p>
<p>For large <span class="math inline">\(n_y\)</span> and <span class="math inline">\(n_x\)</span>, the null distribution of U can be well approximated by a normal distribution with mean <span class="math inline">\(E(U) = n_y n_x /2\)</span> and variance <span class="math inline">\(var(U) = n_y n_x (n+1)/12\)</span>. A large sample z-test can be based on the statistic:</p>
<p><span class="math display">\[
z = \frac{u_y - n_y n_x /2 -1/2}{\sqrt{n_y n_x (n+1)/12}}
\]</span></p>
<p>The test rejects <span class="math inline">\(H_0\)</span> at level <span class="math inline">\(\alpha\)</span> if <span class="math inline">\(z \ge z_{\alpha}\)</span> or if <span class="math inline">\(u_y \ge u_{n_y,n_x,\alpha}\)</span> where</p>
<p><span class="math display">\[
u_{n_y, n_x, \alpha} \approx n_y n_x /2 + 1/2 + z_{\alpha}\sqrt{n_y n_x (n+1)/12}
\]</span></p>
<p>For the 2-sided test, we use the test statistic <span class="math inline">\(u_{max} = max(u_y,u_x)\)</span> and <span class="math inline">\(u_{min} = min(u_y, u_x)\)</span> and p-value is given by</p>
<p><span class="math display">\[
p-value = 2P(U \ge u_{max}) = 2P(U \le u_{min})
\]</span>
Since we assume there are no ties (when <span class="math inline">\(y_i = x_j\)</span>), we count 1/2 towards both <span class="math inline">\(u_y\)</span> and <span class="math inline">\(u_x\)</span>. Even though the sampling distribution is not the same, but large sample approximation is still reasonable,</p>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Satterthwaite_1946">
<p>Satterthwaite, F. E. 1946. “An Approximate Distribution of Estimates of Variance Components.” <em>Biometrics Bulletin</em> 2 (6): 110. <a href="https://doi.org/10.2307/3002019">https://doi.org/10.2307/3002019</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="one-sample-inference.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="categorical-data-analysis.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/mikenguyen13/data_analysis/edit/main/04-basic-inference.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Data Analysis.pdf", "Data Analysis.epub", "Data Analysis.mobi"],
"toc": {
"collapse": "subsection",
"scroll_highlight": true,
"sharing": {
"facebook": true,
"github": true,
"twitter": true,
"linkedin": true
},
"info": true,
"edit": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
