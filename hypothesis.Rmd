# Hypothesis Testing

 * Make **inferences** (an interpretation) about the true parameter value $\beta$ based on our estimator/estimate
 * Test whether our underlying assumptions (about the true population parameters, random variables, or model specification) hold true.


Testing does not  

 * Confirm with 100% a hypothesis is true
 * Confirm with 100% a hypothesis is false
 * Tell you how to interpret the estimate value (Economic vs. Practical vs. Statistical Significance)


Hypothesis: Translate an objective in better understanding the results in terms of specifying a value (or sets of values) in which our population parameters should/should not lie. 

 * **Null hypothesis** ($H_0$): A statement about the population parameter that we take to be true in which we would need the data to provide substantial evidence that against it. 
    + Can be either a single value (ex: $H_0: \beta=0$) or a set of values (ex: $H_0: \beta_1 \ge 0$)
    + Will generally be the value you would not like the population parameter to be (subjective)
        - $H_0: \beta_1=0$ means you would like to see a non-zero coefficient
        - $H_0: \beta_1 \ge 0$ means you would like to see a negative effect
    + "Test of Significance" refers to the two-sided test: $H_0: \beta_j=0$
 * **Alternative hypothesis** ($H_a$ or $H_1$) (Research Hypothesis): All other possible values that the population parameter may be if the null hypothesis does not hold. 


**Type I Error**  

Error made when $H_0$ is rejected when, in fact, $H_0$ is true.  
The probability of committing a Type I error is $\alpha$ (known as **level of significance** of the test)  

Type I error ($\alpha$): probability of rejecting $H_0$ when it is true.  

Legal analogy: In U.S. law, a defendant is presumed to be "innocent until proven guilty".  
If the null hypothesis is that a person is innocent, the Type I error is the probability that you conclude the person is guilty when he is innocent. 


<br>

**Type II Error**  

Type II error level ($\beta$): probability that you fail to reject the null hypothesis when it is false.  

In the legal analogy, this is the probability that you fail to find the person guilty when he or she is guilty. 

Error made when $H_0$ is not rejected when, in fact, $H_1$ is true  
The probability of committing a Type II error is $\beta$ (known as the **power** of the test) 

Formally, power (for the test of the mean) is given by:  

$$
\pi(\mu) = 1 - \beta = P(\text{test rejects } H_0|\mu)
$$
To evaluate the power, one needs to know the distribution of the test statistic if the null hypothesis is false.  

For 1-sided z-test where $H_0: \mu \le \mu_0 \\ H_A: \mu >0$  

The power is:  

$$
\begin{align}
\pi(\mu) &= P(\bar{y} > \mu_0 + z_{\alpha} \sigma/\sqrt{n}|\mu) \\
&= P(Z = \frac{\bar{y} - \mu}{\sigma / \sqrt{n}} > z_{\alpha} + \frac{\mu_0 - \mu}{\sigma/ \sqrt{n}}|\mu) \\
&= 1 - \Phi(z_{\alpha} + \frac{(\mu_0 - \mu)\sqrt{n}}{\sigma}) \\
&= \Phi(-z_{\alpha}+\frac{(\mu -\mu_0)\sqrt{n}}{\sigma})
\end{align}
$$

where $1-\Phi(x) = \Phi(-x)$ since the normal pdf is symmetric  

For 2-sided z-test is:  

$$
\pi(\mu) = \Phi(-z_{\alpha/2} + \frac{(\mu_0 - \mu)\sqrt{n}}{\sigma}) + \Phi(-z_{\alpha/2}+\frac{(\mu - \mu_0)\sqrt{n}}{\sigma})
$$



**Note** Always written in terms of the population parameter ($\beta$) not the estimator/estimate ($\hat{\beta}$)


 * Assuming the null hypothesis is true, what is the (asymptotic) distribution of the estimator
 * Two-sided

$$
H_0: \beta_j = 0 \\
H_1: \beta_j \neq 0 
$$

then under the null, the OLS estimator has the following distribution 

$$
A1-A3a, A5: \sqrt{n} \hat{\beta_j}  \sim  N(0,Avar(\sqrt{n}\hat{\beta}_j))
$$

 * For the one-sided test, the null is a set of values, so now you choose the worst case single value that is hardest to prove and derive the distribution under the null
 * One-sided

$$
H_0: \beta_j\ge 0 \\
H_1: \beta_j < 0 
$$

then the hardest null value to prove is $H_0: \beta_j=0$. Then under this specific null, the OLS estimator has the following asymptotic distribution


$$
A1-A3a, A5: \sqrt{n}\hat{\beta_j} \sim N(0,Avar(\sqrt{n}\hat{\beta}_j))
$$


## Confidence Intervals & Hypothesis Testing
### For the Mean ($\mu$)

| | Confidence Interval $100(1-\alpha)%$ | Sample Sizes <br> Confidence $\alpha$, Error d | Hypothesis Testing <br> Test Statistic |
|---|---|---|---|
When $\sigma^2$ is known, X is normal (or $n \ge 25$) | $\bar{X} \pm z_{\alpha/2}\frac{\sigma}{\sqrt{n}}$ | $n \approx \frac{z_{\alpha/2}^2 \sigma^2}{d^2}$| $z = \frac{\bar{X}-\mu_0}{\sigma/\sqrt{n}}$ |
When $\sigma^2$ is unknown, X is normal (or $n \ge 25$) | $\bar{X} \pm t_{\alpha/2}\frac{s}{\sqrt{n}}$ | $n \approx \frac{z_{\alpha/2}^2 s^2}{d^2}$| $t = \frac{\bar{X}-\mu_0}{s/\sqrt{n}}$ |

### For Single Proportions (p)

| Confidence Interval $100(1-\alpha)%$ | Sample Sizes <br> Confidence $\alpha$, Error d (prior estimate for $\hat{p}$) | (No prior estimate for $\hat{p}$)|Hypothesis Testing <br> Test Statistic |
|---|---|---|---|
|$\hat{p} \pm z_{\alpha/2}\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}$ | $n \approx \frac{z_{\alpha/2}^2 \hat{p}(1-\hat{p})}{d^2}$| $n \approx \frac{z_{\alpha/2}^2}{4d^2}$ |$z = \frac{\hat{p}-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}$ |

### For Difference of Two Proportions ($p_1 - p_2$)

**Mean** 

$$
\hat{p_1}-\hat{p_2}
$$

**Variance**
$$
\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}
$$

**$100(1-\alpha)%$ Confidence Interval**  

$$
\hat{p_1}-\hat{p_2} + z_{\alpha/2}\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}
$$

**Sample Sizes, Confidence $\alpha$, Error d**  
(Prior Estimate fo $\hat{p_1},\hat{p_2}$)

$$
n \approx \frac{z_{\alpha/2}^2[p_1(1-p_1)+p_2(1-p_2)]}{d^2}
$$

(No Prior Estimates for $\hat{p}$)

$$
n \approx \frac{z_{\alpha/2}^2}{2d^2}
$$

**Hypothesis Testing - Test Statistics**  

Null Value $(p_1 - p_2) \neq 0$

$$
z = \frac{(\hat{p_1} - \hat{p_2})-(p_1 - p_2)_0}{\sqrt{\frac{p_1(1-p_1)}{n_1} + \frac{p_2(1-p_2)}{n_2}}}
$$


Null Value $(p_1 - p_2)_0 = 0$

$$
z = \frac{\hat{p_1} - \hat{p_2}}{\sqrt{\hat{p}(1-\hat{p})(\frac{1}{n_1}+\frac{1}{n_2})}}
$$

where   

$$
\hat{p}= \frac{x_1 + x_2}{n_1 + n_2} = \frac{n_1 \hat{p_1} + n_2 \hat{p_2}}{n_1 + n_2}
$$


### For a signle variance ($\sigma^2$)
**$100(1-\alpha)%$ Confidence Interval**  

$$
L_1 = \frac{(n-1)s^2}{\chi^2_{\alpha/2}} \\
L_1 = \frac{(n-1)s^2}{\chi^2_{1-\alpha/2}}
$$
**Hypothesis Testing Test Statistic**

$$
\chi^2 = \frac{(n-1)s^2}{\sigma^2_0}
$$

### For Two Variances ($\sigma^2_1,\sigma^2_2$)

$$
F_{ndf,ddf}= \frac{s^2_1}{s^2_2}
$$
where $s^2_1>s^2_2, ndf = n_1-1,ddf = n_2-1$


### For Difference of Means ($\mu_1-\mu_2$), Independent Samples

| | $100(1-\alpha)%$ Confidence Interval | Hypothesis Testing <br> Test Statistic | |
|---|---|---|---|
|When $\sigma^2$ is known | $\bar{X}_1 - \bar{X}_2 \pm z_{\alpha/2}\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}$ | $z= \frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)_0}{\sqrt{\frac{\sigma^2_1}{n_1}+\frac{\sigma^2_2}{n_2}}}$| |
|When $\sigma^2$ is unknown, Variances Assumed EQUAL |  $\bar{X}_1 - \bar{X}_2 \pm t_{\alpha/2}\sqrt{s^2_p(\frac{1}{n_1}+\frac{1}{n_2})}$ | $t = \frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)_0}{\sqrt{s^2_p(\frac{1}{n_1}+\frac{1}{n_2})}}$| Pooled Variance: $s_p^2 = \frac{(n_1 -1)s^2_1 - (n_2-1)s^2_2}{n_1 + n_2 -2}$ <br> Degrees of Freedom: $\gamma = n_1 + n_2 -2$|
|When $\sigma^2$ is unknown, Variances Assumed UNEQUAL |  $\bar{X}_1 - \bar{X}_2 \pm t_{\alpha/2}\sqrt{(\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2})}$ | $t = \frac{(\bar{X}_1-\bar{X}_2)-(\mu_1-\mu_2)_0}{\sqrt{(\frac{s^2_1}{n_1}+\frac{s^2_2}{n_2})}}$| Degrees of Freedom: $\gamma = \frac{(\frac{s_1^2}{n_1}+\frac{s^2_2}{n_2})^2}{\frac{(\frac{s_1^2}{n_1})^2}{n_1-1}+\frac{(\frac{s_2^2}{n_2})^2}{n_2-1}}$|


### For Difference of Means ($\mu_1 - \mu_2$), Paired Samples (D = X-Y)  

**$100(1-\alpha)%$ Confidence Interval**  
$$
\bar{D} \pm t_{\alpha/2}\frac{s_d}{\sqrt{n}}
$$

**Hypothesis Testing Test Statistic**  

$$
t = \frac{\bar{D}-D_0}{s_d / \sqrt{n}}
$$






## Wald Test
For a null value, what is the probability you would obtained a realization "more extreme" or "worse" than the estimate you actually obtained.

Significance Level ($\alpha$) and Confidence Level ($1-\alpha$)  
 * The significance level is the benchmark in which the probability is so low that we would have to reject the null
 * The confidence level is the probability that sets the bounds on how far away the realization of the estimator would have to be to reject the null. 

**Test Statistics**

 * Standardized (transform) the estimator and null value to a test statistic that always has the same distribution
 * Test Statistic for the OLS estimator for a single hypothesis

$$
T = \frac{\sqrt{n}(\hat{\beta}_j-\beta_{j0})}{\sqrt{n}SE(\hat{\beta_j})} \sim^a N(0,1)
$$

Equivalently,

$$
T = \frac{(\hat{\beta}_j-\beta_{j0})}{SE(\hat{\beta_j})} \sim^a N(0,1)
$$
the test statistic is another random variable that is a function of the data and null hypothesis.  

 * T denotes the random variable test statistic
 * t denotes the single realization of the test statistic

Evaluating Test Statistic: determine whether or not we reject or fail to reject the null hypothesis at a given significance / confidence level  

Three equivalent ways  

 1. Critical Value  
 2. P-value  
 3. Confidence Interval  


 1. Critical Value

For a given significance level, will determine the critical value (c)  
 * One-sided: $H_0: \beta_j \ge \beta_{j0}$

$$
P(T<c|H_0)=\alpha
$$
Reject the null if $t<c$

 * One-sided: $H_0: \beta_j \le \beta_{j0}$

$$
P(T>c|H_0)=\alpha
$$

Reject the null if $t>c$

 * TWo-sided: $H_0: \beta_j \neq \beta_{j0}$

$$
P(|T|>c|H_0)=\alpha
$$

Reject the null if $|t|>c$

 2. p-value  

Calculate the probability that the test statistic was worse than the realization you have  

 * One-sided: $H_0: \beta_j \ge \beta_{j0}$

$$
\text{p-value} = P(T<t|H_0)
$$

 * One-sided: $H_0: \beta_j \le \beta_{j0}$

$$
\text{p-value} = P(T>t|H_0)
$$

 * Two-sided: $H_0: \beta_j \neq \beta_{j0}$

$$
\text{p-value} = P(|T|<t|H_0)
$$

reject the null if p-value $< \alpha$

 3. Confidence Interval

Using the critical value associated with a null hypothesis and significance level, create an interval

$$
CI(\hat{\beta}_j)_{\alpha} = [\hat{\beta}_j-(c \times SE(\hat{\beta}_j)),\hat{\beta}_j+(c \times SE(\hat{\beta}_j))]
$$

If the null set lies outside the interval then we reject the null.  

 * We are not testing whether the true population value is close to the estimate, we are testing that given a field true population value of the parameter, how like it is that we observed this estimate. 
 * Can be interpreted as we believe with $(1-\alpha)\times 100 \%$ probability that the confidence interval captures the true parameter value.

With stronger assumption (A1-A6), we could consider [Finite Sample Properties]  

$$
T = \frac{\hat{\beta}_j-\beta_{j0}}{SE(\hat{\beta}_j)} \sim T(n-k)
$$

 * This above distributional derivation is strongly dependent on [A4][A4 Homoskedasticity] and [A5][A5 Data Generation (random Sampling)]
 * T has a student t-distribution because the numerator is normal and the denominator is $\chi^2$.
 * Critical value and p-values will be calculated from the student t-distribution rather than the standard normal distribution. 
 * $n \to \infty$, $T(n-k)$ is asymptotically standard normal.

**Rule of thumb**

 * if $n-k>120$: the critical values and p-values from the t-distribution are (almost) the same as the critical values and p-values from the standard normal distribution.
 * if $n-k<120$ 
    + if (A1-A6) hold then the t-test is an exact finite distribution test
    + if (A1-A3a, A5) hold, because the t-distribution is asymptotically normal, computing the critical values from a t-distribution is still a valid asymptotic test (i.e., not quite the right critical values and p0values, the difference goes away as $n \to \infty$)


### Multiple Hypothesis

 * test multiple parameters as the same time  
    * $H_0: \beta_1 = 0\ \& \ \beta_2 = 0$
    * $H_0: \beta_1 = 1\ \& \ \beta_2 = 0$
 * perform a series of simply hypothesis does not answer the question (joint distribution vs. two marginal distributions). 
 * The test statistic is based on a restriction written in matrix form. 

$$
y=\beta_0+x_1\beta_1 + x_2\beta_2 + x_3\beta_3 + \epsilon
$$

Null hypothesis is $H_0: \beta_1 = 0 \text{ & }  \beta_2=0$ can be rewritten as $H_0: \mathbf{R}\beta -\mathbf{q}=0$ where  

 * $\mathbf{R}$ is a m x k matrix where m is the number of restrictions and k is the number of parameters. $\mathbf{q}$ is a k x 1 vector
 * $\mathbf{R}$ "picks up" the relevant parameters while $\mathbf{q}$ is a the null value of the parameter

$$
\mathbf{R}= 
\left(
\begin{array}{c}
0 & 1 & 0 & 0 \\
0 & 0 & 1 & 0 \\
\end{array}
\right),
\mathbf{q} = 
\left(
\begin{array}{c}
0 \\
0 \\
\end{array}
\right)
$$

Test Statistic for OLS estimator for a multiple hypothesis 

$$
F = \frac{(\mathbf{R\hat{\beta}-q})\hat{\Sigma}^{-1}(\mathbf{R\hat{\beta}-q})}{m} \sim^a F(m,n-k)
$$

 * $\hat{\Sigma}^{-1}$ is the estimator for the asymptotic variance-covariance matrix
    + if [A4][A4 Homoskedasticity] holds, both the homoskedastic and heteroskedastic versions produce valid estimator 
    + If [A4][A4 Homoskedasticity] does not hold, only the heteroskedastic version produces valid estimators. 
 * When m = 1, there is only a single restriction, then the F-statistic is the t-statistic squared. 
 * F distribution is strictly positive, check [F-Distribution] for more details.


### Linear Combination 

Testing multiple parameters as the same time 

$$
H_0: \beta_1 -\beta_2 = 0 \\
H_0: \beta_1 - \beta_2 > 0 \\
H_0: \beta_1 - 2*\beta_2 =0
$$

Each is a single restriction on a function of the parameters. 

Null hypothesis: 
$$
H_0: \beta_1 -\beta_2 = 0
$$ 
can be rewritten as 

$$
H_0: \mathbf{R}\beta -\mathbf{q}=0
$$ 
where $\mathbf{R}$=(0 1 -1 0 0) and $\mathbf{q}=0$


## Application
```{r}
library("car")

# Multiple hypothesis
mod.davis <- lm(weight ~ repwt, data=Davis)
linearHypothesis(mod.davis, c("(Intercept) = 0", "repwt = 1"),white.adjust = TRUE)

# Linear Combination
mod.duncan <- lm(prestige ~ income + education, data=Duncan)
linearHypothesis(mod.duncan, "1*income - 1*education = 0")

```





